> List("Paris", "London").map(_.length) res0: List[Int] List(5, 6)
def map[B, That](f: A => B)(implicit bf: CanBuildFrom[Repr, B, That]): That
scala> import collection.immutable.BitSet import collection.immutable.BitSet scala> val bits = BitSet(1, 2, 3) bits: scala.collection.immutable.BitSet = BitSet(1, 2, 3) scala> val shifted = bits map { _ + 1 } shifted: scala.collection.immutable.BitSet = BitSet(2, 3, 4) scala> val displayed = bits map { _.toString + "!" } displayed: scala.collection.immutable.Set[java.lang.String] = Set(1!, 2!, 3!)
map(f: Int => Int): BitSet (click here for more general type)
map :: (IterableLike i, IterableLike j) ⇒ (a → b) → i → j
map :: IterableLike i ⇒ (a → b) → i → ([b] → c) → c
def map[B, That](f: A ⇒ B)(implicit bf: CanBuildFrom[Repr, B, That]): That
template <template <class, class> class C, class T, class A, class T_return, class T_arg > C<T_return, typename A::rebind<T_return>::other> map(C<T, A> &c,T_return(*func)(T_arg) ) { C<T_return, typename A::rebind<T_return>::other> res; for ( C<T,A>::iterator it=c.begin() ; it != c.end(); it++ ){ res.push_back(func(*it)); } return res; }
Map(1 -> "a", 2 -> "b").map((t) => (t._2) -> (t._1)) Map(1 -> "a", 2 -> "b").map((t) => t._2)
traverse :: (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
def traverse[A, B](f: A => F[B], a: T[A])(implicit t: Traversable[T], ap: Applicative[F]): F[T[B]
def map[B, That](f: A => B)(implicit bf: CanBuildFrom[Repr, B, That]): That
def orElse[A1 <: A, B1 >: B](that: PartialFunction[A1, B1]): PartialFunction[A1, B1]
def orElse(that: PartialFunction[A1, B1]): PartialFunction[A1, B1]
class A() { def twice(i: Int): Int = 2 * i } val a = new A() a.twice(2)
class X { def m(x: Int) = X.f(x) import X._ def n(x: Int) = f(x) private def o = 2 } object X { private def f(x: Int) = x * x def g(x: X) = { import x._ x.o * o } }
object Hello { def main(args: Array[String]) { println("Hello, World!") } }
object Singleton{ def main(args:Array[String]){ SingletonObject.hello() } } object SingletonObject{ def hello(){ println("Hello, This is Singleton Object") } }
class ComapanionClass{ def hello(){ println("Hello, this is Companion Class.") } } object CompanoinObject{ def main(args:Array[String]){ new ComapanionClass().hello() println("And this is Companion Object.") } }
Hello, this is Companion Class. And this is Companion Object.
class Student{ var id:Int = 0; var name:String = null; } object MainObject{ def main(args:Array[String]){ var s = new Student() println(s.id+" "+s.name); } }
C(1, 2, 3) match { case C(vs @ _*) => vs.foreach(f(_)) }
def toFunction(callByName: => Int): () => Int = callByName _
trait PlaceholderExample { def process[A](f: A => Unit) val set: Set[_ => Unit] set.foreach(process _) set.foreach(process(_)) }
import scala._ import scala.{ Predef => _, _ } def f[M[_]] def f(m: M[_]) _ + _ m _ m(_) _ => 5 case _ => val (a, _) = (1, 2) for (_ <- 1 to 10) f(xs: _*) case Seq(xs @ _*) var i: Int = _ def abc_<>! t._2
def matchTest(x: Int): String = x match { case 1 => "one" case 2 => "two" case _ => "anything other than one and two" } expr match { case List(1,_,_) => " a list with three element and the first element is 1" case List(_*) => " a list with zero or more elements " case Map[_,_] => " matches a map with any key type and any value type " case _ => } List(1,2,3,4,5).foreach(print(_)) List(1,2,3,4,5).foreach( a => print(a))
import scala.util.matching._ import com.test.Fun._ import com.test.Fun.{ Foo => Bar , _ } import com.test.Fun.{ Foo => _ , _ }
class Test { private var a = 0 def age = a def age_=(n:Int) = { require(n>0) a = n } }
List("foo", "bar", "baz").map(n => n.toUpperCase())
def getConnectionProps = { ( Config.getHost, Config.getPort, Config.getSommElse, Config.getSommElsePartTwo ) }
val ( host, port, sommEsle, someElsePartTwo ) = getConnectionProps
val nums = List(1,2,3,4,5,6,7,8,9,10) nums filter (_ % 2 == 0) nums reduce (_ + _) nums.exists(_ > 5) nums.takeWhile(_ < 8)
import scala._ import scala.{ Predef => _, _ } def f[M[_]] def f(m: M[_]) _ + _ m _ m(_) _ => 5 case _ => f(xs: _*) case Seq(xs @ _*) Please check the below link for more details [https:
type StringMatcher = String => (String => Boolean) def starts: StringMatcher = (prefix:String) => _ startsWith prefix
def starts: StringMatcher = (prefix:String) => (s)=>s startsWith prefix
sealed abstract class Tree case class Node(left: Tree, right: Tree) extends Tree case class Leaf[A](value: A) extends Tree case object EmptyLeaf extends Tree
val treeA = Node(EmptyLeaf, Leaf(5)) val treeB = Node(Node(Leaf(2), Leaf(3)), Leaf(5)) val treeC = treeA.copy(left = treeB.left) println("Tree A: "+treeA) println("Tree B: "+treeB) println("Tree C: "+treeC) println("Tree A == Tree B: %s" format (treeA == treeB).toString) println("Tree B == Tree C: %s" format (treeB == treeC).toString) treeA match { case Node(EmptyLeaf, right) => println("Can be reduced to "+right) case Node(left, EmptyLeaf) => println("Can be reduced to "+left) case _ => println(treeA+" cannot be reduced") } def checkTree(t: Tree) = t match { case Node(EmptyLeaf, Node(left, right)) => case Node(Node(left, right), EmptyLeaf) => case Node(Leaf(el), EmptyLeaf) => case Node(Node(l1, r1), Node(l2, r2)) => case Node(Leaf(e1), Leaf(e2)) => case Node(Node(left, right), Leaf(el)) => case Node(Leaf(el), Node(left, right)) => case Leaf(el) => case EmptyLeaf => }
def productElement(n: Int): Any def productArity: Int def productIterator: Iterator[Any]
scala> class Animal(name:String) defined class Animal scala> val an1 = new Animal("Padddington") an1: Animal = Animal@748860cc scala> an1.name <console>:14: error: value name is not a member of Animal an1.name ^
scala> case class Animal(name:String) defined class Animal scala> val an2 = new Animal("Paddington") an2: Animal = Animal(Paddington) scala> an2.name res12: String = Paddington scala> an2 == Animal("fred") res14: Boolean = false scala> an2 == Animal("Paddington") res15: Boolean = true
scala> case class Person(first:String,last:String,age:Int) defined class Person scala> val harry = new Person("Harry","Potter",30) harry: Person = Person(Harry,Potter,30) scala> harry res16: Person = Person(Harry,Potter,30) scala> harry.first = "Saily" <console>:14: error: reassignment to val harry.first = "Saily" ^ scala>val saily = harry.copy(first="Saily") res17: Person = Person(Saily,Potter,30) scala> harry.copy(age = harry.age+1) res18: Person = Person(Harry,Potter,31)
scala> harry match { | case Person("Harry",_,age) => println(age) | case _ => println("no match") | } 30 scala> res17 match { | case Person("Harry",_,age) => println(age) | case _ => println("no match") | } no match
scala> case class Person(first :String,last:String,age:Int) defined class Person scala> object Fred extends Person("Fred","Jones",22) defined object Fred
val classInst = new MyClass(...) val classInst = MyClass(..)
class MyClass(x:Int) { } val classInst = new MyClass(10) classInst.x case class MyClass(x:Int) { } val classInst = MyClass(10) classInst.x
class MyClass(x:Int) { } val classInst = new MyClass(10) val classInst2 = new MyClass(10) classInst == classInst2 case class MyClass(x:Int) { } val classInst = MyClass(10) val classInst2 = MyClass(10) classInst == classInst2
val bobAsTuple = ("bob", 14) val bob = (Person.apply _).tupled(bobAsTuple)
def isIdentityFun(term: Term): Boolean = term match { case Fun(x, Var(y)) if x == y => true case _ => false }
scala> import scala.math._ import scala.math._ scala> def foo[T](t: T)(implicit integral: Integral[T]) {println(integral)} foo: [T](t: T)(implicit integral: scala.math.Integral[T])Unit scala> foo(0) scala.math.Numeric$IntIsIntegral$@3dbea611 scala> foo(0L) scala.math.Numeric$LongIsIntegral$@48c610af
def foo[T](t: T)(implicit integral: Integral[T]) {println(integral)}
def getIndex[T, CC](seq: CC, value: T)(implicit conv: CC => Seq[T]) = seq.indexOf(value) getIndex("abc",
def getIndex[T, CC <% Seq[T]](seq: CC, value: T) = seq.indexOf(value)
def sum[T](list: List[T])(implicit integral: Integral[T]): T = { import integral._ list.foldLeft(integral.zero)(_ + _) }
def sum[T : Integral](list: List[T]): T = { val integral = implicitly[Integral[T]] import integral._ list.foldLeft(integral.zero)(_ + _) }
def reverseSort[T : Ordering](seq: Seq[T]) = seq.sorted.reverse
implicit val n: Int = 5 def add(x: Int)(implicit y: Int) = x + y add(5)
import scala.collection.JavaConversions.mapAsScalaMap def env = System.getenv() val term = env("TERM")
def sum[T : Integral](list: List[T]): T = { val integral = implicitly[Integral[T]] import integral._ list.foldLeft(integral.zero)(_ + _) }
class A(val n: Int) object A { implicit def str(a: A) = "A: %d" format a.n } class B(val x: Int, y: Int) extends A(y) val b = new B(5, 2) val s: String = b
class A(val n: Int) { def +(other: A) = new A(n + other.n) } object A { implicit def fromInt(n: Int) = new A(n) } 1 + new A(1) A.fromInt(1) + new A(1)
class A(val n: Int) object A { implicit val ord = new Ordering[A] { def compare(x: A, y: A) = implicitly[Ordering[Int]].compare(x.n, y.n) } }
class A(val n: Int) { class B(val m: Int) { require(m < n) } } object A { implicit def bToString(b: A } val a = new A(5) val b = new a.B(3) val s: String = b
<- => ( ) [ ] { } . : <: >: <% <? <! " """ @ ` , ; _* _
import scala._ import scala.{ Predef => _, _ } def f[M[_]] def f(m: M[_]) _ + _ m _ m(_) _ => 5 case _ => f(xs: _*) case Seq(xs @ _*)
import _root_.java.lang._ import _root_.scala._ import _root_.scala.Predef._
class Example(arr: Array[Int] = Array.fill(5)(0)) { def apply(n: Int) = arr(n) def update(n: Int, v: Int) = arr(n) = v def a = arr(0); def a_=(v: Int) = arr(0) = v def b = arr(1); def b_=(v: Int) = arr(1) = v def c = arr(2); def c_=(v: Int) = arr(2) = v def d = arr(3); def d_=(v: Int) = arr(3) = v def e = arr(4); def e_=(v: Int) = arr(4) = v def +(v: Int) = new Example(arr map (_ + v)) def unapply(n: Int) = if (arr.indices contains n) Some(arr(n)) else None } val Ex = new Example println(Ex(0)) Ex(0) = 2 Ex.b = 3 val Ex(c) = 2 Ex += 1
val coll = Map(1 -> "Eins", 2 -> "Zwei", 3 -> "Drei")
implicit def any2ArrowAssoc [A] (x: A): ArrowAssoc[A]
for (n <- 1 to 10) n % 2 match { case 0 => println("even") case 1 => println("odd") }
for (n ← 1 to 10) n % 2 match { case 0 ⇒ println("even") case 1 ⇒ println("odd") }
def extract2(l: List[Int]) = l match { case Nil => "empty" case ::(head, Nil) => "exactly one element (" + head + ")" case ::(head, tail) => "more than one element" }
def extract(l: List[Int]) = l match { case Nil => "empty" case head :: Nil => "exactly one element (" + head + ")" case head :: tail => "more than one element" } extract(Nil) extract(List(1)) extract(List(2, 3))
def extract2(l: List[Int]) = l match { case Nil => "empty" case ::(head, Nil) => "exactly one element (" + head + ")" case ::(head, tail) => "more than one element" }
( 1 to 100 ).foldLeft( 0, _+_ ) ( 1 to 100 )./:( 0 )( _+_ ) ( 0 /: ( 1 to 100 ) )( _+_ )
( 1 to 100 ).foldRight( 0, _+_ ) ( 1 to 100 ).:\( 0 )( _+_ ) ( ( 1 to 100 ) :\ 0 )( _+_ )
val m = collection.mutable.Set("Hallo") var i = collection.immutable.Set("Hallo") m += "Welt" i += "Welt"
scala> trait User { def name: String } defined trait User scala> trait Tweeter { | user: User => | def tweet(msg: String) = println(s"$name: $msg") | } defined trait Tweeter scala> trait Wrong extends Tweeter { | def noCanDo = name | } <console>:9: error: illegal inheritance; self-type Wrong does not conform to Tweeter trait Wrong extends Tweeter { ^ <console>:10: error: not found: value name def noCanDo = name ^
scala> trait DummyUser extends User { | override def name: String = "foo" | } defined trait DummyUser scala> trait Right extends Tweeter with User { | val canDo = name | } defined trait Right scala> trait RightAgain extends Tweeter with DummyUser { | val canDo = name | } defined trait RightAgain
trait A extends B trait B extends A error: illegal cyclic reference involving trait A
package org.stairwaybook.scells trait Evaluator { this: Model => ...
sealed trait Person trait Student extends Person trait Teacher extends Person trait Adult { this : Person => } val p : Person = new Student {} p match { case s : Student => println("a student") case t : Teacher => println("a teacher") }
abstract class Graph { type Node <: BaseNode; class BaseNode { self: Node => def connectWith(n: Node): Edge = new Edge(self, n); } class Edge(from: Node, to: Node) { def source() = from; def target() = to; } } class LabeledGraph extends Graph { class Node(label: String) extends BaseNode { def getLabel: String = label; def self: Node = this; } }
trait A { selfA: B => def fa: Int } trait B { selfB: A => def fb: String }
trait A1 extends A { selfA1: B => override def fb = "B trait B1 extends B { selfB1: A => override def fa = "A val myObj = new A1 with B1
trait AB { def fa: String def fb: String } trait A1 extends AB { override def fa = "A trait B1 extends AB { override def fb = "B val myObj = new A1 with B1
trait Outer { trait Inner } trait OuterA extends Outer { trait InnerA extends Inner } trait OuterB extends Outer { trait InnerB extends Inner } trait OuterFinal extends OuterA with OuterB { val myV = new InnerA with InnerB }
trait Outer { trait Inner } trait InnerA {this: Outer trait InnerB {this: Outer trait OuterFinal extends Outer { val myVal = new InnerA with InnerB with Inner }
class ScnBase extends Frame abstract class ScnVista[GT <: GeomBase[_ <: TypesD]](geomRI: GT) extends ScnBase with DescripHolder[GT] ) { val geomR = geomRI } trait EditScn[GT <: GeomBase[_ <: ScenTypes]] extends ScnVista[GT] trait ScnVistaCyl[GT <: GeomBase[_ <: ScenTypes]] extends ScnVista[GT]
trait A { def x = 1 } trait B extends A { override def x = super.x * 5 } trait C1 extends B { override def x = 2 } trait C2 extends A { this: B => override def x = 2} println((new C1 with B).x) println((new C2 with B).x) trait X { type SomeA <: A trait Inner1 { this: SomeA => } trait Inner2 extends SomeA {} }
class Person { def name: String = "..."; } class Expense { def cost: Int = 123; } trait Employee { this: Person with Expense => def roomNo: Int; def officeLabel: String = name + "/" + roomNo; }
scala> List(1,2,3) match { | case l : List[String] => println("A list of strings?!") | case _ => println("Ok") | } warning: there were unchecked warnings; re-run with -unchecked for details A list of strings?!
scala> List(1,2,3) match { | case l : List[String] => println("A list of strings?!") | case _ => println("Ok") | } <console>:6: warning: non variable type-argument String in type pattern is unchecked since it is eliminated by erasure case l : List[String] => println("A list of strings?!") ^ A list of strings?!
object Registry { import scala.reflect.Manifest private var map= Map.empty[Any,(Manifest[_], Any)] def register[T](name: Any, item: T)(implicit m: Manifest[T]) { map = map.updated(name, m -> item) } def get[T](key:Any)(implicit m : Manifest[T]): Option[T] = { map get key flatMap { case (om, s) => if (om <:< m) Some(s.asInstanceOf[T]) else None } } } scala> Registry.register("a", List(1,2,3)) scala> Registry.get[List[Int]]("a") res6: Option[List[Int]] = Some(List(1, 2, 3)) scala> Registry.get[List[String]]("a") res7: Option[List[String]] = None
import scala.reflect.runtime.universe._ def matchList[A: TypeTag](list: List[A]) = list match { case strlist: List[String @unchecked] if typeOf[A] =:= typeOf[String] => println("A list of strings!") case intlist: List[Int @unchecked] if typeOf[A] =:= typeOf[Int] => println("A list of ints!") }
import scala.reflect.{ClassTag, classTag} def matchList2[A : ClassTag](list: List[A]) = list match { case strlist: List[String @unchecked] if classTag[A] == classTag[String] => println("A List of strings!") case intlist: List[Int @unchecked] if classTag[A] == classTag[Int] => println("A list of ints!") }
scala> import shapeless.syntax.typeable._ import shapeless.syntax.typeable._ scala> val l1 : Any = List(1,2,3) l1: Any = List(1, 2, 3) scala> l1.cast[List[String]] res0: Option[List[String]] = None scala> l1.cast[List[Int]] res1: Option[List[Int]] = Some(List(1, 2, 3))
case class StringListHolder(list:List[String]) StringListHolder(List("str1","str2")) match { case holder: StringListHolder => holder.list foreach println }
scala> List(1,2,3) match { | case List(_: String, _*) => println("A list of strings?!") | case _ => println("Ok") | }
scala> List(1,2,3) match { | case List(_: Int, _*) => println("A list of ints") | case _ => println("Ok") | }
import scala.reflect.runtime.universe._ def whatListAmI[A : TypeTag](list : List[A]) = { if (typeTag[A] == typeTag[java.lang.String]) println("its a String") else if (typeTag[A] == typeTag[Int]) println("its a Int") s"A List of ${typeTag[A].tpe.toString}" } val listInt = List(1,2,3) val listString = List("a", "b", "c") println(whatListAmI(listInt)) println(whatListAmI(listString))
list match { case x:List if x.isInstanceOf(List[String]) => do sth case x:List if x.isInstanceOf(List[Int]) => do sth else }
trait A{ def a = 1 } trait X extends A{ override def a = { println("X") super.a } } trait Y extends A{ override def a = { println("Y") super.a } } scala> val xy = new AnyRef with X with Y xy: java.lang.Object with X with Y = $anon$1@6e9b6a scala> xy.a Y X res0: Int = 1 scala> val yx = new AnyRef with Y with X yx: java.lang.Object with Y with X = $anon$1@188c838 scala> yx.a X Y res1: Int = 1
class Foo class Bar extends Foo def meth[A](xs: List[A]) = xs match { case _: List[String] => "list of strings" case _: List[Foo] => "list of foos" }
<console>:23: warning: non-variable type argument String in type pattern List[String]↩ is unchecked since it is eliminated by erasure case _: List[String] => "list of strings" ^ <console>:24: warning: non-variable type argument Foo in type pattern List[Foo]↩ is unchecked since it is eliminated by erasure case _: List[Foo] => "list of foos" ^
scala> class Foo{class Bar} defined class Foo scala> def m(f: Foo)(b: f.Bar)(implicit ev: Manifest[f.Bar]) = ev warning: there were 2 deprecation warnings; re-run with -deprecation for details m: (f: Foo)(b: f.Bar)(implicit ev: Manifest[f.Bar])Manifest[f.Bar] scala> val f1 = new Foo;val b1 = new f1.Bar f1: Foo = Foo@681e731c b1: f1.Bar = Foo$Bar@271768ab scala> val f2 = new Foo;val b2 = new f2.Bar f2: Foo = Foo@3e50039c b2: f2.Bar = Foo$Bar@771d16b9 scala> val ev1 = m(f1)(b1) warning: there were 2 deprecation warnings; re-run with -deprecation for details ev1: Manifest[f1.Bar] = Foo@681e731c.type scala> val ev2 = m(f2)(b2) warning: there were 2 deprecation warnings; re-run with -deprecation for details ev2: Manifest[f2.Bar] = Foo@3e50039c.type scala> ev1 == ev2 res28: Boolean = true
scala> def m(f: Foo)(b: f.Bar)(implicit ev: TypeTag[f.Bar]) = ev m: (f: Foo)(b: f.Bar)(implicit ev: reflect.runtime.universe.TypeTag[f.Bar])↩ reflect.runtime.universe.TypeTag[f.Bar] scala> val ev1 = m(f1)(b1) ev1: reflect.runtime.universe.TypeTag[f1.Bar] = TypeTag[f1.Bar] scala> val ev2 = m(f2)(b2) ev2: reflect.runtime.universe.TypeTag[f2.Bar] = TypeTag[f2.Bar] scala> ev1 == ev2 res30: Boolean = false scala> ev1.tpe =:= ev2.tpe res31: Boolean = false
import scala.reflect.runtime.universe._ def meth[A : TypeTag](xs: List[A]) = typeOf[A] match { case t if t =:= typeOf[String] => "list of strings" case t if t <:< typeOf[Foo] => "list of foos" } scala> meth(List("string")) res67: String = list of strings scala> meth(List(new Bar)) res68: String = list of foos
scala> typeOf[List[java.lang.String]] =:= typeOf[List[Predef.String]] res71: Boolean = true scala> typeOf[List[java.lang.String]] == typeOf[List[Predef.String]] res72: Boolean = false
scala> import scala.reflect._ import scala.reflect._ scala> def createArr[A](seq: A*) = Array[A](seq: _*) <console>:22: error: No ClassTag available for A def createArr[A](seq: A*) = Array[A](seq: _*) ^ scala> def createArr[A : ClassTag](seq: A*) = Array[A](seq: _*) createArr: [A](seq: A*)(implicit evidence$1: scala.reflect.ClassTag[A])Array[A] scala> createArr(1,2,3) res78: Array[Int] = Array(1, 2, 3) scala> createArr("a","b","c") res79: Array[String] = Array(a, b, c)
scala> classTag[Int] res99: scala.reflect.ClassTag[Int] = ClassTag[int] scala> classTag[Int].runtimeClass res100: Class[_] = int scala> classTag[Int].newArray(3) res101: Array[Int] = Array(0, 0, 0) scala> classTag[List[Int]] res104: scala.reflect.ClassTag[List[Int]] =↩ ClassTag[class scala.collection.immutable.List]
scala> typeTag[List[Int]] res105: reflect.runtime.universe.TypeTag[List[Int]] = TypeTag[scala.List[Int]] scala> typeTag[List[Int]].tpe res107: reflect.runtime.universe.Type = scala.List[Int] scala> typeOf[List[Int]] res108: reflect.runtime.universe.Type = scala.List[Int] scala> res107 =:= res108 res109: Boolean = true
scala> def m[A : ClassTag : TypeTag] = (classTag[A], typeTag[A]) m: [A](implicit evidence$1: scala.reflect.ClassTag[A],↩ implicit evidence$2: reflect.runtime.universe.TypeTag[A])↩ (scala.reflect.ClassTag[A], reflect.runtime.universe.TypeTag[A]) scala> m[List[Int]] res36: (scala.reflect.ClassTag[List[Int]],↩ reflect.runtime.universe.TypeTag[List[Int]]) =↩ (scala.collection.immutable.List,TypeTag[scala.List[Int]])
object Macro { import language.experimental.macros import scala.reflect.macros.Context def anymacro[A](expr: A): String = macro __anymacro[A] def __anymacro[A : c.WeakTypeTag](c: Context)(expr: c.Expr[A]): c.Expr[A] = { val aType = implicitly[c.WeakTypeTag[A]].tpe ??? } }
<console>:17: error: macro implementation has wrong shape: required: (c: scala.reflect.macros.Context)(expr: c.Expr[A]): c.Expr[String] found : (c: scala.reflect.macros.Context)(expr: c.Expr[A])(implicit evidence$1: c.TypeTag[A]): c.Expr[A] macro implementations cannot have implicit parameters other than WeakTypeTag evidences def anymacro[A](expr: A): String = macro __anymacro[A] ^
val en: EnumeratorT[String, Task] = EnumeratorT.enumList(List("a", "b", "c")) val it: IterateeT[String, Task, Int] = IterateeT.length (it &= en).run : Task[Int]
val en: EnumeratorT[String, Task] = ... val it: IterateeT[String, Id, Int] = ... val liftedIt = IterateeT.IterateeTMonadTrans[String].hoist( implicitly[Task |>=| Id]).apply(it) (liftedIt &= en).run: Task[Int]
val en: EnumeratorT[String, Id] = ... val it: IterateeT[String, Task, Int] = ... it &= ???
val placeholder = "Hello %s, isn val formatted = placeholder.format("Ivan", "Scala")
val name = "Ivan" val weather = "sunny" s"Hello $name, it
scala> List(1,2,3) ++ List(4,5) res0: List[Int] = List(1, 2, 3, 4, 5) scala> List(1,2,3) ::: List(4,5) res1: List[Int] = List(1, 2, 3, 4, 5) scala> res0 == res1 res2: Boolean = true
1 :: 2 :: Nil list1 ::: list2 list match { case head :: tail => "non-empty" case Nil => "empty" }
scala> List(1, 2, 3) ++ "ab" res0: List[AnyVal] = List(1, 2, 3, a, b)
scala> List(1, 2, 3) + "ab" res1: String = List(1, 2, 3)ab
scala> List(1,2,3).++(List(4,5)) res0: List[Int] = List(1, 2, 3, 4, 5)
scala> List(4,5).:::(List(1,2,3)) res1: List[Int] = List(1, 2, 3, 4, 5)
scala>def time(a: => Unit): Long = { val t = System.currentTimeMillis; a; System.currentTimeMillis - t} scala>def average(a: () => Long) = (for(i<-1 to 100) yield a()).sum/100 scala>average (() => time { (List[Int]() /: (1 to 1000)) { case (l, e) => l ++ List(e) } }) res1: Long = 46 scala>average (() => time { (List[Int]() /: (1 to 1000)) { case (l, e) => l ::: List(e ) } }) res2: Long = 46
object Main extends App { object WeekDay extends Enumeration { type WeekDay = Value val Mon, Tue, Wed, Thu, Fri, Sat, Sun = Value } import WeekDay._ def isWorkingDay(d: WeekDay) = ! (d == Sat || d == Sun) WeekDay.values filter isWorkingDay foreach println }
object WeekDay extends Enumeration { type WeekDay = Value val Mon = Value("Mon") val Tue = Value("Tue") ... etc }
def update(what: Symbol, where: Int, newValue: Array[Int]): MatrixInt = what match { case case case _ => throw new IllegalArgumentException } scala> val a = unitMatrixInt(3) a: teste7.MatrixInt = / 1 0 0 \ | 0 1 0 | \ 0 0 1 / scala> a( res41: teste7.MatrixInt = / 1 0 0 \ | 1 0 0 | \ 0 0 1 / scala> a( res42: teste7.MatrixInt = / 1 0 1 \ | 0 1 0 | \ 0 0 0 /
object Dimension extends Enumeration { type Dimension = Value val Row, Column = Value }
object Dimension extends Enumeration("Row", "Column") { type Dimension = Value val Row, Column = Value }
def update(what: Dimension, where: Int, newValue: Array[Int]): MatrixInt = what match { case Row => replaceRow(where, newValue) case Column => replaceCol(where, newValue) } scala> a(Row, 2) = a.row(1) <console>:13: error: not found: value Row a(Row, 2) = a.row(1) ^ scala> a(Dimension.Row, 2) = a.row(1) res1: teste.MatrixInt = / 1 0 0 \ | 0 1 0 | \ 0 1 0 / scala> import Dimension._ import Dimension._ scala> a(Row, 2) = a.row(1) res2: teste.MatrixInt = / 1 0 0 \ | 0 1 0 | \ 0 1 0 /
sealed abstract class Dimension case object Row extends Dimension case object Column extends Dimension
MatrixInt.scala:70: warning: match is not exhaustive! missing combination Column what match { ^ one warning found
scala> val a = unitMatrixInt(3) a: teste3.MatrixInt = / 1 0 0 \ | 0 1 0 | \ 0 0 1 / scala> a(Row,2) = a.row(0) res15: teste3.MatrixInt = / 1 0 0 \ | 0 1 0 | \ 1 0 0 /
object WeekDay extends Enumeration("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat") { type WeekDay = Value val Sun, Mon, Tue, Wed, Thu, Fri, Sat = Value } WeekDay.valueOf("Wed") WeekDay.Fri.toString
sealed abstract class Constraint(val name: String, val verifier: Int => Boolean) case object NotTooBig extends Constraint("NotTooBig", (_ < 1000)) case object NonZero extends Constraint("NonZero", (_ != 0)) case class NotEquals(x: Int) extends Constraint("NotEquals " + x, (_ != x)) object Main { def eval(ctrs: Seq[Constraint])(x: Int): Boolean = (true /: ctrs){ case (accum, ctr) => accum && ctr.verifier(x) } def main(args: Array[String]) { val ctrs = NotTooBig :: NotEquals(5) :: Nil val evaluate = eval(ctrs) _ println(evaluate(3000)) println(evaluate(3)) println(evaluate(5)) } }
import enumeratum._ sealed trait Greeting extends EnumEntry object Greeting extends Enum[Greeting] { val values = findValues case object Hello extends Greeting case object GoodBye extends Greeting case object Hi extends Greeting case object Bye extends Greeting } Greeting.withName("Hello") Greeting.withName("Haro") Greeting.withNameOption("Hello") Greeting.withNameOption("Haro") Greeting.withNameInsensitive("HeLLo") Greeting.withNameInsensitiveOption("HeLLo") Greeting.withNameUppercaseOnly("HELLO") Greeting.withNameUppercaseOnlyOption("HeLLo") Greeting.withNameLowercaseOnly("hello") Greeting.withNameLowercaseOnlyOption("hello")
val tupleList = List[(String, String)]() val filtered = tupleList.takeWhile( case (s1, s2) => s1 == s2 )
val filtered = tupleList.takeWhile{ case (s1, s2) => s1 == s2 }
List(1, 2, 3).reduceLeft{_ + _} List{1, 2, 3}.reduceLeft(_ + _)
{ case pattern if guard => statements case pattern => statements }
object match { case pattern if guard => statements case pattern => statements }
try { block } catch { case pattern if guard => statements case pattern => statements } finally { block }
{ import stuff._ statement ; statement ; statement var x = 0 while (x < 10) { x += 1 } (x % 5) + 1 } ( expression )
( { var x = 0; while (x < 10) { x += 1}; x } % 5) + 1
val filtered = tupleList takeWhile { case (s1, s2) => s1 == s2 }
def foo(f: Int => Unit) = { println("Entering foo"); f(4) }
val tupleList = List[(String, String)]() val filtered = tupleList.takeWhile( case (s1, s2) => s1 == s2 ) val filtered = tupleList.takeWhile{ case (s1, s2) => s1 == s2 } List(1, 2, 3).reduceLeft(_+_) List(1, 2, 3).reduceLeft{_+_} List(1, 2, 3).reduceLeft _+_ List(1, 2, 3).foldLeft(0)(_ + _) List(1, 2, 3).foldLeft(0){_ + _} List(1, 2, 3).foldLeft {0} {_ + _} List(1, 2, 3).foldLeft(0) _ + _ List(1, 2, 3).foldLeft 0 (_ + _) def foo(f: Int => Unit) = { println("Entering foo"); f(4) } foo { println("Hey"); x => println(x) } def f(x: Int): Int = f {x} def f(x: Int): Int = f x
sealed trait Answer case object Yes extends Answer case object No extends Answer
scala> val x: Answer = Yes x: Answer = Yes scala> x match { | case No => println("No") | } <console>:12: warning: match is not exhaustive! missing combination Yes
/** Turn command line arguments to uppercase */ object Main { def main(args: Array[String]) { val res = for (a <- args) yield a.toUpperCase println("Arguments: " + res.toString) } }
c1.foreach(x => c2.foreach(y => c3.foreach(z => {...})))
c1.flatMap(x => c2.flatMap(y => c3.map(z => {...})))
l.flatMap(sl => sl.filter(el => el > 0).map(el => el.toString.length))
for { sl <- l el <- sl if el > 0 } yield el.toString.length
scala> var found = false found: Boolean = false scala> List.range(1,10).filter(_ % 2 == 1 && !found).foreach(x => if (x == 5) found = true else println(x)) 1 3 7 9 scala> found = false found: Boolean = false scala> Stream.range(1,10).filter(_ % 2 == 1 && !found).foreach(x => if (x == 5) found = true else println(x)) 1 3
for (x <- List.range(1, 10); if x % 2 == 1 && !found) if (x == 5) found = true else println(x) for (x <- Stream.range(1, 10); if x % 2 == 1 && !found) if (x == 5) found = true else println(x)
scala> var found = false found: Boolean = false scala> List.range(1,10).filter(_ % 2 == 1 && !found).foreach(x => if (x == 5) found = true else println(x)) 1 3 7 9 scala> found = false found: Boolean = false scala> List.range(1,10).withFilter(_ % 2 == 1 && !found).foreach(x => if (x == 5) found = true else println(x)) 1 3
val A = for (i <- Int.MinValue to Int.MaxValue; if i > 3) yield i
scala> val nums = Seq(1,2,3) nums: Seq[Int] = List(1, 2, 3) scala> val letters = Seq( letters: Seq[Char] = List(a, b, c) scala> val res = for { | n <- nums | c <- letters | } yield (n, c)
val aList = List( 1,2,3,4,5 ) val res3 = for ( al <- aList if al > 3 ) yield al + 1 val res4 = aList.filter(_ > 3).map(_ + 1) println( res3 ) println( res4 )
val res3 = for (al <- aList) yield al + 1 > 3 val res4 = aList.map( _+ 1 > 3 ) println( res3 ) println( res4 )
val aList = List( 1,2,3,4,5 ) val res3 = for ( al <- aList if al > 3 ) yield al + 1 val res4 = aList.map( _+ 1 > 3 ) println( res3 ) println( res4 )
scala.io.Source.fromPath("file.txt").getLines.reduceLeft(_+_)
import java.util.Scanner import java.io.File new Scanner(new File("file.txt")).useDelimiter("\\Z").next()
Ruby open("file.txt").read Ruby File.read("file.txt") Python open("file.txt").read()
val lines = scala.io.Source.fromFile("file.txt").mkString
val source = scala.io.Source.fromFile("file.txt") val lines = try source.mkString finally source.close()
val lines = scala.io.Source.fromFile("file.txt", "utf-8").getLines.mkString
scala> io.File("/etc/passwd").slurp res0: String = ... etc
import java.nio.charset.StandardCharsets._ import java.nio.file.{Files, Paths} new String(Files.readAllBytes(Paths.get("file.txt")), UTF_8)
def fileToString(file: File, encoding: String) = { val inStream = new FileInputStream(file) val outStream = new ByteArrayOutputStream try { var reading = true while ( reading ) { inStream.read() match { case -1 => reading = false case c => outStream.write(c) } } outStream.flush() } finally { inStream.close() } new String(outStream.toByteArray(), encoding) }
FileUtils.readFileToString(file, StandardCharsets.UTF_8)
import java.io.File def open(filename: String) = new File(filename) implicit class RichFile(val file: File) extends AnyVal { def read = io.Source.fromFile(file).getLines.mkString("\n") }
val bytes : Iterator[Byte] = file.bytes val chars : Iterator[Char] = file.chars val lines : Iterator[String] = file.lines val source : scala.io.BufferedSource = file.content
val content: String = file.contentAsString import scala.io.Codec file.contentAsString(Codec.ISO8859) import scala.io.Codec.string2codec file.write("hello world")(codec = "US-ASCII")
val filePath = Path("path_of_file_to_b_read", val lines = file.lines(includeTerminator = true)
val file = new java.io.File("myFilename") io.Source.fromFile(file, bufferSize = Source.DefaultBufSize * 2)
scala.io.Source.fromFile("test.txt" ).foreach{ print }
scala.io.Source.fromFile("test.txt" ).foreach( x => print(x))
import scala.io.{BufferedSource, Codec, Source} import scala.util.Try def readFileUtf8(path: String): Try[String] = Try { val source: BufferedSource = Source.fromFile(path)(Codec.UTF8) val content = source.mkString source.close() content }
import scala.io.source object ReadLine{ def main(args:Array[String]){ if (args.length>0){ for (line <- Source.fromLine(args(0)).getLine()) println(line) } }
class A(n: Int) { var value = n } class B(n: Int) { val value = new A(n) } object Test { def main(args: Array[String]) { val x = new B(5) x = new B(6) x.value = new A(6) x.value.value = 6 } }
x = new B(0) f(x) if (x.value.value == 0) println("f didn else println("f did something to x")
x = new B(1) f(x) if (x.value.value == 1) { print(x.value.value) }
def toNum(q: scala.collection.mutable.Queue[Int]) = { var num = 0 while (!q.isEmpty) { num *= 10 num += q.dequeue } num }
def toNum(q: scala.collection.immutable.Queue[Int]) = { def recurse(qr: scala.collection.immutable.Queue[Int], num: Int): Int = { if (qr.isEmpty) num else { val (digit, newQ) = qr.dequeue recurse(newQ, num * 10 + digit) } } recurse(q, 0) }
def toNum(q: scala.collection.immutable.Queue[Int]) = { var qr = q var num = 0 while (!qr.isEmpty) { val (digit, newQ) = qr.dequeue num *= 10 num += digit qr = newQ } num }
import collection.immutable import collection.mutable var m = immutable.Set("London", "Paris") m = immutable.Set("New York")
val n = immutable.Set("London", "Paris") n = immutable.Set("New York")
val n = mutable.Set("London", "Paris") n = mutable.Set("New York")
def factorial(num: Int): Int = { if(num == 0) 1 else factorial(num - 1) * num }
val implicits = schema.fields.map { field => val fieldName:String = field.name val fieldType = TypeName(field.valueType.fullName) val in = TermName("implicitField"+fieldName) val tn = TermName(fieldName) val cc = TermName("cc") q"""implicit val $in = Field.apply[$className,$fieldType](Witness($fieldName), ($cc: $className) => $cc.$tn)""" }
sealed abstract class Field[CC, FieldName] { val fieldName: String type fieldType def get(cc : CC) : fieldType } object Field { type Aux[CC, FieldName, fieldType_] = Field[CC, FieldName] { type fieldType = fieldType_ } def apply[CC, fieldType_](fieldWitness : Witness.Lt[String], ext : CC => fieldType_) : Field.Aux[CC, fieldWitness.T, fieldType_] = new Field[CC, fieldWitness.T] { val fieldName : String = fieldWitness.value type fieldType = fieldType_ def get(cc : CC) : fieldType = ext(cc) } }
implicit val implicitFieldname : Field[MyCaseClass, fieldWitness.`type` override type fieldType = java.lang.String }
implicit val implicitFieldname : Field.Aux[MyCaseClass, Witness.Lt[String]
import scala.language.experimental.macros import scala.reflect.macros.blackbox.Context import scala.annotation.StaticAnnotation class fieldable extends StaticAnnotation { def macroTransform(annottees: Any*): Any = macro fieldableMacro.impl } object fieldableMacro { def impl(c: Context)(annottees: c.Expr[Any]*): c.Tree = { import c.universe._ annottees.map(_.tree) match { case (param @ q"case class $className(..$fields)") :: Nil => { val implicits = fields.collect { case field @ q"$mods val $tname: $tpt" => q""" implicit val $tname = Field.apply[$className,$tpt]( Witness(${tname.decodedName.toString}), _.$tname )""" }; q"$param; object ${className.toTermName} {..$implicits}" } } } }
@fieldable case class MyCaseClass(foo: String, bar: Int)
implicit val foo = Field.apply[MyCaseClass, String](Witness("foo"), ((x$1) => x$1.foo)); implicit val bar = Field.apply[MyCaseClass, Int](Witness("bar"), ((x$2) => x$2.bar));
def newTask = Action { implicit request => taskForm.bindFromRequest.fold( errors => BadRequest(views.html.index(Task.all(), errors)), label => { Task.create(label) Redirect(routes.Application.tasks()) } ) }
implicit def double2Int(d : Double) : Int = d.toInt
def double2IntNonImplicit(d : Double) : Int = d.toInt
class Prefixer(val prefix: String) def addPrefix(s: String)(implicit p: Prefixer) = p.prefix + s implicit val myImplicitPrefixer = new Prefixer("***") addPrefix("abc")
implicit def doubleToInt(d: Double) = d.toInt val x: Int = 42.0
def doubleToInt(d: Double) = d.toInt val x: Int = doubleToInt(42.0)
apply(block: (Request[AnyContent]) ⇒ Result): Action[AnyContent]
object HelloWorld { case class Text(content: String) case class Prefix(text: String) implicit def String2Text(content: String)(implicit prefix: Prefix) = { Text(prefix.text + " " + content) } def printText(text: Text): Unit = { println(text.content) } def main(args: Array[String]): Unit = { printText("World!") } implicit val prefixLOL = Prefix("Hello") }
def bindFromRequest()(implicit request: play.api.mvc.Request[_]): Form[T] = { ... }
implicit def doubleToInt(d: Double) = d.toInt implicit def doubleToIntSecond(d: Double) = d.toInt val x: Int = 42.0
object Foo { var y = 5 def apply (x: Int) = x + y } Foo (1)
class MyAdder(x: Int) { def apply(y: Int) = x + y } val adder = new MyAdder(2) val result = adder(4)
trait A { val x: Int def myComplexStrategy: Int } object A { def apply(x: Int): A = new MyA(x) private class MyA(val x: Int) extends A { val myComplexStrategy = 42 } }
object ApplyExample01 extends App { class Greeter1(var message: String) { println("A greeter-1 is being instantiated with message " + message) } class Greeter2 { def apply(message: String) = { println("A greeter-2 is being instantiated with message " + message) } } val g1: Greeter1 = new Greeter1("hello") val g2: Greeter2 = new Greeter2() g2("world") }
var largest=0 for(i<-999 to 1 by -1) { for (j<-i to 1 by -1) { val product=i*j if (largest>product) else if(product.toString.equals(product.toString.reverse)) largest=largest max product } }
var sum = 0 (0 to 1000).iterator.takeWhile(_ => sum < 1000).foreach(i => sum+=i)
var sum = 0 def addTo(i: Int, max: Int) { sum += i; if (sum < max) addTo(i+1,max) } addTo(0,1000)
var sum = 0 var i = 0 while (i <= 1000 && sum <= 1000) { sum += 1; i += 1 }
object AllDone extends Exception { } var sum = 0 try { for (i <- 0 to 1000) { sum += i; if (sum>=1000) throw AllDone } } catch { case AllDone => }
import scala.util.control.Breaks._ var sum = 0 breakable { for (i <- 0 to 1000) { sum += i if (sum >= 1000) break } }
var sum = 0 def findSum { for (i <- 0 to 1000) { sum += i; if (sum>=1000) return } } findSum
import scala.util.control.Breaks._ var largest = 0 breakable { for (i<-999 to 1 by -1; j <- i to 1 by -1) { val product = i * j if (largest > product) { break } else if (product.toString.equals(product.toString.reverse)) { largest = largest max product } } }
var done = false while (i <= length && !done) { if (sum > 1000) { done = true } }
var sum = 0 for (i <- 0 to 1000 ; if sum<1000) sum += i
import scala.util.control._ val loop = new Breaks; loop.breakable{ for(...){ .... loop.break; } }
var (i, sum) = (0, 0) while (sum < 1000) { sum += i i += 1 }
var sum = 0 for ( i <- Iterator.from(1).takeWhile( _ => sum < 1000) ) sum += i
def run(start:Int) = { @tailrec def tr(i:Int, largest:Int):Int = tr1(i, i, largest) match { case x if i > 1 => tr(i-1, x) case _ => largest } @tailrec def tr1(i:Int,j:Int, largest:Int):Int = i*j match { case x if x < largest || j < 2 => largest case x if x.toString.equals(x.toString.reverse) => tr1(i, j-1, x) case _ => tr1(i, j-1, largest) } tr(start, 0) }
var largest = 0 for (i <- 999 to 1 by -1; j <- i to 1 by -1; product = i * j; if (largest <= product && product.toString.reverse.equals (product.toString.reverse.reverse))) largest = product println (largest)
scala> import com.manyangled.breakable._ import com.manyangled.breakable._ scala> val bkb2 = for { | (x, xLab) <- Stream.from(0).breakable | (y, yLab) <- breakable(Stream.from(0)) | if (x % 2 == 1) continue(xLab) | if (y % 2 == 0) continue(yLab) | if (x > 10) break(xLab) | if (y > x) break(yLab) | } yield (x, y) bkb2: com.manyangled.breakable.Breakable[(Int, Int)] = com.manyangled.breakable.Breakable@34dc53d2 scala> bkb2.toVector res0: Vector[(Int, Int)] = Vector((2,1), (4,1), (4,3), (6,1), (6,3), (6,5), (8,1), (8,3), (8,5), (8,7), (10,1), (10,3), (10,5), (10,7), (10,9))
var largest = 0 lazy val ij = for (i <- 999 to 1 by -1; j <- i to 1 by -1) yield (i, j) val largest_ij = ij.find { case(i,j) => val product = i * j if (product.toString == product.toString.reverse) largest = largest max product largest > product } println(largest_ij.get) println(largest)
scala> import util.control.Breaks._ scala> object TestBreak{ def main(args : Array[String]){ breakable { for (i <- 1 to 10){ println(i) if (i == 5){ break; } } } } }
import scala.util.control.Breaks.break object RecurringCharacter { def main(args: Array[String]) { val str = "nileshshinde"; for (i <- 0 to str.length() - 1) { for (j <- i + 1 to str.length() - 1) { if (str(i) == str(j)) { println("First Repeted Character " + str(i)) break() } } } } }
for(id<-0 to 99) { try { var symbol = ctx.read("$.stocks[" + id + "].symbol").toString var name = ctx.read("$.stocks[" + id + "].name").toString stocklist(symbol) = name }catch { case ex: com.jayway.jsonpath.PathNotFoundException=>{break} } }
object awhile { def apply(condition: () => Boolean, action: () => breakwhen): Unit = { while (condition()) { action() match { case breakwhen(true) => return ; case _ => { }; } } } case class breakwhen(break:Boolean);
var i = 0 awhile(() => i < 20, () => { i = i + 1 breakwhen(i == 5) }); println(i)
awhile(() => i < 20, () => { i = i + 1 breakwhen(false) });
import scala.util.control._ object demo_brk_963 { def main(args: Array[String]) { var a = 0; var b = 0; val numList1 = List(1,2,3,4,5,6,7,8,9,10); val numList2 = List(11,12,13); val outer = new Breaks; val inner = new Breaks; outer.breakable { for( a <- numList1) { println( "Value of a: " + a); inner.breakable { for( b <- numList2) { println( "Value of b: " + b); if( b == 12 ) { println( "break-INNER;"); inner.break; } } } if( a == 6 ) { println( "break-OUTER;"); outer.break; } } } } }
def f[A <% Ordered[A]](a: A, b: A) = if (a < b) a else b
def f[A : Ordering](a: A, b: A) = implicitly[Ordering[A]].compare(a, b)
def f[A <% B](a: A) = a.bMethod def f[A](a: A)(implicit ev: A => B) = a.bMethod def g[A : B](a: A) = h(a) def g[A](a: A)(implicit ev: B[A]) = h(a)
def f[A](a: A, b: A)(implicit ord: Ordering[A]) = ord.compare(a, b)
def f[A <% Ordered[A]](a: A, b: A): A = if (a < b) a else b
def f[CC <% Traversable[_]](a: CC, b: CC): CC = if (a.size < b.size) a else b
def f[A <% Ordered[A]](xs: A*): Seq[A] = xs.toSeq.sorted
def f[A : Ordering](a: A, b: A) = if (implicitly[Ordering[A]].lt(a, b)) a else b
def f[A](a: A, b: A)(implicit ord: Ordering[A]) = { import ord.mkOrderingOps if (a < b) a else b }
def f[A : Numeric](a: A, b: A) = implicitly[Numeric[A]].plus(a, b)
sealed abstract class List[+A] extends AbstractSeq[A] with Product with ...
scala> def sumUp(s: Seq[Int]): Int = { s.sum } sumUp: (s: Seq[Int])Int scala> sumUp(List(1,2,3)) res41: Int = 6 scala> sumUp(Vector(1,2,3)) res42: Int = 6 scala> sumUp(Seq(1,2,3)) res44: Int = 6
scala> val a = Seq(1,2,3) a: Seq[Int] = List(1, 2, 3)
scala> val a: Seq[Int] = List(1,2,3) a: Seq[Int] = List(1, 2, 3)
proper first-order higher-order values 10 (x: Int) => x (f: (Int => Int)) => f(10) types (classes) String List Functor types String ({type λ[x] = x})
types (informally) String [x] => x [F[x]] => F[String])
trait Functor [F[_]] { def map[A,B] (fn: A=>B)(fa: F[A]): F[B] }
scala> val pf: PartialFunction[Int, Boolean] = { case i if i > 0 => i % 2 == 0} pf: PartialFunction[Int,Boolean] = <function1> scala> pf.lift res1: Int => Option[Boolean] = <function1> scala> res1(-1) res2: Option[Boolean] = None scala> res1(1) res3: Option[Boolean] = Some(false)
scala> def times2(i: Int) = i * 2 times2: (i: Int)Int
scala> val f = times2 _ f: Int => Int = <function1> scala> f(4) res0: Int = 8
trait Functor[F[_]] { def map[A, B](fa: F[A])(f: A => B): F[B] }
def lift[F[_]: Functor, A, B](f: A => B): F[A] => F[B]
lazy val f: (A, B) => C = ??? val cs = for { a <- as b <- bs.liftM[StreamT] } yield f(a, b) cs.toStream
f: List[A] -> List[B] f(xs) = f(xs(1)), f(xs(2)), ..., f(xs(n))
f: Set[A] -> Set[B] f(xs) = \bigcup_{i = 1}^n f(xs(i))
Seq(1,2,3).lift(2) Option[Int] = Some(3) Seq(1,2,3).lift(22) Option[Int] = None
Seq(1,2,3).lift(2).getOrElse(-1) Int = 3 Seq(1,2,3).lift(22).getOrElse(-1) Int = -1
def unlift[T, R](f: (T) ⇒ Option[R]): PartialFunction[T, R]
import play.api.libs.json._ import play.api.libs.functional.syntax._ case class Location(lat: Double, long: Double) implicit val locationWrites: Writes[Location] = ( (JsPath \ "lat").write[Double] and (JsPath \ "long").write[Double] )(unlift(Location.unapply))
val o1 = f(List(1, 2, 3)) val o2 = m(List(1, 2, 3))
val f = (l: List[Int]) => l mkString "" val g: (AnyVal) => String = { case i: Int => "Int" case d: Double => "Double" case o => "Other" }
val f = new AnyRef with Function1[List[Int], AnyRef] { def apply(x$1: List[Int]) = this.m(x$1) }
scala> val f = () => { return "test" } <console>:4: error: return outside method definition val f = () => { return "test" } ^
scala> def f: String = { | val g = () => { return "test" } | g() | "not this" | } f: String scala> f res4: String = test
scala> def f2: String = { | def g(): String = { return "test" } | g() | "is this" | } f2: String scala> f2 res5: String = is this
scala> val x =List.range(10,20) x: List[Int] = List(10, 11, 12, 13, 14, 15, 16, 17, 18, 19)
scala> (i:Int)=>i+2 res0: Int => Int = <function1> scala> x.map((x)=>x+2) res2: List[Int] = List(12, 13, 14, 15, 16, 17, 18, 19, 20, 21)
scala> val p =(i:Int)=>i+2 p: Int => Int = <function1>
scala> p(2) res4: Int = 4 scala> p res5: Int => Int = <function1>
scala> m1 <console>:9: error: missing arguments for method m1; follow this method with `_
abstract class MaxCell extends AbsCell { type T <: Ordered { type O = T } def setMax(x: T) = if (get < x) set(x) }
class MySuite extends FixtureSuite3[StringBuilder, ListBuffer, Stack] with MyHandyFixture { }
class MySuite extends FixtureSuite3 with MyHandyFixture { }
class MySuite extends FixtureSuite[StringBuilder] with StringBuilderFixture { }
class MySuite extends FixtureSuite with StringBuilderFixture { type FixtureParam = StringBuilder }
trait AA[B<:BB[C,AA[B,C]],C<:CC[AA[B,C],B]] trait BB[C<:CC[A,BB[C,A]],A<:AA[BB[C,A],C]] trait CC[A<:AA[B,CC[A,B]],B<:BB[CC[A,B],A]]
trait AA[+B<:BB[C,AA[B,C]],+C<:CC[AA[B,C],B]] trait BB[+C<:CC[A,BB[C,A]],+A<:AA[BB[C,A],C]] trait CC[+A<:AA[B,CC[A,B]],+B<:BB[CC[A,B],A]]
trait AA[+B<:BB[C,AA[B,C]],+C<:CC[AA[B,C],B]] { def forth(x:B):C def back(x:C):B } trait BB[+C<:CC[A,BB[C,A]],+A<:AA[BB[C,A],C]] { def forth(x:C):A def back(x:A):C } trait CC[+A<:AA[B,CC[A,B]],+B<:BB[CC[A,B],A]] { def forth(x:A):B def back(x:B):A }
trait OO[O <: OO[O]] { this : O => type A <: AA[O] type B <: BB[O] type C <: CC[O] } trait AA[O <: OO[O]] { this : O type A = O type B = O type C = O def left(l:B):C def right(r:C):B = r.left(this) def join(l:B, r:C):A def double(l:B, r:C):A = this.join( l.join(r,this), r.join(this,l) ) } trait BB[O <: OO[O]] { this : O type A = O type B = O type C = O def left(l:C):A def right(r:A):C = r.left(this) def join(l:C, r:A):B def double(l:C, r:A):B = this.join( l.join(r,this), r.join(this,l) ) } trait CC[O <: OO[O]] { this : O type A = O type B = O type C = O def left(l:A):B def right(r:B):A = r.left(this) def join(l:A, r:B):C def double(l:A, r:B):C = this.join( l.join(r,this), r.join(this,l) ) }
class ReprO extends OO[ReprO] { override type A = ReprA override type B = ReprB override type C = ReprC } case class ReprA(data : Int) extends AA[ReprO] { override def left(l:B):C = ReprC(data - l.data) override def join(l:B, r:C) = ReprA(l.data + r.data) } case class ReprB(data : Int) extends BB[ReprO] { override def left(l:C):A = ReprA(data - l.data) override def join(l:C, r:A):B = ReprB(l.data + r.data) } case class ReprC(data : Int) extends CC[ReprO] { override def left(l:A):B = ReprB(data - l.data) override def join(l:A, r:B):C = ReprC(l.data + r.data) }
scala> val x = 15 x: Int = 15 scala> lazy val y = 13 y: Int = <lazy> scala> x res0: Int = 15 scala> y res1: Int = 13
scala> val x = { println("x"); 15 } x x: Int = 15 scala> lazy val y = { println("y"); 13 } y: Int = <lazy> scala> x res2: Int = 15 scala> y y res3: Int = 13 scala> y res4: Int = 13
scala> class X { val x = { Thread.sleep(2000); 15 } } defined class X scala> class Y { lazy val y = { Thread.sleep(2000); 13 } } defined class Y scala> new X res5: X = X@262505b7 scala> new Y res6: Y = Y@1555bd22
trait Foo { val foo: Foo } case class Fee extends Foo { val foo = Faa() } case class Faa extends Foo { val foo = Fee() } println(Fee().foo)
trait Foo { val foo: Foo } case class Fee extends Foo { lazy val foo = Faa() } case class Faa extends Foo { lazy val foo = Fee() } println(Fee().foo)
var x = { println("x"); 15 } lazy val y = { println("y"); x+1 } println("-----") x = 17 println("y is: " + y)
abstract class X { val x: String println ("x is "+x.length) } object Y extends X { val x = "Hello" } Y
abstract class X { val x: String println ("x is "+x.length) } object Y extends X { lazy val x = "Hello" } Y
scala> lazy val lazyEight = { | println("I am lazy !") | 8 | } lazyEight: Int = <lazy> scala> lazyEight I am lazy ! res1: Int = 8
scala> lazy val t: Int = t t: Int = <lazy> scala> t java.lang.StackOverflowError ... scala> val t: Int = t <console>:12: warning: value t does nothing other than call itself recursively val t: Int = t
object MmlAlnApp { val usage = def main(args: Array[String]) { if (args.length == 0) println(usage) val arglist = args.toList type OptionMap = Map[Symbol, Any] def nextOption(map : OptionMap, list: List[String]) : OptionMap = { def isSwitch(s : String) = (s(0) == list match { case Nil => map case "--max-size" :: value :: tail => nextOption(map ++ Map( case "--min-size" :: value :: tail => nextOption(map ++ Map( case string :: opt2 :: tail if isSwitch(opt2) => nextOption(map ++ Map( case string :: Nil => nextOption(map ++ Map( case option :: tail => println("Unknown option "+option) exit(1) } } val options = nextOption(Map(),arglist) println(options) } }
val parser = new scopt.OptionParser[Config]("scopt") { head("scopt", "3.x") opt[Int]( c.copy(foo = x) } text("foo is an integer property") opt[File]( c.copy(out = x) } text("out is a required file property") opt[(String, Int)]("max") action { case ((k, v), c) => c.copy(libName = k, maxCount = v) } validate { x => if (x._2 > 0) success else failure("Value <max> must be >0") } keyValueName("<libname>", "<max>") text("maximum count for <libname>") opt[Unit]("verbose") action { (_, c) => c.copy(verbose = true) } text("verbose is a flag") note("some notes.\n") help("help") text("prints this usage text") arg[File]("<file>...") unbounded() optional() action { (x, c) => c.copy(files = c.files :+ x) } text("optional unbounded args") cmd("update") action { (_, c) => c.copy(mode = "update") } text("update is a command.") children( opt[Unit]("not-keepalive") abbr("nk") action { (_, c) => c.copy(keepalive = false) } text("disable keepalive"), opt[Boolean]("xyz") action { (x, c) => c.copy(xyz = x) } text("xyz is a boolean property") ) } parser.parse(args, Config()) map { config => } getOrElse { }
scopt 3.x Usage: scopt [update] [options] [<file>...] -f <value> | --foo <value> foo is an integer property -o <file> | --out <file> out is a required file property --max:<libname>=<max> maximum count for <libname> --verbose verbose is a flag some notes. --help prints this usage text <file>... optional unbounded args Command: update update is a command. -nk | --not-keepalive disable keepalive --xyz <value> xyz is a boolean property
import org.rogach.scallop._; object Conf extends ScallopConf(List("-c","3","-E","fruit=apple","7.2")) { val count:ScallopOption[Int] = opt[Int]("count", descr = "count the trees", required = true) .map(1+) val properties = props[String]( val size:ScallopOption[Double] = trailArg[Double](required = false) } Conf.count() should equal (4) Conf.properties("fruit") should equal (Some("apple")) Conf.size.get should equal (Some(7.2)) def someInternalFunc(conf:Conf.type) { conf.count() should equal (4) } someInternalFunc(Conf)
var name = "" var port = 0 var ip = "" args.sliding(2, 2).toList.collect { case Array("--ip", argIP: String) => ip = argIP case Array("--port", argPort: String) => port = argPort.toInt case Array("--name", argName: String) => name = argName }
import uk.co.flamingpenguin.jewel.cli.Option trait Person { @Option def name: String @Option def times: Int }
import uk.co.flamingpenguin.jewel.cli.CliFactory.parseArguments import uk.co.flamingpenguin.jewel.cli.ArgumentValidationException object Hello { def main(args: Array[String]) { try { val person = parseArguments(classOf[Person], args:_*) for (i <- 1 to (person times)) println("Hello " + (person name)) } catch { case e: ArgumentValidationException => println(e getMessage) } } }
scalac -cp jewelcli-0.6.jar:. Person.scala Hello.scala scala -cp jewelcli-0.6.jar:. Hello --name="John Doe" --times=3
scalac -cp jewelcli-0.6.jar;. Person.scala Hello.scala scala -cp jewelcli-0.6.jar;. Hello --name="John Doe" --times=3
class Cat extends Command(description = "concatenate files and print on the standard output") { var showAll = opt[Boolean](abbrev = "A", description = "equivalent to -vET") var numberNonblank = opt[Boolean](abbrev = "b", description = "number nonempty output lines, overrides -n") var files = args[Seq[File]](description = "files to concat") }
Cli.parse(args).withCommand(new Cat) { case cat => println(cat.files) }
import org.kohsuke.args4j.{CmdLineException, CmdLineParser, Option} object CliArgs { @Option(name = "-list", required = true, usage = "List of Nutch Segment(s) Part(s)") var pathsList: String = null @Option(name = "-workdir", required = true, usage = "Work directory.") var workDir: String = null @Option(name = "-master", usage = "Spark master url") var masterUrl: String = "local[2]" }
val parser = new CmdLineParser(CliArgs) try { parser.parseArgument(args.toList.asJava) } catch { case e: CmdLineException => print(s"Error:${e.getMessage}\n Usage:\n") parser.printUsage(System.out) System.exit(1) } println("workDir :" + CliArgs.workDir) println("listFile :" + CliArgs.pathsList) println("master :" + CliArgs.masterUrl)
Error:Option "-list" is required Usage: -list VAL : List of Nutch Segment(s) Part(s) -master VAL : Spark master url (default: local[2]) -workdir VAL : Work directory.
object Main { object Args { @Parameter( names = Array("-f", "--file"), description = "File to load. Can be specified multiple times.") var file: java.util.List[String] = null } def main(args: Array[String]): Unit = { new JCommander(Args, args.toArray: _*) for (filename <- Args.file) { val f = new File(filename) printf("file: %s\n", f.getName) } } }
case class AppArgs( seed1: String, seed2: String, ip: String, port: Int ) object AppArgs { def empty = new AppArgs("", "", "", 0) } val args = Array[String]( "--seed1", "akka.tcp: "--seed2", "akka.tcp: "--nodeip", "192.167.1.1", "--nodeport", "2551" ) val argsInstance = args.sliding(2, 1).toList.foldLeft(AppArgs.empty) { case (accumArgs, currArgs) => currArgs match { case Array("--seed1", seed1) => accumArgs.copy(seed1 = seed1) case Array("--seed2", seed2) => accumArgs.copy(seed2 = seed2) case Array("--nodeip", ip) => accumArgs.copy(ip = ip) case Array("--nodeport", port) => accumArgs.copy(port = port.toInt) case unknownArg => accumArgs } }
def parseOptions(args: List[String], required: List[Symbol], optional: Map[String, Symbol], options: Map[Symbol, String]): Map[Symbol, String] = { args match { case Nil => options case key :: value :: tail if optional.get(key) != None => parseOptions(tail, required, optional, options ++ Map(optional(key) -> value)) case value :: tail if required != Nil => parseOptions(tail, required.tail, optional, options ++ Map(required.head -> value)) case _ => printf("unknown argument(s): %s\n", args.mkString(", ")) sys.exit(1) } } def main(sysargs Array[String]) { val required = List( val optional = Map("--flag1" -> var defaultOptions = Map() val options = parseOptions(sysargs.toList, required, optional, defaultOptions) }
def argsToOptionMap(args:Array[String]):Map[String,String]= { def nextOption( argList:List[String], map:Map[String, String] ) : Map[String, String] = { val pattern = "--(\\w+)".r val patternSwitch = "-(\\w+)".r argList match { case Nil => map case pattern(opt) :: value :: tail => nextOption( tail, map ++ Map(opt->value) ) case patternSwitch(opt) :: tail => nextOption( tail, map ++ Map(opt->null) ) case string :: Nil => map ++ Map(string->null) case option :: tail => { println("Unknown option:"+option) sys.exit(1) } } } nextOption(args.toList,Map()) }
val args=Array("--testing1","testing1","-a","-b","--c","d","test2") argsToOptionMap( args )
res0: Map[String,String] = Map(testing1 -> testing1, a -> null, b -> null, c -> d, test2 -> null)
def print_version() = () => println("version is 0.2") def main(args: Array[String]) { val (options, remaining) = OptionParser.getOptions(args, Map( "-f|--flag" -> "-s|--string=s" -> "-i|--int=i" -> "-f|--float=f" -> "-p|-procedure=p" -> { () => println("higher order function" } "-h=p" -> { () => print_synopsis() } "--help|--man=p" -> { () => launch_manpage() }, "--version=p" -> print_version, ))
$ script hello -f --string=mystring -i 7 --float 3.14 --p --version world -- --nothing
remaining = Array("hello", "world", "--nothing") options = Map(
val args: Array[String] = "-silent -samples 100 -silent".split(" +").toArray object Opts extends Enumeration { class OptVal extends Val { override def toString = "-" + super.toString } val nopar, silent = new OptVal() { def apply(): Boolean = args.contains(toString) } val samples, maxgen = new OptVal() { def apply(default: Int) = { val i = args.indexOf(toString) ; if (i == -1) default else args(i+1).toInt} def apply(): Int = apply(-1) } } Opts.nopar() Opts.silent() Opts.samples() Opts.maxgen()
import org.docopt.Docopt import scala.collection.JavaConversions._ import scala.collection.JavaConverters._ val doc = .stripMargin.trim var results = new Docopt(doc). parse(args()). map {case(key, value)=>key ->value.toString} val inputFile = new File(results("<input>")) val sorted = results("--sorted").toBoolean
object ArgParser { val usage = var filename: String = "" var showme: String = "" var debug: Boolean = false val unknown = "(^-[^\\s])".r val pf: PartialFunction[List[String], List[String]] = { case "-v" :: tail => debug = true; tail case "-f" :: (arg: String) :: tail => filename = arg; tail case "-s" :: (arg: String) :: tail => showme = arg; tail case unknown(bad) :: tail => die("unknown argument " + bad + "\n" + usage) } def main(args: Array[String]) { if (args.length == 0) die() val arglist = args.toList val remainingopts = parseArgs(arglist,pf) println("debug=" + debug) println("showme=" + showme) println("filename=" + filename) println("remainingopts=" + remainingopts) } def parseArgs(args: List[String], pf: PartialFunction[List[String], List[String]]): List[String] = args match { case Nil => Nil case _ => if (pf isDefinedAt args) parseArgs(pf(args),pf) else args.head :: parseArgs(args.tail,pf) } def die(msg: String = usage) = { println(msg) sys.exit(1) } }
import ***.ArgsOps._ object Example { val parser = ArgsOpsParser("--someInt|-i" -> 4, "--someFlag|-f", "--someWord" -> "hello") def main(args: Array[String]){ val argsOps = parser <<| args val someInt : Int = argsOps("--someInt") val someFlag : Boolean = argsOps("--someFlag") val someWord : String = argsOps("--someWord") val otherArgs = argsOps.args foo(someWord, someInt, someFlag) } }
input--hdfs:/path/to/myData/part-00199.avro output--hdfs:/path/toWrite/Data fileFormat--avro option1--5
Array("input--hdfs:/path/to/myData/part-00199.avro", "output--hdfs:/path/toWrite/Data","fileFormat--avro","option1--5")
val nArgs = args.map(x=>x.split("--")).map(y=>(y(0),y(1))).toMap
Map(input -> hdfs:/path/to/myData/part-00199.avro, output -> hdfs:/path/toWrite/Data, fileFormat -> avro, option1 -> 5)
def optArg(prefix: String) = args.drop(3).find { _.startsWith(prefix) }.map{_.replaceFirst(prefix, "")} def optSpecified(prefix: String) = optArg(prefix) != None def optInt(prefix: String, default: Int) = optArg(prefix).map(_.toInt).getOrElse(default)
val cacheEnabled = optSpecified("cacheOff") val memSize = optInt("-Xmx", 1000)
val args = "--sw1 1 input_1 --sw2 --sw3 2 input_2 --sw4".split(" ") val (options, inputs) = OptParser.parse(args)
options: Map[Symbol,Any] = Map( inputs: List[Symbol] = List(
object OptParser { val map: Map[Symbol, Any] = Map() val list: List[Symbol] = List() def parse(args: Array[String]): (Map[Symbol, Any], List[Symbol]) = _parse(map, list, args.toList) private [this] def _parse(map: Map[Symbol, Any], list: List[Symbol], args: List[String]): (Map[Symbol, Any], List[Symbol]) = { args match { case Nil => (map, list) case arg :: value :: tail if (arg.startsWith("--") && !value.startsWith("--")) => _parse(map ++ Map(Symbol(arg.substring(2)) -> value), list, tail) case arg :: tail if (arg.startsWith("--")) => _parse(map ++ Map(Symbol(arg.substring(2)) -> true), list, tail) case opt :: tail => _parse(map, list :+ Symbol(opt), tail) } } }
package freecli package examples package command import java.io.File import freecli.core.all._ import freecli.config.all._ import freecli.command.all._ object Git extends App { case class CommitConfig(all: Boolean, message: String) val commitCommand = cmd("commit") { takesG[CommitConfig] { O.help --"help" :: flag --"all" - O.string - } :: runs[CommitConfig] { config => if (config.all) { println(s"Commited all ${config.message}!") } else { println(s"Commited ${config.message}!") } } } val rmCommand = cmd("rm") { takesG[File] { O.help --"help" :: file -~ des("File to remove from git") } :: runs[File] { f => println(s"Removed file ${f.getAbsolutePath} from git") } } val remoteCommand = cmd("remote") { takes(O.help --"help") :: cmd("add") { takesT { O.help --"help" :: string -~ des("Remote name") :: string -~ des("Remote url") } :: runs[(String, String)] { case (s, u) => println(s"Remote $s $u added") } } :: cmd("rm") { takesG[String] { O.help --"help" :: string -~ des("Remote name") } :: runs[String] { s => println(s"Remote $s removed") } } } val git = cmd("git", des("Version control system")) { takes(help --"help" :: version --"version" -~ value("v1.0")) :: commitCommand :: rmCommand :: remoteCommand } val res = runCommandOrFail(git)(args).run }
def main(args: Array[String]) { val cli = args.map(_.split("=") match { case Array(k, v) => k->v } ).toMap val saveAs = cli("saveAs") println(saveAs) }
val thestrings = Array("a","b","c") val joined = ??? println(joined)
def breakOut[From, T, To](implicit b : CanBuildFrom[Nothing, T, To]) = new CanBuildFrom[From, T, To] { def apply(from: From) = b.apply() ; def apply() = b.apply() }
> import scala.collection.breakOut > val map : Map[Int,String] = List("London", "Paris").map(x => (x.length, x))(breakOut) map: Map[Int,String] = Map(6 -> London, 5 -> Paris)
def map[B, That](f : (A) => B)(implicit bf : CanBuildFrom[Repr, B, That]) : That
def breakOut[From, T, To](implicit b : CanBuildFrom[Nothing, T, To]) = new CanBuildFrom[From, T, To] { def apply(from: From) = b.apply() ; def apply() = b.apply() }
From = List[String] T = (Int, String) To = Map[Int, String]
trait CanBuildFrom[-From, -Elem, +To] extends AnyRef
Map(1 -> "one", 2 -> "two") map Function.tupled(_ -> _.length) Map(1 -> "one", 2 -> "two") map (_._2)
trait TraversableLike[+A, +Repr] extends HasNewBuilder[A, Repr] with AnyRef def map[B, That](f : (A) => B)(implicit bf : CanBuildFrom[Repr, B, That]) : That
trait Map[A, +B] extends Iterable[(A, B)] with Map[A, B] with MapLike[A, B, Map[A, B]]
trait Map[A, +B] extends Iterable[(A, B)] with Map[A, B] with MapLike[A, B, Map[A, B]] trait MapLike[A, +B, +This <: MapLike[A, B, This] with Map[A, B]] extends MapLike[A, B, This] trait MapLike[A, +B, +This <: MapLike[A, B, This] with Map[A, B]] extends PartialFunction[A, B] with IterableLike[(A, B), This] with Subtractable[A, This] trait IterableLike[+A, +Repr] extends Equals with TraversableLike[A, Repr] trait TraversableLike[+A, +Repr] extends HasNewBuilder[A, Repr] with AnyRef
map Function.tupled(_ -> _.length): B = (Int, Int) map (_._2): B = String
implicit def canBuildFrom [A, B] : CanBuildFrom[Map, (A, B), Map[A, B]]
implicit def canBuildFrom [A] : CanBuildFrom[Iterable, A, Iterable[A]]
val map : Map[Int,String] = List("London", "Paris").map(x => (x.length, x))(breakOut) sealed abstract class List[+A] extends LinearSeq[A] with Product with GenericTraversableTemplate[A, List] with LinearSeqLike[A, List[A]] trait LinearSeqLike[+A, +Repr <: LinearSeqLike[A, Repr]] extends SeqLike[A, Repr] trait SeqLike[+A, +Repr] extends IterableLike[A, Repr] trait IterableLike[+A, +Repr] extends Equals with TraversableLike[A, Repr] trait TraversableLike[+A, +Repr] extends HasNewBuilder[A, Repr] with AnyRef def map[B, That](f : (A) => B)(implicit bf : CanBuildFrom[Repr, B, That]) : That
scala> import scala.collection.generic._ import scala.collection.generic._ scala> import scala.collection._ import scala.collection._ scala> import scala.collection.mutable._ import scala.collection.mutable._ scala> scala> def breakOut[From, T, To](implicit b : CanBuildFrom[Nothing, T, To]) = | new CanBuildFrom[From, T, To] { | def apply(from: From) = b.apply() ; def apply() = b.apply() | } breakOut: [From, T, To] | (implicit b: scala.collection.generic.CanBuildFrom[Nothing,T,To]) | java.lang.Object with | scala.collection.generic.CanBuildFrom[From,T,To] scala> val l = List(1, 2, 3) l: List[Int] = List(1, 2, 3) scala> val imp = l.map(_ + 1)(breakOut) imp: scala.collection.immutable.IndexedSeq[Int] = Vector(2, 3, 4) scala> val arr: Array[Int] = l.map(_ + 1)(breakOut) imp: Array[Int] = Array(2, 3, 4) scala> val stream: Stream[Int] = l.map(_ + 1)(breakOut) stream: Stream[Int] = Stream(2, ?) scala> val seq: Seq[Int] = l.map(_ + 1)(breakOut) seq: scala.collection.mutable.Seq[Int] = ArrayBuffer(2, 3, 4) scala> val set: Set[Int] = l.map(_ + 1)(breakOut) seq: scala.collection.mutable.Set[Int] = Set(2, 4, 3) scala> val hashSet: HashSet[Int] = l.map(_ + 1)(breakOut) seq: scala.collection.mutable.HashSet[Int] = Set(2, 4, 3)
scala> def buildWith[From, T, To](b : Builder[T, To]) = | new CanBuildFrom[From, T, To] { | def apply(from: From) = b ; def apply() = b | } buildWith: [From, T, To] | (b: scala.collection.mutable.Builder[T,To]) | java.lang.Object with | scala.collection.generic.CanBuildFrom[From,T,To] scala> val a = l.map(_ + 1)(buildWith(Array.newBuilder[Int])) a: Array[Int] = Array(2, 3, 4)
Seq.map[B, That](f: (A) -> B)(implicit bf: CanBuildFrom[Seq[A], B, That]): That
val x: Map[String, Int] = Seq("A", "BB", "CCC").map(s => (s, s.length))
error: type mismatch; found : Seq[(String, Int)] required: Map[String,Int]
def breakOut[From, T, To](implicit b: CanBuildFrom[Nothing, T, To]): CanBuildFrom[From, T, To] = new CanBuildFrom[From, T, To] { def apply(from: From) = b.apply() def apply() = b.apply() }
val x: Map[String, Int] = Seq("A", "BB", "CCC").map(s => (s, s.length))(collection.breakOut)
scala> import collection.breakOut import collection.breakOut scala> val set = Set(1, 2, 3, 4) set: scala.collection.immutable.Set[Int] = Set(1, 2, 3, 4) scala> set.map(_ % 2) res0: scala.collection.immutable.Set[Int] = Set(1, 0) scala> val seq:Seq[Int] = set.map(_ % 2)(breakOut) seq: Seq[Int] = Vector(1, 0, 1, 0)
object Currency extends Enumeration { val GBP = Value("GBP") val EUR = Value("EUR") }
sealed trait Currency { def name: String } case object EUR extends Currency { val name = "EUR" } case class UnknownCurrency(name: String) extends Currency
trade.ccy match { case EUR => case UnknownCurrency(code) => }
trait Enum[A] { trait Value { self: A => } val values: List[A] } sealed trait Currency extends Currency.Value object Currency extends Enum[Currency] { case object EUR extends Currency case object GBP extends Currency val values = List(EUR, GBP) }
trait Enum[A <: {def name: String}] { trait Value { self: A => _values :+= this } private var _values = List.empty[A] def values = _values } sealed abstract class Currency(val name: String) extends Currency.Value object Currency extends Enum[Currency] { val EUR = new Currency("EUR") {} val GBP = new Currency("GBP") {} }
trait Enum[A] { trait Value { self: A => _values :+= this } private var _values = List.empty[A] def values = _values } sealed trait Currency extends Currency.Value object Currency extends Enum[Currency] { case object EUR extends Currency case object GBP extends Currency }
object Currency extends Enum[Currency] sealed trait Currency extends Currency.Value case object EUR extends Currency case object GBP extends Currency
public enum ChessPiece { KING( , QUEEN( , BISHOP( , KNIGHT( , ROOK( , PAWN( ; private char character; private int pointValue; private ChessPiece(char character, int pointValue) { this.character = character; this.pointValue = pointValue; } public int getCharacter() { return character; } public int getPointValue() { return pointValue; } }
sealed trait ChessPiece {def character: Char; def pointValue: Int} object ChessPiece { case object KING extends ChessPiece {val character = case object QUEEN extends ChessPiece {val character = case object BISHOP extends ChessPiece {val character = case object KNIGHT extends ChessPiece {val character = case object ROOK extends ChessPiece {val character = case object PAWN extends ChessPiece {val character = }
object ChessPiece extends Enumeration { val KING = ChessPieceVal( val QUEEN = ChessPieceVal( val BISHOP = ChessPieceVal( val KNIGHT = ChessPieceVal( val ROOK = ChessPieceVal( val PAWN = ChessPieceVal( protected case class ChessPieceVal(character: Char, pointValue: Int) extends super.Val() implicit def convert(value: Value) = value.asInstanceOf[ChessPieceVal] }
import scala.reflect.runtime.universe.{TypeTag,typeTag} import org.public_domain.scala.utils.EnumerationDecorated object ChessPiecesEnhancedDecorated extends EnumerationDecorated { case object KING extends Member case object QUEEN extends Member case object BISHOP extends Member case object KNIGHT extends Member case object ROOK extends Member case object PAWN extends Member val decorationOrderedSet: List[Decoration] = List( Decoration(KING, , Decoration(QUEEN, , Decoration(BISHOP, , Decoration(KNIGHT, , Decoration(ROOK, , Decoration(PAWN, ) final case class Decoration private[ChessPiecesEnhancedDecorated] (member: Member, char: Char, pointValue: Int) extends DecorationBase { val description: String = member.name.toLowerCase.capitalize } override def typeTagMember: TypeTag[_] = typeTag[Member] sealed trait Member extends MemberDecorated }
object DayOfWeek extends Enum { sealed abstract class Val extends EnumVal case object Mon extends Val; Mon() case object Tue extends Val; Tue() case object Wed extends Val; Wed() case object Thu extends Val; Thu() case object Fri extends Val; Fri() case object Sat extends Val; Sat() case object Sun extends Val; Sun() }
object DayOfWeekTest extends App { println( DayOfWeek.valuesById ) println( DayOfWeek.valuesByName ) DayOfWeek.values foreach { v => println( v.id + " = " + v ) } println( DayOfWeek.values.sorted mkString ", " ) println( DayOfWeek.values.sortBy(_.toString) mkString ", " ) println( DayOfWeek("Tue") ) println( DayOfWeek("Xyz") ) println( DayOfWeek(3) ) println( DayOfWeek(9) ) import DayOfWeek._ println( Tue < Fri ) def aufDeutsch( day: DayOfWeek.Val ) = day match { case Mon => "Montag" case Tue => "Dienstag" case Wed => "Mittwoch" case Thu => "Donnerstag" case Fri => "Freitag" } }
DayOfWeekTest.scala:31: warning: match is not exhaustive! missing combination Sat missing combination Sun def aufDeutsch( day: DayOfWeek.Val ) = day match { ^ one warning found
Map(0 -> Mon, 5 -> Sat, 1 -> Tue, 6 -> Sun, 2 -> Wed, 3 -> Thu, 4 -> Fri) Map(Thu -> Thu, Sat -> Sat, Tue -> Tue, Sun -> Sun, Mon -> Mon, Wed -> Wed, Fri -> Fri) 0 = Mon 1 = Tue 2 = Wed 3 = Thu 4 = Fri 5 = Sat 6 = Sun Mon, Tue, Wed, Thu, Fri, Sat, Sun Fri, Mon, Sat, Sun, Thu, Tue, Wed Some(Tue) None Some(Thu) None true
abstract class Enum { type Val <: EnumVal protected var nextId: Int = 0 private var values_ = List[Val]() private var valuesById_ = Map[Int ,Val]() private var valuesByName_ = Map[String,Val]() def values = values_ def valuesById = valuesById_ def valuesByName = valuesByName_ def apply( id : Int ) = valuesById .get(id ) def apply( name: String ) = valuesByName.get(name) protected abstract class EnumVal extends Ordered[Val] { val theVal = this.asInstanceOf[Val] val id = nextId def bumpId { nextId += 1 } def compare( that:Val ) = this.id - that.id def apply() { if ( valuesById_.get(id) != None ) throw new Exception( "cannot init " + this + " enum value twice" ) bumpId values_ ++= List(theVal) valuesById_ += ( id -> theVal ) valuesByName_ += ( toString -> theVal ) } } }
object DayOfWeek extends Enum { sealed abstract class Val( val isWeekday:Boolean = true ) extends EnumVal { def isWeekend = !isWeekday val abbrev = toString take 3 } case object Monday extends Val; Monday() case object Tuesday extends Val; Tuesday() case object Wednesday extends Val; Wednesday() case object Thursday extends Val; Thursday() case object Friday extends Val; Friday() nextId = -2 case object Saturday extends Val(false); Saturday() case object Sunday extends Val(false); Sunday() val (weekDays,weekendDays) = values partition (_.isWeekday) }
@enum sealed trait Toggle case object ON extends Toggle case object OFF extends Toggle
trait CaseEnumValue { def name:String } trait CaseEnum { type V <: CaseEnumValue def values:List[V] def unapply(name:String):Option[String] = { if (values.exists(_.name == name)) Some(name) else None } def unapply(value:V):String = { return value.name } def apply(name:String):Option[V] = { values.find(_.name == name) } }
abstract class Currency(override name:String) extends CaseEnumValue { } object Currency extends CaseEnum { type V = Site case object EUR extends Currency("EUR") case object GBP extends Currency("GBP") var values = List(EUR, GBP) }
object OutboundMarketMakerEntryPointType extends Enumeration { type OutboundMarketMakerEntryPointType = Value val Alpha, Beta = Value }
sealed trait OutboundMarketMakerEntryPointType case object AlphaEntryPoint extends OutboundMarketMakerEntryPointType case object BetaEntryPoint extends OutboundMarketMakerEntryPointType
object DbInstrumentQueries { def instrumentExtractor(tableAlias: String = "s")(rs: ResultSet): Instrument = { val symbol = rs.getString(tableAlias + ".name") val quoteCurrency = rs.getString(tableAlias + ".quote_currency") val fixRepresentation = rs.getString(tableAlias + ".fix_representation") val pointsValue = rs.getInt(tableAlias + ".points_value") val instrumentType = InstrumentType.fromString(rs.getString(tableAlias +".instrument_type")) val productType = ProductType.fromString(rs.getString(tableAlias + ".product_type")) Instrument(symbol, fixRepresentation, quoteCurrency, pointsValue, instrumentType, productType) } } object InstrumentType { def fromString(instrumentType: String): InstrumentType = Seq(CurrencyPair, Metal, CFD) .find(_.toString == instrumentType).get } object ProductType { def fromString(productType: String): ProductType = Seq(Commodity, Currency, Index) .find(_.toString == productType).get }
object DbInstrumentQueries { def instrumentExtractor(tableAlias: String = "s")(rs: ResultSet): Instrument = { val symbol = rs.getString(tableAlias + ".name") val quoteCurrency = rs.getString(tableAlias + ".quote_currency") val fixRepresentation = rs.getString(tableAlias + ".fix_representation") val pointsValue = rs.getInt(tableAlias + ".points_value") val instrumentType = InstrumentType.withNameString(rs.getString(tableAlias + ".instrument_type")) val productType = ProductType.withName(rs.getString(tableAlias + ".product_type")) Instrument(symbol, fixRepresentation, quoteCurrency, pointsValue, instrumentType, productType) } }
/** * Enum for Genre. It contains the type, objects, elements set and parse method. * * This approach supports: * * - Pattern matching * - Parse from name * - Get all elements */ object Genre { sealed trait Genre case object MALE extends Genre case object FEMALE extends Genre val elements = Set (MALE, FEMALE) def apply (code: String) = if (MALE.toString == code) MALE else if (FEMALE.toString == code) FEMALE else throw new IllegalArgumentException } /** * Enum usage (and tests). */ object GenreTest extends App { import Genre._ val m1 = MALE val m2 = Genre ("MALE") assert (m1 == m2) assert (m1.toString == "MALE") val f1 = FEMALE val f2 = Genre ("FEMALE") assert (f1 == f2) assert (f1.toString == "FEMALE") try { Genre (null) assert (false) } catch { case e: IllegalArgumentException => assert (true) } try { Genre ("male") assert (false) } catch { case e: IllegalArgumentException => assert (true) } Genre.elements.foreach { println } }
trait Enum[A] { trait Value { self: A => _values :+= this } private var _values = List.empty[A] def values = _values } sealed trait Currency extends Currency.Value object Currency extends Enum[Currency] { case object EUR extends Currency; EUR case object GBP extends Currency; GBP }
someEnum match { ENUMA => makeThis() ENUMB => makeThat() }
def someCode[SomeCaseClass](implicit val maker: Maker[SomeCaseClass]){ maker.make() } implicit val makerA = new Maker[CaseClassA]{ def make() = ... } implicit val makerB = new Maker[CaseClassB]{ def make() = ... }
scala> object A defined module A scala> case object B defined module B scala> import java.io._ import java.io._ scala> val bos = new ByteArrayOutputStream bos: java.io.ByteArrayOutputStream = scala> val oos = new ObjectOutputStream(bos) oos: java.io.ObjectOutputStream = java.io.ObjectOutputStream@e7da60 scala> oos.writeObject(B) scala> oos.writeObject(A) java.io.NotSerializableException: A$
def something() = { println("calling something") 1 }
def callByValue(x: Int) = { println("x1=" + x) println("x2=" + x) } def callByName(x: => Int) = { println("x1=" + x) println("x2=" + x) }
scala> callByValue(something()) calling something x1=1 x2=1 scala> callByName(something()) calling something x1=1 calling something x2=1
def callByName(x: => Int) = { println("x1=" + x) println("x2=" + x) }
scala> callByName(something()) calling something x1=1 calling something x2=1
def callAlsoByName(x: () => Int) = { println("x1=" + x()) println("x2=" + x()) }
callAlsoByName(() => {something()}) calling something x1=1 calling something x2=1
object main { def main(args: Array[String]) { def onTime(time: Long) { while(time != time) println("Time to Nag!") println("no nags for you!") } def onRealtime(time: => Long) { while(time != time) println("Realtime Nagging executed!") } onTime(System.nanoTime()) onRealtime(System.nanoTime()) } }
object Test { def main(args: Array[String]) { delayed(time()); } def time() = { println("Getting time in nano seconds") System.nanoTime } def delayed( t: => Long ) = { println("In delayed method") println("Param: " + t) t } }
def something() = { println("calling something") 1 }
def callByName(x: => Int) = { println("x1=" + x) println("x2=" + x) }
scala> callByName(something()) calling something x1=1 calling something x2=1
/** * Executes some code block and prints to stdout the time taken to execute the block for interactive testing and debugging. */ def time[T](f: => T): T = { val start = System.nanoTime() val ret = f val end = System.nanoTime() println(s"Time taken: ${(end - start) / 1000 / 1000} ms") ret }
protected def logInfo(msg: => String) { if (log.isInfoEnabled) log.info(msg) }
def returnOne(x: Int, y: => Int): Int = 1 def loop(x: Int): Int = loop(x) returnOne(2, loop(2)) returnOne(loop(2), 2)
def first(a: Int, b: Int): Int = a first(3 + 4, 5 + 6)
def first1(a: Int, b: => Int): Int = a first1(3 + 4, 5 + 6)
object Demo { def main(args: Array[String]) { delayed(time()); } def time() = { println("Getting time in nano seconds") System.nanoTime } def delayed( t: => Long ) = { println("In delayed method") println("Param: " + t) } }
Def test(x:Int, y:Int) = x * x Def test(x: => Int, y: => Int) = x * x
call-by-value: test(3+4,8) → test(7,8) → 7 * 7 → 49 call-by-name: (3+4)*(3+4) → 7 * (3+4) → 7 * 7 → 49
call-by-value: test(7, 2*4) → test(7,8) → 7 * 7 → 49 call-by-name: (7)*(7) → 49
call-by-value: test(7, 2*4) → test(7,8) → 7 * 7 → 49 call-by-name: (3+4)*(3+4) → 7*(3+4) → 7*7 → 49
def something() = { println("calling something") 1 }
def callByValue(x: Int) = { println("x1=" + x) println("x2=" + x) } def callByName(x: => Int) = { println("x1=" + x) println("x2=" + x) }
scala> callByValue(something()) calling something x1=1 x2=1 scala> callByName(something()) calling something x1=1 calling something x2=1
trait Logger { def info(msg: => String) def warn(msg: => String) def error(msg: => String) }
logger.info("Time spent on X: " + computeTimeSpent)
trait Boolean { def &&(other: => Boolean): Boolean = if (this) this else other }
def getTimeByName(f: => Long) = { println(f); Thread.sleep(1000); println(f)}
def getTimeByValue(f: Long) = { println(f); Thread.sleep(1000); println(f)}
object CallbyExample extends App { def CallbyValue(x: Long): Unit = { println("The current system time via CBV: " + x); println("The current system time via CBV " + x); } def CallbyName(x: => Long): Unit = { println("The current system time via CBN: " + x); println("The current system time via CBN: " + x); } CallbyValue(System.nanoTime()); println("\n") CallbyName(System.nanoTime()); }
The current system time via CBV: 1153969332591521 The current system time via CBV 1153969332591521 The current system time via CBN: 1153969336749571 The current system time via CBN: 1153969336856589
val start = Instant.now().toEpochMilli val calc = (x: Boolean) => { Thread.sleep(3000) x } def callByValue(x: Boolean, y: Boolean): Boolean = { if (!x) x else y } def callByName(x: Boolean, y: => Boolean): Boolean = { if (!x) x else y } new Thread(() => { println("========================") println("Call by Value " + callByValue(false, calc(true))) println("Time " + (Instant.now().toEpochMilli - start) + "ms") println("========================") }).start() new Thread(() => { println("========================") println("Call by Name " + callByName(false, calc(true))) println("Time " + (Instant.now().toEpochMilli - start) + "ms") println("========================") }).start() Thread.sleep(5000)
======================== Call by Name false Time 64ms ======================== Call by Value false Time 3068ms ========================
scala> def loop(x:Int) :Int = loop(x-1) loop: (x: Int)Int
scala> def callByName(x:Int,y: => Int)=x callByName: (x: Int, y: => Int)Int
scala> def callByValue(x:Int,y:Int) = x callByValue: (x: Int, y: Int)Int scala> callByValue(1,loop(1))
object NameVsVal extends App { def mul(x: Int, y: => Int) : Int = { println("mul") x * y } def add(x: Int, y: Int): Int = { println("add") x + y } println(mul(3, add(2, 1))) }
def f(x : Int, y :Int) = x f(12 + 3, 4 * 11) f(15, 4194304) 15
libraryDependencies += "com.typesafe.akka" %% "akka-stream" % "2.4.2"
import scala.concurrent._ import akka._ import akka.actor._ import akka.stream._ import akka.stream.scaladsl._ import akka.util._ implicit val system = ActorSystem("TestSystem") implicit val materializer = ActorMaterializer() import system.dispatcher
scala> val s = Source.empty s: akka.stream.scaladsl.Source[Nothing,akka.NotUsed] = ... scala> val s = Source.single("single element") s: akka.stream.scaladsl.Source[String,akka.NotUsed] = ... scala> val s = Source(1 to 3) s: akka.stream.scaladsl.Source[Int,akka.NotUsed] = ... scala> val s = Source(Future("single value from a Future")) s: akka.stream.scaladsl.Source[String,akka.NotUsed] = ... scala> s runForeach println res0: scala.concurrent.Future[akka.Done] = ... single value from a Future
scala> val s = Source.repeat(5) s: akka.stream.scaladsl.Source[Int,akka.NotUsed] = ... scala> s take 3 runForeach println res1: scala.concurrent.Future[akka.Done] = ... 5 5 5
def run(actor: ActorRef) = { Future { Thread.sleep(300); actor ! 1 } Future { Thread.sleep(200); actor ! 2 } Future { Thread.sleep(100); actor ! 3 } } val s = Source .actorRef[Int](bufferSize = 0, OverflowStrategy.fail) .mapMaterializedValue(run) scala> s runForeach println res1: scala.concurrent.Future[akka.Done] = ... 3 2 1
scala> val source = Source(1 to 3) source: akka.stream.scaladsl.Source[Int,akka.NotUsed] = ... scala> val sink = Sink.foreach[Int](elem => println(s"sink received: $elem")) sink: akka.stream.scaladsl.Sink[Int,scala.concurrent.Future[akka.Done]] = ... scala> val flow = source to sink flow: akka.stream.scaladsl.RunnableGraph[akka.NotUsed] = ... scala> flow.run() res3: akka.NotUsed = NotUsed sink received: 1 sink received: 2 sink received: 3
val actor = system.actorOf(Props(new Actor { override def receive = { case msg => println(s"actor received: $msg") } })) scala> val sink = Sink.actorRef[Int](actor, onCompleteMessage = "stream completed") sink: akka.stream.scaladsl.Sink[Int,akka.NotUsed] = ... scala> val runnable = Source(1 to 3) to sink runnable: akka.stream.scaladsl.RunnableGraph[akka.NotUsed] = ... scala> runnable.run() res3: akka.NotUsed = NotUsed actor received: 1 actor received: 2 actor received: 3 actor received: stream completed
scala> val source = Source(1 to 3) source: akka.stream.scaladsl.Source[Int,akka.NotUsed] = ... scala> val sink = Sink.foreach[Int](println) sink: akka.stream.scaladsl.Sink[Int,scala.concurrent.Future[akka.Done]] = ... scala> val invert = Flow[Int].map(elem => elem * -1) invert: akka.stream.scaladsl.Flow[Int,Int,akka.NotUsed] = ... scala> val doubler = Flow[Int].map(elem => elem * 2) doubler: akka.stream.scaladsl.Flow[Int,Int,akka.NotUsed] = ... scala> val runnable = source via invert via doubler to sink runnable: akka.stream.scaladsl.RunnableGraph[akka.NotUsed] = ... scala> runnable.run() res10: akka.NotUsed = NotUsed -2 -4 -6
scala> val s1 = Source(1 to 3) via invert to sink s1: akka.stream.scaladsl.RunnableGraph[akka.NotUsed] = ... scala> val s2 = Source(-3 to -1) via invert to sink s2: akka.stream.scaladsl.RunnableGraph[akka.NotUsed] = ... scala> s1.run() res10: akka.NotUsed = NotUsed -1 -2 -3 scala> s2.run() res11: akka.NotUsed = NotUsed 3 2 1
val source: Source[Int, NotUsed] = Source(1 to 3) val sink: Sink[Int, Future[Done]] = Sink.foreach[Int](println) val flow: Flow[Int, Int, NotUsed] = Flow[Int].map(x => x)
val multiClickStream = clickStream .throttle(250.millis) .map(clickEvents => clickEvents.length) .filter(numberOfClicks => numberOfClicks >= 2)
val multiClickStream = clickStream.throttle(250.millis).map(_.length).filter(_ >= 2)
def mkServer(address: String, port: Int)(implicit system: ActorSystem, materializer: Materializer): Unit = { import system.dispatcher val connectionHandler: Sink[Tcp.IncomingConnection, Future[Unit]] = Sink.foreach[Tcp.IncomingConnection] { conn => println(s"Incoming connection from: ${conn.remoteAddress}") conn.handleWith(serverLogic) } val incomingCnnections: Source[Tcp.IncomingConnection, Future[Tcp.ServerBinding]] = Tcp().bind(address, port) val binding: Future[Tcp.ServerBinding] = incomingCnnections.to(connectionHandler).run() binding onComplete { case Success(b) => println(s"Server started, listening on: ${b.localAddress}") case Failure(e) => println(s"Server could not be bound to $address:$port: ${e.getMessage}") } }
val serverLogic: Flow[ByteString, ByteString, Unit] = { val delimiter = Framing.delimiter( ByteString("\n"), maximumFrameLength = 256, allowTruncation = true) val receiver = Flow[ByteString].map { bytes => val message = bytes.utf8String println(s"Server received: $message") message } val responder = Flow[String].map { message => val answer = s"Server hereby responds to message: $message\n" ByteString(answer) } Flow[ByteString] .via(delimiter) .via(receiver) .via(responder) }
val serverLogic = Flow[ByteString] .via(Framing.delimiter( ByteString("\n"), maximumFrameLength = 256, allowTruncation = true)) .map(_.utf8String) .map(msg => s"Server hereby responds to message: $msg\n") .map(ByteString(_))
$ $ echo "Hello World\nHow are you?" | netcat 127.0.0.1 6666 Server hereby responds to message: Hello World Server hereby responds to message: How are you?
$ $ ./startServer 127.0.0.1 6666 [DEBUG] Server started, listening on: /127.0.0.1:6666 [DEBUG] Incoming connection from: /127.0.0.1:37972 [DEBUG] Server received: Hello World [DEBUG] Server received: How are you?
val connection = Tcp().outgoingConnection(address, port) val flow = Flow[ByteString] .via(Framing.delimiter( ByteString("\n"), maximumFrameLength = 256, allowTruncation = true)) .map(_.utf8String) .map(println) .map(_ ⇒ StdIn.readLine("> ")) .map(_+"\n") .map(ByteString(_)) connection.join(flow).run()
val closeConnection = new GraphStage[FlowShape[String, String]] { val in = Inlet[String]("closeConnection.in") val out = Outlet[String]("closeConnection.out") override val shape = FlowShape(in, out) override def createLogic(inheritedAttributes: Attributes) = new GraphStageLogic(shape) { setHandler(in, new InHandler { override def onPush() = grab(in) match { case "q" ⇒ push(out, "BYE") completeStage() case msg ⇒ push(out, s"Server hereby responds to message: $msg\n") } }) setHandler(out, new OutHandler { override def onPull() = pull(in) }) } }
def serverLogic (conn: Tcp.IncomingConnection) (implicit system: ActorSystem) : Flow[ByteString, ByteString, NotUsed] = Flow.fromGraph(GraphDSL.create() { implicit b ⇒ import GraphDSL.Implicits._ val welcome = Source.single(ByteString(s"Welcome port ${conn.remoteAddress}!\n")) val logic = b.add(internalLogic) val concat = b.add(Concat[ByteString]()) welcome ~> concat.in(0) logic.outlet ~> concat.in(1) FlowShape(logic.in, concat.out) })
def even: Int => Boolean = _ % 2 == 0 even eq even val even: Int => Boolean = _ % 2 == 0 even eq even
val test: () => Int = { val r = util.Random.nextInt () => r } test() test() def test: () => Int = { val r = util.Random.nextInt () => r } test() test()
scala> val even: Int => Boolean = ??? scala.NotImplementedError: an implementation is missing scala> def even: Int => Boolean = ??? even: Int => Boolean scala> even scala.NotImplementedError: an implementation is missing
scala> lazy val even: Int => Boolean = ??? even: Int => Boolean = <lazy> scala> even scala.NotImplementedError: an implementation is missing
lazy val even: Int => Boolean = _ % 2 == 0 even eq even lazy val test: () => Int = { val r = util.Random.nextInt () => r } test() test()
scala> def even: (Int => Boolean) = { println("def"); (x => x % 2 == 0) } even: Int => Boolean scala> val even2: (Int => Boolean) = { println("val"); (x => x % 2 == 0) } val even2: Int => Boolean = <function1> scala> even(1) def res9: Boolean = false scala> even2(1) res10: Boolean = false
scala> import scala.util.Random import scala.util.Random scala> val x = { Random.nextInt } x: Int = -1307706866 scala> x res0: Int = -1307706866 scala> x res1: Int = -1307706866
scala> lazy val y = { Random.nextInt } y: Int = <lazy> scala> y res4: Int = 323930673 scala> y res5: Int = 323930673
val even2: (Int => Boolean) = { println("val"); (x => x % 2 == 0) }
scala> even2(2) res7: Boolean = true scala> even2(3) res8: Boolean = false
scala> val even2: (Int => Boolean) = { | println("val"); | (x => { | println("inside final fn") | x % 2 == 0 | }) | }
scala> even2(3) inside final fn res9: Boolean = false scala> even2(2) inside final fn res10: Boolean = true scala>
def test1: Int => Int = { x => x } --test1: test1[] => Int => Int def test2(): Int => Int = { x => x+1 } --test2: test2[]() => Int => Int def test3(): Int = 4 --test3: test3[]() => Int
scala> def even: Int => Boolean = { _% 2 == 0 } even: Int => Boolean scala> val even: Int => Boolean = { _% 2 == 0 } even: Int => Boolean = $$Lambda$1157/1017502292@57a0aeb8
g match { case g2: Graphics2D => g2 case _ => throw new ClassCastException }
case class Persona(serviceName : String, serviceId : String, sentMessages : Set[String]) val newPersona = Persona(existingPersona.serviceName, existingPersona.serviceId, existingPersona.sentMessages + newMessage)
val newPersona = existingPersona.copy(sentMessages = existingPersona.sentMessages + newMessage)
val newPersona = existingPersona.copy(sentMessages = existing.sentMessages + newMessage)
case class Persona( svcName : String, svcId : String, sentMsgs : Set[String] ) { def plusMsg(msg: String) = this.copy(sentMsgs = this.sentMsgs + msg) }
existingPersona.copy(sentMessages = existingPersona.sentMessages + newMessage)
List(1,2,3) :+ 4 Results in List[Int] = List(1, 2, 3, 4)
scala> import scala.collection.mutable.ListBuffer import scala.collection.mutable.ListBuffer scala> var fruits = new ListBuffer[String]() fruits: scala.collection.mutable.ListBuffer[String] = ListBuffer() scala> fruits += "Apple" res0: scala.collection.mutable.ListBuffer[String] = ListBuffer(Apple) scala> fruits += "Banana" res1: scala.collection.mutable.ListBuffer[String] = ListBuffer(Apple, Banana) scala> fruits += "Orange" res2: scala.collection.mutable.ListBuffer[String] = ListBuffer(Apple, Banana, Orange) scala> val fruitsList = fruits.toList fruitsList: List[String] = List(Apple, Banana, Orange)
scala> val x=List(1,2,3) x: List[Int] = List(1, 2, 3) scala> val y=x:::4::Nil y: List[Int] = List(1, 2, 3, 4)
var l = List(1,2,3) l=l:+4 Result : 1 2 3 4 var ar = Array(4,5,6) for(x<-ar) { l=l:+x} l.foreach(println) Result:1 2 3 4 5 6
var l = List[Int]() for(x<-ar) { l=x::l } l.foreach(println) Result:6 5 4 1 2 3
object working extends App { val list = List(1,2,3) val rddList = Spark.ctx.parallelize(list) val after = rddList.map(someFunc(_)) def someFunc(a:Int) = a+1 after.collect().map(println(_)) }
object NOTworking extends App { new testing().doIT } class testing { val list = List(1,2,3) val rddList = Spark.ctx.parallelize(list) def doIT = { val after = rddList.map(someFunc(_)) after.collect().map(println(_)) } def someFunc(a:Int) = a+1 }
import org.apache.spark.{SparkContext,SparkConf} object Spark { val ctx = new SparkContext(new SparkConf().setAppName("test").setMaster("local[*]")) } object NOTworking extends App { new Test().doIT } class Test extends java.io.Serializable { val rddList = Spark.ctx.parallelize(List(1,2,3)) def doIT() = { val after = rddList.map(someFunc) after.collect().foreach(println) } def someFunc(a: Int) = a + 1 }
import org.apache.spark.{SparkContext,SparkConf} object Spark { val ctx = new SparkContext(new SparkConf().setAppName("test").setMaster("local[*]")) } object NOTworking extends App { new Test().doIT } class Test { val rddList = Spark.ctx.parallelize(List(1,2,3)) def doIT() = { val after = rddList.map(someFunc) after.collect().foreach(println) } val someFunc = (a: Int) => a + 1 }
Serialization stack: - object not serializable (class: testing, value: testing@2dfe2f00) - field (class: testing$$anonfun$1, name: $outer, type: class testing) - object (class testing$$anonfun$1, <function1>)
def genMapper[A, B](f: A => B): A => B = { val locker = com.twitter.chill.MeatLocker(f) x => locker.get.apply(x) }
@transient val rddList = Spark.ctx.parallelize(list)
def genMapper(kryoWrapper: KryoSerializationWrapper[(Foo => Bar)]) (foo: Foo) : Bar = { kryoWrapper.value.apply(foo) } val mapper = genMapper(KryoSerializationWrapper(new Blah(abc))) _ rdd.flatMap(mapper).collectAsMap() object Blah(abc: ABC) extends (Foo => Bar) { def apply(foo: Foo) : Bar = { }
object NOTworking extends App { new testing().doIT } class testing { val list = List(1,2,3) val rddList = Spark.ctx.parallelize(list) def doIT = { val after = rddList.map(someFunc(_)) after.collect().map(println(_)) } def someFunc(a:Int) = a+1 }
def doIT = { def someFunc(a:Int) = a+1 } val after = rddList.map(someFunc(_)) after.collect().map(println(_)) }
case class Foo[A](a:A) { def getStringLength(implicit evidence: A =:= String) = a.length }
scala> Foo(123).getStringLength <console>:9: error: could not find implicit value for parameter evidence: =:=[Int,String]
def getStringLength(implicit evidence: A =:= String)
def smaller = if (first < second) first else second
class Pair[T <: Ordered[T]](val first: T, val second: T)
def smaller(implicit ev: T <:< Ordered[T]) = if (first < second) first else second
/** * Joins an <code>Either</code> through <code>Right</code>. */ def joinRight[A1 >: A, B1 >: B, C](implicit ev: B1 <:< Either[A1, C]): Either[A1, C] = this match { case Left(a) => Left(a) case Right(b) => b } /** * Joins an <code>Either</code> through <code>Left</code>. */ def joinLeft[A1 >: A, B1 >: B, C](implicit ev: A1 <:< Either[C, B1]): Either[C, B1] = this match { case Left(a) => a case Right(b) => Right(b) }
def orNull[A1 >: A](implicit ev: Null <:< A1): A1 = this getOrElse null
Pimped Type | Conversion Method | Returned Type ================================================================================================= scala.collection.Iterator | asJava | java.util.Iterator scala.collection.Iterator | asJavaEnumeration | java.util.Enumeration scala.collection.Iterable | asJava | java.lang.Iterable scala.collection.Iterable | asJavaCollection | java.util.Collection scala.collection.mutable.Buffer | asJava | java.util.List scala.collection.mutable.Seq | asJava | java.util.List scala.collection.Seq | asJava | java.util.List scala.collection.mutable.Set | asJava | java.util.Set scala.collection.Set | asJava | java.util.Set scala.collection.mutable.Map | asJava | java.util.Map scala.collection.Map | asJava | java.util.Map scala.collection.mutable.Map | asJavaDictionary | java.util.Dictionary scala.collection.mutable.ConcurrentMap | asJavaConcurrentMap | java.util.concurrent.ConcurrentMap ————————————————————————————————————————————————————————————————————————————————————————————————— java.util.Iterator | asScala | scala.collection.Iterator java.util.Enumeration | asScala | scala.collection.Iterator java.lang.Iterable | asScala | scala.collection.Iterable java.util.Collection | asScala | scala.collection.Iterable java.util.List | asScala | scala.collection.mutable.Buffer java.util.Set | asScala | scala.collection.mutable.Set java.util.Map | asScala | scala.collection.mutable.Map java.util.concurrent.ConcurrentMap | asScala | scala.collection.mutable.ConcurrentMap java.util.Dictionary | asScala | scala.collection.mutable.Map java.util.Properties | asScala | scala.collection.mutable.Map[String, String]
List<String> javaList = new ArrayList<String>(Arrays.asList("a", "b", "c")); System.out.println(javaList); Buffer<String> scalaBuffer = JavaConversions.asScalaBuffer(javaList); System.out.println(scalaBuffer); List<String> javaListAgain = JavaConversions.bufferAsJavaList(scalaBuffer); System.out.println(javaList == javaListAgain);
object MacroExample extends ReflectionUtils { import scala.language.experimental.macros import scala.reflect.macros.Context def foo(name: String): Any = macro foo_impl def foo_impl(c: Context)(name: c.Expr[String]) = { import c.universe._ val Literal(Constant(lit: String)) = name.tree val anon = newTypeName(c.fresh) c.Expr(Block( ClassDef( Modifiers(Flag.FINAL), anon, Nil, Template( Nil, emptyValDef, List( constructor(c.universe), TypeDef(Modifiers(), newTypeName(lit), Nil, TypeTree(typeOf[Int])) ) ) ), Apply(Select(New(Ident(anon)), nme.CONSTRUCTOR), Nil) )) } }
scala> MacroExample.foo("T") res0: AnyRef{type T = Int} = $1$$1@7da533f6
scala> implicitly[res0.T =:= Int] res1: =:=[res0.T,Int] = <function1>
def bar(name: String): Any = macro bar_impl def bar_impl(c: Context)(name: c.Expr[String]) = { import c.universe._ val Literal(Constant(lit: String)) = name.tree val anon = newTypeName(c.fresh) c.Expr(Block( ClassDef( Modifiers(Flag.FINAL), anon, Nil, Template( Nil, emptyValDef, List( constructor(c.universe), DefDef( Modifiers(), newTermName(lit), Nil, Nil, TypeTree(), c.literal(42).tree ) ) ) ), Apply(Select(New(Ident(anon)), nme.CONSTRUCTOR), Nil) )) }
scala> MacroExample.bar("test") res1: AnyRef = $1$$1@da12492
def baz(name: String): Any = macro baz_impl def baz_impl(c: Context)(name: c.Expr[String]) = { import c.universe._ val Literal(Constant(lit: String)) = name.tree val anon = newTypeName(c.fresh) val wrapper = newTypeName(c.fresh) c.Expr(Block( ClassDef( Modifiers(), anon, Nil, Template( Nil, emptyValDef, List( constructor(c.universe), DefDef( Modifiers(), newTermName(lit), Nil, Nil, TypeTree(), c.literal(42).tree ) ) ) ), ClassDef( Modifiers(Flag.FINAL), wrapper, Nil, Template(Ident(anon) :: Nil, emptyValDef, constructor(c.universe) :: Nil) ), Apply(Select(New(Ident(wrapper)), nme.CONSTRUCTOR), Nil) )) }
scala> MacroExample.baz("test") res0: AnyRef{def test: Int} = $2$$1@6663f834 scala> res0.test res1: Int = 42
object Mac { import scala.language.experimental.macros import scala.reflect.macros.Context def bar(name: String): Any = macro bar_impl def bar_impl(c: Context)(name: c.Expr[String]) = { import c.universe._ val anon = TypeName(c.freshName) val Literal(Constant(s: String)) = name.tree val A = TermName(s) val dmmy = TermName(c.freshName) val tree = q""" class $anon { def $A(i: Int): Int = 2 * i } val $dmmy = 0 new $anon """ c.Expr(tree) } }
def listWithSum(numbers: List[Int]) = numbers.foldLeft((List[Int](), 0)) { (resultingTuple, currentInteger) => (currentInteger :: resultingTuple._1, currentInteger + resultingTuple._2) }
List(1,3,5).foldLeft(0) { _ + _ } List(1,3,5).foldLeft(List[String]()) { (a, b) => b.toString :: a }
List(1,3,5).reduceLeft { (a, b) => println("a " + a + ", b " + b); a + b }
java.lang.UnsupportedOperationException: empty.reduceLeft
myList reduceLeftOption {(a,b) => a+b} match { case None => case Some(v) => println(v) }
abstract class List[T] { ... def reduceLeft(op: (T,T)=>T) : T = this match{ case Nil => throw new Error("Nil.reduceLeft") case x :: xs => (xs foldLeft x)(op) } def foldLeft[U](z: U)(op: (U,T)=>U): U = this match{ case Nil => z case x :: xs => (xs foldLeft op(z, x))(op) } }
object Bar { def foo(xs: Any*) = xs foreach { case _:String => println("str") case _:Int => println("int") case _ => throw new UglyRuntimeException() } }
object Bar { def foo(xs: (String or Int)*) = xs foreach { case _: String => println("str") case _: Int => println("int") } }
type or[L,R] = Either[L,R] implicit def l2Or[L,R](l: L): L or R = Left(l) implicit def r2Or[L,R](r: R): L or R = Right(r) object Bar { def foo(xs: (String or Int)*) = xs foreach { case Left(l) => println("str") case Right(r) => println("int") } }
class StringOrInt[T] object StringOrInt { implicit object IntWitness extends StringOrInt[Int] implicit object StringWitness extends StringOrInt[String] }
object Bar { def foo[T: StringOrInt](x: T) = x match { case _: String => println("str") case _: Int => println("int") } }
type ¬¬[A] = ¬[¬[A]] type |∨|[T, U] = { type λ[X] = ¬¬[X] <:< (T ∨ U) }
def size[T : (Int |∨| String) case i : Int => i case s : String => s.length }
def foo(xs: (String | Int)*) = xs foreach { case _: String => println("str") case _: Int => println("int") }
scala> def f[A](a: A)(implicit ev: (Int with String) <:< A) = a match { | case i: Int => i + 1 | case s: String => s.length | } f: [A](a: A)(implicit ev: <:<[Int with String,A])Int scala> f(3) res0: Int = 4 scala> f("hello") res1: Int = 5 scala> f(9.2) <console>:9: error: Cannot prove that Int with String <:< Double. f(9.2) ^
sealed trait Or[A, B] object Or { implicit def a2Or[A,B](a: A) = new Or[A, B] {} implicit def b2Or[A,B](b: B) = new Or[A, B] {} } object Bar { def foo[T <% String Or Int](x: T) = x match { case _: String => println("str") case _: Int => println("int") } }
object Union { import scala.language.higherKinds sealed trait ¬[-A] sealed trait TSet { type Compound[A] type Map[F[_]] <: TSet } sealed trait ∅ extends TSet { type Compound[A] = A type Map[F[_]] = ∅ } sealed trait ∨[T <: TSet, H] extends TSet { type Member[X] = T type Compound[A] = T type Map[F[_]] = T } def foo[A : (∅ ∨ String ∨ Int ∨ List[Int]) case s: String => "String" case i: Int => "Int" case l: List[_] => "List[Int]" } foo(42) foo("bar") foo(List(1, 2, 3)) foo(42d) foo[Any](???) }
abstract class NameOf[T] { def get : String } implicit object NameOfStr extends NameOf[String] { def get = "str" } implicit object NameOfInt extends NameOf[Int] { def get = "int" } def printNameOf[T](t:T)(implicit name : NameOf[T]) = println(name.get)
scala> printNameOf(1) int scala> printNameOf("sss") str scala> printNameOf(2.0f) <console>:10: error: could not find implicit value for parameter nameOf: NameOf[ Float] printNameOf(2.0f) ^
trait Inv[-X] type Or[U,T] = { type pf[X] = (Inv[U] with Inv[T]) <:< Inv[X] }
class A; class B extends A; class C extends B def foo[X : (B Or String) foo[B] foo[C] foo[String] foo[A] foo[Number]
def foo[X](implicit ev : (B with String) <:< X) = {}
trait Inv[-X] def foo[X](implicit ev : (Inv[B] with Inv[String]) <:< Inv[X]) = {}
trait Inv[-X] type BOrString[X] = (Inv[B] with Inv[String]) <:< Inv[X] def foo[X](implicit ev : BOrString[X]) = {}
trait Inv[-X] type Or[U,T] = { type pf[X] = (Inv[U] with Inv[T]) <:< Inv[X] }
type Or[U,T] = { type pf[X] = ((U => _) with (T => _)) <:< (X => _) }
implicit val x: Int = 0 def foo(a: List[Int])(implicit ignore: Int) { } implicit val y = "" def foo(a: List[String])(implicit ignore: String) { } foo(1::2::Nil) foo("a"::"b"::Nil)
sealed trait IntOrString case class IntOfIntOrString( v:Int ) extends IntOrString case class StringOfIntOrString( v:String ) extends IntOrString implicit def IntToIntOfIntOrString( v:Int ) = new IntOfIntOrString(v) implicit def StringToStringOfIntOrString( v:String ) = new StringOfIntOrString(v) object Int { def unapply( t : IntOrString ) : Option[Int] = t match { case v : IntOfIntOrString => Some( v.v ) case _ => None } } object String { def unapply( t : IntOrString ) : Option[String] = t match { case v : StringOfIntOrString => Some( v.v ) case _ => None } } def size( t : IntOrString ) = t match { case Int(i) => i case String(s) => s.length } scala> size("test") res0: Int = 4 scala> size(2) res1: Int = 2
sealed trait `Int or String` sealed trait `not an Int or String` sealed trait `Int|String`[T,E] case class `IntOf(Int|String)`( v:Int ) extends `Int|String`[Int,`Int or String`] case class `StringOf(Int|String)`( v:String ) extends `Int|String`[String,`Int or String`] case class `NotAn(Int|String)`[T]( v:T ) extends `Int|String`[T,`not an Int or String`] implicit def `IntTo(IntOf(Int|String))`( v:Int ) = new `IntOf(Int|String)`(v) implicit def `StringTo(StringOf(Int|String))`( v:String ) = new `StringOf(Int|String)`(v) implicit def `AnyTo(NotAn(Int|String))`[T]( v:T ) = new `NotAn(Int|String)`[T](v) def disjunction[T,E](x: `Int|String`[T,E])(implicit ev: E =:= `Int or String`) = x def negationOfDisjunction[T,E](x: `Int|String`[T,E])(implicit ev: E =:= `not an Int or String`) = x scala> disjunction(5) res0: Int|String[Int,Int or String] = IntOf(Int|String)(5) scala> disjunction("") res1: Int|String[String,Int or String] = StringOf(Int|String)() scala> disjunction(5.0) error: could not find implicit value for parameter ev: =:=[not an Int or String,Int or String] disjunction(5.0) ^ scala> negationOfDisjunction(5) error: could not find implicit value for parameter ev: =:=[Int or String,not an Int or String] negationOfDisjunction(5) ^ scala> negationOfDisjunction("") error: could not find implicit value for parameter ev: =:=[Int or String,not an Int or String] negationOfDisjunction("") ^ scala> negationOfDisjunction(5.0) res5: Int|String[Double,not an Int or String] = NotAn(Int|String)(5.0)
type ¬[A] = (() => A) => A type ∨[T, U] = ¬[T] with ¬[U] class D[-A](v: A) { def get[T](f: (() => T)) = v match { case x : ¬[T] => x(f) } } def size(t: D[Int ∨ String]) = t match { case x: D[¬[Int]] => x.get( () => 0 ) case x: D[¬[String]] => x.get( () => "" ) case x: D[¬[Double]] => x.get( () => 0.0 ) } implicit def neg[A](x: A) = new D[¬[A]]( (f: (() => A)) => x ) scala> size(5) res0: Any = 5 scala> size("") error: type mismatch; found : java.lang.String("") required: D[?[Int,String]] size("") ^ scala> size("hi" : D[¬[String]]) res2: Any = hi scala> size(5.0 : D[¬[Double]]) error: type mismatch; found : D[(() => Double) => Double] required: D[?[Int,String]] size(5.0 : D[?[Double]]) ^
scala> class D[-A](v: A) { def get[T](f: (() => T))(implicit e: A <:< ¬[T]) = v match { case x : ¬[T] => x(f) } } error: contravariant type A occurs in covariant position in type <:<[A,(() => T) => T] of value e def get[T](f: (() => T))(implicit e: A <:< ?[T]) = v match { ^
type ¬[A] = A => Nothing type ∨[T, U] = ¬[T] with ¬[U] class Super class Sub extends Super scala> implicitly[(Super ∨ String) <:< ¬[Super]] res0: <:<[?[Super,String],(Super) => Nothing] = scala> implicitly[(Super ∨ String) <:< ¬[Sub]] res2: <:<[?[Super,String],(Sub) => Nothing] = scala> implicitly[(Super ∨ String) <:< ¬[Any]] error: could not find implicit value for parameter e: <:<[?[Super,String],(Any) => Nothing] implicitly[(Super ? String) <:< ?[Any]] ^
scala> implicitly[D[¬[Sub]] <:< D[(Super ∨ String)]] error: could not find implicit value for parameter e: <:<[D[(() => Sub) => Sub],D[?[Super,String]]] implicitly[D[?[Sub]] <:< D[(Super ? String)]] ^
trait D[-A] scala> implicitly[D[D[Super]] <:< D[D[Super] with D[String]]] res0: <:<[D[D[Super]],D[D[Super] with D[String]]] = scala> implicitly[D[D[Sub]] <:< D[D[Super] with D[String]]] res1: <:<[D[D[Sub]],D[D[Super] with D[String]]] = scala> implicitly[D[D[Any]] <:< D[D[Super] with D[String]]] error: could not find implicit value for parameter e: <:<[D[D[Any]],D[D[Super] with D[String]]] implicitly[D[D[Any]] <:< D[D[Super] with D[String]]] ^
class D[-A] (v: A) { def get[T <: A] = v match { case x: T => x } } implicit def neg[A](x: A) = new D[D[A]]( new D[A](x) ) def size(t: D[D[Int] with D[String]]) = t match { case x: D[D[Int]] => x.get[D[Int]].get[Int] case x: D[D[String]] => x.get[D[String]].get[String] case x: D[D[Double]] => x.get[D[Double]].get[Double] }
def size(t: D[D[Super] with D[String]]) = t match { case x: D[D[Super]] => x.get[D[Super]].get[Super] case x: D[D[String]] => x.get[D[String]].get[String] } scala> size( new Super ) res7: Any = Super@1272e52 scala> size( new Sub ) res8: Any = Sub@1d941d7
type v[A,B] = Either[Option[A], Option[B]] private def L[A,B](a: A): v[A,B] = Left(Some(a)) private def R[A,B](b: B): v[A,B] = Right(Some(b)) implicit def a2[A,B](a: A): v[A,B] = L(a) implicit def b2[A,B](b: B): v[A,B] = R(b) implicit def a3[A,B,C](a: A): v[v[A,B],C] = L(a2(a)) implicit def b3[A,B,C](b: B): v[v[A,B],C] = L(b2(b)) implicit def a4[A,B,C,D](a: A): v[v[v[A,B],C],D] = L(a3(a)) implicit def b4[A,B,C,D](b: B): v[v[v[A,B],C],D] = L(b3(b)) implicit def a5[A,B,C,D,E](a: A): v[v[v[v[A,B],C],D],E] = L(a4(a)) implicit def b5[A,B,C,D,E](b: B): v[v[v[v[A,B],C],D],E] = L(b4(b)) type JsonPrimtives = (String v Int v Double) type ValidJsonPrimitive[A] = A => JsonPrimtives def test[A : ValidJsonPrimitive](x: A): A = x test("hi") test(9)
sealed class Expr case class Var (x: String) extends Expr case class Apply (f: Expr, e: Expr) extends Expr case class Lambda(x: String, e: Expr) extends Expr
def buildTree(data: List[Data2D]):Node ={ if(data.length == 1){ var point:Data2D = data[0] } return null }
scala> val l = List("a", "b", "c") scala> l.lift(1) Some("b") scala> l.lift(5) None
scala> val a = Array.ofDim[String](2, 3) a: Array[Array[String]] = Array(Array(null, null, null), Array(null, null, null)) scala> a(0) = Array("1","2","3") scala> a(1) = Array("4", "5", "6") scala> a Array[Array[String]] = Array(Array(1, 2, 3), Array(4, 5, 6))
scala> a.map(_(0)) Array[String] = Array(1, 4) scala> a.map(_.apply(0)) Array[String] = Array(1, 4) scala> a.map(a => a(0)) Array[String] = Array(1, 4) scala> a.map(_.lift(0)) Array[Option[String]] = Array(Some(1), Some(4)) scala> a.map(_.head) Array[String] = Array(1, 4)
def addChild(n: Node, newChild: Node) = n match { case Elem(prefix, label, attribs, scope, child @ _*) => Elem(prefix, label, attribs, scope, child ++ newChild : _*) case _ => error("Can only add children to elements!") }
new Elem(prefix: String, label: String, attributes: MetaData, scope: NamespaceBinding, child: Node*)
new Elem(prefix, label, attributes, scope, child1, child2, ... childN)
val x : Seq[Seq[Int]] = Seq(Seq(1),Seq(2)) def f(arg: Seq[Any]*) : Int = { arg.length } f(x) f(x:_*)
val abc = List("A", "B", "C") def add(res: String, x: String) = { println(s"op: $res + $x = ${res + x}") res + x } abc.reduceLeft(add) abc.foldLeft("z")(add) abc.scanLeft("z")(add)
def add(x: String, res: String) = { println(s"op: $x + $res = ${x + res}") x + res } abc.reduceRight(add) abc.foldRight("z")(add) abc.scanRight("z")(add)
val xs = List(1, 2, 3, 4) def minus(res: Int, x: Int) = { println(s"op: $res - $x = ${res - x}") res - x } xs.reduceLeft(minus) xs.foldLeft(0)(minus) xs.scanLeft(0)(minus)
def minus(x: Int, res: Int) = { println(s"op: $x - $res = ${x - res}") x - res } xs.reduceRight(minus) xs.foldRight(0)(minus) xs.scanRight(0)(minus)
object ScanFoldReduce extends App { val list = List("A","B","C","D","E") println("reduce (a+b) "+list.reduce((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" ") a+b })) println("reduceLeft (a+b) "+list.reduceLeft((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" ") a+b })) println("reduceLeft (b+a) "+list.reduceLeft((a,b)=>{ print("{"+a+","+b+"}=>"+ (b+a)+" " ) b+a })) println("reduceRight (a+b) "+list.reduceRight((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b })) println("reduceRight (b+a) "+list.reduceRight((a,b)=>{ print("{"+a+","+b+"}=>"+ (b+a)+" ") b+a })) println("scan "+list.scan("[")((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b })) println("scanLeft (a+b) "+list.scanLeft("[")((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b })) println("scanLeft (b+a) "+list.scanLeft("[")((a,b)=>{ print("{"+a+","+b+"}=>"+ (b+a)+" " ) b+a })) println("scanRight (a+b) "+list.scanRight("[")((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b })) println("scanRight (b+a) "+list.scanRight("[")((a,b)=>{ print("{"+a+","+b+"}=>"+ (b+a)+" " ) b+a })) val list1 = List(-2,-1,0,1,2) println("reduce (a+b) "+list1.reduce((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" ") a+b })) println("reduceLeft (a+b) "+list1.reduceLeft((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" ") a+b })) println("reduceLeft (b+a) "+list1.reduceLeft((a,b)=>{ print("{"+a+","+b+"}=>"+ (b+a)+" " ) b+a })) println(" reduceRight (a+b) "+list1.reduceRight((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b })) println(" reduceRight (b+a) "+list1.reduceRight((a,b)=>{ print("{"+a+","+b+"}=>"+ (b+a)+" ") b+a })) println("scan "+list1.scan(0)((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b })) println("scanLeft (a+b) "+list1.scanLeft(0)((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b })) println("scanLeft (b+a) "+list1.scanLeft(0)((a,b)=>{ print("{"+a+","+b+"}=>"+ (b+a)+" " ) b+a })) println("scanRight (a+b) "+list1.scanRight(0)((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) a+b})) println("scanRight (b+a) "+list1.scanRight(0)((a,b)=>{ print("{"+a+","+b+"}=>"+ (a+b)+" " ) b+a})) }
logger.debug(s"Some ${expensiveExpression} message!")
import com.typesafe.scalalogging.slf4j.LazyLogging class MyClass extends LazyLogging { logger.debug("This is very convenient ;-)") }
class Log4JLogger(val logger: Logger) extends LiftLogger { override def trace(msg: => AnyRef) = if (isTraceEnabled) logger.trace(msg) }
trace("The foobar from " + a + " doesn b + " and you should reset the baz from " + c")
<dependency> <groupId>com.weiglewilczek.slf4s</groupId> <artifactId>slf4s_2.9.1</artifactId> <version>1.0.7</version> </dependency> <dependency> <groupId>org.slf4j</groupId> <artifactId>slf4j-simple</artifactId> <version>1.6.6</version> </dependency>
libraryDependencies += "com.typesafe.scala-logging" %% "scala-logging" % "3.7.2", libraryDependencies += "ch.qos.logback" % "logback-classic" % "1.2.3"
import com.typesafe.scalalogging._ object MyApp extends App with LazyLogging { logger.info("Hello there") }
trait Loggable { val logger:Logger = Logging.getLogger(this) def checkFormat(msg:String, refs:Seq[Any]):String = if (refs.size > 0) msgfmtSeq(msg, refs) else msg def trace(msg:String, refs:Any*) = logger trace checkFormat(msg, refs) def trace(t:Throwable, msg:String, refs:Any*) = logger trace (checkFormat(msg, refs), t) def info(msg:String, refs:Any*) = logger info checkFormat(msg, refs) def info(t:Throwable, msg:String, refs:Any*) = logger info (checkFormat(msg, refs), t) def warn(msg:String, refs:Any*) = logger warn checkFormat(msg, refs) def warn(t:Throwable, msg:String, refs:Any*) = logger warn (checkFormat(msg, refs), t) def critical(msg:String, refs:Any*) = logger error checkFormat(msg, refs) def critical(t:Throwable, msg:String, refs:Any*) = logger error (checkFormat(msg, refs), t) } /** * Note: implementation taken from scalax.logging API */ object Logging { def loggerNameForClass(className: String) = { if (className endsWith "$") className.substring(0, className.length - 1) else className } def getLogger(logging: AnyRef) = LoggerFactory.getLogger(loggerNameForClass(logging.getClass.getName)) }
trait Logging { lazy val logger = LoggerFactory.getLogger(getClass) implicit def logging2Logger(anything: Logging): Logger = anything.logger }
class X with Logging { logger.debug("foo") debug("bar") }
import com.typesafe.scalalogging.slf4j.Logger import org.slf4j.LoggerFactory val logger = Logger(LoggerFactory.getLogger("TheLoggerName")) logger.debug("Useful message....")
libraryDependencies += "com.typesafe" %% "scalalogging-slf4j" % "1.1.0"
import import com.typesafe.scalalogging.Logger import org.slf4j.LoggerFactory val logger = Logger(LoggerFactory.getLogger("TheLoggerName")) logger.debug("Useful message....")
libraryDependencies += "com.typesafe.scala-logging" %% "scala-logging" % "3.1.0"
val map1 = Map(1 -> 9 , 2 -> 20) val map2 = Map(1 -> 100, 3 -> 300)
val list = map1.toList ++ map2.toList val merged = list.groupBy ( _._1) .map { case (k,v) => k -> v.map(_._2).sum }
val merged = (map1 /: map2) { case (map, (k,v)) => map + ( k -> (v + map.getOrElse(k, 0)) ) }
scala> import scalaz._ import scalaz._ scala> import Scalaz._ import Scalaz._ scala> val map1 = Map(1 -> 9 , 2 -> 20) map1: scala.collection.immutable.Map[Int,Int] = Map(1 -> 9, 2 -> 20) scala> val map2 = Map(1 -> 100, 3 -> 300) map2: scala.collection.immutable.Map[Int,Int] = Map(1 -> 100, 3 -> 300) scala> map1 |+| map2 res2: scala.collection.immutable.Map[Int,Int] = Map(1 -> 109, 3 -> 300, 2 -> 20)
map1 ++ map2.map{ case (k,v) => k -> (v + map1.getOrElse(k,0)) }
(map1.keySet ++ map2.keySet).map {i=> (i,map1.getOrElse(i,0) + map2.getOrElse(i,0))}.toMap
val map1 = collection.immutable.HashMap(1 -> 11 , 2 -> 12) val map2 = collection.immutable.HashMap(1 -> 11 , 2 -> 12) map1.merged(map2)({ case ((k,v1),(_,v2)) => (k,v1+v2) })
trait Monoid[M] { def zero: M def op(a: M, b: M): M }
val mapMonoid = new Monoid[Map[Int, Int]] { override def zero: Map[Int, Int] = Map() override def op(a: Map[Int, Int], b: Map[Int, Int]): Map[Int, Int] = (a.keySet ++ b.keySet) map { k => (k, a.getOrElse(k, 0) + b.getOrElse(k, 0)) } toMap }
val map1 = Map(1 -> 9 , 2 -> 20) val map2 = Map(1 -> 100, 3 -> 300) val maps = List(map1, map2) val merged = maps.foldLeft(mapMonoid.zero)(mapMonoid.op)
map1 ++ ( for ( (k,v) <- map2 ) yield ( k -> ( v + map1.getOrElse(k,0) ) ) )
import cats.implicits._ val map1 = Map(1 -> 9 , 2 -> 20) val map2 = Map(1 -> 100, 3 -> 300) map1 combine map2
import scalaz.Scalaz._ map1 |+| map2 map1.intersectWith(map2)(_ + _)
def mergeMap(m1: Map[Char, Int], m2: Map[Char, Int]): Map[Char, Int] = { var map : Map[Char, Int] = Map[Char, Int]() ++ m1 for(p <- m2) { map = map + (p._1 -> (p._2 + map.getOrElse(p._1,0))) } map }
scala> import com.daodecode.scalax.collection.extensions._ scala> val merged = Map("1" -> 1, "2" -> 2).mergedWith(Map("1" -> 1, "2" -> 2))(_ + _) merged: scala.collection.immutable.Map[String,Int] = Map(1 -> 2, 2 -> 4)
def mergedWith(another: Map[K, V])(f: (V, V) => V): Repr = if (another.isEmpty) mapLike.asInstanceOf[Repr] else { val mapBuilder = new mutable.MapBuilder[K, V, Repr](mapLike.asInstanceOf[Repr]) another.foreach { case (k, v) => mapLike.get(k) match { case Some(ev) => mapBuilder += k -> f(ev, v) case _ => mapBuilder += k -> v } } mapBuilder.result() }
val m1 = Map(1 -> 1.0, 3 -> 3.0, 5 -> 5.2) val m2 = Map(0 -> 10.0, 3 -> 3.0) val merged = (m2 foldLeft m1) ( (acc, v) => acc + (v._1 -> (v._2 + acc.getOrElse(v._1, 0.0))) )
map1 ++ map2.map { case (k,v) => k -> (v + map1.getOrElse(k,0)) }
(map1.toSeq ++ map2.toSeq).groupMapReduce(_._1)(_._2)(_+_)
class LazyTest { public int bitmap$0; private String msg; public String msg() { if ((bitmap$0 & 1) == 0) { synchronized (this) { if ((bitmap$0 & 1) == 0) { synchronized (this) { msg = "Lazy"; } } bitmap$0 = bitmap$0 | 1; } } return msg; } }
class Something { lazy val foo = getFoo def getFoo = "foo!" }
0 aload_0 [this] 1 getfield blevins.example.Something.bitmap$0 : int [15] 4 iconst_1 5 iand 6 iconst_0 7 if_icmpne 48 10 aload_0 [this] 11 dup 12 astore_1 13 monitorenter 14 aload_0 [this] 15 getfield blevins.example.Something.bitmap$0 : int [15] 18 iconst_1 19 iand 20 iconst_0 21 if_icmpne 42 24 aload_0 [this] 25 aload_0 [this] 26 invokevirtual blevins.example.Something.getFoo() : java.lang.String [18] 29 putfield blevins.example.Something.foo : java.lang.String [20] 32 aload_0 [this] 33 aload_0 [this] 34 getfield blevins.example.Something.bitmap$0 : int [15] 37 iconst_1 38 ior 39 putfield blevins.example.Something.bitmap$0 : int [15] 42 getstatic scala.runtime.BoxedUnit.UNIT : scala.runtime.BoxedUnit [26] 45 pop 46 aload_1 47 monitorexit 48 aload_0 [this] 49 getfield blevins.example.Something.foo : java.lang.String [20] 52 areturn 53 aload_1 54 monitorexit 55 athrow
public class Example { private String x; private volatile boolean bitmap$0; public String x() { if(this.bitmap$0 == true) { return this.x; } else { return x$lzycompute(); } } private String x$lzycompute() { synchronized(this) { if(this.bitmap$0 != true) { this.x = "Value"; this.bitmap$0 = true; } return this.x; } } }
val regex = "(\\d+)/(\\d+)/(\\d+)".r val regex(year, month, day) = "2010/1/13"
object Closer { def using(closeable: { def close(): Unit }, f: => Unit) { try { f } finally { closeable.close } } }
trait Functor[F[_]] { def fmap[A, B](f: A => B, fa: F[A]): F[B] }
val code: String = ... val ps: ProductService = ... var p: Product = null if (code.endsWith("=")) { p = ps.findCash(code.substring(0, 3)) } else if (code.endsWith(".FWD")) { p = ps.findForward(code.substring(0,3), code.substring(3, 9)) } else { p = ps.lookupProductByRic(code) }
implicit val ps: ProductService = ... val p = code match { case SyntheticCodes.Cash(c) => c case SyntheticCodes.Forward(f) => f case _ => ps.lookupProductByRic(code) }
object SyntheticCodes { object Cash extends (CashProduct => String) { def apply(p: CashProduct) = p.currency.name + "=" def unapply(s: String)(implicit ps: ProductService): Option[CashProduct] = { if (s.endsWith("=") Some(ps.findCash(s.substring(0,3))) else None } } object Forward extends (ForwardProduct => String) { def apply(p: ForwardProduct) = p.currency.name + p.date.toString + ".FWD" def unapply(s: String)(implicit ps: ProductService): Option[ForwardProduct] = { if (s.endsWith(".FWD") Some(ps.findForward(s.substring(0,3), s.substring(3, 9)) else None } }
class CashProduct { def getCode = SyntheticCodes.Cash(this) } class ForwardProduct { def getCode = SyntheticCodes.Forward(this) }
def u(n:Int):TailRec[Int] = { if (n==0) done(1) else tailcall(v(n/2)) } def v(n:Int):TailRec[Int] = { if (n==0) done(5) else tailcall(u(n-1)) } val l=for(n<-0 to 5) yield (n,u(n).result,v(n).result) println(l)
case class Person(name: String, age: Int) val p = Person("Aaron", 28) val name = p.productElement(0) val age = p.productElement(1) val fields = p.productIterator.toList
case class Person(name: String, age: Int) { override def productPrefix = "person: " } println(Person("Aaron", 28))
package <empty> { class A extends java.lang.Object with ScalaObject { def this(): A = { A.super.this(); () }; scala.this.Predef.augmentString("xx").r } }
def dont(code: => Unit) = new DontCommand(code) class DontCommand(code: => Unit) { def unless(condition: => Boolean) = if (condition) code def until(condition: => Boolean) = { while (!condition) {} code } }
dont { println("Yep, 2 really is greater than 1.") } unless (2 > 1) var number = 0; def nextNumber() = { number += 1 println(number) number } dont { println("Done counting to 5!") } until (nextNumber() == 5)
scala> val n = 3 n: Int = 3 scala> import annotation.switch import annotation.switch scala> val s = (n: @switch) match { | case 3 => "Three" | case _ => "NoThree" | } <console>:6: error: could not emit switch for @switch annotated match val s = (n: @switch) match {
object Main { class FooBar[A, B] def main(args: Array[String]): Unit = { var x: FooBar[Int, BigInt] = null var y: Int FooBar BigInt = null } }
def timed[T](thunk: => T) = { val t1 = System.nanoTime val ret = thunk val time = System.nanoTime - t1 println("Executed in: " + time/1000000.0 + " millisec") ret }
val numbers = List(12, 42, 3, 11, 6, 3, 77, 44) val sorted = timed { numbers.sortWith(_<_) } println(sorted)
Executed in: 6.410311 millisec List(3, 3, 6, 11, 12, 42, 44, 77)
class Bar(i:Int) { println("constructing bar " + i) override def toString():String = { "bar with value: " + i } } def foo(x: => Bar) = { println("foo called") println("bar: " + x) } foo(new Bar(22))
scala> case class Dog(name: String) { | def bark() { | println("Bow Vow") | } | } defined class Dog scala> val d = Dog("Barnie") d: Dog = Dog(Barnie) scala> locally { | import d._ | bark() | bark() | } Bow Vow Bow Vow
trait AbstractT2 { println("In AbstractT2:") val value: Int val inverse = 1.0/value println("AbstractT2: value = "+value+", inverse = "+inverse) } val c2c = new { val value = 10 } with AbstractT2 println("c2c.value = "+c2c.value+", inverse = "+c2c.inverse)
In AbstractT2: AbstractT2: value = 10, inverse = 0.1 c2c.value = 10, inverse = 0.1
object Main { type A = {def foo: Unit} type B = {def bar: Unit} type C = A with B class myA { def foo: Unit = println("myA.foo") } class myB { def bar: Unit = println("myB.bar") } class myC extends myB { def foo: Unit = println("myC.foo") } def main(args: Array[String]): Unit = { val a: A = new myA a.foo val b: C = new myC b.bar b.foo } }
_ + 1 x => x + 1 _ * _ (x1, x2) => x1 * x2 (_: Int) * 2 (x: Int) => x * 2 if (_) x else y z => if (z) x else y _.map(f) x => x.map(f) _.map(_ + 1) x => x.map(y => y + 1)
def filesEnding(query: String) = filesMatching(_.endsWith(query))
def sizeBoundedString(s: String, n: Int): String = { if (n < 5 && n < s.length) throw new IllegalArgumentException if (s.length > n) { val trailLength = ((n - 3) / 2) min 3 val headLength = n - 3 - trailLength s.substring(0, headLength)+"..."+s.substring(s.length - trailLength, s.length) } else s }
def sizeBoundedString[T](s: T, n: Int)(implicit toStr: T => String): String = { if (n < 5 && n < s.length) throw new IllegalArgumentException if (s.length > n) { val trailLength = ((n - 3) / 2) min 3 val headLength = n - 3 - trailLength s.substring(0, headLength)+"..."+s.substring(s.length - trailLength, s.length) } else s }
sizeBoundedString(1234567890L, 8)((l : Long) => l.toString)
def sizeBoundedString[T <% String](s: T, n: Int): String = { if (n < 5 && n < s.length) throw new IllegalArgumentException if (s.length > n) { val trailLength = ((n - 3) / 2) min 3 val headLength = n - 3 - trailLength s.substring(0, headLength)+"..."+s.substring(s.length - trailLength, s.length) } else s }
case class Daemon(name: String) { def log(msg: String) = println(name+": "+msg) } object DefaultDaemon extends Daemon("Default") trait Logger { private var logd: Option[Daemon] = None implicit def daemon: Daemon = logd getOrElse DefaultDaemon def logTo(daemon: Daemon) = if (logd == None) logd = Some(daemon) else throw new IllegalArgumentException def log(msg: String)(implicit daemon: Daemon) = daemon.log(msg) } class X extends Logger { logTo(Daemon("X Daemon")) def f = { log("f called") println("Stuff") } def g = { log("g called")(DefaultDaemon) } } class Y extends Logger { def f = { log("f called") println("Stuff") } }
@scala.reflect.BeanProperty var firstName:String = _
trait Foo { def bar } trait Base { def callBar(implicit foo: Foo) = foo.bar } object Test extends Base { val f: Foo => Unit = { implicit foo => callBar } def test = f(new Foo { def bar = println("Hello") }) }
scala> trait PerformFunc[A,B] { def perform(a : A) : B } defined trait PerformFunc scala> implicit val stringToInt = new PerformFunc[String,Int] { def perform(a : String) = 5 } stringToInt: java.lang.Object with PerformFunc[String,Int] = $anon$1@13ccf137 scala> implicit val intToDouble = new PerformFunc[Int,Double] { def perform(a : Int) = 1.0 } intToDouble: java.lang.Object with PerformFunc[Int,Double] = $anon$1@74e551a4 scala> def foo[A, B](x : A)(implicit z : PerformFunc[A,B]) : B = z.perform(x) foo: [A,B](x: A)(implicit z: PerformFunc[A,B])B scala> foo("HAI") res16: Int = 5 scala> foo(1) res17: Double = 1.0
val button = new Button("Click me"){ setWidth("20px") setDescription("Click on this") setIcon(new ThemeResource("icons/ok.png")) }
val logger = new Logger(...) import logger.printerr
def post(tweet: String) = { require(tweet.length < 140 && tweet.length > 0) println(tweet) }
scala> post("that that scala> post("") java.lang.IllegalArgumentException: requirement failed at scala.Predef$.require(Predef.scala:145) at .post(<console>:8) scala> post("way to looooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong tweet") java.lang.IllegalArgumentException: requirement failed at scala.Predef$.require(Predef.scala:145) at .post(<console>:8)
def post(tweet: String) = { require(tweet.length > 0, "too short message") require(tweet.length < 140, "too long message") println(tweet) }
scala> post("") java.lang.IllegalArgumentException: requirement failed: too short message at scala.Predef$.require(Predef.scala:157) at .post(<console>:8)
scala> var errorcount = 0 errorcount: Int = 0 def post(tweet: String) = { require(tweet.length > 0, {errorcount+=1}) println(tweet) } scala> errorcount res14: Int = 0 scala> post("") java.lang.IllegalArgumentException: requirement failed: () at scala.Predef$.require(Predef.scala:157) at .post(<console>:9) ... scala> errorcount res16: Int = 1
trait A { def a(s : String) : String } trait TimingA extends A { abstract override def a(s : String) = { val start = System.currentTimeMillis val result = super.a(s) val dur = System.currentTimeMillis-start println("Executed a in %s ms".format(dur)) result } } trait ParameterPrintingA extends A { abstract override def a(s : String) = { println("Called a with s=%s".format(s)) super.a(s) } } trait ImplementingA extends A { def a(s: String) = s.reverse } scala> val a = new ImplementingA with TimingA with ParameterPrintingA scala> a.a("a lotta as") Called a with s=a lotta as Executed a in 0 ms res4: String = sa attol a
import com.github.nscala_time.time.Imports._ DateTime.now DateTime.now.hour(2).minute(45).second(10) DateTime.now + 2.months DateTime.nextMonth < DateTime.now + 2.months DateTime.now to DateTime.tomorrow (DateTime.now to DateTime.nextSecond).millis 2.hours + 45.minutes + 10.seconds (2.hours + 45.minutes + 10.seconds).millis 2.months + 3.days
USAGE: import org.scala_tools.time.Imports._ DateTime.now DateTime.now.hour(2).minute(45).second(10) DateTime.now + 2.months DateTime.nextMonth < DateTime.now + 2.months DateTime.now to DateTime.tomorrow (DateTime.now to DateTime.nextSecond).millis 2.hours + 45.minutes + 10.seconds (2.hours + 45.minutes + 10.seconds).millis 2.months + 3.days
import scalax.io._ val output:Output = Resource.fromFile("someFile") output.writeIntsAsBytes(1,2,3) output.write("hello")(Codec.UTF8) output.writeStrings(List("hello","world")," ")(Codec.UTF8)
{ import scalax.io.{ FileOps, Path, Codec, OpenOption} implicit val codec = scalax.io.Codec.UTF8 val file: FileOps = Path ("file") file.write (Array (1,2,3) map ( _.toByte)) file.write (List (1,2,3) map (_.toByte)) file.write("Hello my dear file") file.write("Hello my dear file")(codec = Codec.UTF8) file.writeStrings( "It costs" :: "one" :: "dollar" :: Nil) file.writeStrings("It costs" :: "one" :: "dollar" :: Nil, separator="||\n||")(codec = Codec.UTF8) }
def printToFile(f: java.io.File)(op: java.io.PrintWriter => Unit) { val p = new java.io.PrintWriter(f) try { op(p) } finally { p.close() } }
import java.io._ val data = Array("Five","strings","in","a","file!") printToFile(new File("example.txt")) { p => data.foreach(p.println) }
/** * Used for reading/writing to database, files, etc. * Code From the book "Beginning Scala" * http: */ def using[A <: {def close(): Unit}, B](param: A)(f: A => B): B = try { f(param) } finally { param.close() }
def writeToFile(fileName:String, data:String) = using (new FileWriter(fileName)) { fileWriter => fileWriter.write(data) }
def appendToFile(fileName:String, textData:String) = using (new FileWriter(fileName, true)){ fileWriter => using (new PrintWriter(fileWriter)) { printWriter => printWriter.println(textData) } }
import java.io.File import java.io.PrintWriter def writeToFile(p: String, s: String): Unit = { val pw = new PrintWriter(new File(p)) try pw.write(s) finally pw.close() }
def using[A <: {def close(): Unit}, B](resource: A)(f: A => B): B = try f(resource) finally resource.close() def writeToFile(path: String, data: String): Unit = using(new FileWriter(path))(_.write(data)) def appendToFile(path: String, data: String): Unit = using(new PrintWriter(new FileWriter(path, true)))(_.println(data))
import java.nio.file.{Paths, Files, StandardOpenOption} import java.nio.charset.{StandardCharsets} import scala.collection.JavaConverters._ def write(filePath:String, contents:String) = { Files.write(Paths.get(filePath), contents.getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE) } def read(filePath:String):String = { Files.readAllLines(Paths.get(filePath), StandardCharsets.UTF_8).asScala.mkString }
def tryUsingAutoCloseable[A <: AutoCloseable, R] (instantiateAutoCloseable: () => A) (transfer: A => scala.util.Try[R]) : scala.util.Try[R] = Try(instantiateAutoCloseable()) .flatMap( autoCloseable => try transfer(autoCloseable) finally autoCloseable.close() )
val defaultBufferSize: Int = 65536 def tryPrintToFile( lines: List[String], location: java.io.File, bufferSize: Int = defaultBufferSize ): scala.util.Try[Unit] = { tryUsingAutoCloseable(() => new java.io.FileWriter(location)) { fileWriter => tryUsingAutoCloseable(() => new java.io.BufferedWriter(fileWriter, bufferSize)) { bufferedWriter => tryUsingAutoCloseable(() => new java.io.PrintWriter(bufferedWriter)) { printWriter => scala.util.Try( lines.foreach(line => printWriter.println(line)) ) } } } }
def tryWriteToFile( content: String, location: java.io.File, bufferSize: Int = defaultBufferSize ): scala.util.Try[Unit] = { tryUsingAutoCloseable(() => new java.io.FileWriter(location)) { fileWriter => tryUsingAutoCloseable(() => new java.io.BufferedWriter(fileWriter, bufferSize)) { bufferedWriter => Try(bufferedWriter.write(content)) } } }
def tryUsingSource[S <: scala.io.Source, R] (instantiateSource: () => S) (transfer: S => scala.util.Try[R]) : scala.util.Try[R] = Try(instantiateSource()) .flatMap( source => try transfer(source)) finally source.close() )
def tryProcessSource( file: java.io.File , parseLine: (String, Int) => List[String] = (line, index) => List(line) , filterLine: (List[String], Int) => Boolean = (values, index) => true , retainValues: (List[String], Int) => List[String] = (values, index) => values , isFirstLineNotHeader: Boolean = false ): scala.util.Try[List[List[String]]] = tryUsingSource(scala.io.Source.fromFile(file)) { source => scala.util.Try( ( for { (line, index) <- source.getLines().buffered.zipWithIndex values = parseLine(line, index) if (index == 0 && !isFirstLineNotHeader) || filterLine(values, index) retainedValues = retainValues(values, index) } yield retainedValues ).toList ) )
import scala.io.Source import scala.util.Try import java.io.{BufferedWriter, FileWriter, File, PrintWriter} val defaultBufferSize: Int = 65536 def tryUsingAutoCloseable[A <: AutoCloseable, R] (instantiateAutoCloseable: () => A)(transfer: A => scala.util.Try[R]): scala.util.Try[R] = Try(instantiateAutoCloseable()) .flatMap( autoCloseable => try transfer(autoCloseable)) finally autoCloseable.close() ) def tryUsingSource[S <: scala.io.Source, R] (instantiateSource: () => S)(transfer: S => scala.util.Try[R]): scala.util.Try[R] = Try(instantiateSource()) .flatMap( source => try transfer(source)) finally source.close() ) def tryPrintToFile( lines: List[String], location: File, bufferSize: Int = defaultBufferSize ): Try[Unit] = tryUsingAutoCloseable(() => new FileWriter(location)) { fileWriter => tryUsingAutoCloseable(() => new BufferedWriter(fileWriter, bufferSize)) { bufferedWriter => tryUsingAutoCloseable(() => new PrintWriter(bufferedWriter)) { printWriter => Try(lines.foreach(line => printWriter.println(line))) } } } def tryWriteToFile( content: String, location: File, bufferSize: Int = defaultBufferSize ): Try[Unit] = tryUsingAutoCloseable(() => new FileWriter(location)) { fileWriter => tryUsingAutoCloseable(() => new BufferedWriter(fileWriter, bufferSize)) { bufferedWriter => Try(bufferedWriter.write(content)) } } def tryProcessSource( file: File, parseLine: (String, Int) => List[String] = (line, index) => List(line), filterLine: (List[String], Int) => Boolean = (values, index) => true, retainValues: (List[String], Int) => List[String] = (values, index) => values, isFirstLineNotHeader: Boolean = false ): Try[List[List[String]]] = tryUsingSource(Source.fromFile(file)) { source => Try( ( for { (line, index) <- source.getLines().buffered.zipWithIndex values = parseLine(line, index) if (index == 0 && !isFirstLineNotHeader) || filterLine(values, index) retainedValues = retainValues(values, index) } yield retainedValues ).toList ) )
import scalaz._ import scalaz.stream._ def writeLinesToFile(lines: Seq[String], file: String): Task[Unit] = Process(lines: _*) .flatMap(Process(_, "\n")) .pipe(text.utf8Encode) .to(io.fileChunkW(fileName)) .runLog[Task, Unit] .map(_ => ()) writeLinesToFile(Seq("one", "two"), "file.txt").run
def using[A <: {def close() : Unit}, B](resource: A)(f: A => B): B = try f(resource) finally resource.close() def writeStringToFile(file: File, data: String, appending: Boolean = false) = using(new FileWriter(file, appending))(_.write(data))
def write(destinationFile: Path, fileContent: String): Either[Exception, Path] = write(destinationFile, fileContent.getBytes(StandardCharsets.UTF_8)) def write(destinationFile: Path, fileContent: Array[Byte]): Either[Exception, Path] = try { Files.createDirectories(destinationFile.getParent) Right(Files.write(destinationFile, fileContent)) } catch { case exception: Exception => Left(exception) }
val filePath = Paths.get("./testDir/file.txt") write(filePath , "A test") match { case Right(pathToWrittenFile) => println(s"Successfully wrote to $pathToWrittenFile") case Left(exception) => println(s"Could not write to $filePath. Exception: $exception") }
new PrintWriter(outputPath) { write(ArrayName.mkString("")); close }
def writeToFile(p: Path, s: String)(implicit mat: Materializer): Unit = { Source.single(ByteString(s)).runWith(FileIO.toPath(p)) }
scala> sealed trait Foo[T] { def apply(list : List[T]) : Unit }; object Foo { | implicit def stringImpl = new Foo[String] { | def apply(list : List[String]) = println("String") | } | implicit def intImpl = new Foo[Int] { | def apply(list : List[Int]) = println("Int") | } | } ; def foo[A : Foo](x : List[A]) = implicitly[Foo[A]].apply(x) defined trait Foo defined module Foo foo: [A](x: List[A])(implicit evidence$1: Foo[A])Unit scala> foo(1) <console>:8: error: type mismatch; found : Int(1) required: List[?] foo(1) ^ scala> foo(List(1,2,3)) Int scala> foo(List("a","b","c")) String scala> foo(List(1.0)) <console>:8: error: could not find implicit value for evidence parameter of type Foo[Double] foo(List(1.0)) ^
scala> 1.min(2) res21: Int = 1 scala> implicitly[Int => { def min(i: Int): Any }] res22: (Int) => AnyRef{def min(i: Int): Any} = <function1> scala> res22(1) res23: AnyRef{def min(i: Int): Int} = 1 scala> .getClass res24: java.lang.Class[_] = class scala.runtime.RichInt
scala> 1: scala.runtime.RichInt res25: scala.runtime.RichInt = 1
scala> implicitly[Int => scala.runtime.RichInt] res26: (Int) => scala.runtime.RichInt = <function1>
trait Show[T] { def show(t: T): String } object Show { implicit def IntShow: Show[Int] = new Show[Int] { def show(i: Int) = i.toString } implicit def StringShow: Show[String] = new Show[String] { def show(s: String) = s } def ShoutyStringShow: Show[String] = new Show[String] { def show(s: String) = s.toUpperCase } } case class Person(name: String, age: Int) object Person { implicit def PersonShow(implicit si: Show[Int], ss: Show[String]): Show[Person] = new Show[Person] { def show(p: Person) = "Person(name=" + ss.show(p.name) + ", age=" + si.show(p.age) + ")" } } val p = Person("bob", 25) implicitly[Show[Person]].show(p)
Person.PersonShow(si = implicitly, ss = Show.ShoutyStringShow).show(p)
scala> implicit val a = "test" a: java.lang.String = test scala> val b = implicitly[String] b: String = test scala> val c = implicitly[Int] <console>:6: error: could not find implicit value for parameter e: Int val c = implicitly[Int] ^
scala> Nat(3) res10: shapeless.Succ[shapeless.Succ[shapeless.Succ[shapeless._0]]] = Succ()
scala> type OneMillion = Witness.`1000000`.T defined type alias OneMillion scala> type AlsoOneMillion = Witness.`1000000`.T defined type alias AlsoOneMillion scala> type OneMillionAndOne = Witness.`1000001`.T defined type alias OneMillionAndOne scala> implicitly[OneMillion =:= AlsoOneMillion] res0: =:=[OneMillion,AlsoOneMillion] = <function1> scala> implicitly[OneMillion =:= OneMillionAndOne] <console>:16: error: Cannot prove that OneMillion =:= OneMillionAndOne. implicitly[OneMillion =:= OneMillionAndOne] ^
class Person(val name:String,var age:Int ) def person = new Person("Kumar",12) person.age = 20 println(person.age)
scala> def something = 2 + 3 * 4 something: Int scala> something res30: Int = 14
scala> val somethingelse = 2 + 3 * 5 somethingelse: Int = 17
scala> var aVariable = 2 * 3 aVariable: Int = 6 scala> aVariable = 5 aVariable: Int = 5
scala> something = 5 * 6 <console>:8: error: value something_= is not a member of object $iw something = 5 * 6 ^
scala> class Person(val name: String, var age: Int) defined class Person
scala> def personA = new Person("Tim", 25) personA: Person
scala> var personB = new Person("Matt", 36) personB: Person = Person@59cd11fe scala> personB.age = 44 personB.age: Int = 44
def defines a method val defines a fixed value (which cannot be modified) var defines a variable (which can be modified)
def person = new Person("Kumar",12) val p = person p.age=20 println(p.age)
class Person{ public int age; private String name; public Person(String name; int age) { this.name = name; this.age = age; } public String name(){ return name; } } public Person person() { return new Person("Kumar", 12); } person().age = 20; System.out.println(person().age);
class Person(val name:String,var age:Int ) def person =new Person("Kumar",12) person.age=20 println(person.age)
class Person(val name:String,var age:Int ) def person =new Person("Kumar",12) (new Person("Kumar", 12)).age_=(20) println((new Person("Kumar", 12)).age)
class Slot[+T] (var some: Object){ def get() = { some.asInstanceOf[T] } }
abstract class _Slot[+T, V <: T] (var some: V) { def getT() = { some } }
Object[] arr = new Integer[1]; arr[0] = "Hello, there!";
T1 T2 <: T2' ---------------------------------------- S-Fun Function1[T1, T2] <: Function1[T1
class Slot[+T](var some: T) { def get: T = some } val slot: Slot[Dog] = new Slot[Dog](new Dog) val slot2: Slot[Animal] = slot slot2.some = new Animal slot.get ??
val x = new Slot[String]("test") val y: Slot[Any] = x y.set(new Rational(1, 2))
trait Monad[M[_]] { def point[A](a: A): M[A] def bind[A, B](m: M[A])(f: A => M[B]): M[B] }
class EitherMonad[A] extends Monad[({type λ[α] = Either[A, α]}) def point[B](b: B): Either[A, B] def bind[B, C](m: Either[A, B])(f: B => Either[A, C]): Either[A, C] }
private[iteratee] class FG[F[_[_], _], G[_]] { type FGA[A] = F[G, A] type IterateeM[A] = IterateeT[X, E, FGA, A] }
def inc(a: Int) = a + 1; List(1, 2, 3).map(inc) List(1, 2, 3).map(a => a + 1)
type IntTuple[+A]=(Int, A) Functor[IntTuple].map((1, 2))(a => a + 1)) Functor[({type l[a] = (Int, a)})
trait Pure[P[_]] { def pure[A](a: => A): P[A] } object Pure { import Scalaz._ implicit def Tuple2Pure[R: Zero]: Pure[({type ?[a]=(R, a)}) def pure[A](a: => A) = (Ø, a) } }
scala> def foo(x: String, y: String): String = x + " " + y foo: (x: String, y: String)String scala> def world(f: String => String): String = f("world") world: (f: String => String)String scala> world(x => foo("hello", x)) res0: String = hello world scala> type Foo[A, B] = Map[A, B] defined type alias Foo scala> type World[M[_]] = M[Int] defined type alias World scala> type X[A] = World[({ type M[A] = Foo[String, A] }) defined type alias X scala> implicitly[X[Int] =:= Foo[String, Int]] res2: =:=[X[Int],Foo[String,Int]] = <function1>
scala> val g: String => String = x => foo("hello", x) g: String => String = <function1> scala> world(g) res3: String = hello world scala> type G[A] = Foo[String, A] defined type alias G scala> implicitly[X =:= Foo[String, Int]] res5: =:=[X,Foo[String,Int]] = <function1> scala> type T = World[G] defined type alias T scala> implicitly[T =:= Foo[String, Int]] res6: =:=[T,Foo[String,Int]] = <function1>
scala> type Partial2[F[_, _], A] = { | type Get[B] = F[A, B] | } defined type alias Partial2 scala> implicit def Tuple2Pure[R]: Pure[Partial2[Tuple2, R] Tuple2Pure: [R]=> Pure[[B](R, B)]
resolvers += "sbt-idea-repo" at "http: addSbtPlugin("com.github.mpeltonen" % "sbt-idea" % "1.6.0")
resolvers += "sbt-idea-repo" at "http: libraryDependencies += "com.github.mpeltonen" %% "sbt-idea" % "0.10.0"
> *sbtIdeaRepo at http: > *idea is com.github.mpeltonen sbt-idea-processor 0.4.0 ... > update ... > idea ...
import sbt._ class MyProject(info: ProjectInfo) extends ParentProject(info) with IdeaProject { lazy val mySubProject = project("my-subproject", "my-subproject", new DefaultProject(_) with IdeaProject) }
resolvers += "Sonatype snapshots" at "http: addSbtPlugin(dependency="com.github.mpeltonen" % "sbt-idea" % "1.5.0-SNAPSHOT")
git clone https: cd sbt-idea git checkout sbt-0.10 ./sbt package
cp sbt-idea/target/scala-2.8.1.final/*.jar ~/.sbt/plugins/lib
val input = sc.textFile("train.csv", minPartitions=6) val input2 = input.mapPartitionsWithIndex { (idx, iter) => if (idx == 0) iter.drop(1) else iter } val delim1 = "\001" def separateCols(line: String): Array[String] = { val line2 = line.replaceAll("true", "1") val line3 = line2.replaceAll("false", "0") val vals: Array[String] = line3.split(",") for((x,i) <- vals.view.zipWithIndex) { vals(i) = "VAR_%04d".format(i) + delim1 + x } vals } val input3 = input2.flatMap(separateCols) def toKeyVal(line: String): (String, String) = { val vals = line.split(delim1) (vals(0), vals(1)) } val input4 = input3.map(toKeyVal) def valsConcat(val1: String, val2: String): String = { val1 + "," + val2 } val input5 = input4.reduceByKey(valsConcat) input5.saveAsTextFile("output")
a match { case 10 => println("ten") case _ > 10 => println("greater than ten") case _ => println("less than ten") }
a match { case 10 => println("ten") case x if x > 10 => println("greater than ten") case _ => println("less than ten") }
def assess(n: Int) { println( n compare 10 match { case 0 => "ten" case 1 => "greater than ten" case -1 => "less than ten" }) }
(n compare 10).signum match { case -1 => "less than ten" case 0 => "ten" case 1 => "greater than ten" }
val textFile = sc.textFile("/user/emp.txt") textFile.cache
val wordsRDD = textFile.flatMap(line => line.split("\\W"))
val positiveWordsCount = wordsRDD.filter(word => isPositive(word)).count() val negativeWordsCount = wordsRDD.filter(word => isNegative(word)).count()
val textFile = sc.textFile("/user/emp.txt") val wordsRDD = textFile.flatMap(line => line.split("\\W")) wordsRDD.cache() val positiveWordsCount = wordsRDD.filter(word => isPositive(word)).count() val negativeWordsCount = wordsRDD.filter(word => isNegative(word)).count()
def flatten[T <: Product, L <: HList](t : T) (implicit hl : HListerAux[T, L], flatten : Flatten[L]) : flatten.Out = flatten(hl(t)) val t1 = (1, ((2, 3), 4)) val f1 = flatten(t1) val l1 = f1.toList val t2 = (23, ((true, 2.0, "foo"), "bar"), (13, false)) val f2 = flatten(t2) val t2b = f2.tupled
case class Foo(i : Int, s : String) case class Bar(b : Boolean, s : String, d : Double) implicit def fooIso = Iso.hlist(Foo.apply _, Foo.unapply _) implicit def barIso = Iso.hlist(Bar.apply _, Bar.unapply _) implicitly[Monoid[Foo]] val f = Foo(13, "foo") |+| Foo(23, "bar") assert(f == Foo(36, "foobar")) implicitly[Monoid[Bar]] val b = Bar(true, "foo", 1.0) |+| Bar(false, "bar", 3.0) assert(b == Bar(true, "foobar", 4.0))
object size extends Poly1 { implicit def default[T] = at[T](t => 1) implicit def caseString = at[String](_.length) implicit def caseList[T] = at[List[T]](_.length) } scala> val l = 23 :: "foo" :: List( l: Int :: String :: List[Char] :: Boolean :: HNil = 23 :: foo :: List(a, b) :: true :: HNil scala> (l map size).toList res1: List[Int] = List(1, 3, 2, 1)
trait Fruit case class Apple() extends Fruit case class Pear() extends Fruit type FFFF = Fruit :: Fruit :: Fruit :: Fruit :: HNil type APAP = Apple :: Pear :: Apple :: Pear :: HNil val a : Apple = Apple() val p : Pear = Pear() val l = List(a, p, a, p)
scala> import Traversables._ import Traversables._ scala> val apap = l.toHList[Apple :: Pear :: Apple :: Pear :: HNil] res0: Option[Apple :: Pear :: Apple :: Pear :: HNil] = Some(Apple() :: Pear() :: Apple() :: Pear() :: HNil) scala> apap.map(_.tail.head) res1: Option[Pear] = Some(Pear())
val t1 : (Any, Any) = (23, "foo") val t2 : (Any, Any) = (true, 2.0) val c1 = stagedConsumeTuple(t1) assert(c1 == "23foo") val c2 = stagedConsumeTuple(t2) assert(c2 == "+2.0")
def hcons[A,B](head : A, tail : B) = (a,b) def hnil = Unit hcons("foo", hcons(3, hnil)) : (String, (Int, Unit))
def append2[A,B,C](in: (A,B), v: C) : (A,B,C) = (in._1, in._2, v)
m = new HashMap[P, T] c foreach { t => m add (t.getP, t) }
scala> val list = List("this", "maps", "string", "to", "length") map {s => (s, s.length)} list: List[(java.lang.String, Int)] = List((this,4), (maps,4), (string,6), (to,2), (length,6)) scala> val list = List("this", "is", "a", "bunch", "of", "strings") list: List[java.lang.String] = List(this, is, a, bunch, of, strings) scala> val string2Length = Map(list map {s => (s, s.length)} : _*) string2Length: scala.collection.immutable.Map[java.lang.String,Int] = Map(strings -> 7, of -> 2, bunch -> 5, a -> 1, is -> 2, this -> 4)
val list = List("this", "maps", "string", "to", "length") val map = list.foldLeft(Map[String, Int]()) { (m, s) => m(s) = s.length }
val map = c.foldLeft(Map[P, T]()) { (m, t) => m + (t.getP -> t) }
import scala.collection.breakOut val m:Map[P, T] = c.map(t => (t.getP, t))(breakOut)
val m: Map[P, T] = c.groupBy(t => t.p) map { case (p, ts) => p -> ts.head }
scala> case class Foo(bar: Int) defined class Foo scala> import scalaz._, Scalaz._ import scalaz._ import Scalaz._ scala> val c = Vector(Foo(9), Foo(11)) c: scala.collection.immutable.Vector[Foo] = Vector(Foo(9), Foo(11)) scala> c.map(((_: Foo).bar) &&& identity).toMap res30: scala.collection.immutable.Map[Int,Foo] = Map(9 -> Foo(9), 11 -> Foo(11)) scala> c.map(((_: Foo).bar) >>= (Pair.apply[Int, Foo] _).curried).toMap res31: scala.collection.immutable.Map[Int,Foo] = Map(9 -> Foo(9), 11 -> Foo(11))
implicit def list2ListWithMapBy[T](list: List[T]): ListWithMapBy[T] = { new ListWithMapBy(list) } class ListWithMapBy[V](list: List[V]){ def mapBy[K](keyFunc: V => K) = { list.map(a => keyFunc(a) -> a).toMap } }
val list = List("A", "AA", "AAA") list.mapBy(_.length)
val personsMap = persons.foldLeft(scala.collection.mutable.Map[Int, PersonDTO]()) { (m, p) => m(p.id) = p; m }
case class Scheduled(time : Int, callback : => Unit)
case class Scheduled(time : Int, callback : () => Unit)
class Scheduled(time : Int, callback : Unit => Unit)
val f = (x: Unit) => println("I val g = (x: Unit) => println("I val h = f andThen g
case class Scheduled(time : Int, callback : => Unit)
class Scheduled(val time: Int, val callback: () => Unit) { def doit = callback() } object Scheduled { def apply(time: Int, callback: => Unit) = new Scheduled(time, { () => callback }) }
scala> Scheduled(1234, println("x")) res0: Scheduled = Scheduled@5eb10190 scala> Scheduled(1234, println("x")).doit x
class Scheduled(time: Int, cb: => Unit) { private def runCb = cb } object Scheduled { def apply(time: Int, cb: => Unit) = { val instance = new Scheduled(time, cb) Thread.sleep(time*1000) instance.runCb } }
scala> Scheduled(10, println("a")); Scheduled(1, println("b")) a b
def foo[T](x: List[T])(implicit m: Manifest[T]) = { if (m <:< manifest[String]) println("Hey, this list is full of strings") else println("Non-stringy list") } foo(List("one", "two")) foo(List(1, 2)) foo(List("one", 2))
def foo[T: Manifest](x: List[T]) = { if (manifest[T] <:< manifest[String]) println("Hey, this list is full of strings") else println("Non-stringy list") }
def tabulate[T](len:Int, f:Int=>T)(implicit m:ClassManifest[T]) = { val xs = new Array[T](len) for (i <- 0 until len) xs(i) = f(i) xs }
def tabulate[T: ClassManifest](len:Int, f:Int=>T) = { val xs = new Array[T](len) for (i <- 0 until len) xs(i) = f(i) xs }
Manifest.scala: def manifest[T](implicit m: Manifest[T]) = m
def foo[A](somelist: List[A])(implicit m: Manifest[A]): String = { if (m <:< manifest[String]) { "its a string" } else { "its not a string" } }
trait A { this: B => ... } trait A { self: B => ... }
trait A { self: B => ... } trait A { foo: B => ... }
class MyFrame extends JFrame { frame => getContentPane().add( new JButton( "Hide" ) { addActionListener( new ActionListener { def actionPerformed( e: ActionEvent ) { frame.setVisible( false ) } }) }) }
import scala.collection.JavaConverters._ val lst = node.getByXPath(xpath).asScala lst.foreach{ node => .... }
def foo(a: String)(b: Int = 42) = a + b def foo(a: Int) (b: Int = 42) = a + b def foo(a: Int) (b: Int = 42) = a + b def foo(a: String)(b: String = "Foo") = a + b def foo(a: String)(b: Int) = a + b def foo(a: Int) (b: Int = 42) = a + b def foo(a: Int)(b: Int) = a + b def foo(a: Int)(b: String = "Foo") = a + b val bar = foo(42)_
def foo(a: String)(b: Int = 42) = a + b def foo(a: Int) (b: Int = 42) = a + b
def foo$String$default$2 = 42 def foo$Int$default$2 = 42
implicit def left2Either[A,B](a:A):Either[A,B] = Left(a) implicit def right2Either[A,B](b:B):Either[A,B] = Right(b) def foo(a: Either[Int, String], b: Int = 42) = a match { case Left(i) => i + b case Right(s) => s + b }
def foo(a: Int, b: Int) = a + b def foo(a: Int, b: String) = a + b def foo(a: Int) = a + "42" def foo(a: String) = a + "42"
def foo(a: Int)(b: Int = 10)(c: String = "10") = a + b + c def foo(a: Int)(b: String = "10")(c: Int = 10) = a + b + c
def pretty(tree: Tree, showFields: Boolean = false): String = def pretty(tree: List[Tree], showFields: Boolean = false): String = def pretty(tree: Option[Tree], showFields: Boolean = false): String =
def pretty(input: CanPretty, showFields: Boolean = false): String = { input match { case TreeCanPretty(tree) => prettyTree(tree, showFields) case ListTreeCanPretty(tree) => prettyList(tree, showFields) case OptionTreeCanPretty(tree) => prettyOption(tree, showFields) } } sealed trait CanPretty case class TreeCanPretty(tree: Tree) extends CanPretty case class ListTreeCanPretty(tree: List[Tree]) extends CanPretty case class OptionTreeCanPretty(tree: Option[Tree]) extends CanPretty import scala.language.implicitConversions implicit def treeCanPretty(tree: Tree): CanPretty = TreeCanPretty(tree) implicit def listTreeCanPretty(tree: List[Tree]): CanPretty = ListTreeCanPretty(tree) implicit def optionTreeCanPretty(tree: Option[Tree]): CanPretty = OptionTreeCanPretty(tree) private def prettyTree(tree: Tree, showFields: Boolean): String = "fun ..." private def prettyList(tree: List[Tree], showFields: Boolean): String = "fun ..." private def prettyOption(tree: Option[Tree], showFields: Boolean): String = "fun ..."
Overloading If there are multiple overloaded alternatives of a method, at most one is allowed to specify default arguments.
def foo(a: String)(b: Int) = a + (if (b > 0) b else 42)
scala> sys.env("HOME") res0: String = /home/paradigmatic
scala.util.Properties.envOrElse("HOME", "/myhome" )
scala> System.getenv("HOME") res0: java.lang.String = /Users/dhg
System.getenv.forEach((name, value) => println(s"$name: $value"))
type FunctorType = (LocalDate, HolidayCalendar, Int, Boolean) => LocalDate
def doSomeThing(f: (LocalDate, HolidayCalendar, Int, Boolean) => LocalDate)
trait Base { type T def method: T } class Implementation extends Base { type T = Int def method: T = 42 }
class Foo(x: Int, y: Int, z: String) { def this(x: Int, z: String) = this(x, 0, z) def this(z: String) = this(0, z); }
class Foo(x: Int, y: Int) { def this(x: Int) = this(x, 0) }
scala> class Foo(x:Int, y:Int = 0, z:Int=0) { | override def toString() = { "Foo(" + x + ", " + y + ", " + z + ")" } | } defined class Foo scala> new Foo(1, 2, 3) res0: Foo = Foo(1, 2, 3) scala> new Foo(4) res1: Foo = Foo(4, 0, 0)
abstract class Expectation[T] extends BooleanStatement { val expected: Seq[T] … } object Expectation { def apply[T](expd: T ): Expectation[T] = new Expectation[T] {val expected = List(expd)} def apply[T](expd: Seq[T]): Expectation[T] = new Expectation[T] {val expected = expd } def main(args: Array[String]): Unit = { val expectTrueness = Expectation(true) … } }
class A(x: Int, y: Int) { def this(x: Int) = this(x, x) def this() = this(1) override def toString() = "x=" + x + " y=" + y class B(a: Int, b: Int, c: String) { def this(str: String) = this(x, y, str) override def toString() = "x=" + x + " y=" + y + " a=" + a + " b=" + b + " c=" + c } }
val df = sqlContext.load("com.databricks.spark.csv", Map("path" -> "cars.csv", "header" -> "true")) df.printSchema() root |-- year: string (nullable = true) |-- make: string (nullable = true) |-- model: string (nullable = true) |-- comment: string (nullable = true) |-- blank: string (nullable = true) df.show() year make model comment blank 2012 Tesla S No comment 1997 Ford E350 Go get one now th...
df.withColumn("year2", org.apache.spark.sql.DataFrame = [year: int, make: string, model: string, comment: string, blank: string]
df2 <- df %>% mutate(year = year %>% as.integer, make = make %>% toupper)
import org.apache.spark.sql.types.IntegerType val df2 = df.withColumn("yearTmp", df.year.cast(IntegerType)) .drop("year") .withColumnRenamed("yearTmp", "year")
val df2 = df.selectExpr("cast(year as int) year", "make", "model", "comment", "blank")
scala> df.printSchema root |-- Year: string (nullable = true) |-- Month: string (nullable = true) |-- DayofMonth: string (nullable = true) |-- DayOfWeek: string (nullable = true) |-- DepDelay: string (nullable = true) |-- Distance: string (nullable = true) |-- CRSDepTime: string (nullable = true)
import org.apache.spark.sql.functions._ val toInt = udf[Int, String]( _.toInt) val toDouble = udf[Double, String]( _.toDouble) val toHour = udf((t: String) => "%04d".format(t.toInt).take(2).toInt ) val days_since_nearest_holidays = udf( (year:String, month:String, dayOfMonth:String) => year.toInt + 27 + month.toInt-12 )
val featureDf = df .withColumn("departureDelay", toDouble(df("DepDelay"))) .withColumn("departureHour", toHour(df("CRSDepTime"))) .withColumn("dayOfWeek", toInt(df("DayOfWeek"))) .withColumn("dayOfMonth", toInt(df("DayofMonth"))) .withColumn("month", toInt(df("Month"))) .withColumn("distance", toDouble(df("Distance"))) .withColumn("nearestHoliday", days_since_nearest_holidays( df("Year"), df("Month"), df("DayofMonth")) ) .select("departureDelay", "departureHour", "dayOfWeek", "dayOfMonth", "month", "distance", "nearestHoliday")
scala> df.printSchema root |-- departureDelay: double (nullable = true) |-- departureHour: integer (nullable = true) |-- dayOfWeek: integer (nullable = true) |-- dayOfMonth: integer (nullable = true) |-- month: integer (nullable = true) |-- distance: double (nullable = true) |-- nearestHoliday: integer (nullable = true)
df.select( df("year").cast(IntegerType).as("year"), ... )
object DFHelper{ def castColumnTo( df: DataFrame, cn: String, tpe: DataType ) : DataFrame = { df.withColumn( cn, df(cn).cast(tpe) ) } }
import DFHelper._ val df2 = castColumnTo( df, "year", IntegerType )
import org.apache.spark.sql df.withColumn("year", $"year".cast(sql.types.IntegerType))
val df2 = df.select( df.columns.map { case year @ "year" => df(year).cast(IntegerType).as(year) case make @ "make" => functions.upper(df(make)).as(make) case other => df(other) }: _* )
df.selectExpr("cast(year as int) as year", "upper(make) as make", "model", "comment", "blank")
df.withColumn("col_name", df.col("col_name").cast(DataTypes.IntegerType))
import org.apache.spark.sql.jdbc.{JdbcDialects, JdbcType, JdbcDialect} import org.apache.spark.sql.jdbc.JdbcType val SQLServerDialect = new JdbcDialect { override def canHandle(url: String): Boolean = url.startsWith("jdbc:jtds:sqlserver") || url.contains("sqlserver") override def getJDBCType(dt: DataType): Option[JdbcType] = dt match { case StringType => Some(JdbcType("VARCHAR(5000)", java.sql.Types.VARCHAR)) case BooleanType => Some(JdbcType("BIT(1)", java.sql.Types.BIT)) case IntegerType => Some(JdbcType("INTEGER", java.sql.Types.INTEGER)) case LongType => Some(JdbcType("BIGINT", java.sql.Types.BIGINT)) case DoubleType => Some(JdbcType("DOUBLE PRECISION", java.sql.Types.DOUBLE)) case FloatType => Some(JdbcType("REAL", java.sql.Types.REAL)) case ShortType => Some(JdbcType("INTEGER", java.sql.Types.INTEGER)) case ByteType => Some(JdbcType("INTEGER", java.sql.Types.INTEGER)) case BinaryType => Some(JdbcType("BINARY", java.sql.Types.BINARY)) case TimestampType => Some(JdbcType("DATE", java.sql.Types.DATE)) case DateType => Some(JdbcType("DATE", java.sql.Types.DATE)) case t: DecimalType => Some(JdbcType(s"DECIMAL(${t.precision},${t.scale})", java.sql.Types.DECIMAL)) case _ => throw new IllegalArgumentException(s"Don } } JdbcDialects.registerDialect(SQLServerDialect)
val df = spark.range(5).select( col("id").cast("string") )
df.select($"long_col".cast(IntegerType).as("int_col"))
df.show +-------------------+ | a| +-------------------+ |8182175552014127960| +-------------------+ df.selectExpr("cast(a as bigint) a").show +-------------------+ | a| +-------------------+ |8182175552014128100| +-------------------+
root |-- id: integer (nullable = true) |-- flag1: string (nullable = true) |-- flag2: string (nullable = true) |-- name: string (nullable = true) |-- flag3: string (nullable = true)
df=df.withColumnRenamed(<old column name>,<dummy column>) df=df.withColumn(<old column name>,df.col(<dummy column>).cast(<datatype>)).drop(<dummy column>)
root |-- id: integer (nullable = true) |-- flag2: string (nullable = true) |-- name: string (nullable = true) |-- flag1: boolean (nullable = true) |-- flag3: boolean (nullable = true)
df.withColumn("year", df("year").cast(IntegerType))
val fact_df = df.select($"data"(30) as "TopicTypeId", $"data"(31) as "TopicId",$"data"(21).cast(FloatType).as( "Data_Value_Std_Err")).rdd val fact_schema = (new StructType).add("TopicTypeId", StringType).add("TopicId", StringType).add("Data_Value_Std_Err", FloatType) val fact_table = sqlContext.createDataFrame(fact_df, fact_schema).dropDuplicates()
val df = spark.range(5).select( col("id").cast("string")).withColumnRenamed("id","value")
import scala.io.Source val source = Source.fromURL(getClass.getResource("/data.xml"))
Source.fromURL(getClass.getResource("/testData.txt"))
val path = getClass.getResource("/testData.txt").getPath val file = new File(path)
import scala.collection.JavaConversions._ for(file <- new File(".").listFiles ){ println(file.getAbsolutePath) }
:type Map(1 -> (1 to 10), 2 -> (1 to 10).toList) scala.collection.immutable.Map[Int,scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int] with Serializable{def reverse: scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]{def reverse: scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]; def dropRight(n: Int): scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]; def takeRight(n: Int): scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]; def drop(n: Int): scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]; def take(n: Int): scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]}; def dropRight(n: Int): scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]{def reverse: scala.collection.immutable.Seq[Int] with scala.collection.AbstractSeq[Int]; def dropRight(n: Int): scala.collection.immutable.Seq[Int]...
def f = new File("file.txt") def s = f.text f.text = "file contents"
import java.io.PrintWriter new PrintWriter("filename") { write("file contents"); close }
import java.nio.file.{Paths, Files} import java.nio.charset.StandardCharsets Files.write(Paths.get("file.txt"), "file contents".getBytes(StandardCharsets.UTF_8))
reflect.io.File("filename").writeAll("hello world")
Some(new PrintWriter("filename")).foreach{p => p.write("hello world"); p.close}
import java.io._ import scala.io._ class RichFile( file: File ) { def text = Source.fromFile( file )(Codec.UTF8).mkString def text_=( s: String ) { val out = new PrintWriter( file , "UTF-8") try{ out.print( s ) } finally{ out.close } } } object RichFile { implicit def enrichFile( file: File ) = new RichFile( file ) }
scala> import RichFile.enrichFile import RichFile.enrichFile scala> val f = new File("/tmp/example.txt") f: java.io.File = /tmp/example.txt scala> f.text = "hello world" scala> f.text res1: String = "hello world
import scalax.io.Codec import scalax.io.JavaConverters._ implicit val codec = Codec.UTF8 new java.io.File("hi-file.txt").asOutput.write("I
scala> import java.io._ import java.io._ scala> val w = new BufferedWriter(new FileWriter("output.txt")) w: java.io.BufferedWriter = java.io.BufferedWriter@44ba4f scala> w.write("Alice\r\nBob\r\nCharlie\r\n") scala> w.close()
scala> import java.io.ByteArrayInputStream import java.io.ByteArrayInputStream scala> import java.io.FileOutputStream import java.io.FileOutputStream scala> BasicIO.transferFully(new ByteArrayInputStream("test".getBytes("UTF-8")), new FileOutputStream("test.txt"))
val writer = Try(new FileWriter(new File("filename"))) writer.map(w => {w.write("data"); w}).recoverWith{case e => {e.printStackTrace(); writer}}.map(_.close)
writer.map(w => {w.writer("data"); w}).recoverWith{case _ => writer}.map(_.close)
def printToFile(content: String, location: String = "C:/Users/jtdoe/Desktop/WorkSheet.txt") = Some(new java.io.PrintWriter(location)).foreach{f => try{f.write(content)}finally{f.close}}
printToFile("A fancy test string\ncontaining newlines\nOMG!\n")
printToFile("A fancy test string\ncontaining newlines\nOMG!\n", "C:/Users/jtdoe/Desktop/WorkSheet.txt")
import java.io.PrintWriter import java.nio.file.Files import java.nio.file.Paths import java.nio.charset.StandardCharsets import java.nio.file.StandardOpenOption val outfile = java.io.File.createTempFile("", "").getPath val outstream = new PrintWriter(Files.newBufferedWriter(Paths.get(outfile) , StandardCharsets.UTF_8 , StandardOpenOption.WRITE)); outstream.println("content"); outstream.flush(); outstream.close()
case class Address(street: String, city: String, state: String, zipCode: Int) case class Person(firstName: String, lastName: String, address: Address)
val raj = Person("Raj", "Shekhar", Address("M Gandhi Marg", "Mumbai", "Maharashtra", 411342))
val updatedRaj = raj.copy(address = raj.address.copy(zipCode = raj.address.zipCode + 1))
scala> @zip case class Pacman(lives: Int = 3, superMode: Boolean = false) scala> @zip case class Game(state: String = "pause", pacman: Pacman = Pacman()) scala> val g = Game() g: Game = Game("pause",Pacman(3,false)) scala> val g1 = g.copy(state = "run") g1: Game = Game("run",Pacman(3,false)) scala> val g2 = g1.copy(pacman = g1.pacman.copy(superMode = true)) g2: Game = Game("run",Pacman(3,true)) scala> val g3 = g1.loc.pacman.superMode set true g3: Game = Game("run",Pacman(3,true)
val e = Mul (Num (1), Add (Sub (Var ("hello"), Num (2)), Var ("harold"))) val incint = everywheretd (rule { case d : Double => d + 1 }) val r1 = Mul (Num (2), Add (Sub (Var ("hello"), Num (3)), Var ("harold"))) expect (r1) (rewrite (incint) (e))
val addressZipCodeLens = Lens( get = (_: Address).zipCode, set = (addr: Address, zipCode: Int) => addr.copy(zipCode = zipCode)) val personAddressLens = Lens( get = (_: Person).address, set = (p: Person, addr: Address) => p.copy(address = addr))
val personZipCodeLens = personAddressLens andThen addressZipCodeLens
val updatedRaj = personZipCodeLens.set(raj, personZipCodeLens.get(raj) + 1)
val updatedRaj = personZipCodeLens.set(raj, personZipCodeLens(raj) + 1)
val updatedRaj = personZipCodeLens.mod(raj, zip => zip + 1)
case class Lens[A,B](get: A => B, set: (A,B) => A) extends Function1[A,B] with Immutable { def apply(whole: A): B = get(whole) def updated(whole: A, part: B): A = set(whole, part) def mod(a: A, f: B => B) = set(a, f(this(a))) def compose[C](that: Lens[C,A]) = Lens[C,B]( c => this(that(c)), (c, b) => that.mod(c, set(_, b)) ) def andThen[C](that: Lens[B,C]) = that compose this }
case class Email(user: String, domain: String) case class Contact(email: Email, web: String) case class Person(name: String, contact: Contact) val person = Person( name = "Aki Saarinen", contact = Contact( email = Email("aki", "akisaarinen.fi"), web = "http: ) ) scala> Lenser[Person].contact.email.user.set(person, "john") res1: Person = Person(Aki Saarinen,Contact(Email(john,akisaarinen.fi),http:
case class Person(name: String, age: Int) val p = Person("brett", 21) scala> lens[Person].name._1(p) res1: String = brett scala> lens[Person].name._2(p, "bill") res2: Person = Person(bill,21) scala> lens[Person].namexx(())
import monocle.Macro._ import monocle.syntax._ case class A(s: String) case class B(a: A) val aLens = mkLens[B, A]("a") val sLens = aLens |-> mkLens[A, String]("s") val b = B(A("hi")) val newB = b |-> sLens set("goodbye")
resolvers ++= Seq( "Sonatype OSS Releases" at "http: "Sonatype OSS Snapshots" at "http: ) val scalaVersion = "2.11.0" val libraryVersion = "0.4.0" libraryDependencies ++= Seq( "com.github.julien-truffaut" %% "monocle-core" % libraryVersion, "com.github.julien-truffaut" %% "monocle-generic" % libraryVersion, "com.github.julien-truffaut" %% "monocle-macro" % libraryVersion, "com.github.julien-truffaut" %% "monocle-law" % libraryVersion % test )
case class Address(street: String, city: String, state: String, zipCode: Int) case class Person(firstName: String, lastName: String, address: Address) object LensSpec { import shapeless._ val zipLens = lens[Person] >> val surnameLens = lens[Person] >> val surnameZipLens = surnameLens ~ zipLens } class LensSpec extends WordSpecLike with Matchers { import LensSpec._ "Shapless Lens" should { "do the trick" in { val raj = Person("Raj", "Shekhar", Address("M Gandhi Marg", "Mumbai", "Maharashtra", 411342)) val updatedRaj = raj.copy(address = raj.address.copy(zipCode = raj.address.zipCode + 1)) val lensUpdatedRaj = zipLens.set(raj)(raj.address.zipCode + 1) assert(lensUpdatedRaj == updatedRaj) } "better yet chain them together as a template of values to set" in { val raj = Person("Raj", "Shekhar", Address("M Gandhi Marg", "Mumbai", "Maharashtra", 411342)) val updatedRaj = raj.copy(firstName="Rajendra", address = raj.address.copy(zipCode = raj.address.zipCode + 1)) val lensUpdatedRaj = surnameZipLens.set(raj)("Rajendra", raj.address.zipCode+1) assert(lensUpdatedRaj == updatedRaj) } } }
case class Person(firstName: String, lastName: String, address: Address) { def modifyZipCode(modifier: Int => Int) = this.copy(address = address.copy(zipCode = modifier(address.zipCode))) }
val updatedRaj = raj.modifyZipCode(_ => 41).modifyZipCode(_ + 1)
case class Address(street: String, city: String, state: String, zipCode: Int) case class Person(firstName: String, lastName: String, address: Address)
val raj = Person("Raj", "Shekhar", Address("M Gandhi Marg", "Mumbai", "Maharashtra", 411342))
import com.softwaremill.quicklens._ val updatedRaj = raj.modify(_.address.zipCode).using(_ + 1)
scala> Double.NaN == Double.NaN res3: Boolean = false scala> Double.NaN equals Double.NaN res4: Boolean = true
public static void main(final String... args) { final double unboxedNaN = Double.NaN; final Double boxedNaN = Double.valueOf(Double.NaN); System.out.println(unboxedNaN == unboxedNaN); System.out.println(boxedNaN == boxedNaN); System.out.println(boxedNaN.equals(boxedNaN)); }
"org.hibernate" % "hibernate-entitymanager" % "4.1.0.Final", "com.typesafe" %% "play-plugins-mailer" % "2.1"
val appDependencies = Seq( "org.scala-tools" % "scala-stm_2.9.1" % "0.3" )
val appDependencies = Seq( "org.scala-tools" %% "scala-stm" % "0.3" )
object WeekDay extends Enumeration { type WeekDay = Value val Mon, Tue, Wed, Thu, Fri, Sat, Sun = Value } import WeekDay._
def isWorkingDay(d: WeekDay) = ! (d == Sat || d == Sun)
object WeekDay extends Enumeration { val Mon, Tue, Wed, Thu, Fri, Sat, Sun = Value }
def isWorkingDay(d: WeekDay.Value) = ! (d == WeekDay.Sat || d == WeekDay.Sun)
import spark.implicits._ class MyObj(val i: Int) val d = spark.createDataset(Seq(new MyObj(1),new MyObj(2),new MyObj(3)))
import spark.implicits._ case class Wrap[T](unwrap: T) class MyObj(val i: Int) val d = spark.createDataset(Seq(Wrap(new MyObj(1)),Wrap(new MyObj(2)),Wrap(new MyObj(3))))
import spark.implicits._ class MyObj(val i: Int) implicit val myObjEncoder = org.apache.spark.sql.Encoders.kryo[MyObj] val d = spark.createDataset(Seq(new MyObj(1),new MyObj(2),new MyObj(3)))
import scala.reflect.ClassTag implicit def kryoEncoder[A](implicit ct: ClassTag[A]) = org.apache.spark.sql.Encoders.kryo[A](ct)
class MyObj(val i: Int) val d1 = spark.createDataset(Seq(new MyObj(1),new MyObj(2),new MyObj(3))) val d2 = d1.map(d => (d.i+1,d)).alias("d2") val d3 = d1.map(d => (d.i, d)).alias("d3") val d4 = d2.joinWith(d3, $"d2._1" === $"d3._1")
import org.apache.spark.sql.{Encoder,Encoders} import scala.reflect.ClassTag import spark.implicits._ implicit def single[A](implicit c: ClassTag[A]): Encoder[A] = Encoders.kryo[A](c) implicit def tuple2[A1, A2]( implicit e1: Encoder[A1], e2: Encoder[A2] ): Encoder[(A1,A2)] = Encoders.tuple[A1,A2](e1, e2) implicit def tuple3[A1, A2, A3]( implicit e1: Encoder[A1], e2: Encoder[A2], e3: Encoder[A3] ): Encoder[(A1,A2,A3)] = Encoders.tuple[A1,A2,A3](e1, e2, e3)
class MyObj(val i: Int) val d1 = spark.createDataset(Seq(new MyObj(1),new MyObj(2),new MyObj(3))) val d2 = d1.map(d => (d.i+1,d)).toDF("_1","_2").as[(Int,MyObj)].alias("d2") val d3 = d1.map(d => (d.i ,d)).toDF("_1","_2").as[(Int,MyObj)].alias("d3") val d4 = d2.joinWith(d3, $"d2._1" === $"d3._1")
class MyObj(val i: Int, val u: java.util.UUID, val s: Set[String]) type MyObjEncoded = (Int, String, Set[String]) implicit def toEncoded(o: MyObj): MyObjEncoded = (o.i, o.u.toString, o.s) implicit def fromEncoded(e: MyObjEncoded): MyObj = new MyObj(e._1, java.util.UUID.fromString(e._2), e._3)
val d = spark.createDataset(Seq[MyObjEncoded]( new MyObj(1, java.util.UUID.randomUUID, Set("foo")), new MyObj(2, java.util.UUID.randomUUID, Set("bar")) )).toDF("i","u","s").as[MyObjEncoded]
class Bar(i: Int) { override def toString = s"bar $i" def bar = i }
object BarEncoders { implicit def barEncoder: org.apache.spark.sql.Encoder[Bar] = org.apache.spark.sql.Encoders.kryo[Bar] }
object Main { def main(args: Array[String]) { val sc = new SparkContext("local", "test", new SparkConf()) val sqlContext = new SQLContext(sc) import sqlContext.implicits._ import BarEncoders._ val ds = Seq(new Bar(1)).toDS ds.show sc.stop() } }
val longBarEncoder = Encoders.tuple(Encoders.scalaLong, Encoders.kryo[Bar]) spark.createDataset(Seq((1L, new Bar(1))))(longBarEncoder)
object BarConversions { implicit def toInt(bar: Bar): Int = bar.bar implicit def toBar(i: Int): Bar = new Bar(i) } object Main { def main(args: Array[String]) { val sc = new SparkContext("local", "test", new SparkConf()) val sqlContext = new SQLContext(sc) import sqlContext.implicits._ import BarConversions._ type EncodedBar = Int val bars: RDD[EncodedBar] = sc.parallelize(Seq(new Bar(1))) val barsDS = bars.toDS barsDS.show barsDS.map(_.bar).show sc.stop() } }
trait CustomEnum { def value:String } case object Foo extends CustomEnum { val value = "F" } case object Bar extends CustomEnum { val value = "B" } object CustomEnum { def fromString(str:String) = Seq(Foo, Bar).find(_.value == str).get }
class CustomEnumUDT extends UserDefinedType[CustomEnum] { override def sqlType: DataType = org.apache.spark.sql.types.StringType override def serialize(obj: CustomEnum): Any = org.apache.spark.unsafe.types.UTF8String.fromString(obj.value) override def deserialize(datum: Any): CustomEnum = CustomEnum.fromString(datum.toString) override def userClass: Class[CustomEnum] = classOf[CustomEnum] } UDTRegistration.register(classOf[CustomEnum].getName, classOf[CustomEnumUDT].getName)
case class UsingCustomEnum(id:Int, en:CustomEnum) val seq = Seq( UsingCustomEnum(1, Foo), UsingCustomEnum(2, Bar), UsingCustomEnum(3, Foo) ).toDS() seq.filter(_.en == Foo).show() println(seq.collect())
trait CustomPoly case class FooPoly(id:Int) extends CustomPoly case class BarPoly(value:String, secondValue:Long) extends CustomPoly
case class UsingPoly(id:Int, poly:CustomPoly) Seq( UsingPoly(1, new FooPoly(1)), UsingPoly(2, new BarPoly("Blah", 123)), UsingPoly(3, new FooPoly(1)) ).toDS polySeq.filter(_.poly match { case FooPoly(value) => value == 1 case _ => false }).show()
class CustomPolyUDT extends UserDefinedType[CustomPoly] { val kryo = new Kryo() override def sqlType: DataType = org.apache.spark.sql.types.BinaryType override def serialize(obj: CustomPoly): Any = { val bos = new ByteArrayOutputStream() val oos = new ObjectOutputStream(bos) oos.writeObject(obj) bos.toByteArray } override def deserialize(datum: Any): CustomPoly = { val bis = new ByteArrayInputStream(datum.asInstanceOf[Array[Byte]]) val ois = new ObjectInputStream(bis) val obj = ois.readObject() obj.asInstanceOf[CustomPoly] } override def userClass: Class[CustomPoly] = classOf[CustomPoly] }
UDTRegistration.register(classOf[CustomPoly].getName, classOf[CustomPolyUDT].getName)
case class UsingPoly(id:Int, poly:CustomPoly) Seq( UsingPoly(1, new FooPoly(1)), UsingPoly(2, new BarPoly("Blah", 123)), UsingPoly(3, new FooPoly(1)) ).toDS polySeq.filter(_.poly match { case FooPoly(value) => value == 1 case _ => false }).show()
scala> import spark.implicits._ import spark.implicits._ scala> import org.apache.spark.sql.Encoders import org.apache.spark.sql.Encoders scala> case class NormalPerson(name: String, age: Int) { | def aboutMe = s"I am ${name}. I am ${age} years old." | } defined class NormalPerson scala> case class ReversePerson(name: Int, age: String) { | def aboutMe = s"I am ${name}. I am ${age} years old." | } defined class ReversePerson scala> val normalPersons = Seq( | NormalPerson("Superman", 25), | NormalPerson("Spiderman", 17), | NormalPerson("Ironman", 29) | ) normalPersons: Seq[NormalPerson] = List(NormalPerson(Superman,25), NormalPerson(Spiderman,17), NormalPerson(Ironman,29)) scala> val ds1 = sc.parallelize(normalPersons).toDS ds1: org.apache.spark.sql.Dataset[NormalPerson] = [name: string, age: int] scala> val ds2 = ds1.map(np => ReversePerson(np.age, np.name)) ds2: org.apache.spark.sql.Dataset[ReversePerson] = [name: int, age: string] scala> ds1.show() +---------+---+ | name|age| +---------+---+ | Superman| 25| |Spiderman| 17| | Ironman| 29| +---------+---+ scala> ds2.show() +----+---------+ |name| age| +----+---------+ | 25| Superman| | 17|Spiderman| | 29| Ironman| +----+---------+ scala> ds1.foreach(p => println(p.aboutMe)) I am Ironman. I am 29 years old. I am Superman. I am 25 years old. I am Spiderman. I am 17 years old. scala> val ds2 = ds1.map(np => ReversePerson(np.age, np.name)) ds2: org.apache.spark.sql.Dataset[ReversePerson] = [name: int, age: string] scala> ds2.foreach(p => println(p.aboutMe)) I am 17. I am Spiderman years old. I am 25. I am Superman years old. I am 29. I am Ironman years old.
scala> implicit val normalPersonKryoEncoder = Encoders.kryo[NormalPerson] normalPersonKryoEncoder: org.apache.spark.sql.Encoder[NormalPerson] = class[value[0]: binary] scala> implicit val reversePersonKryoEncoder = Encoders.kryo[ReversePerson] reversePersonKryoEncoder: org.apache.spark.sql.Encoder[ReversePerson] = class[value[0]: binary] scala> val ds3 = sc.parallelize(normalPersons).toDS ds3: org.apache.spark.sql.Dataset[NormalPerson] = [value: binary] scala> val ds4 = ds3.map(np => ReversePerson(np.age, np.name)) ds4: org.apache.spark.sql.Dataset[ReversePerson] = [value: binary] scala> ds3.show() +--------------------+ | value| +--------------------+ |[01 00 24 6C 69 6...| |[01 00 24 6C 69 6...| |[01 00 24 6C 69 6...| +--------------------+ scala> ds4.show() +--------------------+ | value| +--------------------+ |[01 00 24 6C 69 6...| |[01 00 24 6C 69 6...| |[01 00 24 6C 69 6...| +--------------------+ scala> ds3.foreach(p => println(p.aboutMe)) I am Ironman. I am 29 years old. I am Spiderman. I am 17 years old. I am Superman. I am 25 years old. scala> ds4.foreach(p => println(p.aboutMe)) I am 25. I am Superman years old. I am 29. I am Ironman years old. I am 17. I am Spiderman years old.
import spark.sqlContext.implicits._ import org.apache.spark.sql.Encoders implicit val encoder = Encoders.bean[MyClasss](classOf[MyClass])
public class Fruit implements Serializable { private String name = "default-fruit"; private String color = "default-color"; public Fruit(String name, String color) { this.name = name; this.color = color; } public Fruit() { this("default-fruit", "default-color"); } }
SparkSession spark = SparkSession.builder().getOrCreate(); JavaSparkContext jsc = new JavaSparkContext(); List<Fruit> fruitList = ImmutableList.of( new Fruit("apple", "red"), new Fruit("orange", "orange"), new Fruit("grape", "purple")); JavaRDD<Fruit> fruitJavaRDD = jsc.parallelize(fruitList); RDD<Fruit> fruitRDD = fruitJavaRDD.rdd(); Encoder<Fruit> fruitBean = Encoders.bean(Fruit.class); Dataset<Fruit> fruitDataset = spark.createDataset(rdd, bean);
class SerializableDenseVector(values: Array[Double]) extends breeze.linalg.DenseVector[Double](values) with DefinedByConstructorParams implicit def BreezeVectorToSerializable(bv: breeze.linalg.DenseVector[Double]): SerializableDenseVector = bv.asInstanceOf[SerializableDenseVector]
o match { case Some(x) => println(x) case None => }
o match { case x @ Some(_) => println(x) case None => }
scala> val d@(c@Some(a), Some(b)) = (Some(1), Some(2)) d: (Some[Int], Some[Int]) = (Some(1),Some(2)) c: Some[Int] = Some(1) a: Int = 1 b: Int = 2 scala> (Some(1), Some(2)) match { case d@(c@Some(a), Some(b)) => println(a, b, c, d) } (1,2,Some(1),(Some(1),Some(2))) scala> for (x@Some(y) <- Seq(None, Some(1))) println(x, y) (Some(1),1) scala> val List(x, xs @ _*) = List(1, 2, 3) x: Int = 1 xs: Seq[Int] = List(2, 3)
case x @ "three" => assert(x.equals("three")) case x @ Some("three") => assert(x.get.equals("three"))) case x @ List("one", "two", "three") => for (element <- x) { println(element) }
abstract class Expr case class Number(n: Int) extends Expr case class Sum(e1: Expr, e2: Expr) extends Expr def eval(e: Expr): Int = e match { case Number(x) => x case Sum(l, r) => eval(l) + eval(r) }
case Sum(l,r) case "hello" case _ : Foo case x => case _ =>
def eval(e: Expr): Int = { <synthetic> val temp10: Expr = e; if (temp10.$isInstanceOf[Number]()) temp10.$asInstanceOf[Number]().n() else if (temp10.$isInstanceOf[Sum]()) { <synthetic> val temp13: Sum = temp10.$asInstanceOf[Sum](); Main.this.eval(temp13.e1()).+(Main.this.eval(temp13.e2())) } else throw new MatchError(temp10) };
list.sorted(Ordering.by((_: TheType).size).reverse)
def Desc[T : Ordering] = implicitly[Ordering[T]].reverse List("1","22","4444","333").sortBy( _.size )(Desc)
scala> val list = List("abc","a","abcde") list: List[java.lang.String] = List(abc, a, abcde) scala> list.sortBy(-_.size) res0: List[java.lang.String] = List(abcde, abc, a) scala> list.sortBy(_.size) res1: List[java.lang.String] = List(a, abc, abcde)
def sortBy [B] (f: (A) ⇒ B)(implicit ord: Ordering[B]): List[A]
scala> implicit object Comp extends Ordering[Int] { | override def compare (x: Int, y: Int): Int = y - x | } defined module Comp List(3,2,5,1,6).sortBy(x => x) res5: List[Int] = List(6, 5, 3, 2, 1)
val list = List(2, 5, 3, 1) list.sortWith(_>_) -> res14: List[Int] = List(5, 3, 2, 1) list.sortWith(_<_) -> res14: List[Int] = List(1, 2, 3, 5)
case class Foo(time:Long, str:String) val l = List(Foo(1, "hi"), Foo(2, "a"), Foo(3, "X")) l.sortWith(_.time > _.time) l.sortBy(- _.time) l.sortBy(_.time)
val buf = collection.mutable.ArrayBuffer[Int]() buf += 3 buf += 9 buf += 1 def sortFn = (A:Int, B:Int) => { A < B } buf.sortWith(sortFn) buf.sortWith((A,B) => { ! sortFn(A,B) })
val wordCounts = logData.flatMap(line => line.split(" ")) .map(word => (word, 1)) .reduceByKey((a, b) => a + b) wordCounts.sortBy(- _._2).collect()
File -> Settings -> Languages & Frameworks -> Scala
.. class Foo extends scala.AnyRef { <paramaccessor> private[this] val bar: Int = _; def <init>(bar: Int): this.Foo = { Foo.super.<init>(); () } } .. .. class Foo extends scala.AnyRef { <paramaccessor> private[this] val bar: Int = _; <stable> <accessor> <paramaccessor> private def bar: Int = Foo.this.bar; def <init>(bar: Int): this.Foo = { Foo.super.<init>(); () } } ..
class Foo(private val bar: Int) { def otherBar(f: Foo) { println(f.bar) } }
scala> val a = new Foo(1) a: Foo = Foo@7a99d0af scala> a.otherBar(new Foo(3)) 3
class Foo(bar: Int) { def otherBar(f: Foo) { println(f.bar) } }
import scala.collection.mutable.ListBuffer def listTestA() ={ var list:List[Int] = Nil for(i <- 0 to 3) list = list ::: List(i) list } def listTestB() ={ val list = new ListBuffer[Int]() for (i <- 0 to 3) list += i list.toList } def listTestC() ={ def _add(l:List[Int], i:Int):List[Int] = i match { case 3 => l ::: List(3) case _ => _add(l ::: List(i), i +1) } _add(Nil, 0) }
scala> val list = for(i <- 1 to 10) yield i list: scala.collection.immutable.IndexedSeq[Int] = Vector(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
List.tabulate(3)( x => 2*x ) res: List(0, 2, 4) List.tabulate(3)( _ => Math.random ) res: List(0.935455779102479, 0.6004888906328091, 0.3425278797788426) List.tabulate(3)( _ => (Math.random*10).toInt ) res: List(8, 0, 7)
import java.util.Date object Listbm { final val listSize = 1048576 final val iterationCounts = 5 def getCurrentTime: BigInt = (new Date) getTime def createList[T] ( f : Int => T )( size : Int ): T = f ( size ) def experiment[T] ( f : Int => T ) ( iterations: Int ) ( size :Int ) : Int = { val start_time = getCurrentTime for ( p <- 0 to iterations ) createList ( f ) ( size ) return (getCurrentTime - start_time) toInt } def printResult ( f: => Int ) : Unit = println ( "execution time " + f ) def main( args : Array[String] ) { args(0) match { case "for" => printResult ( experiment ( x => (for ( p <- ( 0 to x ) ) yield p) toList ) ( iterationCounts ) ( listSize ) ) case "range" => printResult ( experiment ( x => ( 0 to x ) toList ) ( iterationCounts ) ( listSize ) ) case "::" => printResult ( experiment ( x => ((0 to x) :\ List[Int]())(_ :: _) ) ( iterationCounts ) ( listSize ) ) case _ => println ( "please use: for, range or ::\n") } } }
scala> val a : List[Int] = (for( x <- 1 to 10 ) yield x * 3)(collection.breakOut) a: List[Int] = List(3, 6, 9, 12, 15, 18, 21, 24, 27, 30) scala> val b : List[Int] = (1 to 10).map(_ * 3)(collection.breakOut) b: List[Int] = List(3, 6, 9, 12, 15, 18, 21, 24, 27, 30)
case class Board(length: Int, height: Int) { case class Coordinate(x: Int, y: Int) { require(0 <= x && x < length && 0 <= y && y < height) } val occupied = scala.collection.mutable.Set[Coordinate]() } val b1 = Board(20, 20) val b2 = Board(30, 30) val c1 = b1.Coordinate(15, 15) val c2 = b2.Coordinate(25, 25) b1.occupied += c1 b2.occupied += c2 b1.occupied += c2
val b3: b1.type = b1 val c3 = b3.Coordinate(10, 10) b1.occupied += c3
$ scala Welcome to Scala version 2.11.0 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_51). Type in expressions to have them evaluated. Type :help for more information. scala> exit <console>:8: error: not found: value exit exit ^ scala>
import scala.concurrent.duration._ val time = 20 seconds
scala> println (Nil == List()) true scala> println (Nil eq List()) true scala> println (Nil equals List()) true scala> System.identityHashCode(Nil) 374527572 scala> System.identityHashCode(List()) 374527572
scala> val x = List() x: List[Nothing] = List() scala> val y = Nil y: scala.collection.immutable.Nil.type = List() scala> def cmpTypes[A, B](a: A, b: B)(implicit ev: A =:= B = null) = if (ev eq null) false else true cmpTypes: [A, B](a: A, b: B)(implicit ev: =:=[A,B])Boolean scala> cmpTypes(x, y) res0: Boolean = false scala> cmpTypes(x, x) res1: Boolean = true scala> cmpTypes(y, y) res2: Boolean = true
scala> List(1, 2, 3).foldLeft(List[Int]())((x, y) => y :: x) res6: List[Int] = List(3, 2, 1) scala> List(1, 2, 3).foldLeft(Nil)((x, y) => y :: x) <console>:10: error: type mismatch; found : List[Int] required: scala.collection.immutable.Nil.type List(1, 2, 3).foldLeft(Nil)((x, y) => y :: x) ^
Array List Access the ith element θ(1) θ(i) Delete the ith element θ(n) θ(i) Insert an element at i θ(n) θ(i) Reverse θ(n) θ(n) Concatenate (length m,n) θ(n+m) θ(n) Count the elements θ(1) θ(n)
Array List Get the first i elements θ(i) θ(i) Drop the first i elements θ(n-i) θ(1) Insert an element at i θ(n) θ(i) Reverse θ(n) θ(n) Concatenate (length m,n) θ(n+m) θ(n)
[ { { ] val jArray = JsArray(); jArray += (("id", "1"), ("name", "John")) jArray += (("id", "2"), ("name", "Dani")) println(jArray.dump)
scalaVersion := "2.11.5" "net.liftweb" %% "lift-json" % "2.6"
scala> import com.codahale.jerkson.Json._ scala> val l = List( Map( "id" -> 1, "name" -> "John" ), Map( "id" -> 2, "name" -> "Dani") ) scala> generate( l ) res1: String = [{"id":1,"name":"John"},{"id":2,"name":"Dani"}]
object MyJacksonMapper extends JacksonMapper val jsonString = MyJacksonMapper.serializeJson(myObject) val myNewObject = MyJacksonMapper.deserializeJson[MyCaseClass](jsonString)
trait JacksonMapper { def jsonSerializer = { val m = new ObjectMapper() m.registerModule(DefaultScalaModule) m } def xmlSerializer = { val m = new XmlMapper() m.registerModule(DefaultScalaModule) m } def deserializeJson[T: Manifest](value: String): T = jsonSerializer.readValue(value, typeReference[T]) def serializeJson(value: Any) = jsonSerializer.writerWithDefaultPrettyPrinter().writeValueAsString(value) def deserializeXml[T: Manifest](value: String): T = xmlSerializer.readValue(value, typeReference[T]) def serializeXml(value: Any) = xmlSerializer.writeValueAsString(value) private[this] def typeReference[T: Manifest] = new TypeReference[T] { override def getType = typeFromManifest(manifest[T]) } private[this] def typeFromManifest(m: Manifest[_]): Type = { if (m.typeArguments.isEmpty) { m.erasure } else new ParameterizedType { def getRawType = m.erasure def getActualTypeArguments = m.typeArguments.map(typeFromManifest).toArray def getOwnerType = null } } }
val typesaferepo = "TypeSafe Repo" at "http: val play2 = "play" %% "play" % "2.1.1"
import com.owlike.genson.defaultGenson_ val json = toJson(Person(Some("foo"), 99)) val person = fromJson[Person]("""{"name": "foo", "age": 99}""") case class Person(name: Option[String], age: Int)
import org.json4s._ import org.json4s.jackson.JsonMethods._ import org.json4s.JsonDSL._ import java.io._ import scala.io.Source object MyObject { def main(args: Array[String]) { val myMap = Map("a" -> List(3,4), "b" -> List(7,8)) val jsonString = pretty(render(myMap)) val pw = new PrintWriter(new File("my_json.json")) pw.write(jsonString) pw.close() val myString = Source.fromFile("my_json.json").mkString println(myString) val myJSON = parse(myString) println(myJSON) implicit val formats = DefaultFormats val myOldMap = myJSON.extract[Map[String, List[Int]]] println(myOldMap) } }
package mytest import scalaz._, Scalaz._ import argonaut._, Argonaut._ object Mytest extends App { val requestJson = """ { "userid": "1" } """.stripMargin val updatedJson: Option[Json] = for { parsed <- requestJson.parseOption } yield ("name", jString("testuser")) ->: parsed val obj = updatedJson.get.obj printf("Updated user: %s\n", updatedJson.toString()) printf("obj : %s\n", obj.toString()) printf("userid: %s\n", obj.get.toMap("userid")) }
$ sbt > run Updated user: Some({"userid":"1","name":"testuser"}) obj : Some(object[("userid","1"),("name","testuser")]) userid: "1"
test("base") { assert(Json.parse("123").asInt == 123) assert(Json.parse("-123").asInt == -123) assert(Json.parse("111111111111111").asLong == 111111111111111l) assert(Json.parse("true").asBoolean == true) assert(Json.parse("false").asBoolean == false) assert(Json.parse("123.123").asDouble == 123.123) assert(Json.parse("\"aaa\"").asString == "aaa") assert(Json.parse("\"aaa\"").write() == "\"aaa\"") val json = Json.Value(Map("a" -> Array(1,2,3), "b" -> Array(4, 5, 6))) assert(json("a")(0).asInt == 1) assert(json("b")(1).asInt == 5) } test("parse base") { val str = """ {"int":-123, "long": 111111111111111, "string":"asdf", "bool_true": true, "foo":"foo", "bool_false": false} """ val json = Json.parse(str) assert(json.asMap("int").asInt == -123) assert(json.asMap("long").asLong == 111111111111111l) assert(json.asMap("string").asString == "asdf") assert(json.asMap("bool_true").asBoolean == true) assert(json.asMap("bool_false").asBoolean == false) println(json.write()) assert(json.write().length > 0) } test("parse obj") { val str = """ {"asdf":[1,2,4,{"bbb":"ttt"},432]} """ val json = Json.parse(str) assert(json.asMap("asdf").asArray(0).asInt == 1) assert(json.asMap("asdf").asArray(3).asMap("bbb").asString == "ttt") } test("parse array") { val str = """ [1,2,3,4,{"a":[1,2,3]}] """ val json = Json.parse(str) assert(json.asArray(0).asInt == 1) assert(json(4)("a")(2).asInt == 3) assert(json(4)("a")(2).isInt) assert(json(4)("a").isArray) assert(json(4)("a").isMap == false) } test("real") { val str = "{\"styles\":[214776380871671808,214783111085424640,214851869216866304,214829406537908224],\"group\":100,\"name\":\"AO4614【金宏达电子】现货库存 质量保证 欢迎购买@\",\"shopgrade\":8,\"price\":0.59,\"shop_id\":60095469,\"C3\":50018869,\"C2\":50024099,\"C1\":50008090,\"imguri\":\"http: val json = Json.parse(str) println(json.write()) assert(json.asMap.size > 0) }
val json = "com.typesafe.play" %% "play-json" % version val typesafe = "typesafe.com" at "http:
import nl.typeset.sonofjson._ arr( obj(id = 1, name = "John) obj(id = 2, name = "Dani) )
case class User(username: String, friends: Int, enemies: Int, isAlive: Boolean) object User { implicit val userJsonFormat = Json.format[User] }
object SerializingApp extends App { case class Person(name: String, address: Address) case class Address(street: String, town: String, zipCode: String) import upickle.default._ val john = Person("John Doe", Address("Elm Street 1", "Springfield", "ABC123")) val johnAsJson = write(john) Console.println(johnAsJson) Console.println(read[Person](johnAsJson)) }
libraryDependencies += "com.lihaoyi" %% "upickle" % "0.4.3"
trait Recurse { type Next <: Recurse type X[R <: Recurse] <: Int } trait RecurseA extends Recurse { type Next = RecurseA type X[R <: Recurse] = R } object Recurse { type C = RecurseA }
class A { class B def f(b: B) = println("Got my B!") }
scala> val a1 = new A a1: A = A@2fa8ecf4 scala> val a2 = new A a2: A = A@4bed4c8 scala> a2.f(new a1.B) <console>:11: error: type mismatch; found : a1.B required: a2.B a2.f(new a1.B) ^
class A { class B def f(b: B) = println("Got my B!") def g(b: A }
scala> val a1 = new A a1: A = A@1497b7b1 scala> val a2 = new A a2: A = A@2607c28c scala> a2.f(new a1.B) <console>:11: error: type mismatch; found : a1.B required: a2.B a2.f(new a1.B) ^ scala> a2.g(new a1.B) Got a B.
scala> trait R { | type A = Int | } defined trait R scala> val x = null.asInstanceOf[R x: Int = 0
case Process(word) => word.firstLetter match { case([a-c][A-C]) => case _ => } }
val Pattern = "([a-cA-C])".r word.firstLetter match { case Pattern(c) => c bound to capture group here case _ => }
implicit class Regex(sc: StringContext) { def r = new util.matching.Regex(sc.parts.mkString, sc.parts.tail.map(_ => "x"): _*) } scala> "123" match { case r"\d+" => true case _ => false } res34: Boolean = true
scala> "123" match { case r"(\d+)$d" => d.toInt case _ => 0 } res36: Int = 123 scala> "10+15" match { case r"(\d\d)${first}\+(\d\d)${second}" => first.toInt+second.toInt case _ => 0 } res38: Int = 25
scala> object Doubler { def unapply(s: String) = Some(s.toInt*2) } defined module Doubler scala> "10" match { case r"(\d\d)${Doubler(d)}" => d case _ => 0 } res40: Int = 20 scala> object isPositive { def unapply(s: String) = s.toInt >= 0 } defined module isPositive scala> "10" match { case r"(\d\d)${d @ isPositive()}" => d.toInt case _ => 0 } res56: Int = 10
object T { class RegexpExtractor(params: List[String]) { def unapplySeq(str: String) = params.headOption flatMap (_.r unapplySeq str) } class StartsWithExtractor(params: List[String]) { def unapply(str: String) = params.headOption filter (str startsWith _) map (_ => str) } class MapExtractor(keys: List[String]) { def unapplySeq[T](map: Map[String, T]) = Some(keys.map(map get _)) } import scala.language.dynamics class ExtractorParams(params: List[String]) extends Dynamic { val Map = new MapExtractor(params) val StartsWith = new StartsWithExtractor(params) val Regexp = new RegexpExtractor(params) def selectDynamic(name: String) = new ExtractorParams(params :+ name) } object p extends ExtractorParams(Nil) Map("firstName" -> "John", "lastName" -> "Doe") match { case p.firstName.lastName.Map( Some(p.Jo.StartsWith(fn)), Some(p.`.*(\\w)$`.Regexp(lastChar))) => println(s"Match! $fn ...$lastChar") case _ => println("nope") } }
val Process = """([a-cA-C])([^\s]+)""".r for (p <- Process findAllIn "aha bah Cah dah") p match { case Process("b", _) => println("first: case Process(_, rest) => println("some first, rest: " + rest) }
scala> val MY_RE = "(foo|bar).*".r MY_RE: scala.util.matching.Regex = (foo|bar).* scala> val result = "foo123" match { case MY_RE(m) => m; case _ => "No match" } result: String = foo scala> val result = "baz123" match { case MY_RE(m) => m; case _ => "No match" } result: String = No match scala> val result = "abcfoo123" match { case MY_RE(m) => m; case _ => "No match" } result: String = No match
scala> val MY_RE2 = "(foo|bar)".r MY_RE2: scala.util.matching.Regex = (foo|bar) scala> val result = "foo123" match { case MY_RE2(m) => m; case _ => "No match" } result: String = No match
"Cat"(0).toString.matches("[a-cA-C]") res10: Boolean = true
import scala.util.matching.Regex val pattern = "Scala".r val str = "Scala is very cool" val result = pattern findFirstIn str result match { case Some(v) => println(v) case _ => }
val date = """(\d\d\d\d)-(\d\d)-(\d\d)""".r "2014-11-20" match { case date(year, month, day) => "hello" }
def a = 10; while (! done) { receive { case msg => println("MESSAGE RECEIVED: " + msg) } println("after receive and printing a " + a) }
def a = 10; while (! done) { react { case msg => println("MESSAGE RECEIVED: " + msg) } println("after react and printing a " + a) }
-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005
sbt -J-Xdebug -J-Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005
:run "%_JAVACMD%" %_JAVA_OPTS% %SBT_OPTS% -cp "%SBT_HOME%sbt-launch.jar" xsbt.boot.Boot %* if ERRORLEVEL 1 goto error goto end
FOR %%a IN (%*) DO ( if "%%a" == "-jvm-debug" ( set JVM_DEBUG=true set /a JVM_DEBUG_PORT=5005 2>nul >nul ) else if "!JVM_DEBUG!" == "true" ( set /a JVM_DEBUG_PORT=%%a 2>nul >nul if not "%%a" == "!JVM_DEBUG_PORT!" ( set SBT_ARGS=!SBT_ARGS! %%a ) ) else ( set SBT_ARGS=!SBT_ARGS! %%a ) ) if defined JVM_DEBUG_PORT ( set _JAVA_OPTS=!_JAVA_OPTS! -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=!JVM_DEBUG_PORT! ) call :run %SBT_ARGS% if ERRORLEVEL 1 goto error goto end :run "%_JAVACMD%" %_JAVA_OPTS% %SBT_OPTS% -cp "%SBT_HOME%sbt-launch.jar" xsbt.boot.Boot %* goto :eof
I. Give some name example: DebugMyModule II. All needed configurations will be set automatically, But you just verify. In Command line arguments should look like this "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005". III. In IV. put 127.0.0.1 host instead of
project <your-module-name> it:testOnly package.TestSpec
export SBT_OPTS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5009
while (System.in.read() != -1) {} logger.warn("Received end-of-file on stdin. Exiting") System.exit(0)
type ErrorOrT[M[+_], A] = EitherT[M, Throwable, A] type ErrorOr[A] = ErrorOrT[IO, A] def processChunk(c: Chunk, idx: Long): Result def process(data: EnumeratorT[Chunk, ErrorOr]): IterateeT[Vector[(Chunk, Long)], ErrorOr, Vector[Result]] = Iteratee.fold[Vector[(Chunk, Long)], ErrorOr, Vector[Result]](Nil) { (rs, vs) => rs ++ vs map { case (c, i) => processChunk(c, i) } } &= (data.zipWithIndex mapE Iteratee.group(P))
scala> (i1 &= enumArrs(1 << 25, 128)).run.unsafePerformIO res47: Long = 4294967296 scala> (i2 &= (enumArrs(1 << 25, 128) mapE Iteratee.group(4))).run.unsafePerformIO res49: Long = 4294967296 scala> (i3 &= (enumArrs(1 << 25, 128).zipWithIndex mapE Iteratee.group(4))).run.unsafePerformIO java.lang.OutOfMemoryError: Java heap space scala> (i4 &= (enumArrs(1 << 25, 128).zipWithIndex)).run.unsafePerformIO res51: Long = 4294967296 scala> (i1 &= enumArrs(1 << 27, 128)).run.unsafePerformIO res53: Long = 17179869184 scala> (i4 &= (enumArrs(1 << 27, 128).zipWithIndex)).run.unsafePerformIO res54: Long = 17179869184
import scalaz.iteratee._, scalaz.effect.IO, scalaz.std.vector._ def enumArrs(sz: Int, n: Int) = Iteratee.enumIterator[Array[Int], IO]( Iterator.continually(Array.fill(sz)(0)).take(n)) val i1 = Iteratee.fold[Array[Int], IO, Long](0) { (c, a) => c + a.length } val i2 = Iteratee.fold[Vector[Array[Int]], IO, Long](0) { (c, as) => c + as.map(_.length).sum } val i3 = Iteratee.fold[Vector[(Array[Int], Long)], IO, Long](0) { (c, vs) => c + vs.map(_._1.length).sum } val i4 = Iteratee.fold[(Array[Int], Long), IO, Long](0) { (c, v) => c + v._1.length }
def streamArrs(sz: Int, n: Int): Process[Task, Array[Int]] = (Process emit Array.fill(sz)(0)).repeat take n (streamArrs(1 << 25, 1 << 14).zipWithIndex pipe process1.chunk(4) pipe process1.fold(0L) { (c, vs) => c + vs.map(_._1.length.toLong).sum }).runLast.run
def time[R](block: => R): R = { val t0 = System.nanoTime() val result = block val t1 = System.nanoTime() println("Elapsed time: " + (t1 - t0) + "ns") result } val result = 1 to 1000 sum val result = time { 1 to 1000 sum }
scala> def time[R](block: => R): R = { | val t0 = System.nanoTime() | val result = block | println("Elapsed time: " + (System.nanoTime - t0) + "ns") | result | } time: [R](block: => R)R
scala> :wrap time wrap: no such command. Type :help for help.
scala> :power ** Power User mode enabled - BEEP BOOP SPIZ ** ** :phase has been set to ** scala.tools.nsc._ has been imported ** ** global._ and definitions._ also imported ** ** Try :help, vals.<tab>, power.<tab> **
scala> :wrap time Set wrapper to scala> BigDecimal("1.456") Elapsed time: 950874ns Elapsed time: 870589ns Elapsed time: 902654ns Elapsed time: 898372ns Elapsed time: 1690250ns res0: scala.math.BigDecimal = 1.456
scala> :pa package wrappers { object wrap { def apply[A](a: => A): A = { println("running...") ; a } }} scala> $intp.setExecutionWrapper("wrappers.wrap") scala> 42 running... res2: Int = 42
import System.nanoTime def profile[R](code: => R, t: Long = nanoTime) = (code, nanoTime - t) val (result, time) = profile { } val (result2, time2) = profile methodToBeProfiled(foo)
scala> def testMethod {Thread.sleep(100)} testMethod: Unit scala> object Test extends testing.Benchmark { | def run = testMethod | } defined module Test scala> Test.main(Array("5")) $line16.$read$$iw$$iw$Test$ 100 100 100 100 100
Timelog("timer name/description") Timelog("timer name/description")
object Timelog { val timers = scala.collection.mutable.Map.empty[String, Long] // // def timer(timerName:String) = { if (timers contains timerName) { val output = s"$timerName took ${(System.nanoTime() - timers(timerName)) / 1000 / 1000} milliseconds" println(output) } else timers(timerName) = System.nanoTime() }
def profile[R] (repeat :Int)(code: => R, t: Long = System.nanoTime) = { (1 to repeat).foreach(i => code) (System.nanoTime - t)/repeat }
def profile[R] (repeat :Int)(code: => R) = { (1 to 10000).foreach(i => code) val start = System.nanoTime (1 to repeat).foreach(i => code) (System.nanoTime - start)/repeat }
def time[R](block: => R) = { def print_result(s: String, ns: Long) = { val formatter = java.text.NumberFormat.getIntegerInstance println("%-16s".format(s) + formatter.format(ns) + " ns") } var t0 = System.nanoTime() var result = block var t1 = System.nanoTime() print_result("First Run", (t1 - t0)) var lst = for (i <- 1 to 10) yield { t0 = System.nanoTime() result = block t1 = System.nanoTime() print_result("Run (t1 - t0).toLong } print_result("Max", lst.max) print_result("Min", lst.min) print_result("Avg", (lst.sum / lst.length)) }
scala> time {counter_new(lst)} First Run 2,963,261,456 ns Run Run Run Run Run Run Run Run Run Run Max 1,486,928,576 ns Min 1,299,298,316 ns Avg 1,407,390,921 ns scala> time {counter_old(lst)} First Run 444,795,051 ns Run Run Run Run Run Run Run Run Run Run Max 2,085,802,554 ns Min 403,933,518 ns Avg 797,980,787 ns
import org.scalameter._ def sumSegment(i: Long, j: Long): Long = (i to j) sum val (a, b) = (1, 1000000000) val execution_time = measure { sumSegment(a, b) }
execution_time: org.scalameter.Quantity[Double] = 0.260325 ms
import scala.concurrent.duration._ import scala.language.{postfixOps, implicitConversions} package object profile { def profile[R](code: => R): R = profileR(1)(code) def profileR[R](repeat: Int)(code: => R): R = { require(repeat > 0, "Profile: at least 1 repetition required") val start = Deadline.now val result = (1 until repeat).foldLeft(code) { (_: R, _: Int) => code } val end = Deadline.now val elapsed = ((end - start) / repeat) if (repeat > 1) { println(s"Elapsed time: $elapsed averaged over $repeat repetitions; Total elapsed time") val totalElapsed = (end - start) println(s"Total elapsed time: $totalElapsed") } else println(s"Elapsed time: $elapsed") result } }
Welcome to Scala version 2.11.7 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_60). Type in expressions to have them evaluated. Type :help for more information. scala> import scala.concurrent.duration._ import scala.concurrent.duration._ scala> import scala.language.{postfixOps, implicitConversions} import scala.language.{postfixOps, implicitConversions} scala> 1000.millis res0: scala.concurrent.duration.FiniteDuration = 1000 milliseconds scala> 1000.millis.toCoarsest res1: scala.concurrent.duration.Duration = 1 second scala> 1001.millis.toCoarsest res2: scala.concurrent.duration.Duration = 1001 milliseconds scala>
def time[R](block: => R): R = { val t0 = System.currentTimeMillis() val result = block val t1 = System.currentTimeMillis() println("Elapsed time: " + (t1 - t0) + "ms") result }
Account Date Type Amount 1001 2014-04-01 Purchase 100.00 1001 2014-04-01 Purchase 50.00 1001 2014-04-05 Purchase 70.00 1001 2014-04-01 Payment -150.00 1002 2014-04-01 Purchase 80.00 1002 2014-04-02 Purchase 22.00 1002 2014-04-04 Payment -120.00 1002 2014-04-04 Purchase 60.00 1003 2014-04-02 Purchase 210.00 1003 2014-04-03 Purchase 15.00
val partitionedByRange = df.repartitionByRange(42, $"k") partitionedByRange.explain
val df = Seq( ("A", 1), ("B", 2), ("A", 3), ("C", 1) ).toDF("k", "v") val partitioned = df.repartition($"k") partitioned.explain
import org.apache.spark.sql.types._ import org.apache.spark.sql.Row import org.apache.spark.HashPartitioner val schema = StructType(Seq( StructField("x", StringType, false), StructField("y", LongType, false), StructField("z", DoubleType, false) )) val rdd = sc.parallelize(Seq( Row("foo", 1L, 0.5), Row("bar", 0L, 0.0), Row("??", -1L, 2.0), Row("foo", -1L, 0.0), Row("??", 3L, 0.6), Row("bar", -3L, 0.99) )) val partitioner = new HashPartitioner(5) val partitioned = rdd.map(r => (r.getString(0), r)) .partitionBy(partitioner) .values val df = sqlContext.createDataFrame(partitioned, schema)
assert(df.rdd.partitions == partitioned.partitions)
sqlContext.createDataFrame( df.rdd.map(r => (r.getInt(1), r)).partitionBy(partitioner).values, df.schema )
sqlContext.read.jdbc(url, table, Array("foo = 1", "foo = 3"), props)
val df = Seq( ("foo", 1.0), ("bar", 2.0), ("foo", 1.5), ("bar", 2.6) ).toDF("k", "v") df.write.partitionBy("k").json("/tmp/foo.json")
val df1 = sqlContext.read.schema(df.schema).json("/tmp/foo.json") df1.where($"k" === "bar")
spark.conf.set("spark.sql.autoBroadcastJoinThreshold", -1) df.write.bucketBy(42, "k").saveAsTable("df1") val df2 = Seq(("A", -1.0), ("B", 2.0)).toDF("k", "v2") df2.write.bucketBy(42, "k").saveAsTable("df2")
df.registerTempTable("partitionMe") hiveCtx.sql("select * from partitionMe DISTRIBUTE BY accountId SORT BY accountId, date")
class DatePartitioner(partitions: Int) extends Partitioner { override def getPartition(key: Any): Int = { val start_time: Long = key.asInstanceOf[Long] Objects.hash(Array(start_time)) % partitions } override def numPartitions: Int = partitions } myRDD .repartitionAndSortWithinPartitions(new DatePartitioner(24)) .map { v => v._2 } .toDF() .write.mode(SaveMode.Overwrite)
[warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] :: UNRESOLVED DEPENDENCIES :: [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] :: org.jetbrains [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] [warn] Note: Some unresolved dependencies have extra attributes. Check that these dependencies exist with the requested attributes. [warn] org.jetbrains:sbt-structure:latest.integration (sbtVersion=0.13, scalaVersion=2.10)
import sbt._ import Keys._ object Build extends Build { lazy val root = Project(id = "root", base = file(".")).settings( name := "hello", version := "1.0" ) }
split(List(1,2,3,4,5,6,"seven"),4) => List(List(1,2,3,4), List(5,6,"seven"))
scala> List(1,2,3,4,5,6,"seven").grouped(4).toList res0: List[List[Any]] = List(List(1, 2, 3, 4), List(5, 6, seven))
def split[A](xs: List[A], n: Int): List[List[A]] = { if (xs.size <= n) xs :: Nil else (xs take n) :: split(xs drop n, n) }
scala> split(List(1,2,3,4,5,6,"seven"), 4) res15: List[List[Any]] = List(List(1, 2, 3, 4), List(5, 6, seven))
def split[A](xs: List[A], n: Int): List[List[A]] = if (xs.isEmpty) Nil else (xs take n) :: split(xs drop n, n)
def split[A](xs: List[A], n: Int): List[List[A]] = if (xs.isEmpty) Nil else { val (ys, zs) = xs.splitAt(n) ys :: split(zs, n) }
import scala.annotation.tailrec object ListSplitter { def split[A](xs: List[A], n: Int): List[List[A]] = { @tailrec def splitInner[A](res: List[List[A]], lst: List[A], n: Int) : List[List[A]] = { if(lst.isEmpty) res else { val headList: List[A] = lst.take(n) val tailList : List[A]= lst.drop(n) splitInner(headList :: res, tailList, n) } } splitInner(Nil, xs, n).reverse } } object ListSplitterTest extends App { val res = ListSplitter.split(List(1,2,3,4,5,6,7), 2) println(res) }
def split [X] (n:Int, xs:List[X]) : List[List[X]] = if (xs.size <= n) xs :: Nil else (xs.splitAt(n)._1) :: split(n,xs.splitAt(n)._2)
def map[A, B](rdd: RDD[A], fn: (A => B)) (implicit a: Manifest[A], b: Manifest[B]): RDD[B] = { rdd.mapPartitions({ iter: Iterator[A] => for (i <- iter) yield fn(i) }, preservesPartitioning = true) }
def map[A, B](rdd: RDD[A], fn: (A => B)) (implicit a: Manifest[A], b: Manifest[B]): RDD[B] = { rdd.map(fn) }
val newRd = myRdd.mapPartitions(partition => { val connection = new DbConnection val newPartition = partition.map(record => { readMatchingFromDB(record, connection) }).toList connection.close() newPartition.iterator })
val a = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"), 3) val b = a.map(_.length) val c = a.zip(b) c.collect res0: Array[(String, Int)] = Array((dog,3), (salmon,6), (salmon,6), (rat,3), (elephant,8))
val a = sc.parallelize(1 to 9, 3) def myfunc[T](iter: Iterator[T]) : Iterator[(T, T)] = { var res = List[(T, T)]() var pre = iter.next while (iter.hasNext) { val cur = iter.next; res .::= (pre, cur) pre = cur; } res.iterator } a.mapPartitions(myfunc).collect res0: Array[(Int, Int)] = Array((2,3), (1,2), (5,6), (4,5), (8,9), (7,8))
val x = sc.parallelize(List(1, 2, 3, 4, 5, 6, 7, 8, 9,10), 3) def myfunc(iter: Iterator[Int]) : Iterator[Int] = { var res = List[Int]() while (iter.hasNext) { val cur = iter.next; res = res ::: List.fill(scala.util.Random.nextInt(10))(cur) } res.iterator } x.mapPartitions(myfunc).collect res8: Array[Int] = Array(1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 7, 7, 7, 9, 9, 10)
val x = sc.parallelize(1 to 10, 3) x.flatMap(List.fill(scala.util.Random.nextInt(10))(_)).collect res1: Array[Int] = Array(1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10)
def tabulate[T](len: Int, f: Int => T) = { val xs = new Array[T](len) for (i <- 0 until len) xs(i) = f(i) xs }
def tabulate[T](len: Int, f: Int => T)(implicit m: ClassManifest[T]) = { val xs = new Array[T](len) for (i <- 0 until len) xs(i) = f(i) xs }
def tabulate[T: ClassManifest](len: Int, f: Int => T) = { val xs = new Array[T](len) for (i <- 0 until len) xs(i) = f(i) xs }
scala> implicit def int2str(i: Int): String = i.toString int2str: (i: Int)String scala> def f1[T <% String](t: T) = 0 f1: [T](t: T)(implicit evidence$1: (T) => String)Int
scala> trait To[T] { type From[F] = F => T } defined trait To scala> def f2[T : To[String] f2: [T](t: T)(implicit evidence$1: (T) => java.lang.String)Int scala> f2(1) res1: Int = 0
def **[T : Numeric](xs: Iterable[T], ys: Iterable[T]) = xs zip ys map { t => implicitly[Numeric[T]].times(t._1, t._2) }
def **[T : Numeric](xs: Iterable[T], ys: Iterable[T]) = xs zip ys map { t => context[T]().times(t._1, t._2) }
sealed trait Foo { } object Foo { def apply(...): Foo = private class FooImpl(...) extends Foo { ... } }
linesWithSessionId: org.apache.spark.rdd.RDD[String] = FilteredRDD[3]
scala> linesWithSessionId.map(line => println(line))
linesWithSessionId.toArray().foreach(line => println(line))
import spark.implicits._ fruits = sc.parallelize([("apple", 1), ("banana", 2), ("orange", 17)]) fruits.toDF().show()
+------+---+ | _1| _2| +------+---+ | apple| 1| |banana| 2| |orange| 17| +------+---+
linesWithSessionIdCollect = linesWithSessionId.collect() linesWithSessionIdCollect
def p(rdd: org.apache.spark.rdd.RDD[_]) = rdd.foreach(println)
implicit class Printer(rdd: org.apache.spark.rdd.RDD[_]) { def print = rdd.foreach(println) }
val rdd = sc.parallelize(List(1,2,3,4)).map(_*2) p(rdd) rdd.print
def createDataFrame(rowRDD: RDD[Row], schema: StructType): DataFrame
val sqlContext = new SQLContext(sc) import sqlContext.implicits._ rdd.toDF()
import org.apache.spark.sql.{Row, SparkSession} import org.apache.spark.sql.types.{DoubleType, StringType, StructField, StructType}
val spark: SparkSession = SparkSession.builder.master("local").getOrCreate val sc = spark.sparkContext
val rdd = sc.parallelize( Seq( ("first", Array(2.0, 1.0, 2.1, 5.4)), ("test", Array(1.5, 0.5, 0.9, 3.7)), ("choose", Array(8.0, 2.9, 9.1, 2.5)) ) )
val dfWithoutSchema = spark.createDataFrame(rdd) dfWithoutSchema.show() +------+--------------------+ | _1| _2| +------+--------------------+ | first|[2.0, 1.0, 2.1, 5.4]| | test|[1.5, 0.5, 0.9, 3.7]| |choose|[8.0, 2.9, 9.1, 2.5]| +------+--------------------+
val dfWithSchema = spark.createDataFrame(rdd).toDF("id", "vals") dfWithSchema.show() +------+--------------------+ | id| vals| +------+--------------------+ | first|[2.0, 1.0, 2.1, 5.4]| | test|[1.5, 0.5, 0.9, 3.7]| |choose|[8.0, 2.9, 9.1, 2.5]| +------+--------------------+
val rowsRdd: RDD[Row] = sc.parallelize( Seq( Row("first", 2.0, 7.0), Row("second", 3.5, 2.5), Row("third", 7.0, 5.9) ) )
val schema = new StructType() .add(StructField("id", StringType, true)) .add(StructField("val1", DoubleType, true)) .add(StructField("val2", DoubleType, true))
val df = spark.createDataFrame(rowsRdd, schema) df.show() +------+----+----+ | id|val1|val2| +------+----+----+ | first| 2.0| 7.0| |second| 3.5| 2.5| | third| 7.0| 5.9| +------+----+----+
val aRdd = aDF.map(x=>Row(x.getAs[Long]("id"),x.getAs[List[String]]("role").head))
val aStruct = new StructType(Array(StructField("id",LongType,nullable = true),StructField("role",StringType,nullable = true)))
val aNamedDF = sqlContext.createDataFrame(aRdd,aStruct)
val df = rdd.map({ case Row(val1: String, ..., valN: Long) => (val1, ..., valN) }).toDF("col1_name", ..., "colN_name")
case class MyClass(val1: String, ..., valN: Long = 0L) val df = rdd.map({ case Row(val1: String, ..., valN: Long) => MyClass(val1, ..., valN) }).toDF("col1_name", ..., "colN_name")
val rdd = oldDF.rdd val newDF = oldDF.sqlContext.createDataFrame(rdd, oldDF.schema)
scala> val numList = List(1,2,3,4,5) numList: List[Int] = List(1, 2, 3, 4, 5) scala> val numRDD = sc.parallelize(numList) numRDD: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[80] at parallelize at <console>:28 scala> val numDF = numRDD.toDF numDF: org.apache.spark.sql.DataFrame = [_1: int] scala> numDF.show +---+ | _1| +---+ | 1| | 2| | 3| | 4| | 5| +---+
val sqlContext = new org.apache.spark.sql.SQLContext(sc) import sqlContext.implicits._ val df_2 = sc.parallelize(Seq((1L, 3.0, "a"), (2L, -1.0, "b"), (3L, 0.0, "c"))).toDF("x", "y", "z")
case class temp(val1: String,val3 : Double) val rdd = sc.parallelize(Seq( Row("foo", 0.5), Row("bar", 0.0) )) val rows = rdd.map({case Row(val1:String,val3:Double) => temp(val1,val3)}).toDF() rows.show()
from pyspark.sql import Row l = [( Person = Row( rdd = sc.parallelize(l) person = rdd.map(lambda r:Person(*r)) df2 = sqlContext.createDataFrame(person) df2.show()
from pyspark.sql.types import * l = [( rdd = sc.parallelize(l) schema = StructType([StructField ("name" , StringType(), True) , StructField("age" , IntegerType(), True)]) df3 = sqlContext.createDataFrame(rdd, schema) df3.show()
val temp1 = attrib1.map{case Row ( key: Int ) => s"$key" } val temp2 = attrib2.map{case Row ( key: Int) => s"$key" } case class RLT (id: String, attrib_1 : String, attrib_2 : String) import hiveContext.implicits._ val df = result.map{ s => RLT(s(0),s(1),s(2)) }.toDF
import org.apache.spark.sql.SparkSession import org.apache.spark.sql.functions._ import org.apache.spark.sql._ import org.apache.spark.sql.types._ val spark = SparkSession .builder() .getOrCreate() import spark.implicits._ val dfSchema = Seq("col1", "col2", "col3") rdd.toDF(dfSchema: _*)
One needs to create a schema, and attach it to the Rdd.
import org.apache.spark._ import org.apache.spark.sql._ import org.apache.spark.sql.types._ /* Lets gin up some sample data: * As RDD * sample data a three wide, two tall, rectangle of mixed types. * A column of Strings, a column of Longs, and a column of Doubules */ val arrayOfArrayOfAnys = Array.ofDim[Any](2,3) arrayOfArrayOfAnys(0)(0)="aString" arrayOfArrayOfAnys(0)(1)=0L arrayOfArrayOfAnys(0)(2)=3.14159 arrayOfArrayOfAnys(1)(0)="bString" arrayOfArrayOfAnys(1)(1)=9876543210L arrayOfArrayOfAnys(1)(2)=2.71828 /* The way to convert an anything which looks rectangular, * (Array[Array[String]] or Array[Array[Any]] or Array[Row], ... ) into an RDD is to * throw it into sparkContext.parallelize. * http: * the parallelize definition as * def parallelize[T](seq: Seq[T], numSlices: Int = defaultParallelism) * so in our case our ArrayOfArrayOfAnys is treated as a sequence of ArraysOfAnys. * Will leave the numSlices as the defaultParallelism, as I have no particular cause to change it. */ val rddOfArrayOfArrayOfAnys=spark.sparkContext.parallelize(arrayOfArrayOfAnys) /* We * The RDD which goes into createDataFrame is an RDD[Row] which is not what we happen to have. * To convert anything one tall and several wide into a Row, one can use Row.fromSeq(thatThing.toSeq) * As we have an RDD[somethingWeDontWant], we can map each of the RDD rows into the desired Row type. */ val rddOfRows=rddOfArrayOfArrayOfAnys.map(f=> Row.fromSeq(f.toSeq) ) /* Now to construct our schema. This needs to be a StructType of 1 StructField per column in our dataframe. * https: * case class StructField(name: String, dataType: DataType, nullable: Boolean = true, metadata: Metadata = Metadata.empty) * Will leave the two default values in place for each of the columns: * nullability as true, * metadata as an empty Map[String,Any] * */ val schema = StructType( StructField("colOfStrings", StringType) :: StructField("colOfLongs" , LongType ) :: StructField("colOfDoubles", DoubleType) :: Nil ) val df=spark.sqlContext.createDataFrame(rddOfRows,schema) /* * +------------+----------+------------+ * |colOfStrings|colOfLongs|colOfDoubles| * +------------+----------+------------+ * | aString| 0| 3.14159| * | bString|9876543210| 2.71828| * +------------+----------+------------+ */ df.show
val arrayOfArrayOfAnys=Array( Array("aString",0L ,3.14159), Array("bString",9876543210L,2.71828) ) val rddOfRows=spark.sparkContext.parallelize(arrayOfArrayOfAnys).map(f=>Row.fromSeq(f.toSeq)) /* If one knows the datatypes, for instance from JDBC queries as to RDBC column metadata: * Consider constructing the schema from an Array[StructField]. This would allow looping over * the columns, with a match statement applying the appropriate sql datatypes as the second * StructField arguments. */ val sf=new Array[StructField](3) sf(0)=StructField("colOfStrings",StringType) sf(1)=StructField("colOfLongs" ,LongType ) sf(2)=StructField("colOfDoubles",DoubleType) val df=spark.sqlContext.createDataFrame(rddOfRows,StructType(sf.toList)) df.show
val rows: Array[Row]=... implicit val encoder = RowEncoder.apply(schema) import spark.implicits._ rows.toDS
trait Lambda { type subst[U <: Lambda] <: Lambda type apply[U <: Lambda] <: Lambda type eval <: Lambda } trait App[S <: Lambda, T <: Lambda] extends Lambda { type subst[U <: Lambda] = App[S type apply[U] = Nothing type eval = S } trait Lam[T <: Lambda] extends Lambda { type subst[U <: Lambda] = Lam[T] type apply[U <: Lambda] = T type eval = Lam[T] } trait X extends Lambda { type subst[U <: Lambda] = U type apply[U] = Lambda type eval = X }
sealed trait Nat sealed trait _0 extends Nat sealed trait Succ[N <: Nat] extends Nat
class TypeToValue[T, VT](value : VT) { def getValue() = value }
implicit val _0ToInt = new TypeToValue[_0, Int](0) implicit def succToInt[P <: Nat](implicit v : TypeToValue[P, Int]) = new TypeToValue[Succ[P], Int](1 + v.getValue())
def toInt[T <: Nat](v : T)(implicit ttv : TypeToValue[T, Int]) : Int = ttv.getValue()
abstract class Expr { def eval: Int } class Number(n: Int) extends Expr { def eval: Int = n } class Sum(e1: Expr, e2: Expr) extends Expr { def eval: Int = e1.eval + e2.eval }
class Prod(e1: Expr, e2: Expr) extends Expr { def eval: Int = e1.eval * e2.eval }
abstract class Expr { def eval: Int def print } class Number(n: Int) extends Expr { def eval: Int = n def print { Console.print(n) } } class Sum(e1: Expr, e2: Expr) extends Expr { def eval: Int = e1.eval + e2.eval def print { Console.print("(") print(e1) Console.print("+") print(e2) Console.print(")") } }
abstract class Expr { def eval: Int = this match { case Number(n) => n case Sum(e1, e2) => e1.eval + e2.eval } } case class Number(n: Int) extends Expr case class Sum(e1: Expr, e2: Expr) extends Expr
abstract class Expr { def eval: Int = this match { case Number(n) => n case Sum(e1, e2) => e1.eval + e2.eval } def print = this match { case Number(n) => Console.print(n) case Sum(e1,e2) => { Console.print("(") print(e1) Console.print("+") print(e2) Console.print(")") } } }
abstract class Expr { def eval: Int = this match { case Number(n) => n case Sum(e1, e2) => e1.eval + e2.eval case Prod(e1,e2) => e1.eval * e2.eval } def print = this match { case Number(n) => Console.print(n) case Sum(e1,e2) => { Console.print("(") print(e1) Console.print("+") print(e2) Console.print(")") } case Prod(e1,e2) => ... } }
$ javap Person$ Compiled from "Person.scala" public final class Person$ extends scala.runtime.AbstractFunction1 implements scala.ScalaObject,scala.Serializable{ public static final Person$ MODULE$; public static {}; public final java.lang.String toString(); public scala.Option unapply(Person); public Person apply(java.lang.String); public java.lang.Object apply(java.lang.Object); }
import scala.util.parsing.json._ ... val json:Option[Any] = JSON.parseFull(jsonString) val map:Map[String,Any] = json.get.asInstanceOf[Map[String, Any]] val languages:List[Any] = map.get("languages").get.asInstanceOf[List[Any]] languages.foreach( langMap => { val language:Map[String,Any] = langMap.asInstanceOf[Map[String,Any]] val name:String = language.get("name").get.asInstanceOf[String] val isActive:Boolean = language.get("is_active").get.asInstanceOf[Boolean] val completeness:Double = language.get("completeness").get.asInstanceOf[Double] }
class CC[T] { def unapply(a:Any):Option[T] = Some(a.asInstanceOf[T]) } object M extends CC[Map[String, Any]] object L extends CC[List[Any]] object S extends CC[String] object D extends CC[Double] object B extends CC[Boolean] val jsonString = """ { "languages": [{ "name": "English", "is_active": true, "completeness": 2.5 }, { "name": "Latin", "is_active": false, "completeness": 0.9 }] } """.stripMargin val result = for { Some(M(map)) <- List(JSON.parseFull(jsonString)) L(languages) = map("languages") M(language) <- languages S(name) = language("name") B(active) = language("is_active") D(completeness) = language("completeness") } yield { (name, active, completeness) } assert( result == List(("English",true,2.5), ("Latin",false,0.9)))
val result = JSON.parseFull(jsonStr) result match { case Some(map: Map[String, Any]) => println(map) case None => println("Parsing failed") case other => println("Unknown data structure: " + other) }
class CC[T] { def unapply(a:Option[Any]):Option[T] = if (a.isEmpty) { None } else { Some(a.get.asInstanceOf[T]) } } object M extends CC[Map[String, Any]] object L extends CC[List[Any]] object S extends CC[String] object D extends CC[Double] object B extends CC[Boolean] for { M(map) <- List(JSON.parseFull(jsonString)) L(languages) = map.get("languages") language <- languages M(lang) = Some(language) S(name) = lang.get("name") B(active) = lang.get("is_active") D(completeness) = lang.get("completeness") } yield { (name, active, completeness) }
for { M(map) <- Some(JSON.parseFull(jsonString)) } yield { map.get("languages") match { case L(languages) => { for { language <- languages M(lang) = Some(language) S(name) = lang.get("name") B(active) = lang.get("is_active") D(completeness) = lang.get("completeness") } yield { (name, active, completeness) } } case None => "bad json" } }
implicit def any2string(a: Any) = a.toString implicit def any2boolean(a: Any) = a.asInstanceOf[Boolean] implicit def any2double(a: Any) = a.asInstanceOf[Double] case class Language(name: String, isActive: Boolean, completeness: Double) val languages = JSON.parseFull(jstr) match { case Some(x) => { val m = x.asInstanceOf[Map[String, List[Map[String, Any]]]] m("languages") map {l => Language(l("name"), l("isActive"), l("completeness"))} } case None => Nil } languages foreach {println}
val jsonString = """ |{ | "languages": [{ | "name": "English", | "is_active": true, | "completeness": 2.5 | }, { | "name": "Latin", | "is_active": false, | "completeness": 0.9 | }] |} """.stripMargin val result = JSON.parseFull(jsonString).map { case json: Map[String, List[Map[String, Any]]] => json("languages").map(l => (l("name"), l("is_active"), l("completeness"))) }.get println(result) assert( result == List(("English", true, 2.5), ("Latin", false, 0.9)) )
package org.sqkb.service.common.bean import java.text.SimpleDateFormat import org.json4s import org.json4s.JValue import org.json4s.jackson.JsonMethods._ import scala.util.Try /** * */ case class Order(log: String) { implicit lazy val formats = org.json4s.DefaultFormats lazy val json: json4s.JValue = parse(log) lazy val create_time: String = (json \ "create_time").extractOrElse("1970-01-01 00:00:00") lazy val site_id: String = (json \ "site_id").extractOrElse("") lazy val alipay_total_price: Double = (json \ "alipay_total_price").extractOpt[String].filter(_.nonEmpty).getOrElse("0").toDouble lazy val gmv: Double = alipay_total_price lazy val pub_share_pre_fee: Double = (json \ "pub_share_pre_fee").extractOpt[String].filter(_.nonEmpty).getOrElse("0").toDouble lazy val profit: Double = pub_share_pre_fee lazy val trade_id: String = (json \ "trade_id").extractOrElse("") lazy val unid: Long = Try((json \ "unid").extractOpt[String].filter(_.nonEmpty).get.toLong).getOrElse(0L) lazy val cate_id1: Int = (json \ "cate_id").extractOrElse(0) lazy val cate_id2: Int = (json \ "subcate_id").extractOrElse(0) lazy val cate_id3: Int = (json \ "cate_id3").extractOrElse(0) lazy val cate_id4: Int = (json \ "cate_id4").extractOrElse(0) lazy val coupon_id: Long = (json \ "coupon_id").extractOrElse(0) lazy val platform: Option[String] = Order.siteMap.get(site_id) def time_fmt(fmt: String = "yyyy-MM-dd HH:mm:ss"): String = { val dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss") val date = dateFormat.parse(this.create_time) new SimpleDateFormat(fmt).format(date) } }
scala> List(1,2,3,4).partition(x => x % 2 == 0) res0: (List[Int], List[Int]) = (List(2, 4),List(1, 3))
scala> Seq(1,2,3,4).span(x => x % 2 == 0) res0: (Seq[Int], Seq[Int]) = (List(),List(1, 2, 3, 4))
val list:List[Person] = val (students,teachers) = list.foldLeft(List.empty[Student],List.empty[Teacher]) { case ((acc1, acc2), p) => p match { case s:Student => (s :: acc1, acc2) case t:Teacher => (acc1, t :: acc2) } }
def split(list_in: List[String], search: String): List[List[String]] = { def split_helper(accum: List[List[String]], list_in2: List[String], search: String): List[List[String]] = { val (h1, h2) = list_in2.span({x: String => x!= search}) val new_accum = accum :+ h1 if (h2.contains(search)) { return split_helper(new_accum, h2.drop(1), search) } else { return accum } } return split_helper(List(), list_in, search) }
scala> val arr = Array("Hello","World") arr: Array[java.lang.String] = Array(Hello, World)
val list = List(1,2,3,4,5) val arr = Array[Int](list:_*) println(arr.mkString)
val list = List(1,2,3,4,5) val arr = list.toArray println(arr.mkString)
val length = 5 val temp = Array.ofDim[String](length)
val row = 5 val column = 3 val temp = Array.ofDim[String](row, column)
Array.fill(4,3)("") res3: Array[Array[String]] = Array(Array("", "", ""), Array("", "", ""),Array("", "", ""), Array("", "", ""))
def getCompanion(name: String) = Class.forName(s"my.package.$name\$")
scala> val name = "foo" name: String = foo scala> s"my.package.$name$$" res0: String = my.package.foo$
def nBeers(n:Int) = n match { case 0 => ("No more bottles of beer on the wall, no more bottles of beer." + "\nGo to the store and buy some more, " + "99 bottles of beer on the wall.\n") case _ => (n + " bottles of beer on the wall, " + n + " bottles of beer.\n" + "Take one down and pass it around, " + (if((n-1)==0) "no more" else (n-1)) + " bottles of beer on the wall.\n") } for(b <- (0 to 99).reverse) println(nBeers(b))
scala> 10 to 1 by -1 res1: scala.collection.immutable.Range = Range(10, 9, 8, 7, 6, 5, 4, 3, 2, 1)
scala> for (i <- (1 to 10).reverse) {code} scala> for (i <- 10 to(1,-1)) {code}
implicit class RichInt(val value: Int) extends AnyVal { def downto (n: Int) = value to n by -1 def downtil (n: Int) = value until n by -1 }
val r1 = new Range(10, 0, -1) for { i <- r1 } println(i)
def fMatch(s: String) = { s match { case "a" => println("It was a") case _ => println("It was something else") } }
scala> fMatch("a") It was a scala> fMatch("b") It was something else
def mMatch(s: String) = { val target: String = "a" s match { case target => println("It was" + target) case _ => println("It was something else") } }
fMatch: (s: String)Unit <console>:12: error: unreachable code case _ => println("It was something else")
def mMatch(s: String) = { val target: String = "a" s match { case `target` => println("It was" + target) case _ => println("It was something else") } } def mMatch2(s: String) = { val Target: String = "a" s match { case Target => println("It was" + Target) case _ => println("It was something else") } }
import resource._ for(input <- managed(new FileInputStream("test.txt")) { }
import resource._ import java.io._ val lines = for { input <- managed(new FileInputStream("test.txt")) val bufferedReader = new BufferedReader(new InputStreamReader(input)) line <- makeBufferedReaderLineIterator(bufferedReader) } yield line.trim() lines foreach println
import java.io._ import util.continuations._ import resource._ def each_line_from(r : BufferedReader) : String @suspendable = shift { k => var line = r.readLine while(line != null) { k(line) line = r.readLine } } reset { val server = managed(new ServerSocket(8007)) ! while(true) { reset { val connection = managed(server.accept) ! val output = managed(connection.getOutputStream) ! val input = managed(connection.getInputStream) ! val writer = new PrintWriter(new BufferedWriter(new OutputStreamWriter(output))) val reader = new BufferedReader(new InputStreamReader(input)) writer.println(each_line_from(reader)) writer.flush() } } }
def using[T <: { def close() }] (resource: T) (block: T => Unit) { try { block(resource) } finally { if (resource != null) resource.close() } }
using(new BufferedReader(new FileReader("file"))) { r => var count = 0 while (r.readLine != null) count += 1 println(count) }
trait Managed[T] { def onEnter(): T def onExit(t:Throwable = null): Unit def attempt(block: => Unit): Unit = { try { block } finally {} } } def using[T <: Any](managed: Managed[T])(block: T => Unit) { val resource = managed.onEnter() var exception = false try { block(resource) } catch { case t:Throwable => exception = true; managed.onExit(t) } finally { if (!exception) managed.onExit() } } def using[T <: Any, U <: Any] (managed1: Managed[T], managed2: Managed[U]) (block: T => U => Unit) { using[T](managed1) { r => using[U](managed2) { s => block(r)(s) } } } class ManagedOS(out:OutputStream) extends Managed[OutputStream] { def onEnter(): OutputStream = out def onExit(t:Throwable = null): Unit = { attempt(out.close()) if (t != null) throw t } } class ManagedIS(in:InputStream) extends Managed[InputStream] { def onEnter(): InputStream = in def onExit(t:Throwable = null): Unit = { attempt(in.close()) if (t != null) throw t } } implicit def os2managed(out:OutputStream): Managed[OutputStream] = { return new ManagedOS(out) } implicit def is2managed(in:InputStream): Managed[InputStream] = { return new ManagedIS(in) } def main(args:Array[String]): Unit = { using(new FileInputStream("foo.txt"), new FileOutputStream("bar.txt")) { in => out => Iterator continually { in.read() } takeWhile( _ != -1) foreach { out.write(_) } } }
def using[X <: {def close()}, A](resource : X)(f : X => A) = { try { f(resource) } finally { resource.close() } } def resource[X <: {def close()}, B](res : X) = shift(using[X, B](res)) def withResources[A, C](x : => A @cps[A, C]) = reset{x}
def copyFileCPS = using(new BufferedReader(new FileReader("test.txt"))) { reader => { using(new BufferedWriter(new FileWriter("test_copy.txt"))) { writer => { var line = reader.readLine var count = 0 while (line != null) { count += 1 writer.write(line) writer.newLine line = reader.readLine } count } } } } def copyFileDC = withResources { val reader = resource[BufferedReader,Int](new BufferedReader(new FileReader("test.txt"))) val writer = resource[BufferedWriter,Int](new BufferedWriter(new FileWriter("test_copy.txt"))) var line = reader.readLine var count = 0 while(line != null) { count += 1 writer write line writer.newLine line = reader.readLine } count }
trait ContextType[B] def forceContextType[B]: ContextType[B] = null def resource[X <: {def close()}, B: ContextType](res : X): X @cps[B,B] = shift(using[X, B](res)) def withResources[A](x : => A @cps[A, A]) = reset{x} def copyFileDC = withResources { implicit val _ = forceContextType[Int] val reader = resource(new BufferedReader(new FileReader("test.txt"))) val writer = resource(new BufferedWriter(new FileWriter("test_copy.txt"))) var line = reader.readLine var count = 0 while(line != null) { count += 1 writer write line writer.newLine line = reader.readLine } count }
import better.files._ for { in <- inputStream.autoClosed out <- outputStream.autoClosed } in.pipeTo(out)
type Closeable = { def close(): Unit } type ManagedResource[A <: Closeable] = Traversable[A] implicit class CloseableOps[A <: Closeable](resource: A) { def autoClosed: ManagedResource[A] = new Traversable[A] { override def foreach[U](f: A => U) = try { f(resource) } finally { resource.close() } } }
trait GenericDisposable[-T] { def dispose(v:T):Unit } ... def using[T,U](r:T)(block:T => U)(implicit disp:GenericDisposable[T]):U = try { block(r) } finally { Option(r).foreach { r => disp.dispose(r) } }
val ds = new JdbcDataSource() val output = for { conn <- TryClose(ds.getConnection()) ps <- TryClose(conn.prepareStatement("select * from MyTable")) rs <- TryClose.wrap(ps.executeQuery()) } yield wrap(extractResult(rs)) output.resolve match { case Success(result) => case Failure(e) => }
val output = for { outputStream <- TryClose(new ByteArrayOutputStream()) gzipOutputStream <- TryClose(new GZIPOutputStream(outputStream)) _ <- TryClose.wrap(gzipOutputStream.write(content)) } yield wrap({gzipOutputStream.flush(); outputStream.toByteArray}) output.resolve.unwrap match { case Success(bytes) => case Failure(e) => }
scala> val a: String = _ <console>:1: error: unbound placeholder parameter val a: String = _ ^
import scala.concurrent._ import scala.concurrent.ExecutionContext.Implicits.global import scala.util.Success import scala.util.Failure val listOfFutures = Future.successful(1) :: Future.failed(new Exception("Failure")) :: Future.successful(3) :: Nil val futureOfList = Future.sequence(listOfFutures) futureOfList onComplete { case Success(x) => println("Success!!! " + x) case Failure(ex) => println("Failed !!! " + ex) } scala> Failed !!! java.lang.Exception: Failure
def futureToFutureTry[T](f: Future[T]): Future[Try[T]] = f.map(Success(_)).recover(x => Failure(x)) val listOfFutures = ... val listOfFutureTrys = listOfFutures.map(futureToFutureTry(_))
val futureListOfTrys = Future.sequence(listOfFutureTrys)
val futureListOfSuccesses = futureListOfTrys.map(_.filter(_.isSuccess))
val futureListOfFailures = futureListOfTrys.map(_.filter(_.isFailure))
implicit class FutureCompanionOps(val f: Future.type) extends AnyVal { /** Given a list of futures `fs`, returns the future holding the list of Try * The returned future is completed only once all of the futures in `fs` have been completed. */ def allAsTrys[T](fItems: List[Future[T]]): Future[List[Try[T]]] = { val listOfFutureTrys: List[Future[Try[T]]] = fItems.map(futureToFutureTry) Future.sequence(listOfFutureTrys) } def futureToFutureTry[T](f: Future[T]): Future[Try[T]] = { f.map(Success(_)) .recover({case x => Failure(x)}) } def allFailedAsTrys[T](fItems: List[Future[T]]): Future[List[Try[T]]] = { allAsTrys(fItems).map(_.filter(_.isFailure)) } def allSucceededAsTrys[T](fItems: List[Future[T]]): Future[List[Try[T]]] = { allAsTrys(fItems).map(_.filter(_.isSuccess)) } } // test("futureToFutureTry returns Success if no exception") { val future = Future.futureToFutureTry(Future{"mouse"}) Thread.sleep(0, 100) val futureValue = future.value assert(futureValue == Some(Success(Success("mouse")))) } test("futureToFutureTry returns Failure if exception thrown") { val future = Future.futureToFutureTry(Future{throw new IllegalStateException("bad news")}) Thread.sleep(5) val futureValue = future.value assertResult(true) { futureValue match { case Some(Success(Failure(error: IllegalStateException))) => true } } } test("Future.allAsTrys returns Nil given Nil list as input") { val future = Future.allAsTrys(Nil) assert ( Await.result(future, 100 nanosecond).isEmpty ) } test("Future.allAsTrys returns successful item even if preceded by failing item") { val future1 = Future{throw new IllegalStateException("bad news")} var future2 = Future{"dog"} val futureListOfTrys = Future.allAsTrys(List(future1,future2)) val listOfTrys = Await.result(futureListOfTrys, 10 milli) System.out.println("successItem:" + listOfTrys); assert(listOfTrys(0).failed.get.getMessage.contains("bad news")) assert(listOfTrys(1) == Success("dog")) } test("Future.allAsTrys returns successful item even if followed by failing item") { var future1 = Future{"dog"} val future2 = Future{throw new IllegalStateException("bad news")} val futureListOfTrys = Future.allAsTrys(List(future1,future2)) val listOfTrys = Await.result(futureListOfTrys, 10 milli) System.out.println("successItem:" + listOfTrys); assert(listOfTrys(1).failed.get.getMessage.contains("bad news")) assert(listOfTrys(0) == Success("dog")) } test("Future.allFailedAsTrys returns the failed item and only that item") { var future1 = Future{"dog"} val future2 = Future{throw new IllegalStateException("bad news")} val futureListOfTrys = Future.allFailedAsTrys(List(future1,future2)) val listOfTrys = Await.result(futureListOfTrys, 10 milli) assert(listOfTrys(0).failed.get.getMessage.contains("bad news")) assert(listOfTrys.size == 1) } test("Future.allSucceededAsTrys returns the succeeded item and only that item") { var future1 = Future{"dog"} val future2 = Future{throw new IllegalStateException("bad news")} val futureListOfTrys = Future.allSucceededAsTrys(List(future1,future2)) val listOfTrys = Await.result(futureListOfTrys, 10 milli) assert(listOfTrys(0) == Success("dog")) assert(listOfTrys.size == 1) }
def allSuccessful[A, M[X] <: TraversableOnce[X]](in: M[Future[A]]) (implicit cbf: CanBuildFrom[M[Future[A]], A, M[A]], executor: ExecutionContext): Future[M[A]] = { in.foldLeft(Future.successful(cbf(in))) { (fr, fa) ⇒ (for (r ← fr; a ← fa) yield r += a) fallbackTo fr } map (_.result()) }
val futures = Seq(Future{1},Future{throw new Exception}) val seq = Future.sequence(futures.map(_.transform(Success(_)))) val successes = seq.map(_.collect{case Success(x)=>x}) val failures = seq.map(_.collect{case Failure(x)=>x})
def futureToFutureOption[T](f: Future[T]): Future[Option[T]] = f.map(Some(_)).recover { case e => None } val listOfFutureOptions = listOfFutures.map(futureToFutureOption(_)) val futureListOfOptions = Future.sequence(listOfFutureOptions) val futureListOfSuccesses = futureListOfOptions.flatten
libraryDependencies += "org.scalaz" %% "scalaz-core" % "6.0.4"
addSbtPlugin("com.typesafe.sbteclipse" % "sbteclipse-plugin" % "2.1.0-RC1")
libraryDependencies += "net.sf.opencsv" % "opencsv" % "2.3"
Activator new Fetching the latest list of templates... Browse the list of templates: http: Choose from these featured templates or enter a template name: 1) minimal-java 2) minimal-scala 3) play-java 4) play-scala (hit tab to see a list of all templates)
object V { val depProject = "master" } object Projects { lazy val depProject = RootProject(uri("git: } lazy val myProject = Project("my-project", file(".")) .settings(myProjectSettings: _*) .dependsOn(Projects.depProject) .settings( libraryDependencies ++= Seq(...
import sbt.Keys._ import sbt._ object MyBuild extends Build { lazy val root = Project("root", file(".")) .dependsOn(myLibraryinGit) .settings( ..., libraryDependencies ++= Seq(...)) lazy val myLibraryinGit = ProjectRef(uri("git: }
lazy val root = (project in file(".")).dependsOn(playJongo) lazy val playJongo = RootProject(uri("https:
scala> class Foo { class Bar } defined class Foo scala> val foo1 = new Foo foo1: Foo = Foo@24bc0658 scala> val foo2 = new Foo foo2: Foo = Foo@6f7f757 scala> implicitly[foo1.Bar =:= foo1.Bar] res0: =:=[foo1.Bar,foo1.Bar] = <function1> scala> implicitly[foo1.Bar =:= foo2.Bar] <console>:11: error: Cannot prove that foo1.Bar =:= foo2.Bar. implicitly[foo1.Bar =:= foo2.Bar]
scala> trait Sigma { | val foo: Foo | val bar: foo.Bar | } defined trait Sigma scala> val sigma = new Sigma { | val foo = foo1 | val bar = new foo.Bar | } sigma: java.lang.Object with Sigma{val bar: this.foo.Bar} = $anon$1@e3fabd8
scala> def depList[T](t: T)(implicit pi: Pi[T]): List[pi.U] = Nil depList: [T](t: T)(implicit pi: Pi[T])List[pi.U]
scala> object Foo defined module Foo scala> object Bar defined module Bar scala> implicit val fooInt = new Pi[Foo.type] { type U = Int } fooInt: java.lang.Object with Pi[Foo.type]{type U = Int} = $anon$1@60681a11 scala> implicit val barString = new Pi[Bar.type] { type U = String } barString: java.lang.Object with Pi[Bar.type]{type U = String} = $anon$1@187602ae
scala> depList(Foo) res2: List[fooInt.U] = List() scala> depList(Bar) res3: List[barString.U] = List() scala> implicitly[res2.type <:< List[Int]] res4: <:<[res2.type,List[Int]] = <function1> scala> implicitly[res2.type <:< List[String]] <console>:19: error: Cannot prove that res2.type <:< List[String]. implicitly[res2.type <:< List[String]] ^ scala> implicitly[res3.type <:< List[String]] res6: <:<[res3.type,List[String]] = <function1> scala> implicitly[res3.type <:< List[Int]] <console>:19: error: Cannot prove that res3.type <:< List[Int]. implicitly[res3.type <:< List[Int]]
trait Sigma[T] { val x: T type U } def pi[T](t: T)(implicit mapping: Sigma[T] { val x = t }): mapping.U
case class Void(underlying: Nothing) extends AnyVal def impossible() : Void = impossible()
def inputStreamToString(is: InputStream) = { val rd: BufferedReader = new BufferedReader(new InputStreamReader(is, "UTF-8")) val builder = new StringBuilder() try { var line = rd.readLine while (line != null) { builder.append(line + "\n") line = rd.readLine } } finally { rd.close } builder.toString }
scala.io.Source.fromInputStream(is).getLines().mkString("\n")
private def inputStreamToString(is: InputStream) = { val inputStreamReader = new InputStreamReader(is) val bufferedReader = new BufferedReader(inputStreamReader) Iterator continually bufferedReader.readLine takeWhile (_ != null) mkString }
scala> case class A(tag:String, load:Int) scala> val l = List(A("words",50),A("article",2),A("lines",7)) scala> l.sorted.foreach(println) <console>:11: error: No implicit Ordering defined for A. l.sorted.foreach(println) ^
scala> l.map(_.toString).sorted.foreach(println) A(article,2) A(lines,7) A(words,50)
case class A(tag: String, load: Int) extends Ordered[A] { import scala.math.Ordered.orderingToOrdered def compare(that: A): Int = (this.tag, this.load) compare (that.tag, that.load) }
case class Employee(id: Int, firstName: String, lastName: String) object Employee { implicit def orderingByName[A <: Employee]: Ordering[A] = Ordering.by(e => (e.lastName, e.firstName)) val orderingById: Ordering[Employee] = Ordering.by(e => e.id) }
object A { implicit val ord = Ordering.by(unapply) }
case class A(tag:String, load:Int) object A { val lexicographicalOrdering = Ordering.by { foo: A => foo.tag } val loadOrdering = Ordering.by { foo: A => foo.load } } implicit val ord = A.lexicographicalOrdering val l = List(A("words",1), A("article",2), A("lines",3)).sorted implicit val ord = A.loadOrdering val l = List(A("words",1), A("article",2), A("lines",3)).sorted
scala> l.sortBy(_.tag)foreach(println) A(article,2) A(lines,7) A(words,50)
case class Person(name : String, age : Int, email : String) def sortPeople(people : List[Person]) = people.sortBy(Person.unapply)
case class A(tag:String, load:Int) extends Ordered[A] { def compare( a:A ) = tag.compareTo(a.tag) } val ls = List( A("words",50), A("article",2), A("lines",7) ) ls.sorted
class PrivateVal { private val privateVal = 0 def testPrivateVal = privateVal private final val privateFinalVal = 1 def testPrivateFinalVal = privateFinalVal }
Compiled from "PrivateVal.scala" public class PrivateVal { public int testPrivateVal(); Code: 0: aload_0 1: invokespecial 4: ireturn public int testPrivateFinalVal(); Code: 0: iconst_1 1: ireturn public PrivateVal(); Code: 0: aload_0 1: invokespecial 4: aload_0 5: iconst_0 6: putfield 9: return }
scala> $iw.getClass.getPackage res0: Package = package $line3 scala> private val x = 5 <console>:5: error: value x cannot be accessed in object $iw lazy val $result = `x` scala> private val x = 5; println(x); 5
class Dummy { private var name = "default name" } class Dummy { private[this] var name = "default name" }
class Holder[+T] (initialValue: Option[T]) { private[this] var value = initialValue def getValue = value def makeEmpty { value = None } }
class C(private val x: Int) { override def equals(obj: Any) = obj match { case other: C => x == other.x case _ => false } } println(new C(5) == new C(5)) println(new C(5) == new C(4))
class C { private int x; public C(int x) { this.x = x; } public boolean equals(Object obj) { if (obj instanceof C) { return ((C) obj).x == x; } else { return false; } } } System.out.println(new C(5).equals(new C(5))); System.out.println(new C(5).equals(new C(4)));
class C(private[this] val x: Int) { override def equals(obj: Any) = obj match { case other: C => this.x == other.x case _ => false } }
class Foo(foo:Foo){ private[this] val i = 2 println(this.i + foo.i) } >>error: value i is not a member of Foo class Foo(foo:Foo){ private val i = 2 println(this.i + foo.i) } >>defined class Foo
object ObjectPrivateDemo { def main(args: Array[String]) { var real = new User("realUserName", "realPassword") var guest = new User("dummyUserName", "dummyPassword") real.displayUser(guest) } } class User(val username:String,val password:String) { private var _username=username private var _password=password def displayUser(guest:User){ println(" guest username="+guest._username+" guest password="+guest._password) guest._username= this._username guest._password= this._password println(" guest username="+guest._username+" guest password="+guest._password) } }
class User(val username: String, val password: String) { private var _username = username private[this] var _password = password def displayUser(guest: User) { println(this._username) println(this._password) guest._username = this._username guest._password = this._password } }
class PrivateTest{ var data: Int = 0 def data_=(x : Int){ require(x > 0) data = x } }
class PrivateTest{ private[this] var data: Int = 0 def data_=(x : Int){ require(x > 0) data = x } }
class Foo { private var count: Int = 0 def inc(): Unit = synchronized { count += 1 } } class Foo { private[this] var count: Int = 0 def inc(): Unit = synchronized { count += 1 } }
abstract class AnimalCounter { var animals = 0 def name: String def count() { animals += 1 println("%d %ss created so far".format(animals, name)) } } abstract class Animal { def companion: AnimalCounter companion.count() } object Dog extends AnimalCounter { val name = "dog" } class Dog extends Animal { def companion = Dog } object Cat extends AnimalCounter { val name = "cat" } class Cat extends Animal { def companion = Cat }
scala> new Dog 1 dogs created so far scala> new Cat 1 cats created so far scala> new Dog 2 dogs created so far scala> new Cat 2 cats created so far
abstract class AbstractClass; class RealThing(s: String) extends AbstractClass; class AlternativeThing(i: Int) extends AbstractClass; object AbstractClass { def apply(s: String) = { new RealThing(s) } def apply(i: Int) = { new AlternativeThing(i) } } val vs = AbstractClass("asdf") val vi = AbstractClass(123)
def f(x: AnyVal) = println(x) def g(x: AnyRef) = println(x) def h(x: Any) = println(x)
abstract class Foo case class A extends Foo case class B(s:String) extends Foo case class C(s:String) extends Foo def matcher(l: Foo): String = { l match { case A() => "A" case B(sb) | C(sc) => "B" case _ => "default" } }
(fragment of test.scala):10: error: illegal variable in pattern alternative case B(sb) | C(sc) => "B"
def matcher(l: Foo): String = { l match { case A() => "A" case B(_) | C(_) => "B" case _ => "default" } }
def matcher(l: Foo): String = { l match { case A() => "A" case bOrC @ (B(_) | C(_)) => { val s = bOrC.asInstanceOf[{def s: String}].s "B(" + s + ")" } case _ => "default" } }
def doB(s: String) = { "B(" + s + ")" } def matcher(l: Foo): String = { l match { case A() => "A" case B(s) => doB(s) case C(s) => doB(s) case _ => "default" } }
object MuliCase { abstract class Foo case object A extends Foo trait SupportsS {val s: String} type Stype = Foo {val s: String} case class B(s:String) extends Foo case class C(s:String) extends Foo case class D(s:String) extends Foo with SupportsS case class E(s:String) extends Foo with SupportsS def matcher1(l: Foo): String = { l match { case A => "A" case s: Stype => println(s.s); "B" case _ => "default" } } def matcher2(l: Foo): String = { l match { case A => "A" case s: SupportsS => println(s.s); "B" case _ => "default" } } def main(args: Array[String]) { val a = A val b = B("B val c = C("C println(matcher1(a)) println(matcher1(b)) println(matcher1(c)) val d = D("D val e = E("E println(matcher2(d)) println(matcher2(e)) } }
l match { case A() => "A" case B(sb) => "B(" + sb + ")" case C(sc) => "C(" + sc + ")" case _ => "default" }
l match { case A() => "A" case _: B => "B" case _: C => "C" case _ => "default" }
BigDecimal(1.23456789).setScale(2, BigDecimal.RoundingMode.HALF_UP).toDouble
def truncateAt(n: Double, p: Int): Double = { val s = math pow (10, p); (math floor n * s) / s }
def roundAt(p: Int)(n: Double): Double = { val s = math pow (10, p); (math round n * s) / s }
scala> 1.23456789 - (1.23456789 % 0.01) res4: Double = 1.23
val value = 1.4142135623730951 println((value * 1000).round / 1000.toDouble) println((value * 10000).round / 10000.toDouble)
def trunc(x: Double, n: Int) = { def p10(n: Int, pow: Long = 10): Long = if (n==0) pow else p10(n-1,pow*10) if (n < 0) { val m = p10(-n).toDouble math.round(x/m) * m } else { val m = p10(n).toDouble math.round(x*m) / m } }
import scala.math._ object ExtNumber extends App { implicit class ExtendedDouble(n: Double) { def rounded(x: Int) = { val w = pow(10, x) (n * w).toLong.toDouble / w } } val a = 1.23456789 println(a.rounded(2)) }
def round(value: Either[Double, Float], places: Int) = { if (places < 0) 0 else { val factor = Math.pow(10, places) value match { case Left(d) => (Math.round(d * factor) / factor) case Right(f) => (Math.round(f * factor) / factor) } } } def round(value: Double): Double = round(Left(value), 0) def round(value: Double, places: Int): Double = round(Left(value), places) def round(value: Float): Double = round(Right(value), 0) def round(value: Float, places: Int): Double = round(Right(value), places)
Rounding Java Formatter: Elapsed Time: 105 Scala Formatter: Elapsed Time: 167 BigDecimal Formatter: Elapsed Time: 27 Truncation Scala custom Formatter: Elapsed Time: 3
object TestFormatters { val r = scala.util.Random def textFormatter(x: Double) = new java.text.DecimalFormat("0. def scalaFormatter(x: Double) = "$pi%1.2f".format(x) def bigDecimalFormatter(x: Double) = BigDecimal(x).setScale(2, BigDecimal.RoundingMode.HALF_UP).toDouble def scalaCustom(x: Double) = { val roundBy = 2 val w = math.pow(10, roundBy) (x * w).toLong.toDouble / w } def timed(f: => Unit) = { val start = System.currentTimeMillis() f val end = System.currentTimeMillis() println("Elapsed Time: " + (end - start)) } def main(args: Array[String]): Unit = { print("Java Formatter: ") val iters = 10000 timed { (0 until iters) foreach { _ => textFormatter(r.nextDouble()) } } print("Scala Formatter: ") timed { (0 until iters) foreach { _ => scalaFormatter(r.nextDouble()) } } print("BigDecimal Formatter: ") timed { (0 until iters) foreach { _ => bigDecimalFormatter(r.nextDouble()) } } print("Scala custom Formatter (truncation): ") timed { (0 until iters) foreach { _ => scalaCustom(r.nextDouble()) } } } }
/** Constructs a `BigDecimal` using the decimal text representation of `Double` value `d`, rounding if necessary. */ def decimal(d: Double, mc: MathContext): BigDecimal = new BigDecimal(new BigDec(java.lang.Double.toString(d), mc), mc)
def round(x: Double)(p: Int): Double = { var A = x.toString().split( (A(0) + "." + A(1).substring(0, if (p > A(1).length()) A(1).length() else p)).toDouble }
var array = Array( 1, 2, 3 ) array +:= 4 array :+= 0
(service.findAllPresentations.get.first.votes.size) must be equalTo(2).
(service findAllPresentations get first votes size) must be equalTo(2)
string substring (start, end) map (_ toInt) mkString ("<", ", ", ">")
(0 /: list) ((cnt, string) => cnt + string.size) (list foldLeft 0) ((cnt, string) => cnt + string.size)
var z = new D("Hi1", 1) == D{def x: Any; def y: Any}
def myOp2(passByNameString:(Int) => String) { .. } def myOp2(passByNameString:Int => String) { .. }
def myOp2(passByNameString:(Int, String) => String) { .. }
def myOp3(paramFunc0:() => String) { println(paramFunc0) } myOp3(() => "myop3") myOp3(=> "myop3")
def myOp2(passByNameString:Int => String) { println(passByNameString) }
myOp({ val source = sourceProvider.source val p = myObject.findNameFromSource(source) p })
trait Writer { def write(str: String) } object Terminal extends Writer { def write(str: String) { System.out.println(str) } }
trait Writer { def write(str: String): Unit } object Terminal extends Writer { def write(str: String): Unit = { System.out.println(str) } }"
val f1 = (a:Int) => a + 1 def f2 = (a:Int) => a + 1 def f3:(Int => Int) = a => a + 1
scala> f1 res38: (Int) => Int = <function1> scala> f2 res39: (Int) => Int = <function1> scala> f3 res40: (Int) => Int = <function1>
class A(a: Int) { val x = { println("x is set to something"); a } def y = { println("y is set to something"); a } } val a = new A(1) println(a.x) println(a.x) println(a.y) println(a.y)
case class Foo(bar: Int, baz: Int) { def this(bar: Int) = this(bar, 0) } new Foo(1, 2) new Foo(1)
object Foo { def apply(bar: Int) = new Foo(bar) } Foo(1, 2) Foo(1)
case class Baz(bar: Int, baz: Int = 0) new Baz(1) Baz(1)
scala> case class A(i: Int) { def this(s: String) = this(s.toInt) } defined class A scala> A(1) res0: A = A(1) scala> A("2") <console>:8: error: type mismatch; found : java.lang.String("2") required: Int A("2") ^ scala> new A("2") res2: A = A(2)
class SpaceCounter(s: String) { def spaces = s.count(_.isWhitespace) } implicit def string_counts_spaces(s: String) = new SpaceCounter(s) scala> "How many spaces do I have?".spaces res1: Int = 5
class SequentiallyGroupingCollection[A, C[A] <: Seq[A]](ca: C[A]) { def groupIdentical: C[C[A]] = { if (ca.isEmpty) C.empty[C[A]] else { val first = ca.head val (same,rest) = ca.span(_ == first) same +: (new SequentiallyGroupingCollection(rest)).groupIdentical } } }
<console>:12: error: not found: value C if (ca.isEmpty) C.empty[C[A]] ^ <console>:16: error: type mismatch; found : Seq[Seq[A]] required: C[C[A]] same +: (new SequentiallyGroupingCollection(rest)).groupIdentical ^
class GroupingCollection[A, C[A] <: Iterable[A]](ca: C[A]) { import collection.generic.CanBuildFrom def groupedWhile(p: (A,A) => Boolean)( implicit cbfcc: CanBuildFrom[C[A],C[A],C[C[A]]], cbfc: CanBuildFrom[C[A],A,C[A]] ): C[C[A]] = { val it = ca.iterator val cca = cbfcc() if (!it.hasNext) cca.result else { val as = cbfc() var olda = it.next as += olda while (it.hasNext) { val a = it.next if (p(olda,a)) as += a else { cca += as.result; as.clear; as += a } olda = a } cca += as.result } cca.result } } implicit def iterable_has_grouping[A, C[A] <: Iterable[A]](ca: C[A]) = { new GroupingCollection[A,C](ca) }
scala> List(1,2,2,2,3,4,4,4,5,5,1,1,1,2).groupedWhile(_ == _) res0: List[List[Int]] = List(List(1), List(2, 2, 2), List(3), List(4, 4, 4), List(5, 5), List(1, 1, 1), List(2)) scala> Vector(1,2,3,4,1,2,3,1,2,1).groupedWhile(_ < _) res1: scala.collection.immutable.Vector[scala.collection.immutable.Vector[Int]] = Vector(Vector(1, 2, 3, 4), Vector(1, 2, 3), Vector(1, 2), Vector(1))
class GroupingCollection[A, C, D[C]](ca: C)( implicit c2i: C => Iterable[A], cbf: CanBuildFrom[C,C,D[C]], cbfi: CanBuildFrom[C,A,C] ) { def groupedWhile(p: (A,A) => Boolean): D[C] = { val it = c2i(ca).iterator val cca = cbf() if (!it.hasNext) cca.result else { val as = cbfi() var olda = it.next as += olda while (it.hasNext) { val a = it.next if (p(olda,a)) as += a else { cca += as.result; as.clear; as += a } olda = a } cca += as.result } cca.result } }
implicit def collections_have_grouping[A, C[A]](ca: C[A])( implicit c2i: C[A] => Iterable[A], cbf: CanBuildFrom[C[A],C[A],C[C[A]]], cbfi: CanBuildFrom[C[A],A,C[A]] ) = { new GroupingCollection[A,C[A],C](ca)(c2i, cbf, cbfi) }
val vector_string_builder = ( new CanBuildFrom[String, String, Vector[String]] { def apply() = Vector.newBuilder[String] def apply(from: String) = this.apply() } ) implicit def strings_have_grouping(s: String)( implicit c2i: String => Iterable[Char], cbfi: CanBuildFrom[String,Char,String] ) = { new GroupingCollection[Char,String,Vector](s)( c2i, vector_string_builder, cbfi ) }
scala> List(true,false,true,true,true).groupedWhile(_ == _) res1: List[List[Boolean]] = List(List(true), List(false), List(true, true, true)) scala> Array(1,2,5,3,5,6,7,4,1).groupedWhile(_ <= _) res2: Array[Array[Int]] = Array(Array(1, 2, 5), Array(3, 5, 6, 7), Array(4), Array(1)) scala> "Hello there!!".groupedWhile(_.isLetter == _.isLetter) res3: Vector[String] = Vector(Hello, , there, !!)
import scala.collection.generic.{ CanBuildFrom, FromRepr, HasElem } import language.implicitConversions class FilterMapImpl[A, Repr](val r : Repr)(implicit hasElem : HasElem[Repr, A]) { def filterMap[B, That](f : A => Option[B]) (implicit cbf : CanBuildFrom[Repr, B, That]) : That = r.flatMap(f(_).toSeq) } implicit def filterMap[Repr : FromRepr](r : Repr) = new FilterMapImpl(r)
scala> val l = List(1, 2, 3, 4, 5) l: List[Int] = List(1, 2, 3, 4, 5) scala> l.filterMap(i => if(i % 2 == 0) Some(i) else None) res0: List[Int] = List(2, 4) scala> val a = Array(1, 2, 3, 4, 5) a: Array[Int] = Array(1, 2, 3, 4, 5) scala> a.filterMap(i => if(i % 2 == 0) Some(i) else None) res1: Array[Int] = Array(2, 4) scala> val s = "Hello World" s: String = Hello World scala> s.filterMap(c => if(c >= res2: String = HW
class GroupIdenticalImpl[A, Repr : FromRepr](val r: Repr) (implicit hasElem : HasElem[Repr, A]) { def groupIdentical[That](implicit cbf: CanBuildFrom[Repr,Repr,That]): That = { val builder = cbf(r) def group(r: Repr) : Unit = { val first = r.head val (same, rest) = r.span(_ == first) builder += same if(!rest.isEmpty) group(rest) } if(!r.isEmpty) group(r) builder.result } } implicit def groupIdentical[Repr : FromRepr](r: Repr) = new GroupIdenticalImpl(r)
scala> val l = List(1, 1, 2, 2, 3, 3, 1, 1) l: List[Int] = List(1, 1, 2, 2, 3, 3, 1, 1) scala> l.groupIdentical res0: List[List[Int]] = List(List(1, 1),List(2, 2),List(3, 3),List(1, 1)) scala> val a = Array(1, 1, 2, 2, 3, 3, 1, 1) a: Array[Int] = Array(1, 1, 2, 2, 3, 3, 1, 1) scala> a.groupIdentical res1: Array[Array[Int]] = Array(Array(1, 1),Array(2, 2),Array(3, 3),Array(1, 1)) scala> val s = "11223311" s: String = 11223311 scala> s.groupIdentical res2: scala.collection.immutable.IndexedSeq[String] = Vector(11, 22, 33, 11)
import language.implicitConversions import scala.collection.{ GenTraversable=>GT, GenTraversableLike=>GTL, TraversableLike=>TL } import scala.collection.generic.{ CanBuildFrom=>CBF, IsTraversableLike=>ITL } class GroupIdenticalImpl[A, R <% GTL[_,R]](val r: GTL[A,R]) { def groupIdentical[That](implicit cbf: CBF[R, R, That]): That = { val builder = cbf(r.repr) def group(r: GTL[_,R]) { val first = r.head val (same, rest) = r.span(_ == first) builder += same if (!rest.isEmpty) group(rest) } if (!r.isEmpty) group(r) builder.result } } implicit def groupIdentical[A, R <% GTL[_,R]](r: R)(implicit fr: ITL[R]): GroupIdenticalImpl[fr.A, R] = new GroupIdenticalImpl(fr conversion r)
class GroupIdenticalImpl[A, R](val r: GTL[A,R]) { def groupIdentical[That](implicit cbf: CBF[GT[A], GT[A], That]): That = { val builder = cbf(r.toTraversable) def group(r: GT[A]) { val first = r.head val (same, rest) = r.span(_ == first) builder += same if (!rest.isEmpty) group(rest) } if (!r.isEmpty) group(r.toTraversable) builder.result } } implicit def groupIdentical[A, R](r: R)(implicit fr: ITL[R]): GroupIdenticalImpl[fr.A, R] = new GroupIdenticalImpl(fr conversion r)
import language.implicitConversions import scala.collection.{ GenTraversableLike } import scala.collection.generic.{ CanBuildFrom, IsTraversableLike } type GT[A, B] = GenTraversableLike[A, B] type CBF[A, B, C] = CanBuildFrom[A, B, C] type ITL[A] = IsTraversableLike[A] class FilterMapImpl[A, Repr](val r: GenTraversableLike[A, Repr]) { def filterMap[B, That](f: A => Option[B])(implicit cbf : CanBuildFrom[Repr, B, That]): That = r.flatMap(f(_).toSeq) } implicit def filterMap[A, Repr](r: Repr)(implicit fr: ITL[Repr]): FilterMapImpl[fr.A, Repr] = new FilterMapImpl(fr conversion r) class GroupIdenticalImpl[A, R](val r: GT[A,R])(implicit fr: ITL[R]) { def groupIdentical[That](implicit cbf: CBF[R, R, That]): That = { val builder = cbf(r.repr) def group(r0: R) { val r = fr conversion r0 val first = r.head val (same, other) = r.span(_ == first) builder += same val rest = fr conversion other if (!rest.isEmpty) group(rest.repr) } if (!r.isEmpty) group(r.repr) builder.result } } implicit def groupIdentical[A, R](r: R)(implicit fr: ITL[R]): GroupIdenticalImpl[fr.A, R] = new GroupIdenticalImpl(fr conversion r)
type ValidationFunction = ValueType => List[FieldError]
java.lang.RuntimeException: hdfs: at parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:418) at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$refresh$6.apply(newParquet.scala:277) at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$refresh$6.apply(newParquet.scala:276) at scala.collection.parallel.mutable.ParArray$Map.leaf(ParArray.scala:658) at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:54) at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:53) at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:53) at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:56) at scala.collection.parallel.mutable.ParArray$Map.tryLeaf(ParArray.scala:650) at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:165) at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:514) at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
df = spark.read.format("csv").option("header", "true").load("csvfile.csv")
val spark = org.apache.spark.sql.SparkSession.builder .master("local") .appName("Spark CSV Reader") .getOrCreate;
val df = spark.read .format("csv") .option("header", "true") .option("mode", "DROPMALFORMED") .load("hdfs:
val df = spark.sql("SELECT * FROM csv.`csv/file/path/in/hdfs`")
"org.apache.spark" % "spark-core_2.11" % 2.0.0, "org.apache.spark" % "spark-sql_2.11" % 2.0.0,
val df = sqlContext.read .format("com.databricks.spark.csv") .option("header", "true") .option("mode", "DROPMALFORMED") .load("csv/file/path");
"org.apache.spark" % "spark-sql_2.10" % 1.6.0, "com.databricks" % "spark-csv_2.10" % 1.6.0, "com.univocity" % "univocity-parsers" % LATEST,
import org.apache.spark.sql.types.{StructType,StructField,StringType,IntegerType}; import org.apache.spark.sql.Row; val csv = sc.textFile("/path/to/file.csv") val rows = csv.map(line => line.split(",").map(_.trim)) val header = rows.first val data = rows.filter(_(0) != header(0)) val rdd = data.map(row => Row(row(0),row(1).toInt)) val schema = new StructType() .add(StructField("id", StringType, true)) .add(StructField("val", IntegerType, true)) val df = sqlContext.createDataFrame(rdd, schema)
val conf = new SparkConf().setMaster("local[2]").setAppName("my app") val sc = new SparkContext(conf) val sparkSession = SparkSession.builder .config(conf = conf) .appName("spark session example") .getOrCreate() val path = "/Users/xxx/Downloads/usermsg.csv" val base_df = sparkSession.read.option("header","true"). csv(path)
<dependency> <groupId>org.apache.spark</groupId> <artifactId>spark-core_2.11</artifactId> <version>2.0.0</version> </dependency> <!-- https: <dependency> <groupId>org.apache.spark</groupId> <artifactId>spark-sql_2.10</artifactId> <version>2.0.0</version> </dependency> <!-- https: <dependency> <groupId>org.scala-lang</groupId> <artifactId>scala-library</artifactId> <version>2.11.8</version> </dependency> <dependency> <groupId>com.databricks</groupId> <artifactId>spark-csv_2.10</artifactId> <version>1.4.0</version> </dependency>
SparkConf conf = new SparkConf().setAppName("JavaWordCount").setMaster("local"); SparkContext context = new SparkContext(conf); SparkSession sparkSession = new SparkSession(context); Dataset<Row> df = sparkSession.read().format("com.databricks.spark.csv").option("header", true).option("inferSchema", true).load("hdfs: System.out.println("========== Print Schema ============"); df.printSchema(); System.out.println("========== Print Data =============="); df.show(); System.out.println("========== Print title =============="); df.select("title").show();
/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http: * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ val csvdata = spark.read.options(Map( "header" -> "true", "ignoreLeadingWhiteSpace" -> "true", "ignoreTrailingWhiteSpace" -> "true", "timestampFormat" -> "yyyy-MM-dd HH:mm:ss.SSSZZZ", "inferSchema" -> "true", "mode" -> "FAILFAST")) .csv("s3a:
spark = SparkSession.builder.master("local").appName("Classify Urls").getOrCreate() html_df = spark.read.csv(html_csv_file_path, header=True, multiLine=True, ignoreLeadingWhiteSpace=True, ignoreTrailingWhiteSpace=True, encoding="UTF-8", sep= quote= escape= maxColumns=2, inferSchema=True)
import org.apache.spark.sql.{DataFrame, Row, SQLContext, SparkSession} import org.apache.log4j.{Level, LogManager, Logger} object driver { def main(args: Array[String]) { val log = LogManager.getRootLogger log.info("**********JAR EXECUTION STARTED**********") val spark = SparkSession.builder().master("local").appName("ValidationFrameWork").getOrCreate() val df = spark.read.format("csv") .option("header", "true") .option("delimiter","|") .option("inferSchema","true") .load("d:/small_projects/spark/test.pos") df.show() } }
class ForkRun(info: ProjectInfo) extends DefaultProject(info) { override def fork = Some(new ForkScalaRun { override def runJVMOptions = super.runJVMOptions ++ Seq("-Xmx512m") override def scalaJars = Seq(buildLibraryJar.asFile, buildCompilerJar.asFile) }) }
val buildSettings = Defaults.defaultSettings ++ Seq( javaOptions += "-Xmx1G", )
-J-Xms512M -J-Xmx3536M -J-Xss1M -J-XX:+CMSClassUnloadingEnabled -J-XX:+UseConcMarkSweepGC -J-XX:MaxPermSize=724M -J-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005
$ cat /usr/local/bin/sbt test -f ~/.sbtconfig && . ~/.sbtconfig exec java ${SBT_OPTS} -jar /usr/local/Cellar/sbt/0.12.1/libexec/sbt-launch.jar "$@"
$ cat ~/.sbtconfig SBT_OPTS="-Xms512M -Xmx3536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC -XX:MaxPermSize=724M"
-J-Xms512M -J-Xmx3536M -J-Xss1M -J-XX:+CMSClassUnloadingEnabled -J-XX:+UseConcMarkSweepGC -J-XX:MaxPermSize=724M -J-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005
cat .jvmopts -Xms512M -Xmx4096M -Xss2M -XX:MaxMetaspaceSize=1024M
[sameert@pzxdcc0151 approxstrmatch]$ sbt assembly [info] Loading project definition from /apps/sameert/software/approxstrmatch/project [info] Set current project to approxstrmatch (in build file:/apps/sameert/software/approxstrmatch/) [info] Including from cache: scala-library.jar [info] Checking every *.class/*.jar file [info] Merging files... [info] Including from cache: curator-client-2.4.0.jar [info] Including from cache: secondstring-20140729.jar [info] Including from cache: slf4j-api-1.7.5.jar [info] Including from cache: jsr305-1.3.9.jar [info] Including from cache: jul-to-slf4j-1.7.5.jar [info] Including from cache: jcl-over-slf4j-1.7.5.jar [info] Including from cache: commons-digester-1.8.jar [info] Including from cache: compress-lzf-1.0.0.jar [info] Including from cache: commons-beanutils-1.7.0.jar [info] Including from cache: zookeeper-3.4.5.jar [info] Including from cache: slf4j-log4j12-1.7.5.jar [info] Including from cache: commons-beanutils-core-1.8.0.jar [info] Including from cache: commons-net-2.2.jar [info] Including from cache: commons-el-1.0.jar [info] Including from cache: log4j-1.2.17.jar [info] Including from cache: scala-library.jar [info] Including from cache: jline-0.9.94.jar [info] Including from cache: snappy-java-1.0.5.jar [info] Including from cache: hsqldb-1.8.0.10.jar [info] Including from cache: chill_2.10-0.3.6.jar [info] Including from cache: oro-2.0.8.jar [info] Including from cache: chill-java-0.3.6.jar [info] Including from cache: kryo-2.21.jar [info] Including from cache: reflectasm-1.07-shaded.jar [info] Including from cache: minlog-1.2.jar [info] Including from cache: guava-14.0.1.jar [info] Including from cache: jetty-plus-8.1.14.v20131031.jar [info] Including from cache: javax.transaction-1.1.1.v201105210645.jar [info] Including from cache: jackson-mapper-asl-1.8.8.jar [info] Including from cache: jackson-core-asl-1.8.8.jar [info] Including from cache: jetty-webapp-8.1.14.v20131031.jar [info] Including from cache: curator-recipes-2.4.0.jar [info] Including from cache: jetty-xml-8.1.14.v20131031.jar [info] Including from cache: spark-core_2.10-1.0.0.jar [info] Including from cache: objenesis-1.2.jar [info] Including from cache: curator-framework-2.4.0.jar [info] Including from cache: hadoop-client-1.0.4.jar [info] Including from cache: jetty-util-8.1.14.v20131031.jar [info] Including from cache: scalap-2.10.4.jar [info] Including from cache: akka-remote_2.10-2.2.3-shaded-protobuf.jar [info] Including from cache: jetty-servlet-8.1.14.v20131031.jar [info] Including from cache: jetty-security-8.1.14.v20131031.jar [info] Including from cache: jetty-server-8.1.14.v20131031.jar [info] Including from cache: javax.servlet-3.0.0.v201112011016.jar [info] Including from cache: jetty-continuation-8.1.14.v20131031.jar [info] Including from cache: jetty-http-8.1.14.v20131031.jar [info] Including from cache: jetty-io-8.1.14.v20131031.jar [info] Including from cache: hadoop-core-1.0.4.jar [info] Including from cache: jetty-jndi-8.1.14.v20131031.jar [info] Including from cache: xmlenc-0.52.jar [info] Including from cache: commons-codec-1.4.jar [info] Including from cache: javax.mail.glassfish-1.4.1.v201005082020.jar [info] Including from cache: javax.activation-1.1.0.v201105071233.jar [info] Including from cache: commons-math-2.1.jar [info] Including from cache: commons-lang3-3.3.2.jar [info] Including from cache: commons-configuration-1.6.jar [info] Including from cache: metrics-core-3.0.0.jar [info] Including from cache: metrics-jvm-3.0.0.jar [info] Including from cache: metrics-json-3.0.0.jar [info] Including from cache: commons-collections-3.2.1.jar [info] Including from cache: metrics-graphite-3.0.0.jar [info] Including from cache: commons-lang-2.4.jar [info] Including from cache: akka-actor_2.10-2.2.3-shaded-protobuf.jar [info] Including from cache: config-1.0.2.jar [info] Including from cache: tachyon-0.4.1-thrift.jar [info] Including from cache: netty-3.6.6.Final.jar [info] Including from cache: protobuf-java-2.4.1-shaded.jar [info] Including from cache: uncommons-maths-1.2.2a.jar [info] Including from cache: akka-slf4j_2.10-2.2.3-shaded-protobuf.jar [info] Including from cache: json4s-jackson_2.10-3.2.6.jar [info] Including from cache: json4s-core_2.10-3.2.6.jar [info] Including from cache: ant-1.9.0.jar [info] Including from cache: json4s-ast_2.10-3.2.6.jar [info] Including from cache: ant-launcher-1.9.0.jar [info] Including from cache: paranamer-2.6.jar [info] Including from cache: commons-io-2.4.jar [info] Including from cache: jackson-core-2.3.0.jar [info] Including from cache: pyrolite-2.0.1.jar [info] Including from cache: colt-1.2.0.jar [info] Including from cache: concurrent-1.3.4.jar [info] Including from cache: py4j-0.8.1.jar [info] Including from cache: mesos-0.18.1-shaded-protobuf.jar [info] Including from cache: scala-compiler.jar [info] Including from cache: jets3t-0.7.1.jar [info] Including from cache: commons-httpclient-3.1.jar [info] Including from cache: netty-all-4.0.17.Final.jar [info] Including from cache: stream-2.5.1.jar [info] Including from cache: scala-reflect.jar [info] Including from cache: jackson-databind-2.3.0.jar [info] Including from cache: jackson-annotations-2.3.0.jar [warn] Merging [warn] Strategy [info] Checking every *.class/*.jar file [info] Merging files... [warn] Merging [info] Assembly up to date: /apps/sameert/software/approxstrmatch/app/target/scala-2.10/app-assembly-0.1-SNAPSHOT.jar
java.lang.RuntimeException: deduplicate: different file contents found in the following: /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.transaction/orbits/javax.transaction-1.1.1.v201105210645.jar:META-INF/ECLIPSEF.RSA /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.servlet/orbits/javax.servlet-3.0.0.v201112011016.jar:META-INF/ECLIPSEF.RSA /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.mail.glassfish/orbits/javax.mail.glassfish-1.4.1.v201005082020.jar:META-INF/ECLIPSEF.RSA /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.activation/orbits/javax.activation-1.1.0.v201105071233.jar:META-INF/ECLIPSEF.RSA at sbtassembly.Plugin$Assembly$.sbtassembly$Plugin$Assembly$$applyStrategy$1(Plugin.scala:253) at sbtassembly.Plugin$Assembly$$anonfun$15.apply(Plugin.scala:270) at sbtassembly.Plugin$Assembly$$anonfun$15.apply(Plugin.scala:267) at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251) at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251) at scala.collection.Iterator$class.foreach(Iterator.scala:727) at scala.collection.AbstractIterator.foreach(Iterator.scala:1157) at scala.collection.IterableLike$class.foreach(IterableLike.scala:72) at scala.collection.AbstractIterable.foreach(Iterable.scala:54) at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:251) at scala.collection.AbstractTraversable.flatMap(Traversable.scala:105) at sbtassembly.Plugin$Assembly$.applyStrategies(Plugin.scala:272) at sbtassembly.Plugin$Assembly$.x$4$lzycompute$1(Plugin.scala:172) at sbtassembly.Plugin$Assembly$.x$4$1(Plugin.scala:170) at sbtassembly.Plugin$Assembly$.stratMapping$lzycompute$1(Plugin.scala:170) at sbtassembly.Plugin$Assembly$.stratMapping$1(Plugin.scala:170) at sbtassembly.Plugin$Assembly$.inputs$lzycompute$1(Plugin.scala:214) at sbtassembly.Plugin$Assembly$.inputs$1(Plugin.scala:204) at sbtassembly.Plugin$Assembly$.apply(Plugin.scala:230) at sbtassembly.Plugin$Assembly$$anonfun$assemblyTask$1.apply(Plugin.scala:373) at sbtassembly.Plugin$Assembly$$anonfun$assemblyTask$1.apply(Plugin.scala:370) at scala.Function1$$anonfun$compose$1.apply(Function1.scala:47) at sbt.$tilde$greater$$anonfun$$u2219$1.apply(TypeFunctions.scala:42) at sbt.std.Transform$$anon$4.work(System.scala:64) at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237) at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237) at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:18) at sbt.Execute.work(Execute.scala:244) at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237) at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237) at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:160) at sbt.CompletionService$$anon$2.call(CompletionService.scala:30) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)
[error] (approxstrmatch/*:assembly) deduplicate: different file contents found in the following: [error] /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.transaction/orbits/javax.transaction-1.1.1.v201105210645.jar:META-INF/ECLIPSEF.RSA [error] /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.servlet/orbits/javax.servlet-3.0.0.v201112011016.jar:META-INF/ECLIPSEF.RSA [error] /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.mail.glassfish/orbits/javax.mail.glassfish-1.4.1.v201005082020.jar:META-INF/ECLIPSEF.RSA [error] /home/sameert/.ivy2/cache/org.eclipse.jetty.orbit/javax.activation/orbits/javax.activation-1.1.0.v201105071233.jar:META-INF/ECLIPSEF.RSA [error] Total time: 4 s, completed Aug 5, 2014 9:53:06 AM
assemblyMergeStrategy in assembly := { case PathList("META-INF", xs @ _*) => MergeStrategy.discard case x => MergeStrategy.first }
libraryDependencies += "org.apache.spark" %% "spark-core" % "1.1.0" % "provided"
import AssemblyKeys._ name := "approxstrmatch" version := "1.0" scalaVersion := "2.10.4" libraryDependencies+="org.apache.spark"%%"spark-core"%"1.0.0" libraryDependencies ++= Seq( ("org.apache.spark"%%"spark-core"%"1.0.0"). exclude("org.eclipse.jetty.orbit", "javax.servlet"). exclude("org.eclipse.jetty.orbit", "javax.transaction"). exclude("org.eclipse.jetty.orbit", "javax.mail"). exclude("org.eclipse.jetty.orbit", "javax.activation"). exclude("commons-beanutils", "commons-beanutils-core"). exclude("commons-collections", "commons-collections"). exclude("commons-collections", "commons-collections"). exclude("com.esotericsoftware.minlog", "minlog") ) resolvers += "AkkaRepository" at "http: lazy val app = Project("approxstrmatch", file("approxstrmatch"), settings = buildSettings ++ assemblySettings ++ Seq( mergeStrategy in assembly <<= (mergeStrategy in assembly) { (old) => { case PathList("javax", "servlet", xs @ _*) => MergeStrategy.first case PathList("javax", "transaction", xs @ _*) => MergeStrategy.first case PathList("javax", "mail", xs @ _*) => MergeStrategy.first case PathList("javax", "activation", xs @ _*) => MergeStrategy.first case PathList(ps @ _*) if ps.last endsWith ".html" => MergeStrategy.first case "application.conf" => MergeStrategy.concat case "unwanted.txt" => MergeStrategy.discard case x => old(x) } }) ) mainClass in assembly := Some("approxstrmatch.JaccardScore")
libraryDependencies ++= Seq( "joda-time" % "joda-time" % "2.1" )
val ymd = org.joda.time.format.DateTimeFormat.forPattern("yyyyMMdd") ymd.parseDateTime("20121212")
[warn] Class org.joda.convert.FromString not found - continuing with a stub. [warn] Caught: java.lang.NullPointerException while parsing annotations in /home/jack/.ivy2/cache/joda-time/joda-time/jars/joda-time-2.1.jar(org/joda/time/DateTime.class) [error] error while loading DateTime, class file [error] (class java.lang.RuntimeException/bad constant pool tag 10 at byte 42)
[warn] Class net.jcip.annotations.NotThreadSafe not found - continuing with a stub. [warn] Caught: java.lang.NullPointerException while parsing annotations in ~/.ivy2-p2/cache/org.opensaml/xmltooling/jars/xmltooling-1.3.4.jar(org/opensaml/xml/util/IDIndex.class) [error] error while loading AttributeMap, class file [error] (class java.lang.RuntimeException/bad constant pool index: 0 at pos: 12058)
import scala.concurrent.{ future, promise } val p = promise[T] val f = p.future val producer = future { val r = produceSomething() p success r continueDoingSomethingUnrelated() } val consumer = future { startDoingSomething() f onSuccess { case r => doSomethingWithResult() } }
val f = future { produceSomething() } val producer = future { continueDoingSomethingUnrelated() } startDoingSomething() val consumer = future { f onSuccess { case r => doSomethingWithResult() } }
object Promise { /** Creates a promise object which can be completed with a value. * * @tparam T the type of the value in the promise * @return the newly created `Promise` object */ def apply[T](): Promise[T] = new impl.Promise.DefaultPromise[T]() /** Creates an already completed Promise with the specified exception. * * @tparam T the type of the value in the promise * @return the newly created `Promise` object */ def failed[T](exception: Throwable): Promise[T] = new impl.Promise.KeptPromise[T](Failure(exception)) /** Creates an already completed Promise with the specified result. * * @tparam T the type of the value in the promise * @return the newly created `Promise` object */ def successful[T](result: T): Promise[T] = new impl.Promise.KeptPromise[T](Success(result)) }
private[concurrent] trait Promise[T] extends scala.concurrent.Promise[T] with scala.concurrent.Future[T] { def future: this.type = this }
def future[T](body: =>T)(implicit execctx: ExecutionContext): Future[T] = Future[T](body)
private[concurrent] object Future { class PromiseCompletingRunnable[T](body: => T) extends Runnable { val promise = new Promise.DefaultPromise[T]() override def run() = { promise complete { try Success(body) catch { case NonFatal(e) => Failure(e) } } } } def apply[T](body: =>T)(implicit executor: ExecutionContext): scala.concurrent.Future[T] = { val runnable = new PromiseCompletingRunnable(body) executor.execute(runnable) runnable.promise.future } }
def makeHTTPCall(request: Request): Future[Response] = { val p = Promise[Response] registerOnCompleteCallback(buffer => { val response = makeResponse(buffer) p success response }) p.future }
trait TravserableLike { def find(p: A => Boolean): Option[A] = { var result: Option[A] = None breakable { for (x <- this) if (p(x)) { result = Some(x); break } } result } }
trait Iterable { override def find(p: A => Boolean): Option[A] = iterator.find(p) } trait Iterator { def find(p: A => Boolean): Option[A] = { var res: Option[A] = None while (res.isEmpty && hasNext) { val e = next() if (p(e)) res = Some(e) } res } }
scala> val ls = List("Mary", "had", "a", "little", "lamb") scala> ls.zipWithIndex.foreach{ case (e, i) => println(i+" "+e) } 0 Mary 1 had 2 a 3 little 4 lamb
for((e,i) <- List("Mary", "had", "a", "little", "lamb").zipWithIndex) println(i+" "+e)
List("Mary", "had", "a", "little", "lamb").zipWithIndex.foreach( (t) => println(t._2+" "+t._1) )
val myList = List("a", "b", "c") myList.zipWithIndex.map { case (element, index) => println(element, index) s"${element}(${index})" }
object TraversableUtil { class IndexMemoizingFunction[A, B](f: (Int, A) => B) extends Function1[A, B] { private var index = 0 override def apply(a: A): B = { val ret = f(index, a) index += 1 ret } } def doIndexed[A, B](f: (Int, A) => B): A => B = { new IndexMemoizingFunction(f) } }
val ci = List("These","are","words").elements.counted scala> ci map (i => i+"= res0: List[java.lang.String] = List(These=
val ls = List("a","b","c") 0.until(ls.length).map( i => doStuffWithElem(i,ls(i)) )
val ls = List("a","b","c") val ls_index_map = ls.zipWithIndex.toMap
val sampleMap = Map("a" -> "hello", "b" -> "world", "c" -> "again") val result = sampleMap.zipWithIndex.map { case ((key, value), index) => s"Key: $key - Value: $value with Index: $index" }
List( Key: a - Value: hello with Index: 0, Key: b - Value: world with Index: 1, Key: c - Value: again with Index: 2 )
scala> val intParList: ParSeq[Int] = (1 to 100000).map(_ => scala.util.Random.nextInt()).par scala> timeMany(1000, intParList.reduce(_ + _)) Took 462.395867 milli seconds scala> timeMany(1000, intParList.foldLeft(0)(_ + _)) Took 2589.363031 milli seconds
import org.apache.spark.{SparkConf, SparkContext} object FoldExample extends App{ val conf = new SparkConf() .setMaster("local[*]") .setAppName("Simple Application") implicit val sc = new SparkContext(conf) val range = ( val rdd = sc.parallelize(range) println(range.reduce(_ + _)) println(rdd.reduce(_ + _)) println(rdd.fold("")(_ + _)) }
pipe.groupBy( _.reduce( } pipe.groupBy( _.foldLeft( }
import org.apache.spark.sql.SparkSession /* Note: standalone (non-local) mode */ val master = "spark: val spark = SparkSession.builder.master(master).getOrCreate() val rdd = sc.parallelize(Seq("a", "b", "c", "d"), 4).sortBy(identity[String]) require(rdd.collect.sliding(2).forall { case Array(x, y) => x < y }) require(Seq.fill(1000)(rdd.fold("")(_ + _)).toSet.size == 24)
def fold(zeroValue: T)(op: (T, T) => T): T = withScope { var jobResult: T val cleanOp: (T, T) => T val foldPartition = Iterator[T] => T val mergeResult: (Int, T) => Unit sc.runJob(this, foldPartition, mergeResult) jobResult }
def reduce(f: (T, T) => T): T = withScope { val cleanF: (T, T) => T val reducePartition: Iterator[T] => Option[T] var jobResult: Option[T] val mergeResult = (Int, Option[T]) => Unit sc.runJob(this, reducePartition, mergeResult) jobResult.getOrElse(throw new UnsupportedOperationException("empty collection")) }
scala> val m = Map(1 -> "a", 2 -> "b", 4 -> "b") scala> m.groupBy(_._2).mapValues(_.keys) res0: Map[String,Iterable[Int]] = Map(b -> Set(2, 4), a -> Set(1))
import Function.tupled Map() ++ (origMap map tupled {(k,v) => (v,k)})
val newMap = oldMap.foldLeft(Map[B, Seq[A]]().withDefaultValue(Seq())) { case (m, (a, bs)) => bs.foldLeft(m)((map, b) => map.updated(b, m(b) :+ a)) }
scala> val m = Map("a" -> 1, "b" -> 2, "c" -> 3, "d" -> 1) m: scala.collection.immutable.Map[String,Int] = Map(a -> 1, b -> 2, c -> 3, d -> 1) scala> val i = m.map({ case(k , v) => v -> k}) i: scala.collection.immutable.Map[Int,String] = Map(1 -> d, 2 -> b, 3 -> c)
scala> val i = m.toList.map({ case(k , v) => v -> k}) i: List[(Int, String)] = List((1,a), (2,b), (3,c), (1,d))
implicit class MapInverterA[K,V](m :Map[K,V]) { def invert :Map[V,Set[K]] = m.foldLeft(Map.empty[V, Set[K]]) { case (acc,(k, v)) => acc + (v -> (acc.getOrElse(v,Set()) + k)) } }
import scala.collection.generic.CanBuildFrom import scala.collection.mutable.Builder import scala.language.higherKinds implicit class MapInverterB[K,V,C[_]](m :Map[K,C[V]] )(implicit ev :C[V] => TraversableOnce[V]) { def invert(implicit bf :CanBuildFrom[Nothing,K,C[K]]) :Map[V,C[K]] = m.foldLeft(Map.empty[V, Builder[K,C[K]]]) { case (acc, (k, vs)) => vs.foldLeft(acc) { case (a, v) => a + (v -> (a.getOrElse(v,bf()) += k)) } }.mapValues(_.result()) }
Map(2 -> Array( Map( Map(9 -> "this", 8 -> "that", 3 -> "thus", 2 -> "thus").invert Map(1L -> Iterator(3,2), 5L -> Iterator(7,8,3)).invert Map.empty[Unit,Boolean].invert
scala> val m = Map(1 -> "one", 2 -> "two") m: scala.collection.immutable.Map[Int,java.lang.String] = Map(1 -> one, 2 -> two) scala> val reversedM = m map { case (k, v) => (v, k) } reversedM: scala.collection.immutable.Map[java.lang.String,Int] = Map(one -> 1, two -> 2)
scala> val m = Map(1 -> "one", 2 -> "two", 3 -> "one") m: scala.collection.immutable.Map[Int,java.lang.String] = Map(1 -> one, 2 -> two, 3 -> one) scala> val reversedM = m map { case (k, v) => (v, k) } reversedM: scala.collection.immutable.Map[java.lang.String,Int] = Map(one -> 3, two -> 2)
def invertMap[A,B]( m: Map[A,B] ) : Map[B,List[A]] = { val k = ( ( m values ) toList ) distinct val v = k map { e => ( ( m keys ) toList ) filter { x => m(x) == e } } ( k zip v ) toMap }
scala> def invertMap[A, B](inputMap: Map[A, B]): Map[B, List[A]] = { | inputMap.foldLeft(Map[B, List[A]]()) { | case (mapAccumulator, (value, key)) => | if (mapAccumulator.contains(key)) { | mapAccumulator.updated(key, mapAccumulator(key) :+ value) | } else { | mapAccumulator.updated(key, List(value)) | } | } | } invertMap: [A, B](inputMap: Map[A,B])Map[B,List[A]] scala> val map = Map(1 -> 2, 2 -> 2, 3 -> 3, 4 -> 3, 5 -> 5) map: scala.collection.immutable.Map[Int,Int] = Map(5 -> 5, 1 -> 2, 2 -> 2, 3 -> 3, 4 -> 3) scala> invertMap(map) res0: Map[Int,List[Int]] = Map(5 -> List(5), 2 -> List(1, 2), 3 -> List(3, 4)) scala> val map = Map("A" -> "A", "B" -> "A", "C" -> "C", "D" -> "C", "E" -> "E") map: scala.collection.immutable.Map[String,String] = Map(E -> E, A -> A, B -> A, C -> C, D -> C) scala> invertMap(map) res1: Map[String,List[String]] = Map(E -> List(E), A -> List(A, B), C -> List(C, D))
scala> (new DynImpl).method("blah") <console>:17: error: value applyDynamic is not a member of DynImpl error after rewriting to new DynImpl().<applyDynamic: error>("method") possible cause: maybe a wrong Dynamic method signature? (new DynImpl).method("blah") ^
class DynImpl extends Dynamic { def selectDynamic(name: String) = name } scala> val d = new DynImpl d: DynImpl = DynImpl@6040af64 scala> d.foo res37: String = foo scala> d.bar res38: String = bar scala> d.selectDynamic("foo") res54: String = foo
class DynImpl extends Dynamic { var map = Map.empty[String, Any] def selectDynamic(name: String) = map get name getOrElse sys.error("method not found") def updateDynamic(name: String)(value: Any) { map += name -> value } } scala> val d = new DynImpl d: DynImpl = DynImpl@7711a38f scala> d.foo java.lang.RuntimeException: method not found scala> d.foo = 10 d.foo: Any = 10 scala> d.foo res56: Any = 10
class DynImpl extends Dynamic { def applyDynamic(name: String)(args: Any*) = s"method } scala> val d = new DynImpl d: DynImpl = DynImpl@766bd19d scala> d.ints(1, 2, 3) res68: String = method scala> d.foo() res69: String = method scala> d.foo <console>:19: error: value selectDynamic is not a member of DynImpl
class DynImpl extends Dynamic { def applyDynamicNamed(name: String)(args: (String, Any)*) = s"method } scala> val d = new DynImpl d: DynImpl = DynImpl@123810d1 scala> d.ints(i1 = 1, i2 = 2, 3) res73: String = method
class DynImpl extends Dynamic { import reflect.runtime.universe._ def applyDynamic[A : TypeTag](name: String)(args: A*): A = name match { case "sum" if typeOf[A] =:= typeOf[Int] => args.asInstanceOf[Seq[Int]].sum.asInstanceOf[A] case "concat" if typeOf[A] =:= typeOf[String] => args.mkString.asInstanceOf[A] } } scala> val d = new DynImpl d: DynImpl = DynImpl@5d98e533 scala> d.sum(1, 2, 3) res0: Int = 6 scala> d.concat("a", "b", "c") res1: String = abc
object DynTypes { sealed abstract class DynType[A] { def exec(as: A*): A } implicit object SumType extends DynType[Int] { def exec(as: Int*): Int = as.sum } implicit object ConcatType extends DynType[String] { def exec(as: String*): String = as.mkString } } class DynImpl extends Dynamic { import reflect.runtime.universe._ import DynTypes._ def applyDynamic[A : TypeTag : DynType](name: String)(args: A*): A = name match { case "sum" if typeOf[A] =:= typeOf[Int] => implicitly[DynType[A]].exec(args: _*) case "concat" if typeOf[A] =:= typeOf[String] => implicitly[DynType[A]].exec(args: _*) } }
scala> val d = new DynImpl d: DynImpl = DynImpl@24a519a2 scala> d.sum(1, 2, 3) res89: Int = 6 scala> d.concat("a", "b", "c") res90: String = abc
class DynImpl extends Dynamic { import language.experimental.macros def applyDynamic[A](name: String)(args: A*): A = macro DynImpl.applyDynamic[A] } object DynImpl { import reflect.macros.Context import DynTypes._ def applyDynamic[A : c.WeakTypeTag](c: Context)(name: c.Expr[String])(args: c.Expr[A]*) = { import c.universe._ val Literal(Constant(defName: String)) = name.tree val res = defName match { case "sum" if weakTypeOf[A] =:= weakTypeOf[Int] => val seq = args map(_.tree) map { case Literal(Constant(c: Int)) => c } implicitly[DynType[Int]].exec(seq: _*) case "concat" if weakTypeOf[A] =:= weakTypeOf[String] => val seq = args map(_.tree) map { case Literal(Constant(c: String)) => c } implicitly[DynType[String]].exec(seq: _*) case _ => val seq = args map(_.tree) map { case Literal(Constant(c)) => c } c.abort(c.enclosingPosition, s"method } c.Expr(Literal(Constant(res))) } } scala> val d = new DynImpl d: DynImpl = DynImpl@c487600 scala> d.sum(1, 2, 3) res0: Int = 6 scala> d.concat("a", "b", "c") res1: String = abc scala> d.noexist("a", "b", "c") <console>:11: error: method d.noexist("a", "b", "c") ^
val someList: List[Option[String]] = List(Some("Hello"), None, Some("Goodbye")) someList.filter(_ != None)
scala> someList.flatten res0: List[String] = List(Hello, Goodbye)
import cats.implicits._ List(Some(1), Some(2), None).flattenOption == List(1, 2)
trait Foldable[F[_]] { def foldl[A, B](as: F[A], z: B, f: (B, A) => B): B } def sumOf[F[_]](ns: F[Int])(implicit ff: Foldable[F]) = ff.foldl(ns, 0, (x: Int, y: Int) => x + y)
implicit val listFoldable = new Foldable[List] { def foldl[A, B](as: List[A], z: B, f: (B, A) => B) = as.foldLeft(z)(f) } val sumOfOneTwoThree = sumOf(List(1,2,3))
trait Monoid[M] { def zero: M def add(m1: M, m2: M): M } trait Foldable[F[_]] { def foldl[A, B](as: F[A], z: B, f: (B, A) => B): B def foldMap[A, B](as: F[A], f: A => B)(implicit m: Monoid[B]): B = foldl(as, m.zero, (b: B, a: A) => m.add(b, f(a))) } def mapReduce[F[_], A, B](as: F[A], f: A => B) (implicit ff: Foldable[F], m: Monoid[B]) = ff.foldMap(as, f)
case class Sum(value: Int) case class Product(value: Int) implicit val sumMonoid = new Monoid[Sum] { def zero = Sum(0) def add(a: Sum, b: Sum) = Sum(a.value + b.value) } implicit val productMonoid = new Monoid[Product] { def zero = Product(1) def add(a: Product, b: Product) = Product(a.value * b.value) } val sumOf123 = mapReduce(List(1,2,3), Sum) val productOf456 = mapReduce(List(4,5,6), Product)
class Parameterized[T] { def call(func: (Int) => Int) = func(1) def use(l: Long) { println(l) } } val p = new Parameterized[String] p.call((i:Int) => i + 1) p.use(1L) abstract class Abstracted { type T def call(i: Int): Int val l: Long def use() { println(l) } } class Concrete extends Abstracted { type T = String def call(i:Int): Int = i + 1 val l = 1L } val a: Abstracted = new Concrete a.call(1) a.use()
import scala.collection.mutable.ArrayBuffer object MyObject { def main(args: Array[String]) { val a = ArrayBuffer(1,2,3,4) silly(a) println(a) } def silly(a: ArrayBuffer[Int]): Unit = { a += 10 println(s"length: ${a.length}") } }
object MyObject { def main(args: Array[String]) { var v = Vector(1,2,3,4) silly(v) println(v) } def silly(v: Vector[Int]): Unit = { v = v :+ 10 println(s"length of v: ${v.length}") } }
implicit def string2quant(s: String) = new Quantifiable{ def quantify = s.size } implicit def list2quantifiable[A](l: List[A]) = new Quantifiable{ val quantify = l.size }
implicit val stringQuantifiable = new Quantified[String] { def quantify(s: String) = s.size }
def sumQuantities[A](as: List[A])(implicit ev: Quantified[A]) = as.map(ev.quantify).sum
def sumQuantities[A: Quantified](as: List[A]) = as.map(implicitly[Quantified[A]].quantify).sum
def myMethod(): Unit = { implicit object MyIntFoo extends Foo[Int] { ... } foo(5) foo(6) foo(7)(new Foo[Int] { ... }) }
trait Default[T] { def value : T } implicit object DefaultInt extends Default[Int] { def value = 42 } implicit def listsHaveDefault[T : Default] = new Default[List[T]] { def value = implicitly[Default[T]].value :: Nil } def default[T : Default] = implicitly[Default[T]].value scala> default[List[List[Int]]] resN: List[List[Int]] = List(List(42))
trait Foo1[A] { def foo(a: A): Int } trait Foo0 { def foo: Int }
import java.io.File def recursiveListFiles(f: File): Array[File] = { val these = f.listFiles these ++ these.filter(_.isDirectory).flatMap(recursiveListFiles) }
myBigFileArray.filter(f => .r.findFirstIn(f.getName).isDefined)
import scala.util.matching.Regex def recursiveListFiles(f: File, r: Regex): Array[File] = { val these = f.listFiles val good = these.filter(f => r.findFirstIn(f.getName).isDefined) good ++ these.filter(_.isDirectory).flatMap(recursiveListFiles(_,r)) }
import scala.collection.JavaConversions._ def getFileTree(f: File): Stream[File] = f else Stream.empty)
getFileTree(new File("c:\\main_dir")).filter(_.getName.endsWith(".scala")).foreach(println)
for (file <- new File("c:\\").listFiles) { processFile(file) }
import java.nio.file.{FileSystems, Files} import scala.collection.JavaConverters._ val dir = FileSystems.getDefault.getPath("/some/path/here") Files.walk(dir).iterator().asScala.filter(Files.isRegularFile(_)).foreach(println)
import org.apache.commons.io.filefilter.IOFileFilter implicit def newIOFileFilter (filter: File=>Boolean) = new IOFileFilter { def accept (file: File) = filter (file) def accept (dir: File, name: String) = filter (new java.io.File (dir, name)) }
def tree(root: File, skipHidden: Boolean = false): Stream[File] = if (!root.exists || (skipHidden && root.isHidden)) Stream.empty else root root.listFiles match { case null => Stream.empty case files => files.toStream.flatMap(tree(_, skipHidden)) })
tree(new File(".")).filter(f => f.isFile && f.getName.endsWith(".html")).foreach(println)
import scala.collection.JavaConversions._ import org.apache.commons.io.FileUtils FileUtils.listFiles(new File("c:\temp"), Array("foo"), true).foreach{ f => }
val dir = "src"/"test" val matches: Iterator[File] = dir.glob("**/*.{java,scala}") dir.listRecursively.filter(f => f.extension == Some(".java") || f.extension == Some(".scala"))
def tree( root: File, descendCheck: File => Boolean = { _ => true } ): Stream[File] = { require(root != null) def directoryEntries(f: File) = for { direntries <- Option(f.list).toStream d <- direntries } yield new File(f, d) val shouldDescend = root.isDirectory && descendCheck(root) ( root.exists, shouldDescend ) match { case ( false, _) => Stream.Empty case ( true, true ) => root case ( true, false) => Stream( root ) } } def treeIgnoringHiddenFilesAndDirectories( root: File ) = tree( root, { !_.isHidden } ) filter { !_.isHidden }
def allFiles(path:File):List[File]= { val parts=path.listFiles.toList.partition(_.isDirectory) parts._2 ::: parts._1.flatMap(allFiles) }
import scala.reflect.io.Path Path(path) walkFilter { p => p.isDirectory || .r.findFirstIn(p.name).isDefined }
def listFiles(file: File): List[File] = { @tailrec def listFiles(files: List[File], result: List[File]): List[File] = files match { case Nil => result case head :: tail if head.isDirectory => listFiles(Option(head.listFiles).map(_.toList ::: tail).getOrElse(tail), result) case head :: tail if head.isFile => listFiles(tail, head :: result) } listFiles(List(file), Nil) }
import java.io.File def findFiles(fileFilter: (File) => Boolean = (f) => true)(f: File): List[File] = { val ss = f.list() val list = if (ss == null) { Nil } else { ss.toList.sorted } val visible = list.filter(_.charAt(0) != val these = visible.map(new File(f, _)) these.filter(fileFilter) ++ these.filter(_.isDirectory).flatMap(findFiles(fileFilter)) }
val srcDir = new File( ... ) val htmlFiles = findFiles( _.getName endsWith ".html" )( srcDir )
val path = scala.reflect.io.Path(dir) scala.tools.nsc.io.Path.onlyFiles(path.walk).foreach(println)
import scala.collection.JavaConversions._ import org.apache.commons.io.FileUtils FileUtils.listFiles(dir, null, true).foreach(println)
import scalax.file.Path Path.fromString("c:\temp") ** "a*.foo"
import scalax.file.ImplicitConversions.string2path "c:\temp" ** "a*.foo"
import scalax.file.Path import scalax.file.ImplicitConversions.string2path val dir: Path = "c:\temp" dir ** "a*.foo"
def findFiles(dir: File, criterion: (File) => Boolean): Seq[File] = { if (dir.isFile) Seq() else { val (files, dirs) = dir.listFiles.partition(_.isFile) files.filter(criterion) ++ dirs.toSeq.map(findFiles(_, criterion)).foldLeft(Seq[File]())(_ ++ _) } }
object DirectoryTraversal { import java.io._ def main(args: Array[String]) { val dir = new File("C:/Windows") val files = scan(dir) val out = new PrintWriter(new File("out.txt")) files foreach { file => out.println(file) } out.flush() out.close() } def scan(file: File): List[File] = { @scala.annotation.tailrec def sc(acc: List[File], files: List[File]): List[File] = { files match { case Nil => acc case x :: xs => { x.isDirectory match { case false => sc(x :: acc, xs) case true => sc(acc, xs ::: x.listFiles.toList) } } } } sc(List(), List(file)) } }
import scala.reflect.io.AbstractFile def tree(root: AbstractFile, descendCheck: AbstractFile => Boolean = {_=>true}): Stream[AbstractFile] = if (root == null || !root.exists) Stream.empty else (root.exists, root.isDirectory && descendCheck(root)) match { case (false, _) => Stream.empty case (true, true) => root case (true, false) => Stream(root) }
package object investigations { val PackageObjectVal = "A package object val" } package investigations { object PackageObjectTest { def main(args: Array[String]) { println("Referencing a package object val: " + PackageObjectVal) } } }
package foo package object bar { def BarVersionString = "1.0" type StringMap[+T] = Map[String,T] type DateTime = org.joda.time.DateTime type JList[T] = java.util.List[T] implicit def a2b(a: A): B = }
package object bar extends Versioning with JodaAliases with JavaAliases { override val version = "1.0" type StringMap[+T] = Map[String,T] implicit def a2b(a: A): B = }
trait A{ def a = 1 } trait X extends A{ override def a = { println("X") super.a } } trait Y extends A{ override def a = { println("Y") super.a } } scala> val xy = new AnyRef with X with Y xy: java.lang.Object with X with Y = $anon$1@6e9b6a scala> xy.a Y X res0: Int = 1 scala> val yx = new AnyRef with Y with X yx: java.lang.Object with Y with X = $anon$1@188c838 scala> yx.a X Y res1: Int = 1
import scala.collection.immutable._ def foo(s: Set[CharSequence]): Unit = { println(s) } def bar(): Unit = { val s: Set[String] = Set("Hello", "World"); foo(s); }
trait Set[A] extends (A=>Boolean) { def apply(e: A): Boolean }
import scala.collections.immutable._ def findCharSequences(): Set[CharSequence] = Set("Hello", "World")
def myfun(arg:String)(implicit p1: String)(implicit p2:Int)={}
def myfun(arg:String)(implicit p1: String, p2:Int)={}
def foo(a:Int, b:Int) = {} foo(a,b) foo(getParams) def getParams = { (a,b) }
scala> def foo(x: Int, y: Double) = x * y foo: (x: Int,y: Double)Double scala> foo _ res0: (Int, Double) => Double = <function2> scala> foo _ tupled res1: ((Int, Double)) => Double = <function1> scala> foo _ curried res2: (Int) => (Double) => Double = <function1> scala> Function.tupled(foo _) res3: ((Int, Double)) => Double = <function1> scala> Function.curried(foo _) warning: there were deprecation warnings; re-run with -deprecation for details res6: (Int) => (Double) => Double = <function1>
scala> val c = foo _ curried c: (Int) => (Double) => Double = <function1> scala> c(5) res13: (Double) => Double = <function1> scala> c(5)(10) res14: Double = 50.0
scala> val f = foo _ tupled f: ((Int, Double)) => Double = <function1> scala> val c = foo _ curried c: (Int) => (Double) => Double = <function1> scala> Function.uncurried(c) res9: (Int, Double) => Double = <function2> scala> Function.untupled(f) res12: (Int, Double) => Double = <function2>
scala> class Person(firstName: String, lastName: String) { | override def toString = firstName + " " + lastName | } defined class Person scala> object Person { | def apply(firstName: String, lastName: String) = new Person(firstName, lastName) | } defined module Person scala> (Person.apply _).tupled(("Rahul", "G")) res17: Person = Rahul G
scala> case class Person(firstName: String, lastName: String) defined class Person scala> Person.tupled(("Rahul", "G")) res18: Person = Person(Rahul,G)
def originalFunc(a: A, b: B): C = ... def wrapperFunc(ab: (A, B)): C = (originalFunc _).tupled(ab)
def foo(t: Tuple2[Int, Int]) = { println("Hello " + t._1 + t._2) "Makes no sense but ok!" } def getParams = { val a = 1; val b = 2; (a, b) } foo(getParams) foo(1, 3)
val ThisIsAConstant = 1.23 val THIS_IS_ANOTHER_CONSTANT = 1.55 val thisIsAThirdConstant = 1.94
object Case { val lowerConst = "lower" val UpperConst = "UPPER" def main(args: Array[String]) { for (i <- Seq(lowerConst, UpperConst, "should mismatch.").map(Option.apply)) { print("Input i match { case Some(UpperConst) => println("UPPER!!!") case Some(lowerConst) => println("lower!") case _ => println("mismatch!") } } } }
<buildSpec> <buildCommand> <name>org.eclipse.jdt.core.javabuilder</name> <arguments> </arguments> </buildCommand> </buildSpec>
package models case class Bar(id: Option[Int] = None, name: String) object Bars extends Table[Bar]("bar") { def id = column[Int]("id", O.PrimaryKey, O.AutoInc) def name = column[String]("name") def * = id.? ~ name <>(Bar, Bar.unapply _) }
object Bars extends Table[(Int, String)]("bar") { def id = column[Int]("id", O.PrimaryKey, O.AutoInc) def name = column[String]("name") def * = id ~ name }
implicit val session: Session = val result = Query(Bars).list
val q = for (b <- Bars if b.id === 42) yield (b.name ~ 1)
q.list.map { case (name, n) => } Queury(Bars).list.map { case (id, name) => }
(id ~ name) case class Bar(id: Int, name: String) (id ~ name <> (Bar, Bar.unapply _)) Query(Bars).list.map ( b.name )
val bar1 = Bar(1, "one") val Bar(id, name) = bar1 val bars: List[Bar] = val barNames = bars.map { case Bar(_, name) => name } val x = Bar.unapply(bar1)
object Bars extends Table[Bar]("bar") { def id = column[Int]("id", O.PrimaryKey, O.AutoInc) def name = column[String]("name") def * = id ~ name <>(Bar, Bar.unapply _) }
case class Baz(name: String, num: Int) val q1 = for (b <- Bars if b.id === 42) yield (b.name ~ 1 <> (Baz, Baz.unapply _))
case class Bar(id: Option[Int] = None, name: String) val q0 = for (b <- Bars if b.id === 42) yield (b.id.? ~ b.name <> (Bar, Bar.unapply _)) q0.list
val ns = 1 to 100 toList; val result = for { i <- ns if i*i % 2 == 0 } yield (i*i)
val result = for { i <- ns i2 <- Some(i*i) if i2 % 2 == 0 } yield i2 def evenSqr(n: Int) = { val sqr = n*n if (sqr % 2 == 0) Some (sqr) else None } result = for { i <- ns i2 <- evenSqr(i) } yield i2
val result = ns.flatMap(i => Some(i*i)).filter(i2 => i2 %2 ==0) result = ns.flatMap(i => evenSqr(i))
val q = Query(Bars).filter(b => b.id === 42).map(b => b.name ~ 1) val r: List[(String, Int)] = q.list
import scala.annotation.tailrec class Factorial2 { def factorial(n: Int): Int = { @tailrec def factorialAcc(acc: Int, n: Int): Int = { if (n <= 1) acc else factorialAcc(n * acc, n - 1) } factorialAcc(1, n) } }
C:\Prog\Scala\tests>scala Welcome to Scala version 2.8.0.RC5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.6.0_18). Type in expressions to have them evaluated. Type :help for more information. scala> import scala.annotation.tailrec import scala.annotation.tailrec scala> class Tails { | @tailrec def boom(x: Int): Int = { | if (x == 0) throw new Exception("boom!") | else boom(x-1)+ 1 | } | @tailrec def bang(x: Int): Int = { | if (x == 0) throw new Exception("bang!") | else bang(x-1) | } | } <console>:9: error: could not optimize @tailrec annotated method: it contains a recursive call not in tail position @tailrec def boom(x: Int): Int = { ^ <console>:13: error: could not optimize @tailrec annotated method: it is neither private nor final so can be overridden @tailrec def bang(x: Int): Int = { ^
scala> import annotation.tailrec import annotation.tailrec scala> @tailrec def length(as: List[_]): Int = as match { | case Nil => 0 | case head :: tail => 1 + length(tail) | } <console>:7: error: could not optimize @tailrec annotated method: it contains a recursive call not in tail position @tailrec def length(as: List[_]): Int = as match { ^
scala> def length(as: List[_]): Int = { | @tailrec def length0(as: List[_], tally: Int = 0): Int = as match { | case Nil => tally | case head :: tail => length0(tail, tally + 1) | } | length0(as) | } length: (as: List[_])Int
class Foo { } object Foo { def apply() = new Foo } val f = Foo() val f2 = new Foo
class Foo { } object Foo { def apply() = 7 } > println(new Foo) test@5c79cc94 > println(Foo()) 7
scala> object LonelyGuy { def mood = "sad" } defined module LonelyGuy scala> LonelyGuy res0: LonelyGuy.type = LonelyGuy$@3449a8 scala> LonelyGuy.mood res4: java.lang.String = sad
scala> case class Foo(bar: String) defined class Foo scala> Foo("baz") res2: Foo = Foo(baz)
scala> class Foo(val bar: String) defined class Foo scala> new Foo("baz") res0: Foo = Foo@2ad6a0 scala> Foo("baz") <console>:8: error: not found: value Foo Foo("baz")
scala> new { val bar = "baz" } res2: java.lang.Object{val bar: java.lang.String} = $anon$1@10ee5b8 scala> res2.bar res3: java.lang.String = baz
reset { shift { cf: (Int=>Int) => val eleven = cf(10) println(eleven) val oneHundredOne = cf(100) println(oneHundredOne) oneHundredOne } + 1 }
def f(k: Int => Int): Int = k(k(k(7))) reset( shift(f) + 1 ) * 2
def read(callback: Byte => Unit): Unit = myCallback = callback reset { val byte = "byte" val byte1 = shift(read) println(byte + "1 = " + byte1) val byte2 = shift(read) println(byte + "2 = " + byte2) }
val byte = "byte" read(callback) def callback(x: Byte): Unit { val byte1 = x println(byte + "1 = " + byte1) read(callback2) def callback2(x: Byte): Unit { val byte2 = x println(byte + "2 = " + byte1) } }
def aread(env: ENV): Tuple2[Byte,ENV] { def read(callback: Tuple2[Byte,ENV] => ENV): ENV = env.myCallback(callback) shift(read) } def pure(val env: ENV): ENV { reset { val (byte1, env) = aread(env) val env = env.println("byte1 = " + byte1) val (byte2, env) = aread(env) val env = env.println("byte2 = " + byte2) } }
def read(callback: Tuple2[Byte,ENV] => ENV, env: ENV): ENV = env.myCallback(callback) def pure(val env: ENV): ENV { read(callback,env) def callback(x: Tuple2[Byte,ENV]): ENV { val (byte1, env) = x val env = env.println("byte1 = " + byte1) read(callback2,env) def callback2(x: Tuple2[Byte,ENV]): ENV { val (byte2, env) = x val env = env.println("byte2 = " + byte2) } } }
reset { println("A") shift { k1: (Unit=>Unit) => println("B") k1() println("C") } println("D") shift { k2: (Unit=>Unit) => println("E") k2() println("F") } println("G") }
import org.apache.spark.sql.functions._ df.orderBy(asc("col1"))
import org.apache.spark.sql.functions._ df.sort(desc("col1"))
import sqlContext.implicits._ df.orderBy($"col1".desc)
import sqlContext.implicits._ df.sort($"col1".desc)
import org.apache.spark.sql.functions.desc df.orderBy(desc("columnname1"),desc("columnname2"),asc("columnname3"))
Dataset<Row> d1 = e_data.distinct().join(s_data.distinct(), "e_id").orderBy("salary");
SQLContext sqlCtx = spark.sqlContext(); sqlCtx.sql("select * from global_temp.salary order by salary desc").show();
def findAllQuestion():List[Question]={ questionDao.getAllQuestions() }
var list = new java.util.ArrayList[Int](1,2,3) list.foreach{println}
import scala.collection.JavaConverters._ def findAllQuestion():List[Question] = { questionDao.getAllQuestions().asScala }
def findAllStudentTest(): List[StudentTest] = { studentTestDao.getAllStudentTests().asScala.toList }
import scala.collection.JavaConverters._ def findAllQuestion():List[Question] = { questionDao.getAllQuestions().asScala.toList }
scala> dirty.distinct res0: List[java.lang.String] = List(a, b, c)
scala> List("a", "b", "a", "c").toSet.toList res1: List[java.lang.String] = List(a, b, c)
def dedupe(str: String): String = { val words = { str split " " }.toList val unique = words.foldLeft[List[String]] (Nil) { (l, s) => { val test = l find { _.toLowerCase == s.toLowerCase } if (test == None) s :: l else l } }.reverse unique mkString " " }
implicit def zeroNull[B >: Null] = new Zero[B] { def apply = null }
object Run extends App { def sayHello(): Unit = println("hello?") sayHello() }
trait Option[E] case class Some[E](value: E) extends Option[E] case object None extends Option[Nothing]
trait Datastore { def runQuery(query: String): List[String] } trait EmailServer { def sendEmail(to: String, content: String): Unit } class FindUsers(datastore: Datastore) { def inactive(): Unit = () } class UserReminder(findUser: FindUsers, emailServer: EmailServer) { def emailInactive(): Unit = () } class CustomerRelations(userReminder: UserReminder) { def retainUsers(): Unit = {} }
case class Reader[Conf, T](read: Conf => T) { self => def map[U](convert: T => U): Reader[Conf, U] = Reader(self.read andThen convert) def flatMap[V](toReader: T => Reader[Conf, V]): Reader[Conf, V] = Reader[Conf, V](conf => toReader(self.read(conf)).read(conf)) def local[BiggerConf](extractFrom: BiggerConf => Conf): Reader[BiggerConf, T] = Reader[BiggerConf, T](extractFrom andThen self.read) } object Reader { def pure[C, A](a: A): Reader[C, A] = Reader(_ => a) implicit def funToReader[Conf, A](read: Conf => A): Reader[Conf, A] = Reader(read) }
class Foo(dep: Dep) { def bar(arg: Arg): Res = ??? }
trait Datastore { def runQuery(query: String): List[String] } trait EmailServer { def sendEmail(to: String, content: String): Unit } object FindUsers { def inactive: Datastore => () => List[String] = dataStore => () => dataStore.runQuery("select inactive") } object UserReminder { def emailInactive(inactive: () => List[String]): EmailServer => () => Unit = emailServer => () => inactive().foreach(emailServer.sendEmail(_, "We miss you")) } object CustomerRelations { def retainUsers(emailInactive: () => Unit): () => Unit = () => { println("emailing inactive users") emailInactive() } }
object Main extends App { case class Config(dataStore: Datastore, emailServer: EmailServer) val config = Config( new Datastore { def runQuery(query: String) = List("john.doe@fizzbuzz.com") }, new EmailServer { def sendEmail(to: String, content: String) = println(s"sending [$content] to $to") } ) import Reader._ val reader = for { getAddresses <- FindUsers.inactive.local[Config](_.dataStore) emailInactive <- UserReminder.emailInactive(getAddresses).local[Config](_.emailServer) retainUsers <- pure(CustomerRelations.retainUsers(emailInactive)) } yield retainUsers reader.read(config)() }
getAddresses <- ((ds: Datastore) => new FindUsers(ds).inactive _).local[Config](_.dataStore)
$ sudo docker run -i -t -h sandbox sequenceiq/spark:1.1.0 /etc/bootstrap.sh -bash bash-4.1 bash-4.1 README.md bash-4.1 scala> val f = sc.textFile("README.md") 14/12/04 12:11:14 INFO storage.MemoryStore: ensureFreeSpace(164073) called with curMem=0, maxMem=278302556 14/12/04 12:11:14 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 160.2 KB, free 265.3 MB) f: org.apache.spark.rdd.RDD[String] = README.md MappedRDD[1] at textFile at <console>:12 scala> val wc = f.flatMap(l => l.split(" ")).map(word => (word, 1)).reduceByKey(_ + _) org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs: at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)
${HADOOP_COMMON_HOME}/bin/hadoop fs -put /path/to/README.md README.md
$ spark-shell --master=local scala> val df = spark.read.json("file: df: org.apache.spark.sql.DataFrame = [age: bigint, name: string] scala> df.show() +----+-------+ | age| name| +----+-------+ |null|Michael| | 30| Andy| | 19| Justin| +----+-------+
$ hdfs dfs -mkdir -p /hdfs/spark/examples $ hadoop fs -put /usr/lib/spark/examples/src/main/resources/people.json /hdfs/spark/examples $ hadoop fs -ls /hdfs/spark/examples Found 1 items -rw-r--r-- 1 hadoop hadoop 73 2017-05-01 00:49 /hdfs/spark/examples/people.json $ spark-shell scala> val df = spark.read.json("/hdfs/spark/examples/people.json") df: org.apache.spark.sql.DataFrame = [age: bigint, name: string] scala> df.show() +----+-------+ | age| name| +----+-------+ |null|Michael| | 30| Andy| | 19| Justin| +----+-------+
val conf = new SparkConf().setMaster("local[*]").setAppName("HDFSFileReader") conf.set("fs.defaultFS", "hdfs:
StructType schemata = DataTypes.createStructType( new StructField[]{ createStructField("COL1", StringType, false), createStructField("COL2", StringType, false), ... } ); String separator = ";"; String filePath = "C:\\work\\myProj\\myFile.csv"; SparkContext sparkContext = new SparkContext(new SparkConf().setAppName("MyApp").setMaster("local")); JavaSparkContext jsc = new JavaSparkContext (sparkContext ); SQLContext sqlContext = SQLContext.getOrCreate(sparkContext ); List<String[]> result = new ArrayList<>(); try (BufferedReader br = new BufferedReader(new FileReader(filePath))) { String line; while ((line = br.readLine()) != null) { String[] vals = line.split(separator); result.add(vals); } } catch (Exception ex) { System.out.println(ex.getMessage()); throw new RuntimeException(ex); } JavaRDD<String[]> jRdd = jsc.parallelize(result); JavaRDD<Row> jRowRdd = jRdd .map(RowFactory::create); Dataset<Row> data = sqlContext.createDataFrame(jRowRdd, schemata);
case class Row(var firstName: String, var lastName: String, var city: String) var rows = List(new Row("Oscar", "Wilde", "London"), new Row("Otto", "Swift", "Berlin"), new Row("Carl", "Swift", "Paris"), new Row("Hans", "Swift", "Dublin"), new Row("Hugo", "Swift", "Sligo")) rows.sortBy(_.lastName)
<console>:14: error: wrong number of parameters; expected = 1 rows.sortBy (_.lastName + _.firstName) ^
scala> var zz = List((1, 0.1), (2, 0.5), (3, 0.6), (4, 0.3), (5, 0.1)) zz: List[(Int, Double)] = List((1,0.1), (2,0.5), (3,0.6), (4,0.3), (5,0.1)) scala> zz.sortBy( x => (-x._2, x._1)) res54: List[(Int, Double)] = List((3,0.6), (2,0.5), (4,0.3), (1,0.1), (5,0.1))
abstract class Person { def name: String def age: Int } case class Employer(val name: String, val age: Int, val taxno: Int) extends Person case class Employee(val name: String, val age: Int, val salary: Int) extends Person
trait Identifiable { def name: String } trait Locatable { def address: String } case class Employer(val name: String, val address: String, val taxno: Int) extends Identifiable with Locatable case class Employee(val name: String, val address: String, val salary: Int) extends Identifiable with Locatable
sealed trait Person { def name: String } case class Employee( override val name: String, salary: Int ) extends Person case class Tourist( override val name: String, bored: Boolean ) extends Person
case class Employee( person: Person, salary: Int ) val employee = ... println(employee.person.name)
val x = Employee(name = "Jack", salary = 50000) x match { case Employee(name) => println(s"I }
warning: match is not exhaustive! missing combination Tourist
class ColoredPoint( x : Int, y : Int, c : Color) extends Point
sealed trait IVehicle case class Vehicle(color: String) extends IVehicle case class Car(vehicle: Vehicle, doors: Int) extends IVehicle val vehicle: IVehicle = ... vehicle match { case Car(Vehicle(color), doors) => println(s"$color car with $doors doors") case Vehicle(color) => println(s"$color vehicle") }
def add(a:Int)(b:Int) = {a + b} add(5)(6) val f = add(5) val f = add(5)_ f(10) def add2(a:Int) = { b:Int => a + b } add2(5)(6) val f = add2(5) f(10) val f = add2(5)_
def foldLeft[B](z: B)(op: (B, A) => B): B List("").foldLeft(0)(_ + _.length)
List("").foldLeft(0, (b: Int, a: String) => a + b.length) List("").foldLeft[Int](0, _ + _.length)
def loop[A](n: Int)(body: => A): Unit = (0 until n) foreach (n => body) loop(2) { println("hello!") }
val f = (a: Int) => (b: Int) => (c: Int) => a + b + c val g = f(1)(2)
def v(t: Double, k: Double): Double = { val ft = f(t) g(ft, k) } v(1, 1); v(1, 2);
def v(t: Double, ks: Seq[Double]: Seq[Double] = { val ft = f(t) ks map {k => g(ft, k)} }
val v = { (t: Double) => val ft = f(t) (k: Double) => g(ft, k) } val t = 1 val ks = Seq(1, 2) val vs = ks map (v(t))
def v(t:Double): Double => Double = { val ft = f(t) (k: Double) => g(ft, k) }
def v(t: Double)(k: Double): Double = { ^ `-- Can }
import scala.tools.nsc.Interpreter._ object TestDebugger { def main(args: Array[String]) { 0 to 10 foreach { i => breakIf(i == 5, DebugParam("i", i)) println(i) } } }
C:\Users\Daniel\Documents\Scala\Programas>scala TestDebugger 0 1 2 3 4 j: Int scala> j res0: Int = 5
import scala.tools.nsc.Interpreter._ object TestDebugger { def main(args: Array[String]) { 0 to 10 foreach { i => breakIf(i == 5, DebugParam("j", i)) println(i) if (i == 7) break(Nil) } } }
C:\Users\Daniel\Documents\Scala\Programas>scalac TestDebugger.scala C:\Users\Daniel\Documents\Scala\Programas>scala TestDebugger 0 1 2 3 4 j: Int scala> j res0: Int = 5 scala> :quit 5 6 7 scala> j <console>:5: error: not found: value j j ^ scala> :quit 8 9 10 C:\Users\Daniel\Documents\Scala\Programas>
import scala.tools.nsc.interpreter.ILoop import scala.tools.nsc.interpreter.SimpleReader import scala.tools.nsc.Settings val repl = new ILoop repl.settings = new Settings repl.settings.Yreplsync.value = true repl.in = SimpleReader() repl.createInterpreter() repl.intp.bind("row", "Int", row) repl.intp.bind("col", "Int", col) repl.loop() repl.closeInterpreter()
import java.util.Arrays val start = Array(1, 2, 3) Arrays.copyOfRange(start, 0, 2)
def main(args: List[String]) { val start = Array(1, 2, 3) arrayCopy(start, 0, 2) } def arrayCopy[A](arr: Array[A], start: Int, end: Int)(implicit manifest: Manifest[A]): Array[A] = { val ret = new Array(end - start) Array.copy(arr, start, ret, 0, end - start) ret }
scala> Array("foo", "hoo", "goo", "ioo", "joo").slice(1, 4) res6: Array[java.lang.String] = Array(hoo, goo, ioo)
def filter(xs: List[Int], p: Int => Boolean): List[Int] = if (xs.isEmpty) xs else if (p(xs.head)) xs.head :: filter(xs.tail, p) else filter(xs.tail, p) def modN(n: Int)(x: Int) = ((x % n) == 0)
val nums = List(1,2,3,4,5,6,7,8) println(filter(nums, modN(2))
def modN(n: Int, x: Int) = ((x % n) == 0) val p = modN(2, _: Int) println(filter(nums, p))
scala> def modN(n: Int, x: Int) = ((x % n) == 0) scala> modN(5, _ : Int) res0: Int => Boolean = <function1>
scala> def modNCurried(n: Int)(x: Int) = ((x % n) == 0)
scala> modNCurried(5) <console>:9: error: missing arguments for method modN; follow this method with `_ modNCurried(5)
scala> modNCurried(5) _ res24: Int => Boolean = <function1>
scala> modN _ res35: (Int, Int) => Boolean = <function2> scala> modNCurried _ res36: Int => (Int => Boolean) = <function1>
scala> def foo(a:Int, b:Int)(x:Int)(y:Int) = a * b + x - y scala> foo _ res42: (Int, Int) => Int => (Int => Int) = <function2> scala> res42(5) <console>:10: error: not enough arguments for method apply: (v1: Int, v2: Int)Int => (Int => Int) in trait Function2. Unspecified value parameter v2.
scala> (modN _).curried res45: Int => (Int => Boolean) = <function1 scala> modNCurried _ res46: Int => (Int => Boolean) = <function1>
scala> modN(5, _) <console>:9: error: missing parameter type for expanded function ((x$1) => modN(5, x$1))
scala> modNCurried(5) _ res3: Int => Boolean = <function1>
curry :: ((a, b) -> c) -> a -> b -> c -- curry converts a function that takes all args in a tuple -- into one that takes separate arguments uncurry :: (a -> b -> c) -> (a, b) -> c -- uncurry converts a function of separate args into a function on pairs.
scala> modN(_,_) res38: (Int, Int) => Boolean = <function2> scala> modN(1,_) <console>:13: error: missing parameter type for expanded function ((x$1) => modN(1, x$1)) modN(1,_) ^
scala> val s = "hello world" s: String = hello world scala> s.getClass res0: Class[_ <: String] = class java.lang.String
val l = List(List("a1", "b1", "c1"), List("a2", "b2", "c2"), List("a3", "b3", "c3"))
List(("a1", "a2", "a3"), ("b1", "b2", "b3"), ("c1", "c2", "c3"))
scala> l reduceLeft ((a, b) => a zip b) <console>:6: error: type mismatch; found : List[(String, String)] required: List[String] l reduceLeft ((a, b) => a zip b)
scala> (List(1,2,3),List(4,5,6),List(7,8,9)).zipped.toList res0: List[(Int, Int, Int)] = List((1,4,7), (2,5,8), (3,6,9))
as zip bs zip cs map { case ((a,b), c) => (a,b,c) }
def transpose[T](l: List[List[T]]): List[List[T]] = l match { case Nil => Nil case Nil :: _ => Nil case _ => (l map (_.head)) :: transpose(l map (_.tail)) }
def combineLists[A](ss:List[A]*) = { val sa = ss.reverse; (sa.head.map(List(_)) /: sa.tail)(_.zip(_).map(p=>p._2 :: p._1)) }
combineLists(List(1, 2, 3), List(10,20), List(100, 200, 300))
import scala.{Tuple2 => &} for (i1 & i2 & i3 & i4 <- list1 zip list2 zip list3 zip list4) yield (i1, i2, i3, i4)
scala> List(1,2,3) flatZip Seq("a","b","c") flatZip Vector(1.0,2.0,3.0) flatZip Seq(9,8,7) res1: com.github.marklister.collections.immutable.CollSeq4[Int,String,Double,Int] = CollSeq((1,a,1.0,9), (2,b,2.0,8), (3,c,3.0,7))
import scalaz.Zip import scalaz.std.list._ Zip[List].ap.tuple3(List("a1", "b1"), List("a2", "b2"), List("a3", "b3")) Zip[List].ap.tuple4(List("a1", "b1"), List("a2", "b2"), List("a3", "b3"), List("a4", "b4")) Zip[List].ap.tuple5(List("a1", "b1"), List("a2", "b2"), List("a3", "b3"), List("a4", "b4"), List("a5", "b5"))
Zip[List].ap.apply6(List("a1", "b1"), List("a2", "b2"), List("a3", "b3"), List("a4", "b4"), List("a5", "b5"), List("a6", "b6"))((_, _, _, _, _, _)) Zip[List].ap.apply7(List("a1", "b1"), List("a2", "b2"), List("a3", "b3"), List("a4", "b4"), List("a5", "b5"), List("a6", "b6"), List("a7", "b7"))((_, _, _, _, _, _, _)) ... Zip[List].ap.apply12(List("a1", "b1"), List("a2", "b2"), List("a3", "b3"), List("a4", "b4"), List("a5", "b5"), List("a6", "b6"), List("a7", "b7"), List("a8", "b8"), List("a9", "b9"), List("a10", "b10"), List("a11", "b11"), List("a12", "b12"))((_, _, _, _, _, _, _, _, _, _, _, _))
object HelloWorld { def main(args: Array[String]) = { println("Hello!") } }
object HelloWorld { def main(args: Array[String]) { println("Hello!") } }
object HelloWorld { def main(args: Array[String]): Unit = { println("Hello!") 123 } }
object HelloWorld { def main(args: Array[String]) = { println("Hello!") 123 } }
def printBar(bar: Baz) { println(bar) } def printBar(bar: Bar): Unit = { println(bar) }
val result = this.getClass.getSimpleName if (result.endsWith("$")) result.init else result
object TernaryOp { class Ternary[T](t: T) { def is[R](bte: BranchThenElse[T,R]) = if (bte.branch(t)) bte.then(t) else bte.elze(t) } class Branch[T](branch: T => Boolean) { def ?[R] (then: T => R) = new BranchThen(branch,then) } class BranchThen[T,R](val branch: T => Boolean, val then: T => R) class Elze[T,R](elze: T => R) { def :: (bt: BranchThen[T,R]) = new BranchThenElse(bt.branch,bt.then,elze) } class BranchThenElse[T,R](val branch: T => Boolean, val then: T => R, val elze: T => R) implicit def any2Ternary[T](t: T) = new Ternary(t) implicit def fct2Branch[T](branch: T => Boolean) = new Branch(branch) implicit def fct2Elze[T,R](elze: T => R) = new Elze(elze) }
this.getClass.getSimpleName is {s: String => s.endsWith("$")} ? {s: String => s.init} :: {s: String => s}
this.getClass.getSimpleName is {_.endsWith("$")} ? {_.init} :: {identity}
scala> "Hi".getClass.getSimpleName |> {x => x.endsWith("$") ? x.init | x} res0: String = String scala> List.getClass.getSimpleName |> {x => x.endsWith("$") ? x.init | x} res1: String = List
case class Bool(b: Boolean) { def ?[X](t: => X) = new { def |(f: => X) = if(b) t else f } } object Bool { implicit def BooleanBool(b: Boolean) = Bool(b) }
object T { val condition = true import Bool._ val x = condition ? "yes" | "no" }
"Hi".getClass.getSimpleName match { case x if x.endsWith("$") => x.init case x => x }
implicit class Question[T](predicate: => Boolean) { def ?(left: => T) = predicate -> left } implicit class Colon[R](right: => R) { def ::[L <% R](pair: (Boolean, L)): R = if (q._1) q._2 else right } val x = (5 % 2 == 0) ? 5 :: 4.5
class Ball { def properties(): List[String] = List() override def toString() = "It properties.mkString(" ", ", ", " ") + "ball" } trait Red extends Ball { override def properties() = super.properties ::: List("red") } trait Shiny extends Ball { override def properties() = super.properties ::: List("shiny") } object Balls { def main(args: Array[String]) { val myBall = new Ball with Shiny with Red println(myBall) } }
package ground.learning.scala.traits /** * Created by Mohan on 31/08/2014. * * Stacks are layered one top of another, when moving from Left -> Right, * Right most will be at the top layer, and receives method call. */ object TraitMain { def main(args: Array[String]) { val strangers: List[NoEmotion] = List( new Stranger("Ray") with NoEmotion, new Stranger("Ray") with Bad, new Stranger("Ray") with Good, new Stranger("Ray") with Good with Bad, new Stranger("Ray") with Bad with Good) println(strangers.map(_.hi + "\n")) } } trait NoEmotion { def value: String def hi = "I am " + value } trait Good extends NoEmotion { override def hi = "I am " + value + ", It is a beautiful day!" } trait Bad extends NoEmotion { override def hi = "I am " + value + ", It is a bad day!" } case class Stranger(value: String) { }
class Shuttle extends Spacecraft with ControlCabin with PulseEngine{ val maxPulse = 10 def increaseSpeed = speedUp }
lazy val foo = Project(id = "foo", base = file("foo")) lazy val bar = Project(id = "bar", base = file("bar")) dependsOn(foo)
object ProjectDependencies { val commons = RootProject(file("../commons")) } object ProjectBuild extends Build { import ProjectDependencies._ lazy val root = Project(id = "foo", base = file(".")).dependsOn(commons) }
val s = Seq("apple", "oranges", "apple", "banana", "apple", "oranges", "oranges") s.groupBy(identity).mapValues(_.size)
val s = Seq("apple", "oranges", "apple", "banana", "apple", "oranges", "oranges") s.groupBy(l => l).map(t => (t._1, t._2.length))
val list = List(1, 2, 4, 2, 4, 7, 3, 2, 4) l map(x => l.count(_ == x)) List[Int] = List(1, 3, 3, 3, 3, 1, 1, 3, 3) l map(x => (x, l.count(_ == x)))
Map[Int, Int] = Map(1 -> 1, 2 -> 3, 7 -> 1, 3 -> 1, 4 -> 3)
val s = Seq("apple", "oranges", "apple", "banana", "apple", "oranges", "oranges") s.foldLeft(Map.empty[String, Int]) { (m, x) => m + ((x, m.getOrElse(x, 0) + 1)) } res1: scala.collection.immutable.Map[String,Int] = Map(apple -> 3, oranges -> 3, banana -> 1)
implicit class Count[T](list: List[T]) { def count(n: T): Int = list.count(_ == n) } List(1,2,4,2,4,7,3,2,4).count(2) List(1,2,4,2,4,7,3,2,4).count(5)
import scalaz._, Scalaz._ xs.foldMap(x => Map(x -> 1))
xs.map(x => Map(x -> 1)).foldMap(identity) xs.map(x => Map(x -> 1)).foldMap() xs.map(x => Map(x -> 1)).suml xs.map(_ -> 1).foldMap(Map(_)) xs.foldMap(x => Map(x -> 1))
type Word = String type Sentence = Seq[Word] type Occurrences = scala.collection.Map[Char, Int] def woGrouped(w: Word): Occurrences = { w.groupBy(c => c).map({case (c, list) => (c -> list.length)}) } def woGetElse0Map(w: Word): Occurrences = { val map = Map[Char, Int]() w.foldLeft(map)((m, c) => m + (c -> (m.getOrElse(c, 0) + 1)) ) } def woDeflt0Map(w: Word): Occurrences = { val map = Map[Char, Int]().withDefaultValue(0) w.foldLeft(map)((m, c) => m + (c -> (m(c) + 1)) ) } def dfltHashMap(w: Word): Occurrences = { val map = scala.collection.immutable.HashMap[Char, Int]().withDefaultValue(0) w.foldLeft(map)((m, c) => m + (c -> (m(c) + 1)) ) } def mmDef(w: Word): Occurrences = { val map = scala.collection.mutable.Map[Char, Int]().withDefaultValue(0) w.foldLeft(map)((m, c) => m += (c -> (m(c) + 1)) ) } val functions = List("grp" -> woGrouped _, "mtbl" -> mmDef _, "else" -> woGetElse0Map _ , "dfl0" -> woDeflt0Map _, "hash" -> dfltHashMap _ ) val len = 100 * 1000 def test(len: Int) { val data: String = scala.util.Random.alphanumeric.take(len).toList.mkString val firstResult = functions.head._2(data) def run(f: Word => Occurrences): Int = { val time1 = System.currentTimeMillis() val result= f(data) val time2 = (System.currentTimeMillis() - time1) assert(result.toSet == firstResult.toSet) time2.toInt } def log(results: Seq[Int]) = { ((functions zip results) map {case ((title, _), r) => title + " " + r} mkString " , ") } var groupResults = List.fill(functions.length)(1) val integrals = for (i <- (1 to 10)) yield { val results = functions map (f => (1 to 33).foldLeft(0) ((acc,_) => run(f._2))) println (log (results)) groupResults = (results zip groupResults) map {case (r, gr) => r + gr} log(groupResults).toUpperCase } integrals foreach println } test(len) test(len * 2) println("Done") def main(args: Array[String]) { }
grp 5 , mtbl 5 , else 13 , dfl0 17 , hash 17 grp 3 , mtbl 6 , else 14 , dfl0 16 , hash 16 grp 3 , mtbl 6 , else 13 , dfl0 17 , hash 15 grp 4 , mtbl 5 , else 13 , dfl0 15 , hash 16 grp 23 , mtbl 6 , else 14 , dfl0 15 , hash 16 grp 5 , mtbl 5 , else 13 , dfl0 16 , hash 17 grp 4 , mtbl 6 , else 13 , dfl0 16 , hash 16 grp 4 , mtbl 6 , else 13 , dfl0 17 , hash 15 grp 3 , mtbl 5 , else 14 , dfl0 16 , hash 16 grp 3 , mtbl 6 , else 14 , dfl0 16 , hash 16 GRP 5 , MTBL 5 , ELSE 13 , DFL0 17 , HASH 17 GRP 8 , MTBL 11 , ELSE 27 , DFL0 33 , HASH 33 GRP 11 , MTBL 17 , ELSE 40 , DFL0 50 , HASH 48 GRP 15 , MTBL 22 , ELSE 53 , DFL0 65 , HASH 64 GRP 38 , MTBL 28 , ELSE 67 , DFL0 80 , HASH 80 GRP 43 , MTBL 33 , ELSE 80 , DFL0 96 , HASH 97 GRP 47 , MTBL 39 , ELSE 93 , DFL0 112 , HASH 113 GRP 51 , MTBL 45 , ELSE 106 , DFL0 129 , HASH 128 GRP 54 , MTBL 50 , ELSE 120 , DFL0 145 , HASH 144 GRP 57 , MTBL 56 , ELSE 134 , DFL0 161 , HASH 160 grp 7 , mtbl 11 , else 28 , dfl0 31 , hash 31 grp 7 , mtbl 10 , else 28 , dfl0 32 , hash 31 grp 7 , mtbl 11 , else 28 , dfl0 31 , hash 32 grp 7 , mtbl 11 , else 28 , dfl0 31 , hash 33 grp 7 , mtbl 11 , else 28 , dfl0 32 , hash 31 grp 8 , mtbl 11 , else 28 , dfl0 31 , hash 33 grp 8 , mtbl 11 , else 29 , dfl0 38 , hash 35 grp 7 , mtbl 11 , else 28 , dfl0 32 , hash 33 grp 8 , mtbl 11 , else 32 , dfl0 35 , hash 41 grp 7 , mtbl 13 , else 28 , dfl0 33 , hash 35 GRP 7 , MTBL 11 , ELSE 28 , DFL0 31 , HASH 31 GRP 14 , MTBL 21 , ELSE 56 , DFL0 63 , HASH 62 GRP 21 , MTBL 32 , ELSE 84 , DFL0 94 , HASH 94 GRP 28 , MTBL 43 , ELSE 112 , DFL0 125 , HASH 127 GRP 35 , MTBL 54 , ELSE 140 , DFL0 157 , HASH 158 GRP 43 , MTBL 65 , ELSE 168 , DFL0 188 , HASH 191 GRP 51 , MTBL 76 , ELSE 197 , DFL0 226 , HASH 226 GRP 58 , MTBL 87 , ELSE 225 , DFL0 258 , HASH 259 GRP 66 , MTBL 98 , ELSE 257 , DFL0 293 , HASH 300 GRP 73 , MTBL 111 , ELSE 285 , DFL0 326 , HASH 335 Done
seq.groupMapReduce(identity)(_ => 1)(_ + _) seq.groupMapReduce(identity)(_ => 1)(_ + _)("apple")
seq.groupBy(identity).mapValues(_.map(_ => 1).reduce(_ + _))
scala> val list = List(1,2,4,2,4,7,3,2,4) list: List[Int] = List(1, 2, 4, 2, 4, 7, 3, 2, 4) scala> list.groupBy(x => x) map { case (k,v) => k-> v.length } res74: scala.collection.immutable.Map[Int,Int] = Map(1 -> 1, 2 -> 3, 7 -> 1, 3 -> 1, 4 -> 3)
scala> val list = List(1,2,4,2,4,7,3,2,4) list: List[Int] = List(1, 2, 4, 2, 4, 7, 3, 2, 4) scala> println(list.filter(_ == 2).size) 3
val list = List("apple", "oranges", "apple", "banana", "apple", "oranges", "oranges") list.groupBy(x=>x).map(t => (t._1, t._2.size))
import cats.implicits._ "Alphabet".toLowerCase().map(c => Map(c -> 1)).toList.combineAll "Alphabet".toLowerCase().map(c => Map(c -> 1)).toList.foldMap(identity)
[info] Compiling 1 Scala source to /Users/gruetter/Workspaces/scala/helloscala/target/scala-2.9.0/test-classes... java.lang.OutOfMemoryError: PermGen space Error during sbt execution: java.lang.OutOfMemoryError: PermGen space
-J-Xmx4G -J-XX:MaxMetaspaceSize=1G -J-XX:MaxPermSize=1G -J-XX:+CMSClassUnloadingEnabled
java -XX:MaxPermSize=256M -Xmx2048M -jar /path/to/sbt-launch.jar test
get_mem_opts () { local mem=${1:-1536} local perm=$(( $mem / 4 )) (( $perm > 256 )) || perm=1024 (( $perm < 1024 )) || perm=2048 local codecache=$(( $perm / 2 )) echo "-Xms${mem}m -Xmx${mem}m -XX:MaxPermSize=${perm}m -XX:ReservedCodeCacheSize=${codecache}m" }
export SBT_OPTS="-XX:+CMSClassUnloadingEnabled -XX:PermSize=1024M -XX:MaxPermSize=2048M"
class Foo(x: Int) { def apply(y: Int) = { x*x + y*y } } val f = new Foo(3) f(4)
quickSort [K](a : Array[K])(implicit view$1 : (K) => Ordered[K]) : Unit
class MyClass(n: Int) extends Ordered[MyClass] { ... def compare(that: MyClass) = this.n - that.n }
List("Steve", "Tom", "John", "Bob").sort((e1, e2) => (e1 compareTo e2) < 0) List(1, 4, 3, 2).sort((e1, e2) => (e1 < e2))
Sort the list according to the comparison function <(e1: a, e2: a) =>
val array = Array((for(i <- 0 to 10) yield scala.util.Random.nextInt): _*) scala.util.Sorting.quickSort(array)
scala> case class Person(name: String) defined class Person scala> val array = Array(Person("John"), Person("Mike"), Person("Abe")) array: Array[Person] = Array(Person(John), Person(Mike), Person(Abe)) scala> scala.util.Sorting.quickSort(array) <console>:11: error: no implicit argument matching parameter type (Person) => Ordered[Person] was found. scala.util.Sorting.quickSort(array) ^ scala> class OrderedPerson(val person: Person) extends Ordered[Person] { | def compare(that: Person) = person.name.compare(that.name) | } defined class OrderedPerson scala> implicit def personToOrdered(p: Person) = new OrderedPerson(p) personToOrdered: (p: Person)OrderedPerson scala> scala.util.Sorting.quickSort(array) scala> array res8: Array[Person] = Array(Person(Abe), Person(John), Person(Mike))
scala> case class Person(name: String) extends Ordered[Person] { | def compare(that: Person) = name.compare(that.name) | } defined class Person scala> val array = Array(Person("John"), Person("Mike"), Person("Abe")) array: Array[Person] = Array(Person(John), Person(Mike), Person(Abe)) scala> scala.util.Sorting.quickSort(array) scala> array res10: Array[Person] = Array(Person(Abe), Person(John), Person(Mike))
import System.out.println import scala.util.Sorting.quickSort class Foo(x:Int) { def get = x } class OrdFoo(x:Foo) extends Ordered[Foo] { def compare(that:Foo) = x.get-that.get } class OrdFoo2(x:Foo) extends Ordered[Foo] { def compare(that:Foo) = that.get-x.get } implicit def convert(a:Foo) = new OrdFoo(a) val arr = Array(new Foo(2),new Foo(3),new Foo(1)) scala.util.Sorting.quickSort(arr) arr foreach (a=>println(a.get)) scala.util.Sorting.quickSort(arr)(new OrdFoo2(_)) arr foreach (a=>println(a.get))
val arr = Array(7,5,1, 9,2) scala.util.Sorting.quickSort(arr)
val fut1 = Future{...} val fut2 = Future{...} val fut3 = Future{...} val aggFut = for{ f1Result <- fut1 f2Result <- fut2 f3Result <- fut3 } yield (f1Result, f2Result, f3Result)
val fut1 = Future{Thread.sleep(3000);1} val fut2 = Promise.failed(new RuntimeException("boo")).future val fut3 = Future{Thread.sleep(1000);3} def processFutures(futures:Map[Int,Future[Int]], values:List[Any], prom:Promise[List[Any]]):Future[List[Any]] = { val fut = if (futures.size == 1) futures.head._2 else Future.firstCompletedOf(futures.values) fut onComplete{ case Success(value) if (futures.size == 1)=> prom.success(value :: values) case Success(value) => processFutures(futures - value, value :: values, prom) case Failure(ex) => prom.failure(ex) } prom.future } val aggFut = processFutures(Map(1 -> fut1, 2 -> fut2, 3 -> fut3), List(), Promise[List[Any]]()) aggFut onComplete{ case value => println(value) }
def sequenceOrBailOut[A, M[_] <: TraversableOnce[_]](in: M[Future[A]] with TraversableOnce[Future[A]])(implicit cbf: CanBuildFrom[M[Future[A]], A, M[A]], executor: ExecutionContext): Future[M[A]] = { val p = Promise[M[A]]() in.foreach(_.onFailure{case i => p.tryFailure(i)}) Future.sequence(in).foreach(p trySuccess _) p.future }
val f1 = Future { Thread.sleep(1000) ; 5 / 0 } val f2 = Future { 5 } val f3 = Future { None.get } Future.sequence(List(f1,f2,f3)).onFailure{case i => println(i)}
val f1 = Future { Thread.sleep(1000) ; 5 / 0 } val f2 = Future { 5 } val f3 = Future { None.get } sequenceOrBailOut(List(f1,f2,f3)).onFailure{case i => println(i)}
import scala.util._ import scala.concurrent._ import java.util.concurrent.atomic.AtomicInteger def allSucceed[T](fs: Future[T]*): Future[T] = { val remaining = new AtomicInteger(fs.length) val p = promise[T] fs foreach { _ onComplete { case s @ Success(_) => { if (remaining.decrementAndGet() == 0) { p tryComplete s } } case f @ Failure(_) => { p tryComplete f } } } p.future }
import scala.annotation.tailrec import scala.util.{Try, Success, Failure} import scala.concurrent._ import scala.concurrent.duration.Duration import ExecutionContext.Implicits.global @tailrec def awaitSuccess[A](fs: Seq[Future[A]], done: Seq[A] = Seq()): Either[Throwable, Seq[A]] = { val first = Future.firstCompletedOf(fs) Await.ready(first, Duration.Inf).value match { case None => awaitSuccess(fs, done) case Some(Failure(e)) => Left(e) case Some(Success(_)) => val (complete, running) = fs.partition(_.isCompleted) val answers = complete.flatMap(_.value) answers.find(_.isFailure) match { case Some(Failure(e)) => Left(e) case _ => if (running.length > 0) awaitSuccess(running, answers.map(_.get) ++: done) else Right( answers.map(_.get) ++: done ) } } }
scala> awaitSuccess(Seq(Future{ println("Hi!") }, Future{ Thread.sleep(1000); println("Fancy meeting you here!") }, Future{ Thread.sleep(2000); println("Bye!") } )) Hi! Fancy meeting you here! Bye! res1: Either[Throwable,Seq[Unit]] = Right(List((), (), ()))
scala> awaitSuccess(Seq(Future{ println("Hi!") }, Future{ Thread.sleep(1000); throw new Exception("boo"); () }, Future{ Thread.sleep(2000); println("Bye!") } )) Hi! res2: Either[Throwable,Seq[Unit]] = Left(java.lang.Exception: boo) scala> Bye!
class ResultCombiner(futs: Future[_]*) extends Actor { var origSender: ActorRef = null var futsRemaining: Set[Future[_]] = futs.toSet override def receive = { case () => origSender = sender for(f <- futs) f.onComplete(result => self ! if(result.isSuccess) f else false) case false => origSender ! SomethingFailed case f: Future[_] => futsRemaining -= f if(futsRemaining.isEmpty) origSender ! EverythingSucceeded } } sealed trait Result case object SomethingFailed extends Result case object EverythingSucceeded extends Result
val actor = actorSystem.actorOf(Props(new ResultCombiner(f1, f2, f3))) try { val f4: Future[Result] = actor ? () implicit val timeout = new Timeout(30 seconds) Await.result(f4, timeout.duration).asInstanceOf[Result] match { case SomethingFailed => println("Oh noes!") case EverythingSucceeded => println("It all worked!") } } finally { actor ! PoisonPill }
implicit class Sugar_PimpMyFuture[T](val self: Future[T]) extends AnyVal { def concurrently = ConcurrentFuture(self) } case class ConcurrentFuture[A](future: Future[A]) extends AnyVal { def map[B](f: Future[A] => Future[B]) : ConcurrentFuture[B] = ConcurrentFuture(f(future)) def flatMap[B](f: Future[A] => ConcurrentFuture[B]) : ConcurrentFuture[B] = concurrentFutureFlatMap(this, f) } def concurrentFutureFlatMap[A,B](outer: ConcurrentFuture[A], f: Future[A] => ConcurrentFuture[B]) : ConcurrentFuture[B] = { val p = Promise[B]() val inner = f(outer.future) inner.future onFailure { case t => p.tryFailure(t) } outer.future onFailure { case t => p.tryFailure(t) } inner.future onSuccess { case b => p.trySuccess(b) } ConcurrentFuture(p.future) }
def func1 : Future[Int] = Future { println("f1!");throw new RuntimeException; 1 } def func2 : Future[String] = Future { Thread.sleep(2000);println("f2!");"f2" } def func3 : Future[Double] = Future { Thread.sleep(2000);println("f3!");42.0 } val f : Future[(Int,String,Double)] = { for { f1 <- func1.concurrently f2 <- func2.concurrently f3 <- func3.concurrently } yield for { v1 <- f1 v2 <- f2 v3 <- f3 } yield (v1,v2,v3) }.future f.onFailure { case t => println("future failed $t") }
val l = List(1, 6, 8) val f = l.map{ i => future { println("future " +i) Thread.sleep(i* 1000) if (i == 12) throw new Exception("6 is not legal.") i } } val f1 = Future.sequence(f) f1 onSuccess{ case l => { logInfo("onSuccess") l.foreach(i => { logInfo("h : " + i) }) } } f1 onFailure{ case l => { logInfo("onFailure") }
while ({bytesRead = in.read(buffer); bytesRead != -1}) { ...
class MyBean { private var internalState: String = _ def state = internalState def state_=(state: String) = internalState = state }
func foo(x): var list = new List(4, -2, 3, 1) list.Append(x) list.Sort() var smallest = list.First() return smallest + list.Length()
func bar(x): var list = new List(4, -2, 3, 1) var smallest = list.Append(x).Sort().First() return smallest + list.Length()
for(int bytesRead = in.read(buffer); bytesRead != -1; bytesRead = in.read(buffer)) { }
case class Ref[T](var value: T) { def := (newval: => T)(pred: T => Boolean): Boolean = { this.value = newval pred(this.value) } }
val bytesRead = Ref(0) while ((bytesRead := in.read(buffer)) (_ != -1)) { println(bytesRead.value) }
scala> "%07d".format(123) res5: String = 0000123 scala> "%07d".formatLocal(java.util.Locale.US, 123) res6: String = 0000123
scala> val i = 9 i: Int = 9 scala> val paddedVal = f"${num}%02d" paddedVal: String = 09 scala> println(paddedVal) 09
def leftPad(s: String, len: Int, elem: Char): String = { elem.toString * (len - s.length()) + s }
scala> import java.text._ import java.text._ scala> NumberFormat.getIntegerInstance.asInstanceOf[DecimalFormat] res0: java.text.DecimalFormat = java.text.DecimalFormat@674dc scala> .applyPattern("0000000") scala> res0.format(123) res2: String = 0000123
def str(i: Int) = (i % 10000000 + 10000000).toString.substring(1)
def str(i: Int) = { val f = "000000" + i; f.substring(f.length() - 7) }
val nf = java.text.NumberFormat.getIntegerInstance(java.util.Locale.US) nf.setMinimumIntegerDigits(7) nf.setGroupingUsed(false) nf.format(-123)
attrs.foreach {keyVal => println(keyVal._1 + "=" + keyVal._2)}
attrs.foreach( kv => ... ) attrs.foreach{ case (k,v) => ... } for ((k,v) <- attrs) { ... }
def withBufferedWriter(file: File)(block: BufferedWriter => Unit)
withBufferedWriter(new File("myfile.txt")) { out => out write "whatever" ... }
scala> def foo(as: Int*)(bs: Int*)(cs: Int*) = as.sum * bs.sum * cs.sum foo: (as: Int*)(bs: Int*)(cs: Int*)Int scala> foo(1, 2, 3)(4, 5, 6, 7, 9)(10, 11) res7: Int = 3906
def foo[T](a: T, b: T)(op: (T,T)=>T) = op(a,b) foo(1,2){_+_}
(A, B, C, D, E) => F ((A, B), (C, D, E)) => F (A, B) => (C, D, E) => F
scala> def foo(a:Int, b:Int)(c:Int, d:Int, e:Int):Int = 9 foo: (a: Int,b: Int)(c: Int,d: Int,e: Int)Int scala> foo _ res4: (Int, Int) => (Int, Int, Int) => Int = <function2>
case class Foo(bar: Int) def test(f: Foo)(i: Int = f.bar) = i*i test(Foo(3))()
df .repartition(1) .write.format("com.databricks.spark.csv") .option("header", "true") .save("mydata.csv")
df .coalesce(1) .write.format("com.databricks.spark.csv") .option("header", "true") .save("mydata.csv")
import org.apache.hadoop.conf.Configuration import org.apache.hadoop.fs._ def merge(srcPath: String, dstPath: String): Unit = { val hadoopConfig = new Configuration() val hdfs = FileSystem.get(hadoopConfig) FileUtil.copyMerge(hdfs, new Path(srcPath), hdfs, new Path(dstPath), true, hadoopConfig, null) } val newData = << create your dataframe >> val outputfile = "/user/feeds/project/outputs/subject" var filename = "myinsights" var outputFileName = outputfile + "/temp_" + filename var mergedFileName = outputfile + "/merged_" + filename var mergeFindGlob = outputFileName newData.write .format("com.databricks.spark.csv") .option("header", "false") .mode("overwrite") .save(outputFileName) merge(mergeFindGlob, mergedFileName ) newData.unpersist()
val fileprefix= "/mnt/aws/path/file-prefix" dataset .coalesce(1) .write .option("header", "true") .option("delimiter","\t") .csv(fileprefix+".tmp") val partition_path = dbutils.fs.ls(fileprefix+".tmp/") .filter(file=>file.name.endsWith(".csv"))(0).path dbutils.fs.cp(partition_path,fileprefix+".tab") dbutils.fs.rm(fileprefix+".tmp",recurse=true)
/** * Merges multiple partitions of spark text file output into single file. * @param srcPath source directory of partitioned files * @param dstPath output path of individual path * @param deleteSource whether or not to delete source directory after merging * @param spark sparkSession */ def mergeTextFiles(srcPath: String, dstPath: String, deleteSource: Boolean): Unit = { import org.apache.hadoop.fs.FileUtil import java.net.URI val config = spark.sparkContext.hadoopConfiguration val fs: FileSystem = FileSystem.get(new URI(srcPath), config) FileUtil.copyMerge( fs, new Path(srcPath), fs, new Path(dstPath), deleteSource, config, null ) }
import java.io._ def printToFile(f: java.io.File)(op: java.io.PrintWriter => Unit) { val p = new java.io.PrintWriter(f); try { op(p) } finally { p.close() } } printToFile(new File("C:/TEMP/df.csv")) { p => df.collect().foreach(p.println)}
val x: Any = 5 def f[T](v: T) = v match { case _: Int => "Int" case _: String => "String" case _ => "Unknown" } f(x)
val x: Any = 5 import scala.reflect.ClassTag def f[T](v: T)(implicit ev: ClassTag[T]) = ev.toString f(x)
def f[A, B](a: A, b: B) = a match { case _: B => "A is a B" case _ => "A is not a B" }
val x = val y = 5 val z: Any = 5 import scala.reflect.ClassTag def f[A, B: ClassTag](a: A, b: B) = a match { case _: B => "A is a B" case _ => "A is not a B" } f(x, y) f(x, z)
val x: Any = 5 val y = 5 import scala.reflect.ClassTag def f(a: Any, b: Any) = { val B = ClassTag(b.getClass) ClassTag(a.getClass) match { case B => "a is the same class as b" case _ => "a is not the same class as b" } } f(x, y) == f(y, x)
import scala.reflect.runtime.universe.TypeTag def f[A, B](a: A, b: B)(implicit evA: TypeTag[A], evB: TypeTag[B]) = evA == evB type X = Int val x: X = 5 val y = 5 f(x, y)
scala> def manOf[T: Manifest](t: T): Manifest[T] = manifest[T] manOf: [T](t: T)(implicit evidence$1: Manifest[T])Manifest[T] scala> val x = List(1,2,3) x: List[Int] = List(1, 2, 3) scala> println(manOf(x)) scala.collection.immutable.List[Int]
val name = "sam"; name: java.lang.String = sam name.getClass res0: java.lang.Class[_] = class java.lang.String
val x = 9 def printType[T](x:T) :Unit = {println(x.getClass.toString())}
val m = collection.immutable.Map(1->"one",2->"Two") val n = collection.mutable.Map(m.toSeq: _*)
val myImmutableMap = collection.immutable.Map(1->"one",2->"two") val myMutableMap = collection.mutable.Map() ++ myImmutableMap
import collection.{mutable, immutable, breakOut} val myImmutableMap = immutable.Map(1->"one",2->"two") val myMutableMap: mutable.Map[Int, String] = myImmutableMap.map(identity)(breakOut)
scala> import collection.immutable.{Map => IMap} scala> import collection.mutable.HashMap scala> val iMap = IMap(1 -> "one", 2 -> "two") scala> val mMap = new HashMap[Int,String] { | override def default(key: Int): String = iMap(key) | } scala> mMap(1) scala> mMap(2) scala> mMap(3) scala> mMap(2) = "three" scala> mMap(2)
def curriedFunc(arg1: Int) (arg2: String) = { ... }
object NonCurr { def tabulate[A](n: Int, fun: Int => A) = IndexedSeq.tabulate(n)(fun) } NonCurr.tabulate[Double](10, _) val x = IndexedSeq.tabulate[Double](10) _ x(math.exp(_))
NonCurr.tabulate(10, { i => val j = util.Random.nextInt(i + 1); i - i % 2 })
IndexedSeq.tabulate(10) { i => val j = util.Random.nextInt(i + 1) i - i % 2 }
IndexedSeq.fill(10) { println("debug: operating the random number generator") util.Random.nextInt(99) }
def doSomething(f: java.io.File)(modDate: Long = f.lastModified) = ???
def foo(as: Int*)(bs: Int*)(cs: Int*) = as.sum * bs.sum * cs.sum
def foo[T](a: T, b: T)(op: (T,T) => T) = op(a, b) foo(1, 2){_ + _} def foo2[T](a: T, b: T, op: (T,T) => T) = op(a, b) foo2(1, 2, _ + _)
def gaga [A](x: A)(implicit mf: Manifest[A]) = ??? def gaga2[A](x: A, implicit mf: Manifest[A]) = ???
def f(x: Int, y: Int = x * 2) = x + y def g(x: Int)(y: Int = x * 2) = x + y
code match { case Left(x) | Right(x) => case null => }
val a: Msg => Promise[Rep] = f.promise val reply: Rep = a(msg).get
scala> val x = List("a" -> "b", "c" -> "d", "a" -> "f") scala> x.groupBy(_._1).map { case (k,v) => (k,v.map(_._2))}
implicit class Pairs[A, B](p: List[(A, B)]) { def toMultiMap: Map[A, List[B]] = p.groupBy(_._1).mapValues(_.map(_._2)) } > List("a" -> "b", "a" -> "c", "d" -> "e").toMultiMap > Map("a" -> List("b", "c"), "d" -> List("e"))
val x = List("a" -> "b", "c" -> "d", "a" -> "f") x.foldLeft(Map.empty[String, Seq[String]]) { case (acc, (k, v)) => acc.updated(k, acc.getOrElse(k, Seq.empty[String]) ++ Seq(v)) } res0: scala.collection.immutable.Map[String,Seq[String]] = Map(a -> List(b, f), c -> List(d))
val list: List[(String, String)] = List(("a","b"),("c","d"),("a","f"))
list.groupBy(_._1).map(v => (v._1, v._2.map(_._2)))
list.foldLeft[Map[String, List[String]]](Map())((acc, value) => { acc.get(value._1).fold(acc ++ Map(value._1 -> List(value._2))){ v => acc ++ Map(value._1 -> (value._2 :: v)) } })
list.aggregate[Map[String, List[String]]](Map())( (acc, value) => acc.get(value._1).fold(acc ++ Map(value._1 -> List(value._2))){ v => acc ++ Map(value._1 -> (value._2 :: v)) }, (l, r) => l ++ r )
import org.apache.spark.rdd._ import org.apache.spark.{SparkContext, SparkConf} val conf: SparkConf = new SparkConf().setAppName("Spark").setMaster("local") val sc: SparkContext = new SparkContext (conf) val rdd: RDD[(String, List[String])] = sc.parallelize(list).combineByKey( (value: String) => List(value), (acc: List[String], value) => value :: acc, (accLeft: List[String], accRight: List[String]) => accLeft ::: accRight ) rdd.collect().toMap
scala> val b = new Array[Int](3) scala> val c = b.map(x => (x -> x * 2)) scala> val d = Map(c : _*)
List("a" -> "b", "c" -> "d", "a" -> "f").groupMap(_._1)(_._2)
scala> def times(n: Int, s: String) = | (for(i <- 1 to n) yield s).toList times: (n: Int, s: String)List[String] scala> times(3, "foo") res4: List[String] = List(foo, foo, foo)
scala> List.fill(3)("foo") res1: List[String] = List(foo, foo, foo)
implicit class ListGeneric[A](l: List[A]) { def nDuplicate(x: Int): List[A] = { def duplicateN(x: Int, tail: List[A]): List[A] = { l match { case Nil => Nil case n :: xs => concatN(x, n) ::: duplicateN(x, xs) } def concatN(times: Int, elem: A): List[A] = List.fill(times)(elem) } duplicateN(x, l) }
def times(n: Int, ls: List[String]) = ls.flatMap{ List.fill(n)(_) }
abstract class Animal case class Dog(name:String) extends Animal var foo:Animal = Dog("rover") var bar:Dog = foo
var bar:Dog = foo match { case x:Dog => x case _ => { } }
object A { def apply(s: String) = new A(s.toUpperCase) }
case class A(s: String) { require(! s.toCharArray.exists( _.isLower ), "Bad string: "+ s) }
class A private (val s: String) { } object A { def apply(s: String): A = new A(s.toUpperCase) }
val a1 = A("Hi There") val a2 = a1.copy(s = "gotcha")
object A { def apply(s: String, i: Int): A = new A(s.toUpperCase, i) {} } abstract case class A private[A] (s: String, i: Int) { private def readResolve(): Object = A.apply(s, i) def copy(s: String = s, i: Int = i): A = A.apply(s, i) }
object A { def apply(s: String, i: Int): A = { require(s.forall(_.isUpper), s"Bad String: $s") new A(s, i) {} } } abstract case class A private[A] (s: String, i: Int) { private def readResolve(): Object = A.apply(s, i) def copy(s: String = s, i: Int = i): A = A.apply(s, i) }
object A { private[A] abstract case class AImpl private[A] (s: String, i: Int) def apply(s: String, i: Int): A = { require(s.forall(_.isUpper), s"Bad String: $s") new A(s, i) } } final class A private[A] (s: String, i: Int) extends A.AImpl(s, i) { private def readResolve(): Object = A.apply(s, i) def copy(s: String = s, i: Int = i): A = A.apply(s, i) }
class UpperCaseString(s: String) extends Proxy { val self: String = s.toUpperCase } implicit def stringToUpperCaseString(s: String) = new UpperCaseString(s) implicit def upperCaseStringToString(s: UpperCaseString) = s.self case class A(val s: UpperCaseString) println(A("hello"))
object A { def apply(s: String)(implicit ev: Boolean) = new A(s.toLowerCase) } case class A(s: String)
sealed trait A { def s:String } object A { private case class AImpl(s:String) def apply(s:String):A = AImpl(s.toUpperCase) }
case class A(private val _s: String) { val s = _s.toUpperCase }
scala> case class A(val s: String) defined class A scala> object A { | def apply(s: String) = new A(s.toUpperCase) | } defined module A scala> A("hello") res0: A = A(HELLO)
import java.util.Random def dice() = State[Random, Int](r => (r, r.nextInt(6) + 1))
def TwoDice() = for { r1 <- dice() r2 <- dice() } yield (r1, r2) TwoDice().eval(new Random(1L))
type StateRandom[x] = State[Random,x] val list2 = list.sequence[StateRandom, (Int,Int)] val tenDoubleThrows2 = list2.eval(new Random(1L))
val list3 = list.sequenceU val tenDoubleThrows3 = list3.eval(new Random(1L))
def freqSum(dice: (Int, Int)) = State[Map[Int,Int], Int]{ freq => val s = dice._1 + dice._2 val tuple = s -> (freq.getOrElse(s, 0) + 1) (freq + tuple, s) }
type StateFreq[x] = State[Map[Int,Int],x] tenDoubleThrows2.copoint.traverse[StateFreq, Int](freqSum).exec(Map[Int,Int]())
tenDoubleThrows2.copoint.traverseU(freqSum).exec(Map[Int,Int]())
def stateBicompose[S, T, A, B]( f: State[S, A], g: (A) => State[T, B]) = State[(S,T), B]{ case (s, t) => val (newS, a) = f(s) val (newT, b) = g(a) apply t (newS, newT) -> b }
def diceAndFreqSum = stateBicompose(TwoDice, freqSum) type St2[x] = State[(Random, Map[Int,Int]), x] List.fill(10)(diceAndFreqSum).sequence[St2, Int].exec((new Random(1L), Map[Int,Int]()))
val test1 = for { a <- init[Int] _ <- modify[Int](_ + 1) b <- init[Int] } yield (a, b) val go1 = test1 ! 0
val test2 = for { a <- init[String] _ <- modify[String](_ + "1") b <- init[String] } yield (a, b) val go2 = test2 ! "0"
type StateString[x] = State[String, x] val test3 = { val stTrans = stateT[StateString, Int, String]{ i => for { _ <- init[String] _ <- modify[String](_ + "1") s <- init[String] } yield (i+1, s) } val initT = stateT[StateString, Int, Int]{ s => (s,s).pure[StateString] } for { b <- stTrans a <- initT } yield (a, b) } val go3 = test3 ! 0 ! "0"
val test31 = stateT[StateString, Int, (Int, String)]{ i => val (_, a) = test1 ! i for (t <- test2) yield (a, (a, t._2)) }
case class GameUnit(health: Int) case class Game(score: Int, boss: GameUnit, party: List[GameUnit]) object Game { val init = Game(0, GameUnit(100), List(GameUnit(20), GameUnit(10))) }
def strike : State[Game, Unit] = modify[Game] { s => s.copy( boss = s.boss.copy(health = s.boss.health - 10) ) }
def fireBreath : State[Game, Unit] = modify[Game] { s => val us = s.party .map(u => u.copy(health = u.health - 5)) .filter(_.health > 0) s.copy(party = us) }
def play = for { _ <- strike _ <- fireBreath _ <- fireBreath _ <- strike } yield ()
val res = play.exec(Game.init) println(res) >> Game(0,GameUnit(80),List(GameUnit(10)))
A => State[S, B] B => State[S, C] ------------------ A => State[S, C]
def modify[S](f: S => S) : State[S, Unit] = for { s <- get _ <- put(f(s)) } yield ()
def modify[S](f: S => S) : State[S, Unit] = get[S].flatMap(s => put(f(s)))
def sumEvenNumbers(nums: Iterable[Int]): Option[Int] = { nums.foldLeft (Some(0): Option[Int]) { case (Some(s), n) if n % 2 == 0 => Some(s + n) case _ => None } }
def sumEvenNumbers(nums: Iterable[Int]) = { def sumEven(it: Iterator[Int], n: Int): Option[Int] = { if (it.hasNext) { val x = it.next if ((x % 2) == 0) sumEven(it, n+x) else None } else Some(n) } sumEven(nums.iterator, 0) }
def sumEvenNumbers(nums: Iterable[Int]): Option[Int] = { Some(nums.foldLeft(0){ (n,x) => if ((n % 2) != 0) return None n+x }) }
import scala.util.control.ControlThrowable case class Returned[A](value: A) extends ControlThrowable {} def shortcut[A](a: => A) = try { a } catch { case Returned(v) => v } def sumEvenNumbers(nums: Iterable[Int]) = shortcut{ Option(nums.foldLeft(0){ (n,x) => if ((x % 2) != 0) throw Returned(None) n+x }) }
def foldOrFail[A,B](it: Iterable[A])(zero: B)(fail: A => Boolean)(f: (B,A) => B): Option[B] = { val ii = it.iterator var b = zero while (ii.hasNext) { val x = ii.next if (fail(x)) return None b = f(b,x) } Some(b) } def sumEvenNumbers(nums: Iterable[Int]) = foldOrFail(nums)(0)(_ % 2 != 0)(_ + _)
val list = List(2,4,6,8,6,4,2,5,3,2) list.takeWhile(_ % 2 == 0)
scala> val list = List(2,4,5,6,8) list: List[Int] = List(2, 4, 5, 6, 8) scala> def condition(i: Int) = { | println("processing " + i) | i % 2 == 0 | } condition: (i: Int)Boolean scala> list.iterator.takeWhile(condition _).sum processing 2 processing 4 processing 5 res4: Int = 6
import scalaz._ import Scalaz._ val str = Stream(2,1,2,2,2,2,2,2,2) var i = 0 val r = str.foldr(Some(0):Option[Int])((n,s) => { println(i) i+=1 if (n % 2 == 0) s.map(n+) else None })
scala> def sumEvenNumbers(nums: Iterable[Int]): Option[Int] = { | nums.foldLeft (Some(0): Option[Int]) { | case (None, _) => return None | case (Some(s), n) if n % 2 == 0 => Some(s + n) | case (Some(_), _) => None | } | } sumEvenNumbers: (nums: Iterable[Int])Option[Int] scala> sumEvenNumbers(2 to 10) res8: Option[Int] = None scala> sumEvenNumbers(2 to 10 by 2) res9: Option[Int] = Some(30)
def sumEvenNumbers(nums: Iterable[Int]): Option[Int] = { nums.foldLeft (Some(0): Option[Int]) { case (Some(s), n) if n % 2 == 0 => Some(s + n) case _ => return None } }
def sumEvenNumbers(nums: Stream[Int]): Option[Long] = { import cats.implicits._ nums.foldM(0L) { case (acc, c) if c % 2 == 0 => Some(acc + c) case _ => None } }
var continue = true val evenSum = (Stream.fill(10)(2) ++ Stream.fill(10)(3)).takeWhile(_ => continue) .foldLeft(Option[Int](0)){ case (result,i) if i%2 != 0 => continue = false; result case (optionSum,i) => optionSum.map( _ + i) }
val (l, r) = numbers.span(_ % 2 == 0) if(r.isEmpty) Some(l.sum) else None
var headers = Source.fromFile(file).getLines().next().split(",") var closeHeaderIdx = headers.takeWhile { s => !"Close".equals(s) }.foldLeft(0)((i, S) => i+1)
var headers = Source.fromFile(file).getLines().next().split(",").toList var closeHeaderIdx = headers.indexOf("Close")
object Application extends App { println("Hello World") }
object Application { def main(args: Array[String]): Unit = { println("Hello World"); } }
def unique[A](ls: List[A]) = { def loop(set: Set[A], ls: List[A]): List[A] = ls match { case hd :: tail if set contains hd => loop(set, tail) case hd :: tail => hd :: loop(set + hd, tail) case Nil => Nil } loop(Set(), ls) }
implicit def listToSyntax[A](ls: List[A]) = new { def unique = unique(ls) } List(1, 1, 2, 3, 4, 5, 4).unique
scala> val l = List(1,2,3,3,4,6,5,6) l: List[Int] = List(1, 2, 3, 3, 4, 6, 5, 6) scala> l.foldLeft(Nil: List[Int]) {(acc, next) => if (acc contains next) acc else next :: acc }.reverse res0: List[Int] = List(1, 2, 3, 4, 6, 5)
val list = List(1,2,3,4,2,3,4,99) val l2 = list.removeDuplicates
scala> val list = List(2,1,2,4,2,9,3) list: List[Int] = List(2, 1, 2, 4, 2, 9, 3) scala> val l2 = list.removeDuplicates l2: List[Int] = List(1, 4, 2, 9, 3)
ili.toSet.filter (i => ili.indexOf (i) == ili.lastIndexOf (i))
val l = List(1,2,3,3,3,4,5,5,6,7,8,8,8,9,9) val s = Set() ++ x println(s)
- main -- java -- resources -- scalaresources --- commandFiles
def readData(runtype: String, snmphost: String, comstring: String, specificType: String): Unit = { val realOrInvFile = "/commandFiles/snmpcmds." +runtype.trim try { if (specificType.equalsIgnoreCase("Cisco")) { val specificDeviceFile: String = "/commandFiles/snmpcmds."+runtype.trim+ ".cisco" val realOrInvCmdsList = scala.io.Source.fromFile(realOrInvFile).getLines().toList.filterNot(line => line.startsWith(" } val specificCmdsList = scala.io.Source.fromFile(specificDeviceFile).getLines().toList.filterNot(line => line.startsWith(" } } } catch { case e: Exception => e.printStackTrace } } }
testing_styles/ ├── build.sbt ├── src │ └── main │ ├── resources │ │ └── readme.txt
import scala.io.Source val readmeText : Iterator[String] = Source.fromResource("readme.txt").getLines
val stream : InputStream = getClass.getResourceAsStream("/readme.txt") val lines = scala.io.Source.fromInputStream( stream ).getLines
import scala.io.Source import scala.util.Try def niceFeedbackReadResource(resource: String): List[String] = Try(Source.fromResource(resource).getLines.toList) .recover(throw new FileNotFoundException(resource))
scala.io.Source.fromResource("located_in_resouces.any")
val source_html = Source.fromResource("file.html").getLines().mkString("\n")
import scala.io.Source object Demo { def main(args: Array[String]): Unit = { val fileStream = getClass.getResourceAsStream("/json-sample.js") val lines = Source.fromInputStream(fileStream).getLines lines.foreach(line => println(line)) } }
class A(val n: Int) class B(val m: Int, val n: Int) class C(val m: Int, val n: Int, val o: Int) { def total = m + n + o } object T1 { implicit def toA(n: Int): A = new A(n) implicit def aToB(a: A): B = new B(a.n, a.n) implicit def bToC(b: B): C = new C(b.m, b.n, b.m + b.n) println(5.total) println(new A(5).total) println(new B(5, 5).total) println(new C(5, 5, 10).total) }
object T2 { implicit def toA(n: Int): A = new A(n) implicit def aToB[A1 <% A](a: A1): B = new B(a.n, a.n) implicit def bToC[B1 <% B](b: B1): C = new C(b.m, b.n, b.m + b.n) println(5.total) println(new A(5).total) println(new B(5, 5).total) println(new C(5, 5, 10).total) }
object T1Translated { implicit def toA(n: Int): A = new A(n) implicit def aToB(a: A): B = new B(a.n, a.n) implicit def bToC(b: B): C = new C(b.m, b.n, b.m + b.n) println(bToC(aToB(toA(5))).total) println(bToC(aToB(new A(5))).total) println(bToC(new B(5, 5)).total) println(new C(5, 5, 10).total) } object T2Translated { implicit def toA(n: Int): A = new A(n) implicit def aToB[A1 <% A](a: A1): B = new B(a.n, a.n) implicit def bToC[B1 <% B](b: B1): C = new C(b.m, b.n, b.m + b.n) println(bToC(5)(x => aToB(x)(y => toA(y))).total) println(bToC(new A(5))(x => aToB(x)(identity)).total) println(bToC(new B(5, 5))(identity).total) println(new C(5, 5, 10).total) }
class Wrap { class A(implicit b : B) class B(implicit c : C) class C(implicit a : A) implicit def c = new C implicit def b = new B implicit def a = new A }
import scala.language.implicitConversions case class A(l: List[Char]) case class B(l: List[Char]) case class C(l: List[Char]) case class D(l: List[Char]) case class E(l: List[Char]) implicit def ad[A1 <% A](x: A1) = D(x.l :+ implicit def bc[B1 <% B](x: B1) = C(x.l :+ implicit def ce[C1 <% C](x: C1) = E(x.l :+ implicit def ea[E1 <% E](x: E1) = A(x.l :+ def pathFrom(end:D) = end pathFrom(B(Nil))
object A { def foo(a: Int) = 0 def foo(b: Boolean) = 0 def foo(a: Int, b: Int) = 0 val function = foo _ }
scala> implicit def S2B(s: String) = !s.isEmpty S2B: (s: String)Boolean scala> implicit def S2I(s: String) = s.length S2I: (s: String)Int scala> object test { def foo(a: Int) = 0; def foo(b: Boolean) = 1; foo("") } <console>:15: error: ambiguous reference to overloaded definition, both method foo in object test of type (b: Boolean)Int and method foo in object test of type (a: Int)Int match argument types (java.lang.String) object test { def foo(a: Int) = 0; def foo(b: Boolean) = 1; foo("") }
object test { def foo(a: Int) = 0; def foo(a: Int, b: Int = 0) = 1 }
scala> object O { def apply[T](ts: T*) = (); def apply(f: (String => Int)) = () } defined object O scala> O((i: String) => f(i))
val myStrings = new Array[String](3) myStrings.foreach(println(_)) myStrings.foreach(println(_.toString))
export SBT_OPTS="-Xmx1536M -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=2G -Xss2M -Duser.timezone=GMT"
export SBT_OPTS="-Xmx2G -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=2G -Xss2M -Duser.timezone=GMT"
execRunner "$java_cmd" \ ${SBT_OPTS:-$default_sbt_opts} \ - $(get_mem_opts $sbt_mem) \ ${java_opts} \ ${java_args[@]} \ -jar "$sbt_jar" \ "${sbt_commands[@]}" \ "${residual_args[@]}"
rem FIRST we load the config file of extra options. set FN=%SBT_HOME%\..\conf\sbtconfig.txt set CFG_OPTS= FOR /F "tokens=* eol= set DO_NOT_REUSE_ME=%%i rem ZOMG (Part rem CFG_OPTS, otherwise it remains "" for this loop. set CFG_OPTS=!CFG_OPTS! !DO_NOT_REUSE_ME! )
rem We use the value of the JAVA_OPTS environment variable if defined, rather than the config. set _JAVA_OPTS=%JAVA_OPTS% if "%_JAVA_OPTS%"=="" set _JAVA_OPTS=%CFG_OPTS% :run "%_JAVACMD%" %_JAVA_OPTS% %SBT_OPTS% -cp "%SBT_HOME%sbt-launch.jar" xsbt.boot.Boot %*
test -f ~/.sbtconfig && . ~/.sbtconfig exec java -Xmx512M ${SBT_OPTS} -jar /usr/local/Cellar/sbt/0.12.3/libexec/sbt-launch.jar "$@"
$env:SBT_OPTS="-Xms512M -Xmx1024M -Xss2M -XX:MaxMetaspaceSize=1024M"
scala> val f: Function1[Int,String] = myInt => "my int: "+myInt.toString f: (Int) => String = <function1> scala> f(0) res0: String = my int: 0 scala> val f2: Int => String = myInt => "my int v2: "+myInt.toString f2: (Int) => String = <function1> scala> f2(1) res1: String = my int v2: 1
scala> val f: () => Unit = () => { println("x")} f: () => Unit = <function0> scala> f() x scala> val f2: Function0[Unit] = () => println("x2") f: () => Unit = <function0> scala> f2() x2
Traversable | | Iterable | +------------------+--------------------+ Map Set Seq | | | | +----+----+ +-----+------+ Sorted Map SortedSet BitSet Buffer Vector LinearSeq
xs.iterator An iterator that yields every element in xs, in the same order as foreach traverses elements. xs takeRight n A collection consisting of the last n elements of xs (or, some arbitrary n elements, if no order is defined). xs dropRight n The rest of the collection except xs takeRight n. xs sameElements ys A test whether xs and ys contain the same elements in the same order
def removeOne(c: Card, left: List[Card], right: List[Card]): List[Card] = { if (Nil == right) { return left } if (c == right.head) { return left ::: right.tail } return removeOne(c, right.head :: left, right.tail) } def removeCard(c: Card, cards: List[Card]): List[Card] = { return removeOne(c, Nil, cards) }
scala> def remove(num: Int, list: List[Int]) = list diff List(num) remove: (num: Int,list: List[Int])List[Int] scala> remove(2,List(1,2,3,4,5)) res2: List[Int] = List(1, 3, 4, 5)
scala> remove(2,List(2,2,2)) res0: List[Int] = List(2, 2)
val data = "test" list = List("this", "is", "a", "test") list.filterNot(elm => elm == data)
scala> val (left,right) = List(1,2,3,2,4).span(_ != 2) left: List[Int] = List(1) right: List[Int] = List(2, 3, 2, 4) scala> left ::: right.tail res7: List[Int] = List(1, 3, 2, 4)
def removeInt(i: Int, li: List[Int]) = { val (left, right) = li.span(_ != i) left ::: right.drop(1) }
scala> collection.mutable.ArrayBuffer(1,2,3,2,4) - 2 res0: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(1, 3, 2, 4)
scala> List(1,2,3,2,4) - 2 warning: there were deprecation warnings; re-run with -deprecation for details res1: List[Int] = List(1, 3, 4)
import collection.mutable.ArrayBuffer._ scala> ((ArrayBuffer() ++ List(1,2,3,2,4)) - 2).toList res2: List[Int] = List(1, 3, 2, 4)
def removeInt(i: Int, li: List[Int]) = { def removeOne(i: Int, left: List[Int], right: List[Int]): List[Int] = right match { case r :: rest => if (r == i) left.reverse ::: rest else removeOne(i, r :: left, rest) case Nil => left.reverse } removeOne(i, Nil, li) } scala> removeInt(2, List(1,2,3,2,4)) res3: List[Int] = List(1, 3, 2, 4)
def removeAtIdx[T](idx: Int, listToRemoveFrom: List[T]): List[T] = { assert(listToRemoveFrom.length > idx && idx >= 0) val (left, _ :: right) = listToRemoveFrom.splitAt(idx) left ++ right }
def remove[A](i:A, li:List[A]) = { val (head,_::tail) = li.span(i != _) head ::: tail }
def removeOne(l: List[Card], c: Card) = l indexOf c match { case -1 => l case n => (l take n) ++ (l drop (n + 1)) }
def removeCard(c: Card, cards: List[Card]) = { val (head, tail) = cards span {c!=} head ::: (tail match { case x :: xs => xs case Nil => Nil }) }
def remove[A](item : A, lst : List[A]) : List[A] = { lst.:\[List[A]](Nil)((lst, lstItem) => if (lstItem == item) lst else lstItem::lst ) }
def removeElement[T](list: List[T], ele: T): List[T] = { @tailrec def removeElementHelper(list: List[T], accumList: List[T] = List[T]()): List[T] = { if (list.length == 1) { if (list.head == ele) accumList.reverse else accumList.reverse ::: list } else { list match { case head :: tail if (head != ele) => removeElementHelper(tail, head :: accumList) case head :: tail if (head == ele) => (accumList.reverse ::: tail) case _ => accumList } } } removeElementHelper(list) }
val list : Array[Int] = Array(6, 5, 3, 1, 8, 7, 2) val test2 = list.splitAt(list.length / 2)._2 val res = test2.patch(1, Nil, 1)
object HelloWorld { def main(args: Array[String]) { var months: List[String] = List("December","November","October","September","August", "July","June","May","April","March","February","January") println("Deleting the reverse list one by one") var i = 0 while (i < (months.length)){ println("Deleting "+months.apply(i)) months = (months.drop(1)) } println(months) } }
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.12.0")
lazy val commonSettings = Seq( name := "Spark-Test" version := "1.0" scalaVersion := "2.11.4" ) lazy val app = (project in file("app")). settings(commonSettings: _*). settings( libraryDependencies ++= Seq( "org.apache.spark" %% "spark-core" % "1.2.0", "org.apache.spark" %% "spark-streaming" % "1.2.0", "org.apache.spark" % "spark-streaming-twitter_2.10" % "1.2.0" ) )
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.12.0")
lazy val root = (project in file(".")). settings( name := "my-project", version := "1.0", scalaVersion := "2.11.4", mainClass in Compile := Some("myPackage.MyMainObject") ) libraryDependencies ++= Seq( "org.apache.spark" %% "spark-core" % "1.2.0" % "provided", "org.apache.spark" %% "spark-streaming" % "1.2.0" % "provided", "org.apache.spark" % "spark-streaming-twitter_2.10" % "1.2.0" ) mergeStrategy in assembly <<= (mergeStrategy in assembly) { (old) => { case PathList("META-INF", xs @ _*) => MergeStrategy.discard case x => MergeStrategy.first } }
/my-project/target/scala-2.11/my-project-assembly-1.0.jar
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.12.0")
mainClass in assembly := some("package.MainClass") assemblyJarName := "desired_jar_name_after_assembly.jar" val meta = """META.INF(.)*""".r assemblyMergeStrategy in assembly := { case PathList("javax", "servlet", xs @ _*) => MergeStrategy.first case PathList(ps @ _*) if ps.last endsWith ".html" => MergeStrategy.first case n if n.startsWith("reference.conf") => MergeStrategy.concat case n if n.endsWith(".conf") => MergeStrategy.concat case meta(_) => MergeStrategy.discard case x => MergeStrategy.first }
trait Foo { def bar: Int } object F1 extends Foo { def bar = util.Random.nextInt(33) } class F2(val bar: Int) extends Foo object F3 extends Foo { lazy val bar = { Thread.sleep(5000) 42 } }
trait Foo { val bar: Int val schoko = bar + bar } object Fail extends Foo { val bar = 33 } Fail.schoko
trait Holder { type Inner val init : Inner } class Access(val holder : Holder) { val access : holder.Inner = holder.init } trait Access2 { def holder : Holder def access : holder.Inner = holder.init }
StableIdentifier.scala:14: error: stable identifier required, but Access2.this.holder found. def access : holder.Inner =
trait Entity { def id:Int} object Table { def create(e:Entity) = {e.id = 1 } }
withClue("NumberOfElements: ") { NumberOfElements() should be (5) }
assert(NumberOfElements() == 5, "NumberOfElements should be 5")
scala> import org.scalatest.matchers.ShouldMatchers._ import org.scalatest.matchers.ShouldMatchers._ scala> withClue ("Hi:") { 1 + 1 should equal (3) } org.scalatest.TestFailedException: Hi: 2 did not equal 3 at org.scalatest.matchers.Matchers$class.newTestFailedException(Matchers.scala:150) at org.scalatest.matchers.ShouldMatchers$.newTestFailedException(ShouldMatchers.scala:2331) scala> class AssertionHolder(f: => Any) { | def withMessage(s: String) { | withClue(s) { f } | } | } defined class AssertionHolder scala> implicit def convertAssertion(f: => Any) = new AssertionHolder(f) convertAssertion: (f: => Any)AssertionHolder scala> { 1 + 1 should equal (3) } withMessage ("Ho:") org.scalatest.TestFailedException: Ho: 2 did not equal 3 at org.scalatest.matchers.Matchers$class.newTestFailedException(Matchers.scala:150) at org.scalatest.matchers.ShouldMatchers$.newTestFailedException(ShouldMatchers.scala:2331)
{ NumberOfElements() should be (5) } withMessage ("NumberOfElements:")
import org.scalatest.{AppendedClues, Matchers, WordSpec} class SomeTest extends WordSpec with Matchers with AppendedClues { "Clues" should { "not be appended" when { "assertions pass" in { "hi" should equal ("hi") withClue "Greetings scala tester!" } } "be appended" when { "assertions fail" in { 1 + 1 should equal (3) withClue ", not even for large values of 1!" } } "not be needed" when { "looking at collection sizes" in { val list = List(1, 2, 3) list should have size 5 } } } }
SomeTest: Clues should not be appended - when assertions pass should be appended - when assertions fail *** FAILED *** 2 did not equal 3, not even for large values of 1! (SomeTest.scala:15) should not be needed - when looking at collection sizes *** FAILED *** List(1, 2, 3) had size 3 instead of expected size 5 (SomeTest.scala:21)
class AkkaWorkerFT extends Actor { def receive = { case Work(n, c) if n < 0 => throw new Exception("Negative number") case Work(n, c) => self reply n.isProbablePrime(c); } }
val workers = Vector.fill(nrOfWorkers)(actorOf[AkkaWorkerFT].start()); val router = Routing.loadBalancerActor(SmallestMailboxFirstIterator(workers)).start()
futures.foreach( _.await ) router ! Broadcast(PoisonPill) router ! PoisonPill
Thread [akka:event-driven:dispatcher:event:handler-6] (Suspended) Unsafe.park(boolean, long) line: not available [native method] LockSupport.park(Object) line: 158 AbstractQueuedSynchronizer$ConditionObject.await() line: 1987 LinkedBlockingQueue<E>.take() line: 399 ThreadPoolExecutor.getTask() line: 947 ThreadPoolExecutor$Worker.run() line: 907 MonitorableThread(Thread).run() line: 680 MonitorableThread.run() line: 182
class Child extends Actor { var state = 0 def receive = { case ex: Exception ⇒ throw ex case x: Int ⇒ state = x case "get" ⇒ sender ! state } }
class Supervisor extends Actor { import akka.actor.OneForOneStrategy import akka.actor.SupervisorStrategy._ import scala.concurrent.duration._ override val supervisorStrategy = OneForOneStrategy(maxNrOfRetries = 10, withinTimeRange = 1 minute) { case _: ArithmeticException ⇒ Resume case _: NullPointerException ⇒ Restart case _: IllegalArgumentException ⇒ Stop case _: Exception ⇒ Escalate } def receive = { case p: Props ⇒ sender ! context.actorOf(p) } }
def shutdown() { foreachListener(_.stop()) EventHandlerDispatcher.shutdown() }
val xs = Array("first", "second", "third") for (i=0; i<xs.length; i++) { println("String }
val xs = Array("first", "second", "third") val indexed = xs zipWithIndex for (x <- indexed) println("String
import scala.annotation.tailrec @tailrec def printArray(i: Int, xs: Array[String]) { if (i < xs.length) { println("String printArray(i+1, xs) } } printArray(0, Array("first", "second", "third"))
scala> val xs = Array("first", "second", "third") xs: Array[java.lang.String] = Array(first, second, third) scala> for (i <- xs.indices) | println(i + ": " + xs(i)) 0: first 1: second 2: third
scala> val xs = Array("first","second","third") xs: Array[java.lang.String] = Array(first, second, third) scala> for (i <- 0 until xs.length) | println("String String String String
scala> for (i <- 0 to xs.length-1) | println("String String String String
val a = Array("One", "Two", "Three") a.foldLeft(0) ((i, x) => {println(i + ": " + x); i + 1;} )
def zipWithIndex: Iterator[(A, Int)] = new AbstractIterator[(A, Int)] { var idx = 0 def hasNext = self.hasNext def next = { val ret = (self.next, idx) idx += 1 ret } }
def foreachWithIndex[A](as: Traversable[A])(f: (Int,A) => Unit) { var i = 0 for (a <- as) { f(i, a) i += 1 } } def mapWithIndex[A,B](in: List[A])(f: (Int,A) => B): List[B] = { def mapWithIndex0(in: List[A], gotSoFar: List[B], i: Int): List[B] = { in match { case Nil => gotSoFar.reverse case one :: more => mapWithIndex0(more, f(i, one) :: gotSoFar, i+1) } } mapWithIndex0(in, Nil, 0) } @Test def testForeachWithIndex() { var out = List[Int]() ScalaUtils.foreachWithIndex(List(1,2,3,4)) { (i, num) => out :+= i * num } assertEquals(List(0,2,6,12),out) } @Test def testMapWithIndex() { val out = ScalaUtils.mapWithIndex(List(4,3,2,1)) { (i, num) => i * num } assertEquals(List(0,3,4,3),out) }
scala> val lens = for (x <- xs) yield (x.length) lens: Array[Int] = Array(5, 6, 5)
scala> ("" /: xs) (_ + _) res21: java.lang.String = firstsecondthird
def ijIter (i: Int = 0, j: Int = 0, carry: Int = 0) : Int = if (i + j >= 100) carry else ijIter (i+2*j, j+i+2, carry / 3 + 2 * i - 4 * j + 10)
scala> (1 until 4) res43: scala.collection.immutable.Range with scala.collection.immutable.Range.ByOne = Range(1, 2, 3) scala> (0 to 8 by 2) res44: scala.collection.immutable.Range = Range(0, 2, 4, 6, 8) scala> (26 to 13 by -3) res45: scala.collection.immutable.Range = Range(26, 23, 20, 17, 14)
val myArray = new Array[String](3) myArray(0)="0"; myArray(1)="1"; myArray(2)="2";
for(data <- myArray)println(data) for (i <- 0 until myArray.size) println(i + ": " + myArray(i))
var i = 0 xs foreach { el => println("String i += 1 }
object HelloV2 { def main(args: Array[String]) { var msg = ""; for (i <- args.indices) { msg+=(args(i)); } var msg1=""; for (i <- 0 until args.length) { msg1 += (args(i)); } var msg3="" args.foreach{ arg => msg3 += (arg) } println("msg= " + msg); println("msg1= " + msg1); println("msg3= " + msg3); } }
object TraversableUtil { class IndexMemoizingFunction[A, B](f: (Int, A) => B) extends Function1[A, B] { private var index = 0 override def apply(a: A): B = { val ret = f(index, a) index += 1 ret } } def doIndexed[A, B](f: (Int, A) => B): A => B = { new IndexMemoizingFunction(f) } }
val list1 = List(Some(1), None, Some(2)) val list2 = list1.flatten
scala> val list1 = List(Some(1), None, Some(2)) list1: List[Option[Int]] = List(Some(1), None, Some(2)) scala> list1 flatten res0: List[Int] = List(1, 2) scala> list1.flatten(Option.option2Iterable) res1: List[Int] = List(1, 2) scala> list1 flatMap (x => x) res2: List[Int] = List(1, 2) scala> list1 flatMap Option.option2Iterable res3: List[Int] = List(1, 2) scala> list1 collect { case Some(x) => x } res4: List[Int] = List(1, 2)
scala> import scalaz._; import Scalaz._ import scalaz._ import Scalaz._ scala> val list1: List[Option[Int]] = List(Some(1), None, Some(2)) list1: List[Option[Int]] = List(Some(1), None, Some(2)) scala> list1.sequence res1: Option[List[Int]] = None scala> val list2: List[Option[Int]] = List(Some(1), Some(2)) list2: List[Option[Int]] = List(Some(1), Some(2)) scala> list2.sequence res2: Option[List[Int]] = Some(List(1, 2))
Welcome to Scala version 2.9.1.final (Java HotSpot(TM) 64-Bit Server VM, Java 1.6.0_26). Type in expressions to have them evaluated. Type :help for more information. scala> util.Properties.versionString res0: java.lang.String = version 2.9.1.final
scala> util.Properties.versionNumberString res103: String = 2.11.4 scala> util.Properties.versionString res104: String = version 2.11.4 scala> util.Properties.versionMsg res105: String = Scala library version 2.11.4 -- Copyright 2002-2013, LAMP/EPFL
scala> scala.tools.nsc.Properties.versionString res7: java.lang.String = version 2.9.0.final
scala> "5" match { case Digit() => true case _ => false } res4: Boolean = true
scala> Digit.pattern.matcher("5").matches res6: Boolean = true
object RegexUtils { implicit class RichRegex(val underlying: Regex) extends AnyVal { def matches(s: String) = underlying.pattern.matcher(s).matches } }
import RegexUtils._ val Digit = .r if (Digit matches "5") println("match") else println("no match")
scala> val Digit = .r Digit: scala.util.matching.Regex = \d scala> Digit unapplySeq "1" res9: Option[List[String]] = Some(List()) scala> Digit unapplySeq "123" res10: Option[List[String]] = None scala> Digit unapplySeq "string" res11: Option[List[String]] = None
.r.unapplySeq("5").isDefined .r.unapplySeq("a").isDefined
val digit = """(\d)""".r "2" match { case digit( a) => println(a + " is Digit") case _ => println("it is something else") }
+---------------------+-------------------------------------+ | eval | toString | +---------------+---------------------+-------------------------------------+ | constant | value | value.toString | +---------------+---------------------+-------------------------------------+ | addition | lhs.eval + rhs.eval | lhs.toString + " + " + rhs.toString | +---------------+---------------------+-------------------------------------+ | mutiplication | lhs.eval * rhs.eval | lhs.toString + " * " + rhs.toString | +---------------+---------------------+-------------------------------------+
val application = new Object extends Communications with Parsing with Persistence with Logging with ProductionDataSource application.startup
val application = if (test) new Object extends Communications with Parsing with Persistence with Logging with TestDataSource else new Object extends Communications with Parsing with Persistence with Logging with ProductionDataSource application.startup
java -cp first.jar:second.jar com.example.MyMainClass context.xml
trait Module { def foo: Int } trait DelegatedModule extends Module { var delegate: Module = _ def foo = delegate.foo } class Impl extends Module { def foo = 1 } val composed: Module with ... with ... = new DelegatedModule with ... with ... composed.delegate = choose()
trait Locking{ protected def lock(body: =>A):A } class MyService{ this:Locking => } val myService:MyService = new MyService with JDK15Locking
import scala.language.experimental.macros import scala.reflect.macros.Context object TupleExample { def fill[A](arity: Int)(a: A): Product = macro fill_impl[A] def fill_impl[A](c: Context)(arity: c.Expr[Int])(a: c.Expr[A]) = { import c.universe._ arity.tree match { case Literal(Constant(n: Int)) if n < 23 => c.Expr( Apply( Select(Ident("Tuple" + n.toString), "apply"), List.fill(n)(a.tree) ) ) case _ => c.abort( c.enclosingPosition, "Desired arity must be a compile-time constant less than 23!" ) } } }
scala> TupleExample.fill(3)("hello") res0: (String, String, String) = (hello,hello,hello)
def bothMatch(pat:String,pat2:String,s:String):Option[Boolean] = for { f <- mkMatcher(pat) g <- mkMatcher(pat2) } yield f(s) && g(s)
def bothMatch(pat:String,pat2:String,s:String):Option[Boolean] = mkMatcher(pat) flatMap (f => mkMatcher(pat2) map (g => f(s) && g(s)))
def mkMatcher(pat:String):Option[String => Boolean] = pattern(pat) map (p => (s:String) => p.matcher(s).matches)
import java.util.regex._ def pattern(s:String):Option[Pattern] = try { Some(Pattern.compile(s)) }catch{ case e: PatternSyntaxException => None }
/* applies a transformation of the monad "content" mantaining the * monad "external shape" * i.e. a List remains a List and an Option remains an Option * but the inner type changes */ def map(f: A => B): M[B] /* applies a transformation of the monad "content" by composing * this monad with an operation resulting in another monad instance * of the same type */ def flatMap(f: A => M[B]): M[B]
val list = List("neo", "smith", "trinity") val f: String => List[Int] = s => s.map(_.toInt).toList list map f >> List(List(110, 101, 111), List(115, 109, 105, 116, 104), List(116, 114, 105, 110, 105, 116, 121)) list flatMap f >> List(110, 101, 111, 115, 109, 105, 116, 104, 116, 114, 105, 110, 105, 116, 121)
for { bound <- list out <- f(bound) } yield out list.flatMap { bound => f(bound).map { out => out } } list.flatMap { bound => f(bound) } list flatMap f
for { bound <- list } yield f(bound) list.map { bound => f(bound) } list map f
case class Customer(value: Int) case class Consultant(portfolio: List[Customer]) case class Branch(consultants: List[Consultant]) case class Company(branches: List[Branch]) def getCompanyValue(company: Company): Int = { val valuesList = for { branch <- company.branches consultant <- branch.consultants customer <- consultant.portfolio } yield (customer.value) valueList reduce (_ + _) }
def bothMatch(pat:String,pat2:String,s:String):Option[Boolean] = for { f <- mkMatcher(pat) g <- mkMatcher(pat2) } yield f(s) && g(s)
def bothMatch(pat:String,pat2:String,s:String):Option[Boolean] = for { f <- mkMatcher(pat) g <- mkMatcher(pat2) } yield f(s) && g(s)
def match items(pat:List[Int] ,pat2:List[Char]):Unit = for { f <- pat g <- pat2 } println(f +"->"+g) bothMatch( (1 to 9).toList, (
pattern(pat) map (p => (s:String) => p.matcher(s).matches)
val x = List(1, 2, 3) val t = x match { case List(a, b, c) => (a, b, c) }
val t = x match { case List(a, b, c, _*) => (a, b, c) }
import shapeless._ import syntax.std.traversable._ val x = List(1, 2, 3) val xHList = x.toHList[Int::Int::Int::HNil] val t = xHList.get.tupled
import shapeless._ import HList._ import syntax.std.traversable._ val x = List(1, 2, 3) val y = x.toHList[Int::Int::Int::HNil] val z = y.get.tupled
scala> import shapeless._ import shapeless._ scala> import HList._ import HList._ scala> val hlist = "z" :: 6 :: "b" :: true :: HNil hlist: shapeless.::[String,shapeless.::[Int,shapeless.::[String,shapeless.::[Boolean,shapeless.HNil]]]] = z :: 6 :: b :: true :: HNil scala> val tup = hlist.tupled tup: (String, Int, String, Boolean) = (z,6,b,true) scala> tup res0: (String, Int, String, Boolean) = (z,6,b,true)
val list = List( val tuple = list(0) -> list(1) val list = List( val tuple = (list(0), list(1), list(2))
scala> import shapeless._ scala> import shapeless.syntax.sized._ scala> val x = List(1, 2, 3) x: List[Int] = List(1, 2, 3) scala> x.sized(3).map(_.tupled) res1: Option[(Int, Int, Int)] = Some((1,2,3))
val x: List[Int] = List(1, 2, 3) def doSomething(a:Int *) doSomething(x:_*)
implicit class EnrichedWithToTuple[A](elements: Seq[A]) { def toTuple: Product = elements.length match { case 2 => toTuple2 case 3 => toTuple3 } def toTuple2 = elements match {case Seq(a, b) => (a, b) } def toTuple3 = elements match {case Seq(a, b, c) => (a, b, c) } } val product = List(1, 2, 3).toTuple product.productElement(5) val tuple = List(1, 2, 3).toTuple3 tuple._5
val xs: Seq[Any] = List(1:Int, 2.0:Double, "3":String) val t: (Int,Double,String) = xs.foldLeft((Tuple3[Int,Double,String] _).curried:Any)({ case (f,x) => f.asInstanceOf[Any=>Any](x) }).asInstanceOf[(Int,Double,String)]
def listToTuple[A <: Object](list:List[A]):Product = { val class = Class.forName("scala.Tuple" + list.size) class.getConstructors.apply(0).newInstance(list:_*).asInstanceOf[Product] } listToTuple: [A <: java.lang.Object](list: List[A])Product scala> listToTuple(List("Scala", "Smart")) res15: Product = (Scala,Smart)
max() : Int { global x : Int; global y : Int; ... }
def max[T <% Ordered[T]](a: T, b: T): T = if (a < b) b else a def max[T](a: T, b: T)(implicit $ev1: Function1[T, Ordered[T]]): T = if ($ev1(a) < b) b else a
def max[T](a: T, b: T)(implicit $ev1: Ordering[T]): T = if ($ev1.lt(a, b)) b else a def max[T: Ordering](a: T, b: T): T = if (implicitly[Ordering[T]].lt(a, b)) b else a
def f[T: ClassManifest](size: Int) = new Array[T](size)
Manifest ClassManifest Ordering Numeric CanBuildFrom
def withTransaction(f: Transaction => Unit) = { val txn = new Transaction try { f(txn); txn.commit() } catch { case ex => txn.rollback(); throw ex } } withTransaction { txn => op1(data)(txn) op2(data)(txn) op3(data)(txn) }
withTransaction { implicit txn => op1(data) op2(data) op3(data) }
def flatten[B](implicit ev: A <:< Option[B]): Option[B]
scala> Option(Option(2)).flatten res0: Option[Int] = Some(2) scala> Option(2).flatten <console>:8: error: Cannot prove that Int <:< Option[B]. Option(2).flatten ^
trait ScalaActorRef { this: ActorRef => ... def !(message: Any)(implicit sender: ActorRef = null): Unit ... }
trait Actor { ... implicit val self = context.self ... }
someOtherActor.!(SomeMessage)(anotherActorAltogether)
implicit val num = 2 implicit val item = "Orange" def shopping(implicit num: Int, item: String) = { "I’m buying "+num+" "+item+(if(num==1) "." else "s.") } scala> shopping res: java.lang.String = I’m buying 2 Oranges.
def map[B, That](f: (A) ⇒ B)(implicit bf: CanBuildFrom[GenSeq[A], B, That]): That
def myFunction(): Int = { implicit val y: Int = 33 implicit val z: Double = 3.3 functionWithImplicit("foo") } def functionWithImplicit(foo: String)(implicit x: Int, d: Double) =
abstract class myImplicitClass { implicit val config = new myConfigClass() val conf = new SparkConf().setMaster().setAppName() implicit val sc = new SparkContext(conf) def overrideThisMethod(implicit sc: SparkContext, config: Config) : Unit } class MyClass extends myImplicitClass { override def overrideThisMethod(implicit sc: SparkContext, config: Config){ def firstFn(firstParam: Int) (implicit sc: SparkContext, config: Config){ val myRdd = sc.parallelize(List("abc","123")) } def secondFn(firstParam: Int) (implicit sc: SparkContext, config: Config){ val keyspace = config.getString("keyspace") val tableName = config.getString("table") val hostName = config.getString("host") val userName = config.getString("username") val pswd = config.getString("password") implicit val cassandraConnectorObj = CassandraConnector(....) val cassandraRdd = sc.cassandraTable(keyspace, tableName) } } }
expr match { case UnOp("abs", e @ UnOp("abs", _)) => e case _ => }
scala> class Magic { | private var x :Int = _ | override def toString = "Magic(%d)".format(x) | def member = x | def member_=(m :Int){ x = m } | } defined class Magic scala> val m = new Magic m: Magic = Magic(0) scala> m.member res14: Int = 0 scala> m.member = 100 scala> m res15: Magic = Magic(100) scala> m.member += 99 scala> m res17: Magic = Magic(199)
foo.method("blah") ~~> foo.applyDynamic("method")("blah") foo.method(x = "blah") ~~> foo.applyDynamicNamed("method")(("x", "blah")) foo.method(x = 1, 2) ~~> foo.applyDynamicNamed("method")(("x", 1), ("", 2)) foo.field ~~> foo.selectDynamic("field") foo.varia = 10 ~~> foo.updateDynamic("varia")(10) foo.arr(10) = 13 ~~> foo.selectDynamic("arr").update(10, 13) foo.arr(10) ~~> foo.applyDynamic("arr")(10)
import scala.language.dynamics object Dyn extends Dynamic { def applyDynamic(name: String)(a1: Int, a2: String) { println("Invoked " + name + " on (" + a1 + "," + a2 + ")"); } } Dyn.foo(3, "x"); Dyn.bar(3, "y");
scala> :paste if (true) print("that was true") else print("false") [Ctrl-D] that was true
scala> :paste ~/Desktop/repl_seeder.scala Pasting file ~/Desktop/repl_seeder.scala... defined object test1 scala> test1.main(Str) my first scala program
name := "sbt_test" version := "1.0" scalaVersion := "2.10.1-local" autoScalaLibrary := false scalaHome := Some(file("/Program Files (x86)/scala/")) mainClass := Some("Hi") libraryDependencies ++= Seq( "org.scalatest" % "scalatest_2.10" % "2.0.M5b" % "test" ) EclipseKeys.withSource := true
object Hi { def main(args: Array[String]) = println("Hi!") }
The system cannot find the file C:\work\externals\sbt\bin\sbtconfig.txt. [info] Loading project definition from C:\work\test_projects\sbt_test\project [info] Set current project to sbt_test (in build file:/C:/work/test_projects/sbt_test/) java.lang.RuntimeException: No main class detected. at scala.sys.package$.error(package.scala:27) [trace] Stack trace suppressed: run last compile:run for the full output. [error] (compile:run) No main class detected. [error] Total time: 0 s, completed Apr 8, 2013 6:14:41 PM
object Main extends App { println("Hello from main scala object") }
project moduleX [info] Set current project to moduleX (in build file:/path/to/Projects/) > run [info] Running main
[info] Project module is not set. Please use or set in Built file (LinkToDocu)
val projectMainClass = "com.saeed.ApplicationMain" mainClass in (Compile, run) := Some(projectMainClass)
mainClass in (Compile, packageBin) := Some(projectMainClass)
Multiple main classes detected, select one to run: [1] a.b.DummyMain1 [2] a.b.DummyMain2 Enter number:
import java.util.concurrent.Executors import scala.concurrent._ implicit val ec = new ExecutionContext { val threadPool = Executors.newFixedThreadPool(1000); def execute(runnable: Runnable) { threadPool.submit(runnable) } def reportFailure(t: Throwable) {} }
implicit val ec = ExecutionContext.fromExecutor(Executors.newFixedThreadPool(10))
-Dscala.concurrent.context.numThreads=8 -Dscala.concurrent.context.maxThreads=8
implicit val ec = new ExecutionContext { val threadPool = Executors.newFixedThreadPool(conf.getInt("5")); override def reportFailure(cause: Throwable): Unit = {}; override def execute(runnable: Runnable): Unit = threadPool.submit(runnable); def shutdown() = threadPool.shutdown(); }
myMap.exists(_ == ("fish",3)) myMap.exists(_ == "fish" -> 3)
myMap.values.exists(_ == 3) myMap.exists(_._2 == 3)
myMap.keySet.exists(_ == "fish") myMap.exists(_._1 == "fish") myMap.contains("fish")
val mymap = Map(9->"lolo", 7->"lala") mymap.exists(_._1 == 7) mymap.exists(x => x._1 == 7 && x._2 == "lolo") mymap.exists(x => x._1 == 7 && x._2 == "lala")
for (first <- Some(1); second <- List(1,2,3)) yield (first,second) <console>:6: error: type mismatch; found : List[(Int, Int)] required: Option[?] for (first <- Some(1); second <- List(1,2,3)) yield (first,second)
for (first <- List(1,2,3); second <- Some(1)) yield (first,second) res41: List[(Int, Int)] = List((1,1), (2,1), (3,1))
for (first <- Some(1); second <- Some(2)) yield (first,second)
for(x <- Some(1).toSeq ; y <- List(1,2,3)) yield (x, y)
val f = (i:Int) => if (i > 0) Some(List.range(0, i)) else None for (i <- Some(5); j <- f(i)) yield j for (i <- None; j <- f(i)) yield j for (i <- Some(-3); j <- f(i)) yield j
scala> val foo: Option[Seq[Int]] = Some(Seq(1, 2, 3, 4, 5)) foo: Option[Seq[Int]] = Some(List(1, 2, 3, 4, 5)) scala> foo.flatten <console>:13: error: Cannot prove that Seq[Int] <:< Option[B]. foo.flatten ^ scala> val bar: Seq[Seq[Int]] = Seq(Seq(1, 2, 3, 4, 5)) bar: Seq[Seq[Int]] = List(List(1, 2, 3, 4, 5)) scala> bar.flatten res1: Seq[Int] = List(1, 2, 3, 4, 5) scala> foo.toSeq.flatten res2: Seq[Int] = List(1, 2, 3, 4, 5)
libraryDependencies += "com.typesafe.play" %% "play-ws" % "2.4.3"
val wsClient = NingWSClient() wsClient .url("http: .get() .map { wsResponse => }
val request = sttp .cookie("session", "*!@ .body(file) .put(uri"http: .auth.basic("me", "1234") .header("Custom-Header", "Custom-Value") .response(asByteArray)
implicit val sttpHandler = AsyncHttpClientFutureHandler() val futureFirstResponse: Future[Response[String]] = request.send()
import cirrus.clients.BasicHTTP.GET import scala.concurrent.Await import scala.concurrent.duration._ object MinimalExample extends App { val html = Await.result(Cirrus(GET("https: println(html) }
libraryDependencies += "com.github.godis" % "cirrus_2.11" % "1.4.1"
import com.twitter.finagle.{Http, Service} import com.twitter.finagle.http import com.twitter.util.{Await, Future} object Client extends App { val client: Service[http.Request, http.Response] = Http.newService("www.scala-lang.org:80") val request = http.Request(http.Method.Get, "/") request.host = "www.scala-lang.org" val response: Future[http.Response] = client(request) Await.result(response.onSuccess { rep: http.Response => println("GET success: " + rep) }) }
val map = scala.collection.mutable.Map map("mykey") = "myval" map += "mykey" -> "myval" map.put("mykey","myval")
scala> val map = scala.collection.mutable.Map[String,String]() map: scala.collection.mutable.Map[String,String] = Map() scala> map("k1") = "v1" scala> map res1: scala.collection.mutable.Map[String,String] = Map((k1,v1)) scala> map += "k2" -> "v2" res2: map.type = Map((k1,v1), (k2,v2)) scala> map.put("k3","v3") res3: Option[String] = None scala> map res4: scala.collection.mutable.Map[String,String] = Map((k3,v3), (k1,v1), (k2,v2))
val map = Map( "mykey" -> "myval", "myotherkey" -> "otherval" )
val map = collection.mutable.Map( "mykey" -> "myval", "myotherkey" -> "otherval" ) map += "nextkey" -> "nextval"
var map = Map( "mykey" -> "myval", "myotherkey" -> "otherval" ) map += "nextkey" -> "nextval"
val map : Map[String, String] = Map.empty val map = Map.empty[String,String] val map = collection.mutable.Map.empty[String,String]
map: collection.mutable.Map.type = scala.collection.mutable.Map$@fae93e
scala> val map = scala.collection.mutable.Map[String, Int]() map: scala.collection.mutable.Map[String,Int] = Map() scala> map("asdf") = 9 scala> map res6: scala.collection.mutable.Map[String,Int] = Map((asdf,9))
var test = scala.collection.mutable.Map.empty[String, String] test("myKey") = "myValue"
scala> val m1 = Map("k0" -> "v0") m1: scala.collection.immutable.Map[String,String] = Map(k0 -> v0)
scala> val m2 = m1 + ("k1" -> "v1") m2: scala.collection.immutable.Map[String,String] = Map(k0 -> v0, k1 -> v1)
scala> var d= collection.mutable.Map[Any, Any]() d: scala.collection.mutable.Map[Any,Any] = Map()
scala> var d= collection.mutable.Map[Any, Any]("a"->3,1->234,2->"test") d: scala.collection.mutable.Map[Any,Any] = Map(2 -> test, a -> 3, 1 -> 234)
scala> d res123: scala.collection.mutable.Map[Any,Any] = Map(2 -> test, 100 -> new element, a -> ABC, 1 -> 234)
scala> val s = "Dave" s: java.lang.String = Dave scala> val p = s:Object p: java.lang.Object = Dave scala> p.length <console>:7: error: value length is not a member of java.lang.Object p.length ^ scala> p.getClass res10: java.lang.Class[_ <: java.lang.Object] = class java.lang.String scala> s.getClass res11: java.lang.Class[_ <: java.lang.Object] = class java.lang.String scala> p.asInstanceOf[String].length res9: Int = 4
scala> val s = "Dave" s: java.lang.String = Dave scala> val p = s: Object p: java.lang.Object = Dave scala> val ss = scala.collection.mutable.Set(s) ss: scala.collection.mutable.Set[java.lang.String] = Set(Dave) scala> val ps = scala.collection.mutable.Set(p) ps: scala.collection.mutable.Set[java.lang.Object] = Set(Dave) scala> ss += Nil <console>:7: error: type mismatch; found : scala.collection.immutable.Nil.type (with underlying type object Nil) required: java.lang.String ss += Nil ^ scala> ps += Nil res3: ps.type = Set(List(), Dave)
def prefixesOf(s: String) = s.foldLeft(Nil) { case (head :: tail, char) => (head + char) :: head :: tail case (lst, char) => char.toString :: lst }
def prefixesOf(s: String) = s.foldLeft(Nil: List[String]) { case (head :: tail, char) => (head + char) :: head :: tail case (lst, char) => char.toString :: lst }
def firstVowel(s: String) = s.foldLeft(None: Option[Char]) { case (None, char) => if ("aeiou" contains char.toLower) Some(char) else None case (vowel, _) => vowel }
Expr1 ::= ... | PostfixExpr Ascription Ascription ::= ‘:’ InfixType | ‘:’ Annotation {Annotation} | ‘:’ ‘_’ ‘*’
scala> val x = List(1,2,3,4) x: List[Int] = List(1, 2, 3, 4) scala> x.foldLeft(Nil)( (acc,elem) => elem::acc) <console>:9: error: type mismatch; found : List[Int] required: scala.collection.immutable.Nil.type x.foldLeft(Nil)( (acc,elem) => elem::acc) ^ scala> x.foldLeft(Nil:List[Int])( (acc,elem) => elem::acc ) res2: List[Int] = List(4, 3, 2, 1)
scala> x.foldLeft(List.empty[Int])( (acc,elem) => elem::acc ) res3: List[Int] = List(4, 3, 2, 1)
def t1 : Option[Option[String]] = Some(None) > t1: Option[Option[String]]
def t2 = Some(None: Option[String]) > t2: Some[Option[String]]
import java.nio.file.{Files, Paths} val byteArray = Files.readAllBytes(Paths.get("/path/to/file"))
val bis = new BufferedInputStream(new FileInputStream(fileName)) val bArray = Stream.continually(bis.read).takeWhile(-1 !=).map(_.toByte).toArray
val is = new FileInputStream(fileName) val cnt = is.available val bytes = Array.ofDim[Byte](cnt) is.read(bytes) is.close()
import scala.io._ import java.io._ object Main { def main(args: Array[String]) { val ss = Source.fromFile("data.bin") println("Scala:" + ss.next.toInt) ss.close val bis = new BufferedInputStream(new FileInputStream("data.bin")) println("Java:" + bis.read) bis.close } }
import org.apache.commons.compress.utils.IOUtils val file = new File("data.bin") IOUtils.toByteArray(new FileInputStream(file))
val arrayOfTuples = List((1, "Two"), (3, "Four")) arrayOfTuples.map { (e1: Int, e2: String) => e1.toString + e2 }
arrayOfTuples.map { t => val e1 = t._1 val e2 = t._2 e1.toString + e2 }
arrayOfTuples map {case (e1: Int, e2: String) => e1.toString + e2}
import Function.tupled arrayOfTuples map tupled { (e1, e2) => e1.toString + e2 }
arrayOfTuples.map { t => val (e1,e2) = t e1.toString + e2 }
case class MyClass(param1: String, param2: String) val x = MyClass("hello", "world")
getCCParams(x) returns "param1" -> "hello", "param2" -> "world"
def getCCName(caseobj: Product) = caseobj.productPrefix getCCName(x) returns "MyClass"
def getCCParams(cc: AnyRef) = (Map[String, Any]() /: cc.getClass.getDeclaredFields) {(a, f) => f.setAccessible(true) a + (f.getName -> f.get(cc)) }
def getCCParams(cc: Product) = cc.getClass.getDeclaredFields.map( _.getName ) .zip( cc.productIterator.to ).toMap
def getCCParams(cc: Product) = { val values = cc.productIterator cc.getClass.getDeclaredFields.map( _.getName -> values.next ).toMap }
def getCCParams(cc: Product): Map[String, Any] = { val values = cc.productIterator cc.getClass.getDeclaredFields.map { _.getName -> (values.next() match { case p: Product if p.productArity > 0 => getCCParams(p) case x => x }) }.toMap }
case class Person(name:String, age:Int) def personToMap(person: Person): Map[String, Any] = { val fieldNames = person.getClass.getDeclaredFields.map(_.getName) val vals = Person.unapply(person).get.productIterator.toSeq fieldNames.zip(vals).toMap } scala> println(personToMap(Person("Tom", 50))) res02: scala.collection.immutable.Map[String,Any] = Map(name -> Tom, age -> 50)
import tools.nsc.interpreter.ProductCompletion def getCCParams(cc: Product) = { val pc = new ProductCompletion(cc) pc.caseNames.zip(pc.caseFields).toMap }
case class X(a: Boolean, b: String,c:Int) case class Y(a: String, b: String)
import shapeless._ import shapeless.ops.product._ import shapeless.syntax.std.product._ object X { implicit val lgenX = LabelledGeneric[X] } object Y { implicit val lgenY = LabelledGeneric[Y] }
object ToMapImplicits { implicit class ToMapOps[A <: Product](val a: A) extends AnyVal { def mkMapAny(implicit toMap: ToMap.Aux[A, Symbol, Any]): Map[String, Any] = a.toMap[Symbol, Any] .map { case (k: Symbol, v) => k.name -> v } } implicit class ToMapOps2[A <: Product](val a: A) extends AnyVal { def mkMapString(implicit toMap: ToMap.Aux[A, Symbol, Any]): Map[String, String] = a.toMap[Symbol, Any] .map { case (k: Symbol, v) => k.name -> v.toString } } }
object Run extends App { import ToMapImplicits._ val x: X = X(true, "bike",26) val y: Y = Y("first", "second") val anyMapX: Map[String, Any] = x.mkMapAny val anyMapY: Map[String, Any] = y.mkMapAny println("anyMapX = " + anyMapX) println("anyMapY = " + anyMapY) val stringMapX: Map[String, String] = x.mkMapString val stringMapY: Map[String, String] = y.mkMapString println("anyMapX = " + anyMapX) println("anyMapY = " + anyMapY) }
import org.json4s.{Extraction, _} case class MyClass(param1: String, param2: String) val x = MyClass("hello", "world") Extraction.decompose(x)(DefaultFormats).values.asInstanceOf[Map[String,String]]
object CaseMappingTest { case class MyCase(a: String, b: Int) def caseClassToMap(obj: AnyRef) = { val c = obj.getClass val predefined = List("$tag", "productArity", "productPrefix", "hashCode", "toString") val casemethods = c.getMethods.toList.filter{ n => (n.getParameterTypes.size == 0) && (n.getDeclaringClass == c) && (! predefined.exists(_ == n.getName)) } val values = casemethods.map(_.invoke(obj, null)) casemethods.map(_.getName).zip(values).foldLeft(Map[String, Any]())(_+_) } def main(args: Array[String]) { println(caseClassToMap(MyCase("foo", 1))) } }
commons.mapper.Mappers.Mappers.beanToMap(caseClassBean)
(x.productElementNames zip x.productIterator).toMap
val year = sc.textFile("apat63_99.txt").map(_.split(",")(1)).flatMap(_.split(",")).map((_,1)).reduceByKey((_+_)).map(_.swap) year.saveAsTextFile("year")
package com.whatever.package import org.apache.spark.rdd.RDD import org.apache.hadoop.fs.{FileSystem, FileUtil, Path} import org.apache.hadoop.io.compress.CompressionCodec object SparkHelper { implicit class RDDExtensions(val rdd: RDD[String]) extends AnyVal { def saveAsSingleTextFile(path: String): Unit = saveAsSingleTextFileInternal(path, None) def saveAsSingleTextFile(path: String, codec: Class[_ <: CompressionCodec]): Unit = saveAsSingleTextFileInternal(path, Some(codec)) private def saveAsSingleTextFileInternal( path: String, codec: Option[Class[_ <: CompressionCodec]] ): Unit = { val hdfs = FileSystem.get(rdd.sparkContext.hadoopConfiguration) hdfs.delete(new Path(s"$path.tmp"), true) codec match { case Some(codec) => rdd.saveAsTextFile(s"$path.tmp", codec) case None => rdd.saveAsTextFile(s"$path.tmp") } hdfs.delete(new Path(path), true) FileUtil.copyMerge( hdfs, new Path(s"$path.tmp"), hdfs, new Path(path), true, rdd.sparkContext.hadoopConfiguration, null ) hdfs.delete(new Path(s"$path.tmp"), true) } } }
import com.whatever.package.SparkHelper.RDDExtensions rdd.saveAsSingleTextFile("path/to/file.txt") import org.apache.hadoop.io.compress.GzipCodec rdd.saveAsSingleTextFile("path/to/file.txt.gz", classOf[GzipCodec])
val year = sc.textFile("apat63_99.txt").map(_.split(",")(1)).flatMap(_.split(",")).map((_,1)).reduceByKey((_+_)).map(_.swap) var repartitioned = year.repartition(1) repartitioned.saveAsTextFile("C:/Users/TheBhaskarDas/Desktop/wc_spark00")
pair_result.coalesce(1).saveAsTextFile("/app/data/")
val year = sc.textFile("apat63_99.txt") .map(_.split(",")(1)) .flatMap(_.split(",")) .map((_,1)) .reduceByKey((_+_)).map(_.swap) year.saveAsTextFile("year")
type RestfulParams = Map[String, String] def canonicalize(params: RestfulParams): String = { ... }
object RestfulTypes { type RestfulParams = Map[String, String] etc }
import utils.{RestfulTypes => RT} def get(resource: String, params: RT.RestfulParams): String = { ... }
trait RestfulTypes { type Params = Map[String,String] } object MyRestService extends RestService with RestfulTypes { }
./project/project/project/target ./project/project/target ./project/target
rmdir /s /q target project/target project/project/target
-Dsbt.global.base=project/.sbtboot -Dsbt.boot.directory=project/.boot -Dsbt.ivy.home=project/.ivy
find . -regextype posix-awk -regex \.(/project)*/target -exec rm -r {} +
find -E . -regex \.(/project)*/target -exec rm -r {} +
def printFirst(x : Array[T] forSome {type T}) = println(x(0))
def addToFirst(x : Array[T] forSome {type T <: Integer}) = x(0) + 1
type In = Long type Count = Int type Out = Count type S = Map[Int, Count] val inputToIn: String => Option[In] = s => try Some(s.toLong) catch { case _ : Throwable => None } def transition(in: In): S => (S, Out) = s => { val n = s.getOrElse(in, 0); (s + (in -> n+1), n+1) } val ZeroOut: Out = 0 val InitialState: S = Map.empty
val runOnce = StateT[IO, S, Out](s => IO.readLn.map(inputToIn) flatMap { case None => IO((s, ZeroOut)) case Some(in) => val (t, o) = transition(in)(s) IO.putStrLn(t.toString) |+| IO.putStrLn(o.toString) >| IO((t, o)) }) Stream.continually(runOnce).sequenceU.eval(InitialState)
type Transition = S => (S, Out) val NoTransition: Transition = s => (s, 0) io.stdInLines.map(inputToIn).map(_.fold(NoTransition)(transition))
for { i <- Process.eval(Task.now(InitialState)) l <- io.stdInLines.map(inputToIn) ...
type In_ = (S, Option[In]) type Out_ = (S, Out) val input: Process[Task, In_] = for { i <- Process.emit(InitialState) o <- io.stdInLines.map(inputToIn) } yield (i, o) val prog = input.pipe(process1.collect[In_, Out_]) { case (s, Some(in)) => transition(in)(s) }).to(io.stdOutLines.contramap[Out_](_.toString))
type In_ = In type Out_ = (S, Out) val InitialOut_ = (InitialState, ZeroOut) val program = io.stdInLines.collect(Function.unlift(inputToIn)).pipe( process1.scan[In_, Out_](InitialOut_) { case ((s, _), in) => transition(in)(s) }).to(io.stdOutLines.contramap[Out_](_.shows))
val m = Map("a" -> 1, "b" -> 2) val incM = m map {case (key, value) => (key, value + 1)}
val m = Map(1 -> "one", 2 -> "two") def f(k: Int, v: String) = k + "-" + v m map {case (k, v) => (k, f(k, v))}
def mapKeysAndValues[A,B,C](input: Map[A,B], fun: (A, B) => C) = input map {case(k,v) => (k, fun(k, v))}
mapKeysAndValues( Map(1 -> "one", 2 -> "two"), (k: Int, v: String) => k + "-" + v )
m map (t => (t._1, t._2 + 1)) m map (t => t._1 -> t._2 + 1)
scala> def fst[A, B] = (x: (A, B)) => x._1 fst: [A, B]=> (A, B) => A scala> Map(1 -> "Lorem", 2 -> "Ipsum").map(fst &&& Function.tupled(_.toString + _)) res1: scala.collection.immutable.Map[Int,java.lang.String] = Map(1 -> 1Lorem, 2 -> 2Ipsum)
class MyMapLike[K,V](m:MapLike[K,V,_]){ def mapKeysAndValues[R](f: (K, V) => R)={ m.map{case (k,v)=> f(k,v)} } } object MyMapLike{ implicit def maplike2mymaplike[K,V](ml:MapLike[K,V,_]):MyMapLike[K,V]=new MyMapLike(m) } import MyMapLike._ Map(1 -> "one", 2 -> "two").mapKeysAndValues(k,v=>v*k)
import scala.actors.Futures._ val urls: List[String] = ... val fimages: List[Future[...]] = urls.map (url => future { download url }) fimages.foreach (_.foreach (display _))
import scala.concurrent.{future, blocking, Future, Await, ExecutionContext.Implicits.global} import scala.concurrent.duration._ val urls: List[String] = ... val imagesFuts: List[Future[...]] = urls.map { url => future { blocking { download url } } } val futImages: Future[List[...]] = Future.sequence(imagesFuts) Await.result(futImages, 10 seconds).foreach(display)
val all = Future.traverse(urls){ url => val f = future(download url) /*(downloadContext)*/ f.onComplete(display)(displayContext) f } Await.result(all, ...)
fimages.foreach (_.foreach(im => SwingUtilities.invokeLater(new Runnable { display im })))
val result = Http("http: .header("Content-Type", "application/json") .header("Charset", "UTF-8") .option(HttpOptions.readTimeout(10000)).asString
libraryDependencies += "org.scalaj" % "scalaj-http_2.11" % "2.3.0"
import spray.client.pipelining._ val url = "http: val pipeline: HttpRequest => Future[HttpResponse] = sendReceive val responseFuture1: Future[String] = pipeline(Post(Uri(url) withParams ("param" -> paramValue), yourPostData) map (_.entity.asString) val responseFuture2: Future[String] = pipeline(Post(url, yourPostData)) map (_.entity.asString)
import dispatch._ val svc = url("http: val country = Http(svc OK as.String) for (c <- country) println(c)
private def buildStockMasterUrl(url:String, stockStatus:Option[String]) = { stockStatus match { case Some(stockStatus) => s"$url?stockStatus=${stockStatus}" case _ => url } } private def fetchBooksMasterData(stockStatus:Option[String]): util.ArrayList[BooksMasterData] = { val url: String = buildBooksMasterUrl("http: val booksMasterJson : String = scala.io.Source.fromURL(url).mkString val mapper = new ObjectMapper() apper.readValue(booksMasterJson,classOf[util.ArrayList[BooksMasterData]]) } case class BooksMasterData(id:String,description: String,category: String)
test("validate booksMasterData resource") { val booksMasterData = fetchBooksMasterData(Option(null)) booksMasterData.size should be (740) }
val dm = List[String]() val dk = List[Map[String,Object]]() ..... dm.add("text") dk.add(Map("1" -> "ok"))
var dm = List[String]() var dk = List[Map[String,AnyRef]]() ..... dm = "text" :: dm dk = Map(1 -> "ok") :: dk
val l = List.fill(50)(scala.util.Random.nextInt) val l = Stream.continually(scala.util.Random.nextInt).takeWhile(x => x > 0).toList val l = List.tabulate(5)(x => x * 2) val l = List.iterate(1, 10)(x => x * 2) val l = Stream.iterate(0)(x => x * 2 + 1).takeWhile(x => x < 1000).toList val l = (for (line <- scala.io.Source.fromFile("filename.txt").getLines) yield line.length).toList
scala> val list = scala.collection.mutable.MutableList[String]() list: scala.collection.mutable.MutableList[String] = MutableList() scala> list += "hello" res0: list.type = MutableList(hello) scala> list += "world" res1: list.type = MutableList(hello, world) scala> list mkString " " res2: String = hello world
scala> val strList = List.empty[String] strList: List[String] = List() scala> strList:+ "Text" res3: List[String] = List(Text) scala> val mapList = List.empty[Map[String, Any]] mapList: List[Map[String,Any]] = List() scala> mapList :+ Map("1" -> "ok") res4: List[Map[String,Any]] = List(Map(1 -> ok))
import scala.collection.mutable.ListBuffer val dm = ListBuffer[String]() dm: scala.collection.mutable.ListBuffer[String] = ListBuffer() dm += "text1" dm += "text2" dm = ListBuffer(text1, text2)
val list = List(1, 2, 3) var go = true val result = for(i <- list; if(go)) yield { go = false i }
val result = list withFilter { case i => go } map { case i => { go = false i } }
val r2 = list filter { case i => go } map { case i => { go = false i } }
import scala.collection.AbstractIterator class RandomIntIterator extends AbstractIterator[Int] { val rand = new java.util.Random def next: Int = rand.nextInt() def hasNext: Boolean = true } val rand_integers = new RandomIntIterator val rand_naturals = rand_integers.withFilter(_ > 0) val rand_even_naturals = rand_naturals.withFilter(_ % 2 == 0) println(rand_even_naturals.map(identity).take(10).toList) println(rand_even_naturals.map(identity).take(10).toList)
myList.map{ case x: Int => x case x: String => Int.parseInt(x) }
sealed trait Positioning[A] case object Append extends Positioning[Nothing] case class AppendIf[A](condition: A => Boolean) extends Positioning[A] case class Explicit[A](f: Seq[A] => Seq[A]) extends Positioning[A]
scala> :t Append Append.type scala> :t AppendIf[Int](Function const true) AppendIf[Int] -- Haskell haskell> :t Append Append :: Positioning a haskell> :t AppendIf (const True) AppendIf (const True) :: Positioning a
scala> val subtypeProof = implicitly[AppendIf[Int] <:< Positioning[Int]] subtypeProof: <:<[AppendIf[Int],Positioning[Int]] = <function1>
scala> import play.api.libs.json._ import play.api.libs.json._ scala> val obj = Json.obj("key" -> 3) obj: play.api.libs.json.JsObject = {"key":3} scala> obj.fields res0: Seq[(String, play.api.libs.json.JsValue)] = ArrayBuffer((key,3)) scala> val arr = Json.arr(3, 4) arr: play.api.libs.json.JsArray = [3,4] scala> arr.fields <console>:15: error: value fields is not a member of play.api.libs.json.JsArray arr.fields ^ scala> val jsons = Set(obj, arr) jsons: scala.collection.immutable.Set[Product with Serializable with play.api.libs.json.JsValue] = Set({"key":3}, [3,4])
scala> import argonaut._, Argonaut._ import argonaut._ import Argonaut._ scala> val obj = Json.obj("k" := 3) obj: argonaut.Json = {"k":3} scala> obj.obj.map(_.toList) res6: Option[List[(argonaut.Json.JsonField, argonaut.Json)]] = Some(List((k,3))) scala> val arr = Json.array(jNumber(3), jNumber(4)) arr: argonaut.Json = [3,4] scala> arr.obj.map(_.toList) res7: Option[List[(argonaut.Json.JsonField, argonaut.Json)]] = None
sealed trait ADT case class Case1(x: Int) extends ADT case class Case2(x: String) extends ADT val xs = List(Case1(42), Case1(12))
val a = Pair (1,"two") val b = Triple (1,"two",3.0)
import shapeless.syntax.std.tuple._ val t = ("a", 2, true, 0.0) val s = t(0) val i = t(1)
trait Addable[T] { def zero: T def append(a: T, b: T): T }
implicit object IntIsAddable extends Addable[Int] { def zero = 0 def append(a: Int, b: Int) = a + b } implicit object StringIsAddable extends Addable[String] { def zero = "" def append(a: String, b: String) = a + b }
def sum[T](xs: List[T])(implicit addable: Addable[T]) = xs.FoldLeft(addable.zero)(addable.append) def sum[T : Addable](xs: List[T]) = { val addable = implicitly[Addable[T]] xs.FoldLeft(addable.zero)(addable.append) }
case class Default[T](val default: T) object Default { implicit def IntDefault: Default[Int] = Default(0) implicit def OptionDefault[T]: Default[Option[T]] = Default(None) ... }
map += key -> (value :: map.getOrElse(key, List()))
trait Addable[C, CC] { def add(c: C, cc: CC) : CC def empty: CC } object Addable { implicit def listAddable[A] = new Addable[A, List[A]] { def empty = Nil def add(c: A, cc: List[A]) = c :: cc } implicit def addableAddable[A, Add](implicit cbf: CanBuildFrom[Add, A, Add]) = new Addable[A, Add] { def empty = cbf().result def add(c: A, cc: Add) = (cbf(cc) += c).result } }
class RichCollectionMap[A, C, B[_], M[X, Y] <: collection.Map[X, Y]](map: M[A, B[C]])(implicit adder: Addable[C, B[C]]) { def updateSeq[That](a: A, c: C)(implicit cbf: CanBuildFrom[M[A, B[C]], (A, B[C]), That]): That = { val pair = (a -> adder.add(c, map.getOrElse(a, adder.empty) )) (map + pair).asInstanceOf[That] } def +++[That](t: (A, C))(implicit cbf: CanBuildFrom[M[A, B[C]], (A, B[C]), That]): That = updateSeq(t._1, t._2)(cbf) } implicit def toRichCollectionMap[A, C, B[_], M[X, Y] <: col
/** * Created by nihat.hosgur on 2/19/17. */ case class PrintTwiceString(val original: String) { def printTwice = original + original } object TypeClassString extends App { implicit def stringToString(s: String) = PrintTwiceString(s) val name: String = "Nihat" name.printTwice }
val strings = List("a", "b", "c") val myString = "a" strings.find(x=>x == myString) match { case Some(_) => myFunction(true) case None => myFunction(false) }
myFunction(strings.exists { x => customPredicate(x) })
myFunction(strings.find( _ == mystring ).isDefined)
trait Narrowable[A] extends Iterable[A] { def narrow[B <: A & B <: AnyRef] : Iterable[B] }
trait Narrowable[A] extends Iterable[A] { def narrow[B <: A with AnyRef] : Iterable[B] }
lazy val coreProject: Project = Project( id = "core-project", base = file("./core-project"), )) lazy val extensions: Project = Project( id = "extensions", base = file("./extensions"), dependencies = Seq(coreProject) )
dependencies = Seq(coreProject % "compile->compile;test->test")
lazy val coreProject = Project("core-project") lazy val extensions = Project("extensions").dependsOn(coreProject % "compile->compile;test->test")
object WorkUnitController extends Controller { def updateObject[T](toUpdate: T, body: JsonObject){ val source = gson.fromJson(body, classOf[T]); ... } }
import scala.reflect.ClassTag import scala.reflect._ object WorkUnitController extends Controller { def updateObject[T: ClassTag](toUpdate: T, body: JsonObject){ val source = gson.fromJson(body, classTag[T].runtimeClass) ??? } }
object WorkUnitController extends Controller { def updateObject[T: ClassManifest](toUpdate: T, body: JsonObject){ val source = gson.fromJson(body, classManifest[T].erasure); ... } }
import scala.reflect.ClassTag object WorkUnitController extends Controller { def updateObject[T](toUpdate: T, body: JsonObject)(implicit tag: ClassTag[T]){ val source = gson.fromJson(body, tag.runtimeClass) ??? } }
import scala.util.Try Try(myString.toBoolean).getOrElse(false)
Try(if (p(11).toString == "1" || p(11).toString == "true") true else false).getOrElse(false))
[error] inspect usage: [error] inspect [uses|tree|definitions] <key> Prints the value for [error] [error] inspect [error] ^
addSbtPlugin("net.virtual-void" % "sbt-dependency-graph" % "0.9.2")
lazy val mavenDependencyTree = taskKey[Unit]("Prints a Maven dependency tree") mavenDependencyTree := { val scalaReleaseSuffix = "_" + scalaVersion.value.split( val pomXml = <project> <modelVersion>4.0.0</modelVersion> <groupId>groupId</groupId> <artifactId>artifactId</artifactId> <version>1.0</version> <dependencies> { libraryDependencies.value.map(moduleId => { val suffix = moduleId.crossVersion match { case binary: sbt.librarymanagement.Binary => scalaReleaseSuffix case _ => "" } <dependency> <groupId>{moduleId.organization}</groupId> <artifactId>{moduleId.name + suffix}</artifactId> <version>{moduleId.revision}</version> </dependency> }) } </dependencies> </project> val printer = new scala.xml.PrettyPrinter(160, 2) val pomString = printer.format(pomXml) val pomPath = java.nio.file.Files.createTempFile("", ".xml").toString val pw = new java.io.PrintWriter(new File(pomPath)) pw.write(pomString) pw.close() println(s"Formed pom file: $pomPath") import sys.process._ s"mvn -f $pomPath dependency:tree".! }
name := "Scala Playground" version := "1.0" scalaVersion := "2.10.2" libraryDependencies += "com.twitter" % "algebird-core" % "0.2.0"
initialCommands in console += "import com.twitter.algebird._"
16/06/24 15:42:06 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 0.0 (TID 2, cluster-node-02): java.lang.ExceptionInInitializerError at GroupEvolutionES$$anonfun$6.apply(GroupEvolutionES.scala:579) at GroupEvolutionES$$anonfun$6.apply(GroupEvolutionES.scala:579) at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:390) at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1595) at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157) at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157) at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1858) at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1858) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66) at org.apache.spark.scheduler.Task.run(Task.scala:89) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) Caused by: org.apache.spark.SparkException: A master URL must be set in your configuration at org.apache.spark.SparkContext.<init>(SparkContext.scala:401) at GroupEvolutionES$.<init>(GroupEvolutionES.scala:37) at GroupEvolutionES$.<clinit>(GroupEvolutionES.scala) ... 14 more 16/06/24 15:42:06 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 0.0 (TID 5, cluster-node-02): java.lang.NoClassDefFoundError: Could not initialize class GroupEvolutionES$ at GroupEvolutionES$$anonfun$6.apply(GroupEvolutionES.scala:579) at GroupEvolutionES$$anonfun$6.apply(GroupEvolutionES.scala:579) at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:390) at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1595) at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157) at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157) at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1858) at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1858) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66) at org.apache.spark.scheduler.Task.run(Task.scala:89) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)
SparkSession spark = SparkSession .builder() .appName("Java Spark SQL basic example") .config("spark.master", "local") .getOrCreate();
SparkSession .builder() .appName("Java Spark SQL basic example") .getOrCreate();
SparkConf sparkConf = new SparkConf().setAppName("SOME APP NAME");
SparkConf sparkConf = new SparkConf().setAppName("SOME APP NAME").setMaster("local[2]").set("spark.executor.memory","1g");
SparkSession spark = SparkSession .builder() .appName("SomeAppName") .getOrCreate();
SparkSession spark = SparkSession .builder() .appName("SomeAppName") .config("spark.master", "local") .getOrCreate();
val conf = new SparkConf().setAppName("Samples").setMaster("local") val sc = new SparkContext(conf) val textData = sc.textFile("sample.txt").cache()
SparkConf sparkConf = new SparkConf().setAppName("SOME APP NAME"); WITH SparkConf sparkConf = new SparkConf().setAppName("SOME APP NAME").setMaster("local[2]").set("spark.executor.memory","1g");
package com.asagaama import org.apache.spark.SparkContext import org.apache.spark.SparkConf import org.apache.spark.rdd.RDD /** * Created by asagaama on 16/02/2017. */ object Word { def countWords(sc: SparkContext) = { val input = sc.textFile("/Users/Documents/spark/testscase/test/test.txt") val words = input.flatMap(line => line.split(" ")) val counts = words.map(word => (word, 1)).reduceByKey { case (x, y) => x + y } counts.saveAsTextFile("/Users/Documents/spark/testscase/test/result.txt") } def main(args: Array[String]) = { val conf = new SparkConf().setAppName("wordCount") val sc = new SparkContext(conf) countWords(sc) } }
val conf = new SparkConf().setAppName("wordCount").setMaster("local[*]")
var appName:String ="test" val conf = new SparkConf().setAppName(appName).setMaster("local[*]").set("spark.executor.memory","1g"); val sc = SparkContext.getOrCreate(conf) sc.setLogLevel("WARN")
val spark = SparkSession .builder() .appName("Spark Hive Example") .config("spark.sql.warehouse.dir", warehouseLocation) .enableHiveSupport() .getOrCreate()
val spark = SparkSession .builder() .appName("Spark Hive Example") .config("spark.sql.warehouse.dir", warehouseLocation) .enableHiveSupport() .master("local[*]") .getOrCreate()
import org.apache.spark.sql.SparkSession trait SparkSessionWrapper { lazy val spark:SparkSession = { SparkSession .builder() .getOrCreate() } }
val sc = new SparkContext(master, "WordCount", System.getenv("SPARK_HOME"))
val jobName = "WordCount"; val conf = new SparkConf().setAppName(jobName); val sc = new SparkContext(conf)
val spark = SparkSession .builder() .appName("Spark SQL basic example") .config("spark.some.config.option", "some-value") .master("local[*]") .getOrCreate()
case class Point(x: Int, y: Int) case class ColoredPoint(x: Int, y: Int, c: Color) extends Point(x, y)
case class Point(x: Int, y: Int) case class ColoredPoint(x: Int, y: Int, c: Color) extends Point(x, y) Point(0, 0) equals ColoredPoint(0, 0, RED) Point(0, 0) equals ColoredPoint(0, 0, null) ColoredPoint(0, 0, RED) equals Point(0, 0) ColoredPoint(0, 0, null) equals Point(0, 0)
case class ColoredPoint(x: Int, y: Int, c: String) class RedPoint(x: Int, y: Int) extends ColoredPoint(x, y, "red") class GreenPoint(x: Int, y: Int) extends ColoredPoint(x, y, "green") val colored = ColoredPoint(0, 0, "red") val red1 = new RedPoint(0, 0) val red2 = new RedPoint(0, 0) val green = new GreenPoint(0, 0) red1 equals colored red2 equals colored red1 equals red2 colored equals green red1 equals green red2 equals green def foo(p: GreenPoint) = ???
trait Monad[F[_]] { def flatMap[A, B](f: A => F[B]): F[A] => F[B] }
getUserById(userId: Int): Option[User] = ... getPhone(user: User): Option[Phone] = ...
def getPhoneByUserId(userId: Int): Option[Phone] = getUserById(userId).flatMap(user => getPhone(user))
trait Applicative[F[_]] { def apply[A, B](f: F[A => B]): F[A] => F[B] }
case class Foo(s: Symbol, n: Int) val maybeFoo = for { s <- maybeComputeS(whatever) n <- maybeComputeN(whatever) } yield Foo(s, n)
val maybeFoo = maybeComputeS(whatever).flatMap( s => maybeComputeN(whatever).map(n => Foo(s, n)) )
val maybeFoo = (maybeComputeS(whatever) |@| maybeComputeN(whatever))(Foo(_, _))
trait Functor[C[_]] { def map[A, B](f : A => B): C[A] => C[B] }
val g = (x: Int) => (y: Int) => x + y Option(5) map g
trait Applicative[F[_]] { def apply[A, B](f: F[A => B]): F[A] => F[B] }
(Applicative[Option] apply (Functor[Option] map g)(Option(5)))(Option(10))
class Animal {} class Dog extends Animal {} class Car {} class SportsCar extends Car {}
case class List[+B](elements: B*) {} val animals: List[Animal] = List( new Dog(), new Animal() ) val cars: List[Car] = List ( new Car(), new SportsCar() )
case class Shelter(animals: List[Animal]) {} val animalShelter: Shelter = Shelter( List(new Animal()): List[Animal] ) val dogShelter: Shelter = Shelter( List(new Dog()): List[Dog] )
case class Barn[A <: Animal](animals: A*) {} val animalBarn: Barn[Animal] = Barn( new Dog(), new Animal() ) val carBarn = Barn( new SportsCar() ) /* error: inferred type arguments [SportsCar] do not conform to method apply val carBarn = Barn(new SportsCar()) ^ */
for( i <- 0 to origCols.length - 1) { df.withColumnRenamed( df.columns(i), df.columns(i).toLowerCase ); }
val df = Seq((1L, "a", "foo", 3.0)).toDF df.printSchema
val newNames = Seq("id", "x1", "x2", "x3") val dfRenamed = df.toDF(newNames: _*) dfRenamed.printSchema
val lookup = Map("_1" -> "foo", "_3" -> "bar") df.select(df.columns.map(c => col(c).as(lookup.getOrElse(c, c))): _*)
lookup.foldLeft(df)((acc, ca) => acc.withColumnRenamed(ca._1, ca._2))
val nested = spark.read.json(sc.parallelize(Seq( """{"foobar": {"foo": {"bar": {"first": 1.0, "second": 2.0}}}, "id": 1}""" ))) nested.printSchema @transient val foobarRenamed = struct( struct( struct( $"foobar.foo.bar.first".as("x"), $"foobar.foo.bar.first".as("y") ).alias("point") ).alias("location") ).alias("record") nested.select(foobarRenamed, $"id").printSchema
nested.select($"foobar".cast( "struct<location:struct<point:struct<x:double,y:double>>>" ).alias("record")).printSchema
import org.apache.spark.sql.types._ nested.select($"foobar".cast( StructType(Seq( StructField("location", StructType(Seq( StructField("point", StructType(Seq( StructField("x", DoubleType), StructField("y", DoubleType))))))))) ).alias("record")).printSchema
merchants_df_renamed = merchants_df.toDF( merchants_df_renamed.printSchema()
def aliasAllColumns(t: DataFrame, p: String = "", s: String = ""): DataFrame = { t.select( t.columns.map { c => t.col(c).as( p + c + s) } : _* ) }
class TestDoubleDef{ def foo(p:List[String]) = {} def foo(p:List[Int]) = {} }
[error] double definition: [error] method foo:(List[String])Unit and [error] method foo:(List[Int])Unit at line 120 [error] have same type after erasure: (List)Unit
case class IntList(list: List[Int]) case class StringList(list: List[String]) implicit def il(list: List[Int]) = IntList(list) implicit def sl(list: List[String]) = StringList(list) def foo(i: IntList) { println("Int: " + i.list)} def foo(s: StringList) { println("String: " + s.list)}
def foo(p: List[String]) { println("Strings") } def foo[X: ClassManifest](p: List[Int]) { println("Ints") } def foo[X: ClassManifest, Y: ClassManifest](p: List[Double]) { println("Doubles") }
def foo(list: => List[Int]) = { println("Int-List " + list)} def foo(list: List[String]) = { println("String-List " + list)}
class TestMultipleDef { def foo(p:List[String]) = () def foo(p:List[Int])(implicit d: DummyImplicit) = () def foo(p:List[java.util.Date])(implicit d1: DummyImplicit, d2: DummyImplicit) = () }
class TestDoubleDef { object dummy1 { implicit val dummy: dummy1.type = this } object dummy2 { implicit val dummy: dummy2.type = this } def foo(p:List[String])(implicit d: dummy1.type) = {} def foo(p:List[Int])(implicit d: dummy2.type) = {} } object App extends Application { val a = new TestDoubleDef() a.foo(1::2::Nil) a.foo("a"::"b"::Nil) }
class TestDoubleDef{ def foo(p:List[String])(implicit ignore: String) = {} def foo(p:List[Int])(implicit ignore: Int) = {} } object App extends Application { implicit val x = 0 implicit val y = "" val a = new A() a.foo(1::2::Nil) a.foo("a"::"b"::Nil) }
@annotation.implicitNotFound(msg = "Type ${T} not supported only Int and String accepted") sealed abstract class Acceptable[T]; object Acceptable { implicit object IntOk extends Acceptable[Int] implicit object StringOk extends Acceptable[String] } class TestDoubleDef { def foo[A : Acceptable : Manifest](p:List[A]) = { val m = manifest[A] if (m equals manifest[String]) { println("String") } else if (m equals manifest[Int]) { println("Int") } } }
scala> val a = new TestDoubleDef a: TestDoubleDef = TestDoubleDef@f3cc05f scala> a.foo(List(1,2,3)) Int scala> a.foo(List("test","testa")) String scala> a.foo(List(1L,2L,3L)) <console>:21: error: Type Long not supported only Int and String accepted a.foo(List(1L,2L,3L)) ^ scala> a.foo("test") <console>:9: error: type mismatch; found : java.lang.String("test") required: List[?] a.foo("test") ^
object Foo { implicit def stringImpl = new Foo[String] { def apply(list : List[String]) = println("String") } implicit def intImpl = new Foo[Int] { def apply(list : List[Int]) = println("Int") } } def foo[A : Foo](x : List[A]) = implicitly[Foo[A]].apply(x)
scala> @annotation.implicitNotFound(msg = "Foo does not support ${T} only Int and String accepted") | sealed trait Foo[T] { def apply(list : List[T]) : Unit }; object Foo { | implicit def stringImpl = new Foo[String] { | def apply(list : List[String]) = println("String") | } | implicit def intImpl = new Foo[Int] { | def apply(list : List[Int]) = println("Int") | } | } ; def foo[A : Foo](x : List[A]) = implicitly[Foo[A]].apply(x) defined trait Foo defined module Foo foo: [A](x: List[A])(implicit evidence$1: Foo[A])Unit scala> foo(1) <console>:8: error: type mismatch; found : Int(1) required: List[?] foo(1) ^ scala> foo(List(1,2,3)) Int scala> foo(List("a","b","c")) String scala> foo(List(1.0)) <console>:32: error: Foo does not support Double only Int and String accepted foo(List(1.0)) ^
import scala.reflect.Manifest object Reified { def foo[T](p:List[T])(implicit m: Manifest[T]) = { def stringList(l: List[String]) { println("Strings") } def intList(l: List[Int]) { println("Ints") } val StringClass = classOf[String] val IntClass = classOf[Int] m.erasure match { case StringClass => stringList(p.asInstanceOf[List[String]]) case IntClass => intList(p.asInstanceOf[List[Int]]) case _ => error("???") } } def main(args: Array[String]) { foo(List("String")) foo(List(1, 2, 3)) } }
object Baz { private object dummy1 { implicit val dummy: dummy1.type = this } private object dummy2 { implicit val dummy: dummy2.type = this } def foo(xs: String*)(implicit e: dummy1.type) = 1 def foo(xs: Int*)(implicit e: dummy2.type) = 2 }
final object ErasureEvidence { class E1 private[ErasureEvidence]() class E2 private[ErasureEvidence]() implicit final val e1 = new E1 implicit final val e2 = new E2 } import ErasureEvidence._ class Baz { def foo(xs: String*)(implicit e:E1) = 1 def foo(xs: Int*)(implicit e:E2) = 2 }
final object ErasureEvidence { class E1[T] private[ErasureEvidence]() class E2[T] private[ErasureEvidence]() implicit def e1[T] = new E1[T] implicit def e2[T] = new E2[T] } import ErasureEvidence._ class Baz { def foo(xs: String*)(implicit e:E1[Baz]) = 1 def foo(xs: Int*)(implicit e:E2[Baz]) = 2 }
class Supercalifragilisticexpialidocious[A,B,C,D,E,F,G,H,I,J,K,L,M] { private trait E def foo(xs: String*)(implicit e:E1[E]) = 1 def foo(xs: Int*)(implicit e:E2[E]) = 2 }
def foo[T <: String](s: List[T]) { println("Strings: " + s) } def foo[T <: Int](i: List[T]) { println("Ints: " + i) }
def foo[T : String](s: List[T]) { println("Strings: " + s) } def foo[T : String2](s: List[T]) { println("String2s: " + s) }
new HashPartitoner(1) new HashPartitoner(2) new HashPartitoner(10)
val rdd = sc.parallelize(for { x <- 1 to 3 y <- 1 to 2 } yield (x, None), 8)
import org.apache.spark.rdd.RDD def countByPartition(rdd: RDD[(Int, None.type)]) = { rdd.mapPartitions(iter => Iterator(iter.length)) }
import org.apache.spark.HashPartitioner val rddOneP = rdd.partitionBy(new HashPartitioner(1))
val rddTwoP = rdd.partitionBy(new HashPartitioner(2))
(1 to 3).map((k: Int) => (k, k.hashCode, k.hashCode % 2))
rddTwoP.mapPartitions(iter => Iterator(iter.map(_._1).toSet)).collect()
val rddSevenP = rdd.partitionBy(new HashPartitioner(7)) rddSevenP.partitions.length
artifactName := { (sv: ScalaVersion, module: ModuleID, artifact: Artifact) => artifact.name + "-" + module.revision + "." + artifact.extension }
def birthdays(from: Option[String], to: Option[String]) = Action { }
GET /birthday controllers.Application.birthday(from: Option[String], to: Option[String])
GET /users controllers.Application.users(max:java.lang.Integer ?= 50, page:java.lang.Integer ?= 0)
public static Result users(Integer max, Integer page) {...}
String from = request().getQueryString("from"); String to = request().getQueryString("to");
import play.libs.F.Option; public static Result birthdays(Option<String> from, Option<String> to) { }
GET /birthday controllers.Application.birthday(from: play.libs.F.Option[String], to: play.libs.F.Option[String])
public static Result birthdays(Option<String> from, Option<String> to) { String blarg = request().getQueryString("blarg"); }
GET /birthdays controllers.Application.method(from: Long, to: Long)
GET /birthdays controllers.Application.method(from: Long ?= 0, to: Long ?= 10)
GET /birthdays/ controllers.Birthdays.getBirthdays(period: util.Period)
public class Period implements QueryStringBindable<Period> { public static final String PATTERN = "dd.MM.yyyy"; public Date start; public Date end; @Override public F.Option<Period> bind(String key, Map<String, String[]> data) { SimpleDateFormat sdf = new SimpleDateFormat(PATTERN); try { start = data.containsKey("startDate")?sdf.parse(data.get("startDate") [0]):null; end = data.containsKey("endDate")?sdf.parse(data.get("endDate")[0]):null; } catch (ParseException ignored) { return F.Option.None(); } return F.Option.Some(this); } @Override public String unbind(String key) { SimpleDateFormat sdf = new SimpleDateFormat(PATTERN); return "startDate=" + sdf.format(start) + "&amp;" + "endDate=" + sdf.format(end); } @Override public String javascriptUnbind() { return null; } public void applyDateFilter(ExpressionList el) { if (this.start != null) el.ge("eventDate", this.start); if (this.end != null) el.le("eventDate", new DateTime(this.end.getTime()).plusDays(1).toDate()); } }
/home/spark/spark-1.6.1-bin-hadoop2.6/bin/spark-submit \ --files /home/spark/jobs/fact_stats_ad.conf \ --conf spark.executor.extraJavaOptions=-Dconfig.fuction.conf \ --conf --class jobs.DiskDailyJob \ --packages com.databricks:spark-csv_2.10:1.4.0 \ --jars /home/spark/jobs/alluxio-core-client-1.2.0-RC2-jar-with-dependencies.jar \ --driver-memory 2g \ /home/spark/jobs/convert_to_parquet.jar \ AD_COOKIE_REPORT FACT_AD_STATS_DAILY | tee /data/fact_ad_stats_daily.log
spark.driver.extraJavaOptions –Dlog4j.configuration=file: spark.executor.extraJavaOptions –Dlog4j.configuration=file: spark.application.properties.file hdfs:
Array(".../spark-submit", ..., "--conf", confValues, ...)
val config = ConfigFactory.parseFile(File<"my-app.conf">) .withFallback(ConfigFactory.load()) .resolve .getConfig("my-app")
spark-submit \ --master yarn \ --deploy-mode cluster \ --name my-app \ --driver-java-options= --files my-app.conf \ my-app.jar
my-app { environment: dev environment: ${?env.override} other: xxx }
spark-submit \ --master yarn \ --deploy-mode cluster \ --name my-app \ --driver-java-options= --files my-app.conf \ my-app.jar
spark-submit --driver-java-options "-Denv=DEV -Dmode=local" --class co.xxx.datapipeline.jobs.EventlogAggregator target/datapipeline-jobs-1.0-SNAPSHOT.jar
def foo() : String = { val x : Option[String] = ... x.getOrException() }
def foo() : String = { val x : Option[String] = ... x.get }
def foo(): String = { val x: Option[String] = None x match { case Some(value) => value case None => throw new MyRuntimeException("blah") } }
def foo(): String = { val x: Option[String] = None x.getOrElse("my alternative value") }
def myGet[A](oa: Option[A]) = oa.getOrElse(throw new RuntimeException("Can
def addPrint(oi:Option[Int]) = oi.map(_+1).foreach(println) addPrint(Some(41)) addPrint(Some(1336)) addPrint(None)
myMap.getOrElse(myKey, throw new MyCustomException("Custom Message HERE")
sealed abstract class Tree case class Node(left: Tree, right: Tree) extends Tree case class Leaf[T](value: T) extends Tree case object Empty extends Tree def dps(t: Tree): Unit = t match { case Node(left, right) => dps(left); dps(right) case Leaf(x) => println("Leaf "+x) }
def balanceMain(elem: List[Char]): Boolean = { if (elem.isEmpty) if (count == 0) true; else false; if (elem.head == balanceMain(elem.tail, open, count + 1);....
def f() = { if (something) "A" else "B" if (somethingElse) 1 else 2 }
def f() = { if(somethingFirst) { if (something) "A" else "B" } else { if (somethingElse) 1 else 2 "C" }
def sum(ns: Int*): Int = ns.foldLeft(0)((n, m) => n + m) scala> sum(33, 42, 99) res2: Int = 174 def sumR(ns: Int*): Int = ns.foldLeft(0)((n, m) => return n + m) scala> sumR(33, 42, 99) res3: Int = 33
def balanceMain(elem: List[Char]): Boolean = { elem.isEmpty && count == 0 }
def balanceMain(elem: List[Char]): Boolean = { if (elem.isEmpty) { count == 0 } else { if (elem.head == "(") { balanceMain(elem.tail, open, count + 1) } ... someBoolExpression } }
def balanceMain(elem: List[Char]): Boolean = { if (elem.isEmpty) if (count == 0) true else false else if (elem.head == balanceMain(elem.tail, open, count + 1) else....
scala> val b = new Object{ def set_=(a: Int) = println(a) } b: java.lang.Object{def set_=(Int): Unit} = $anon$1@17e4cec scala> b.set = 5 <console>:6: error: value set is not a member of java.lang.Object{def set_=(Int): Unit} b.set = 5 ^ scala> val c = new Object{ def set = 0 ; def set_=(a:Int) = println(a) } c: java.lang.Object{def set: Int; def set_=(Int): Unit} = $anon$1@95a253 scala> c.set = 5 5
class test(val x:Int) { def %%(y: Int) = new test(x*y) } var a = new test(10) a.x a %%= 5 a.x
def until(cond: => Boolean)(body: => Unit) = while(!cond) body var a = 0 until (a > 5) {a += 1}
val tuple1 = ("Hello",1) val tuple2 = Tuple2[String,Int]("Hello",1)
trait Gender trait Male extends Gender trait Female extends Gender object Male extends Male object Female extends Female class Person(val g: Gender, val age: Int) object Adult { def unapply(p: Person) = p.age >= 18 } def check(p: Person) = p match { case Adult() => println("An Adult") case _ => println("A Child") } check(new Person(Female, 18)) check(new Person(Male, 17))
object Person { def apply(g: Gender, age: Int) = new Person(g, age) def unapply(p: Person) = if(p.age < 0) None else Some((p.g, p.age)) } val alice = Person(Female, 30) val bob = Person(Male, 25) val Person(alice_gender, alice_age) = alice bob match { case Person(Female, _) => println("Hello ma case Person(Male, age) if age < 18 => println("Hey dude") case _ => println("Hello Sir") } Person(Male,-1) match { case Person(_, _) => println("Hello person") case _ => println("Are you Human?") }
scala> List.unapplySeq(List(1,2,3)) res2: Some[List[Int]] = Some(List(1, 2, 3))
def suml[T: Monoid](xs: List[T]) = { val T = implicitly[Monoid[T]] xs.foldLeft(T.mzero)(T.mplus) }
def suml[T](xs: List[T])(implicit evidence$1: Monoid[T]]) = { ... }
def suml[T: Monoid](xs: List[T]) = { val T = evidence$1 ... }
private[this]object MMMap extends HashMap[A, Set[B]] with MultiMap[A, B]
collection.immutable.Map( x.map(kv => (kv._1,collection.immutable.Set(kv._2.toList: _*))).toList: _* )
scala> val mutableMap = new HashMap[Int, String] mutableMap: scala.collection.mutable.HashMap[Int,String] = Map() scala> mutableMap += 1 -> "a" res5: mutableMap.type = Map((1,a)) scala> mutableMap res6: scala.collection.mutable.HashMap[Int,String] = Map((1,a)) scala> val immutableMap = mutableMap.toMap immutableMap: scala.collection.immutable.Map[Int,String] = Map((1,a)) scala> immutableMap += 2 -> "b" <console>:11: error: reassignment to val immutableMap += 2 -> "b" ^
def toMap[T, U](implicit ev: A <:< (T, U)): immutable.Map[T, U] = { val b = immutable.Map.newBuilder[T, U] for (x <- self) b += x b.result }
ActorRef roundRobinRouter = getContext().actorOf( Props.create(ExampleActor.class).withRouter(new RoundRobinRouter(5)),"router");
class Obj { private def foo(x: Int, y: String): Long = x + y.length }
import scala.reflect.Invocation._ (new Obj) o val x: Long = (new Obj) oo
def add(e:Entity): Option[Long] = { DB.withConnection {implicit conn => SQL("insert into ENTITY(name, description) values({name}, {description})").on( } }
list1::list2 returns: List[Any] = List(List(1, 2), 3, 4) list1:::list2 returns: List[Int] = List(1, 2, 3, 4)
1 :: List(2, 3) will return List(1, 2, 3) List(1, 2) ::: List(3, 4) will return List(1, 2, 3, 4)
scala> val l = List(Some("Hello"), None, Some("World")) l: List[Option[java.lang.String]] = List(Some(Hello), None, Some(World)) scala> l.flatMap( o => o) res0: List[java.lang.String] = List(Hello, World)
l flatMap identity[Option[String]] > List[String] = List(Hello, World)
l.flatMap( x => Option.option2Iterable(identity(x)))
scala> val l = List(Some("Hello"), None, Some("World")) l: List[Option[java.lang.String]] = List(Some(Hello), None, Some(World)) scala> l.flatten[String] res0: List[String] = List(Hello, World)
package models import scala.slick.driver.PostgresDriver.simple._ case class Account(id: Option[Long], email: String, password: String) object Accounts extends Table[Account]("account") { def id = column[Long]("id", O.PrimaryKey, O.AutoInc) def email = column[String]("email") def password = column[String]("password") def * = id.? ~ email ~ password <> (Account, Account.unapply _) }
package test import org.specs2.mutable._ import play.api.test._ import play.api.test.Helpers._ import scala.slick.driver.H2Driver.simple._ import Database.threadLocalSession import models.{Accounts, Account} class AccountSpec extends Specification { "An Account" should { "be creatable" in { Database.forURL("jdbc:h2:mem:test1", driver = "org.h2.Driver") withSession { Accounts.ddl.create Accounts.insert(Account(None, "user@gmail.com", "Password")) val account = for (account <- Accounts) yield account account.first.id.get mustEqual 1 } } } }
import play.api.Application import play.api.GlobalSettings import play.api.Play.current import play.api.db.DB import scala.slick.driver.PostgresDriver.simple._ import Database.threadLocalSession import models.Accounts object Global extends GlobalSettings { override def onStart(app: Application) { lazy val database = Database.forDataSource(DB.getDataSource()) database withSession { Accounts.ddl.create } } }
"net.danieldietrich" %% "slick-integration" % "1.0-SNAPSHOT"
package models import scala.slick.integration._ case class Account(id: Option[Long], email: String, password: String) extends Entity[Account] { def withId(id: Long): Account = copy(id = Some(id)) } trait AccountComponent extends _Component { self: Profile => import profile.simple._ object Accounts extends Mapper[Account]("account") { def email = column[String]("email") def password = column[String]("password") def * = id.? ~ email ~ password <> (Account, Account.unapply _) } }
package models import scala.slick.integration.PlayProfile import scala.slick.integration._DAL import scala.slick.lifted.DDL import play.api.Play.current class DAL(dbName: String) extends _DAL with AccountComponent with PlayProfile { val profile = loadProfile(dbName) def db = dbProvider(dbName) lazy val ddl: DDL = Accounts.ddl } object DAL extends DAL("default")
package test import models._ import models.DAL._ import org.specs2.mutable.Specification import play.api.test.FakeApplication import play.api.test.Helpers._ import scala.slick.session.Session class AccountSpec extends Specification { def fakeApp[T](block: => T): T = running(FakeApplication(additionalConfiguration = inMemoryDatabase() ++ Map("slick.default.driver" -> "scala.slick.driver.H2Driver", "evolutionplugin" -> "disabled"))) { try { db.withSession { implicit s: Session => try { create block } finally { drop } } } } "An Account" should { "be creatable" in fakeApp { val account = Accounts.insert(Account(None, "user@gmail.com", "Password")) val id = account.id id mustNotEqual None Accounts.findById(id.get) mustEqual Some(account) } } }
object EvolutionGenerator extends App { import models.DAL import play.api.test._ import play.api.test.Helpers._ running(FakeApplication(additionalConfiguration = inMemoryDatabase() ++ Map("slick.default.driver" -> "scala.slick.driver.PostgresDriver", "evolutionplugin" -> "disabled"))) { val evolution = ( + DAL.ddl.createStatements.mkString("\n", ";\n\n", ";\n") + + DAL.ddl.dropStatements.mkString("\n", ";\n\n", ";\n")).stripMargin println(evolution) } }
package mypackage import scala.slick.driver.H2Driver import scala.slick.driver.ExtendedProfile import scala.slick.driver.PostgresDriver object MovableDriver { val simple = profile.simple lazy val profile: ExtendedProfile = { sys.env.get("database") match { case Some("postgres") => PostgresDriver case _ => H2Driver } } }
package mypackage import com.typesafe.config.ConfigFactory import scala.slick.driver.{H2Driver, JdbcDriver, MySQLDriver} object AgnosticDriver { val simple = profile.simple lazy val profile: JdbcDriver = { sys.env.get("DB_ENVIRONMENT") match { case Some(e) => ConfigFactory.load().getString(s"$e.slickDriver") match { case "scala.slick.driver.H2Driver" => H2Driver case "scala.slick.driver.MySQLDriver" => MySQLDriver } case _ => H2Driver } } }
val system = ActorSystem() val myActor = system.actorOf(Props[MyActor])
group version apply plugin: apply plugin: sourceCompatibility = 1.8 repositories { mavenCentral() } dependencies { compile testCompile testRuntime testCompile group: }
You can add the scala maven plugin reference in the pom.xml as below <build> <sourceDirectory>src/main/scala</sourceDirectory> <testSourceDirectory>src/test/scala</testSourceDirectory> <plugins> <plugin> <groupId>net.alchim31.maven</groupId> <artifactId>scala-maven-plugin</artifactId> <version>3.2.2</version> <executions> <execution> <goals> <goal>compile</goal> <goal>testCompile</goal> </goals> </execution> </executions> <configuration> <scalaCompatVersion>2.11</scalaCompatVersion> <scalaVersion>2.11.8</scalaVersion> </configuration> </plugin> </plugins> </build> Once you do this and build you will be able to see the option of the scala class.
try { throw new java.io.IOException("no such file") } catch { case e @ (_ : RuntimeException | _ : java.io.IOException) => println(e) }
try { throw new IOException("no such file") } catch { case _ : SQLException | _ : IOException => println("Resource failure") case e => println("Other failure"); }
def onFilesAndDb(code: => Unit) { try { code } catch { your handling code } }
try { throw new RuntimeException("be careful") } catch { case e : RuntimeException => e match { case _ : NullPointerException | _ : IllegalArgumentException => println("Basic exception " + e) case a: IndexOutOfBoundsException => println("Arrray access " + a) case _ => println("Less common exception " + e) } case _ => println("Not a runtime exception") }
import scala.util.control.Exception._ import java.io.IOException handling(classOf[RuntimeException], classOf[IOException]) by println apply { throw new IOException("foo") }
try { throw new CustomValidationException1( CustomErrorCodeEnum.STUDIP_FAIL, "could be throw new CustomValidationException2") } catch { case e if (e.isInstanceOf[CustomValidationException1] || e .isInstanceOf[CustomValidationException2]) => { println(e.getMessage) println(e.errorCode.toString) } case e: Exception => { println("Unknown error occurred while reading files!!!") println(e.getMessage) } } class CustomValidationException1(val errorCode: CustomErrorCodeEnum, val message: String) class CustomValidationException2(val errorCode: CustomErrorCodeEnum, val message: String)
fun calculateSum(list): sum = 0 for each element in list: sum = sum + element return sum
fun calculateSum(list): sum = 0 foreach(list, lambda element: sum = sum + element ) return sum
fun calculateSum([H|T]): return H + calculateSum(T) fun calculateSum([]): return 0
fun calculateSum([H|T], partialSum): return calculateSum(T, H + partialSum) fun calculateSum([], partialSum): return partialSum fun calculateSum(list): return calculateSum(list, 0)
length xs = last results where results = length3 0 xs length3 a [] = [a] length3 a (x:xs) = a : length3 (a+1) xs
def processLine(tokens: Array[String]) = tokens match {
def processLine(tokens: Array[String]) = tokens match { case Array(_, "", _*) => "second is empty" case _ => "default" }
def processLine(tokens: List[String]) = tokens match { case _ :: "" :: _ => "second is empty" case _ => "default" }
for( t <- tokens ) t match { case "" => println( "Empty" ) case s => println( "Value: " + s ) }
if( tokens.exists( _ == "" ) ) { println("Found empty token") }
val lines: List[String] = List("Alice Bob Carol", "Bob Carol", "Carol Diane Alice") lines foreach { line => line split "\\s+" match { case Array(userName, friends@_*) => { } } }
abstract class X { val name: String val size = name.size } class Y extends { val name = "class Y" } with X
object InlineExample { final class C(val i: Int) { @inline def t2 = i*2 @inline def t4 = t2*2 } final class D(val i: Int) { def t2 = i*2 def t4 = t2*2 } }
def foo() { new { val a: Any = sys.error("b is " + b) val b: Any = sys.error("a is " + a) } }
scala> import io.Source import io.Source scala> class Test { | lazy val foo = Source.fromFile("./bar.txt").getLines | } defined class Test scala> val baz = new Test baz: Test = Test@ea5d87 scala> baz.foo java.io.FileNotFoundException: ./bar.txt (No such file or directory) at java.io.FileInputStream.open(Native Method) at java.io.FileInputStream.<init>(FileInputStream.java:137) ... scala> baz.foo res2: Iterator[String] = empty iterator
scala> val result1 = {println("hello val"); "returns val"} hello val result1: String = returns val
scala> lazy val result2 = {println("hello lazy val"); "returns lazy val"} result2: String = <lazy>
scala> result2 hello lazy val res1: String = returns lazy val
scala> def result3 = {println("hello def"); "returns def"} result3: String scala> result3 hello def res3: String = returns def scala> result3 hello def res4: String = returns def
scala> val array = Array.fill(2,2)(0) array: Array[Array[Int]] = Array(Array(0, 0), Array(0, 0)) scala> println(array) [[I@d2f01d
scala> println(java.util.Arrays.deepToString(array)) <console>:7: error: type mismatch; found : Array[Array[Int]] required: Array[java.lang.Object] println(java.util.Arrays.deepToString(array))
scala> println(array.map(_.mkString(" ")).mkString("\n")) 0 0 0 0
scala> val array = Array.fill(2,2)(0) array: Array[Array[Int]] = Array(Array(0, 0), Array(0, 0)) scala> println(array.deep.mkString("\n")) Array(0, 0) Array(0, 0)
scala> val array = Array.fill(2,2)(0) array: Array[Array[Int]] = Array(Array(0, 0), Array(0, 0)) scala> import scala.runtime.ScalaRunTime._ import scala.runtime.ScalaRunTime._ scala> val str = stringOf(array) str: String = Array(Array(0, 0), Array(0, 0))
val a = Array(1, 7, 2, 9) a.mkString(" and ") a.mkString("<", ",", ">")
val array1 = Array(1,2,3) println(array1.mkString(",")) println(array1.mkString("\n")) def printArray[k](a:Array[k])= println(a.mkString(",")) printArray(array1)
scala> array foreach{case a => a foreach {b => print(b.toString + " ")}; print( 0 0 0 0
scala> array foreach{a => a foreach println} 0 0 0 0
def arrayToString(a: Array[Array[Int]]) : String = { val str = for (l <- a) yield l.mkString("{", ",", "}") str.mkString("{",",\n","}") } val foo = Array.fill(2,2)(0) println(arrayToString(foo))
def main(args: Array[String]) { val n = args(0).toInt }
val str = "Hello world!" str take (str.length - 1) mkString
user.password == enteredPassword match { case true => println("User is authenticated") case false => println("Entered password is invalid") }
if(user.password == enteredPassword) println("User is authenticated") else println("Entered password is invalid")
class MatchVsIf { def i(b: Boolean) = if (b) 5 else 4 def m(b: Boolean) = b match { case true => 5; case false => 4 } }
scala> :javap -cp MatchVsIf Compiled from "<console>" public class MatchVsIf extends java.lang.Object implements scala.ScalaObject{ public int i(boolean); Code: 0: iload_1 1: ifeq 8 4: iconst_5 5: goto 9 8: iconst_4 9: ireturn public int m(boolean); Code: 0: iload_1 1: istore_2 2: iload_2 3: iconst_1 4: if_icmpne 11 7: iconst_5 8: goto 17 11: iload_2 12: iconst_0 13: if_icmpne 18 16: iconst_4 17: ireturn 18: new 21: dup 22: iload_2 23: invokestatic 26: invokespecial 29: athrow
println( if(user.password == enteredPassword) "User is authenticated" else "Entered password is invalid" )
user.password match { case `enteredPassword` => Right(user) case _ => Left("passwords don }
val errorMessage = user.password == enteredPassword match { case true => "User is authenticated" case false => "Entered password is invalid" } println(errorMesssage)
var errorMessage = "" if(user.password == enteredPassword) errorMessage = "User is authenticated" else errorMessage = "Entered password is invalid" println(errorMessage)
def factorial(x: Int): Int = { def loop(acc: Int, c: Int): Int = { c match { case 0 => acc case _ => loop(acc * c, c - 1) } } loop(1, x) } def factorialIf(x: Int): Int = { def loop(acc: Int, c: Int): Int = if (c == 0) acc else loop(acc * c, c - 1) loop(1, x) } def measure(e: (Int) => Int, arg:Int, numIters: Int): Long = { def loop(max: Int): Unit = { if (max == 0) return else { val x = e(arg) loop(max-1) } } val startMatch = System.currentTimeMillis() loop(numIters) System.currentTimeMillis() - startMatch } val timeIf = measure(factorialIf, 1000,1000000) val timeMatch = measure(factorial, 1000,1000000)
Trivial match can be simplified less... (⌘F1) Suggests to replace trivial pattern match on a boolean expression with a conditional statement. Before: bool match { case true => ??? case false => ??? } After: if (bool) { ??? } else { ??? }
val foo = List(1, 2, 3) foo.foldLeft(0)(_ + _) foo.fold(0)(_ + _) >:7: error: value fold is not a member of List[Int] foo.fold(0)(_ + _) ^
val ns = List(1, 2, 3, 4) val s0 = ns.foldLeft (0) (_+_) val s1 = ns.fold (0) (_+_) assert(s0 == s1)
object MyClass { def main(args: Array[String]) { val numbers = List(5, 4, 8, 6, 2) val a = numbers.fold(0) { (z, i) => { println("fold val1 " + z +" val2 " + i) z + i } } println(a) val b = numbers.foldLeft(0) { (z, i) => println("foldleft val1 " + z +" val2 " + i) z + i } println(b) val c = numbers.foldRight(0) { (z, i) => println("fold right val1 " + z +" val2 " + i) z + i } println(c) } }
fold val1 0 val2 5 fold val1 5 val2 4 fold val1 9 val2 8 fold val1 17 val2 6 fold val1 23 val2 2 25 foldleft val1 0 val2 5 foldleft val1 5 val2 4 foldleft val1 9 val2 8 foldleft val1 17 val2 6 foldleft val1 23 val2 2 25 fold right val1 2 val2 0 fold right val1 6 val2 2 fold right val1 8 val2 8 fold right val1 4 val2 16 fold right val1 5 val2 20 25
def boom(n: Int): Nothing = if(n<=0) throw new Exception else boom(n-1) boom(10)
import scala.annotation.tailrec @tailrec def factorialAcc(acc: Int, n: Int): Int = { if (n <= 1) acc else factorialAcc(n * acc, n - 1) }
dcs@ayanami:~$ mkdir myproject dcs@ayanami:~$ cd myproject dcs@ayanami:~/myproject$ sbt Project does not exist, create new project? (y/N/s) y Name: myproject Organization: org.dcsobral Version [1.0]: Scala version [2.7.7]: 2.8.1 sbt version [0.7.4]: Getting Scala 2.7.7 ... :: retrieving :: org.scala-tools.sbt confs: [default] 2 artifacts copied, 0 already retrieved (9911kB/134ms) Getting org.scala-tools.sbt sbt_2.7.7 0.7.4 ... :: retrieving :: org.scala-tools.sbt confs: [default] 15 artifacts copied, 0 already retrieved (4096kB/91ms) [success] Successfully initialized directory structure. Getting Scala 2.8.1 ... :: retrieving :: org.scala-tools.sbt confs: [default] 2 artifacts copied, 0 already retrieved (15118kB/160ms) [info] Building project myproject 1.0 against Scala 2.8.1 [info] using sbt.DefaultProject with sbt 0.7.4 and Scala 2.7.7 > quit [info] [info] Total session time: 8 s, completed May 6, 2011 12:31:43 PM [success] Build completed successfully. dcs@ayanami:~/myproject$ find . -type d -print . ./project ./project/boot ./project/boot/scala-2.7.7 ./project/boot/scala-2.7.7/lib ./project/boot/scala-2.7.7/org.scala-tools.sbt ./project/boot/scala-2.7.7/org.scala-tools.sbt/sbt ./project/boot/scala-2.7.7/org.scala-tools.sbt/sbt/0.7.4 ./project/boot/scala-2.7.7/org.scala-tools.sbt/sbt/0.7.4/compiler-interface-bin_2.7.7.final ./project/boot/scala-2.7.7/org.scala-tools.sbt/sbt/0.7.4/compiler-interface-src ./project/boot/scala-2.7.7/org.scala-tools.sbt/sbt/0.7.4/compiler-interface-bin_2.8.0.RC2 ./project/boot/scala-2.7.7/org.scala-tools.sbt/sbt/0.7.4/xsbti ./project/boot/scala-2.8.1 ./project/boot/scala-2.8.1/lib ./target ./lib ./src ./src/main ./src/main/resources ./src/main/scala ./src/test ./src/test/resources ./src/test/scala
$ g8 ymasory/sbt project_license_url [http: name [myproj]: project_group_id [com.example]: developer_email [john.doe@example.com]: developer_full_name [John Doe]: project_license_name [GPLv3]: github_username [johndoe]: Template applied in ./myproj $ tree myproj myproj ├── build.sbt ├── LICENSE ├── project │ ├── build.properties │ ├── build.scala │ └── plugins.sbt ├── README.md ├── sbt └── src └── main └── scala └── Main.scala 4 directories, 8 files
$ mkdir myproj; cd myproj $ sbt [info] Loading global plugins from /home/dcsobral/.sbt/plugins [warn] Multiple resolvers having different access mechanism configured with same name [info] Set current project to default-c642a2 (in build file:/home/dcsobral/myproj/) [info] Generated build file [info] Generated source directories [success] Total time: 0 s, completed Apr 12, 2013 12:08:31 PM $ tree . ├── build.sbt ├── src │ ├── main │ │ ├── resources │ │ └── scala │ └── test │ ├── resources │ └── scala └── target └── streams └── compile └── np └── $global └── out 12 directories, 2 files
$ mkdir -p myproj/src/{main,test}/{resource,scala,java} $ tree myproj myproj └── src ├── main │ ├── java │ ├── resource │ └── scala └── test ├── java ├── resource └── scala 9 directories, 0 files
sealed abstract class Tree case class Node(left: Tree, right: Tree) extends Tree case class Leaf(n: Int) extends Tree scala> def isLeaf(t: Tree) = t match { | case Leaf(n: Int) => println("Leaf "+n) | } <console>:11: warning: match is not exhaustive! missing combination Node def isLeaf(t: Tree) = t match { ^ isLeaf: (t: Tree)Unit
package org.dcsobral.myproject.model import org.dcsobral.myproject.view import org.dcsobral.myproject.controller
trait Foo { def foo() } trait M extends Foo { override def foo() { println("M") super.foo() } } class FooImpl1 extends Foo { override def foo() { println("Impl") } } class FooImpl2 extends FooImpl1 with M
trait Foo { def foo() } trait M extends Foo { abstract override def foo() {println("M"); super.foo()} } class FooImpl1 extends Foo { override def foo() {println("Impl")} } class FooImpl2 extends FooImpl1 with M
"abcde" map {_.toUpperCase} "abcde" map {_.toInt} BitSet(1,2,3,4) map {2*} BitSet(1,2,3,4) map {_.toString}
"abcde" map {_.toUpperCase} "abcde" map {_.toInt} BitSet(1,2,3,4) map {2*} BitSet(1,2,3,4) map {_.toString}
implicit def canBuildFrom: CanBuildFrom[BitSet, Int, BitSet] = bitsetCanBuildFrom
implicit def canBuildFrom[A]: CanBuildFrom[Coll, A, Set[A]] = setCanBuildFrom[A]
class R(n: Int, d: Int) { private val g = myfunc val x = n / g val y = d / g }
class R(n: Int, d: Int) { val (x, y) = { val g = myfunc (n/g, d/g) } }
class R private (val x: Int, val y: Int); object R { def apply(n: Int, d: Int): R = { val g = myfunc; new R(n / g, d / g); } }
import org.scalatest._ import matchers.MustMatchers class Foo extends FunSpec with MustMatchers { describe("Message here...") { it("Must do something") { } it("Must be ok") { } } } class Bar extends FunSpec with MustMatchers { describe("Hello you...") { it("One more!") { } } } class EndpointTests extends Suites(new Foo, new Bar) with BeforeAndAfterAll { override def beforeAll(configMap: Map[String, Any]) { println("Before!") } override def afterAll(configMap: Map[String, Any]) { println("After!") } }
class EndpointTests extends FunSpec with MustMatchers with BeforeAndAfterAll with Foo with Bar { override def beforeAll(configMap: Map[String, Any]) { println("Before!") } override def afterAll(configMap: Map[String, Any]) { println("After!") } }
trait Foo extends FunSpec with MustMatchers { describe("Message here...") { it("Must do something") { } it("Must be ok") { } } } trait Bar extends FunSpec with MustMatchers { describe("Hello you...") { it("One more!") { } } }
object && { def unapply[A](a: A) = Some((a, a)) } object StartsWith { def unapply(s: String) = s.headOption } object EndsWith { def unapply(s: String) = s.reverse.headOption } object Length { def unapply(s: String) = Some(s.length) } "foo" match { case StartsWith( case StartsWith( case _ => "_" }
class Function1W[A, B](self: A => B) { def lift[F[_]: Functor]: F[A] => F[B] }
type F[Y] = X => Y (X => A) andThen (A => B) is X => B F[A] A => B F[B]
trait Functor[F[_]] { def fmap[A, B](fa: F[A], f: A => B): F[B] }
def lift[F[_]: Functor]: F[A] => F[B] = (f: F[A]) => implicitly[Functor[F]].fmap(f, self)
implicit val OptionFunctor = new Functor[Option] { def fmap[A, B](fa: Option[A], f: A => B) = fa map f } implicit def Functor1Functor[X] = new Functor[({type l[a]=X => a}) def fmap[A, B](fa: X => B, f: A => B) = f compose fa }
trait Monad[M[_]] { def pure[A](a: A): M[A] def bind[A, B](ma: M[A], f: A => B): M[B] }
trait Functor[T[_]]{ def fmap[A,B](f:A=>B)(ta:T[A]):T[B] }
trait Applicative[T[_]] extends Functor[T]{ def pure[A](a:A):T[A] def <*>[A,B](tf:T[A=>B])(ta:T[A]):T[B] }
trait Monad[M[_]] extends Applicative[M]{ def >>=[A,B](ma:M[A])(f:A=>M[B]):M[B] }
trait Functor[F[_]] { def fmap[A, B](f: A => B): F[A] => F[B] }
def any[A](s: Traversable[A], f: A => Boolean): Boolean = { s.foldLeft(false)((bool, elem) => bool || f(elem)) }
scala> Vector(3, 4, 5).exists(_ % 2 == 0) res1: Boolean = true scala> Vector(3, 4, 5).forall(_ % 2 == 0) res2: Boolean = false
def all[A](xs: Traversable[A], p: A => Boolean): Boolean = xs forall p def any[A](xs: Traversable[A], p: A => Boolean): Boolean = xs exists p
scala> List(1,2,3).exists(_ > 2) res12: Boolean = true
case class Greets[T]( private val name: T ) { def hello() { println("Hello " + name) } def getName: T = name }
def sayHi2[T]( g: Greets[T] ) { g.hello() } sayHi2( Greets("John")) sayHi2( Greets(
def sayHi3( g: Greets[_] ) { g.hello() } sayHi3( Greets("John")) sayHi3( Greets(
val greets1: Greets[String] = Greets("John") val greets2: Greets[Symbol] = Greets( val greetsList1: List[Greets[Any]] = List( greets1, greets2 )
val greetsList2: List[Greets[_]] = List( greets1, greets2 )
class Actorz extends Actor with ActorLogging { val actorName = def receive = { case x => log.debug(actorName+": Received Message: "+x) } } val actor = system.actorOf(Props[Actorz], "named") actor ! "dogs"
trait A { val me: this.type = this } class B extends A val v = new B
scala> val s = "a string" s: java.lang.String = a string scala> var v: s.type = s v: s.type = a string scala> v = "another string" <console>:7: error: type mismatch; found : java.lang.String("another string") required: s.type v = "another string"
sc.makeRDD(Seq((1, "a"), (1, "b"), (2, "c"))) .writeAsMultiple(prefix, compressionCodecOption)
val people_rdd = sc.parallelize(Seq((1, "alice"), (1, "bob"), (2, "charlie"))) val people_df = people_rdd.toDF("number", "name")
people_rdd = sc.parallelize([(1, "alice"), (1, "bob"), (2, "charlie")]) people_df = people_rdd.toDF(["number", "name"])
people_df.write.partitionBy("number").text("people")
people_df.write.partitionBy("number").json("people-json") people_df.write.partitionBy("number").parquet("people-parquet")
people/ _SUCCESS number=1/ part-abcd part-efgh number=2/ part-abcd part-efgh
import org.apache.hadoop.io.NullWritable import org.apache.spark._ import org.apache.spark.SparkContext._ import org.apache.hadoop.mapred.lib.MultipleTextOutputFormat class RDDMultipleTextOutputFormat extends MultipleTextOutputFormat[Any, Any] { override def generateActualKey(key: Any, value: Any): Any = NullWritable.get() override def generateFileNameForKeyValue(key: Any, value: Any, name: String): String = key.asInstanceOf[String] } object Split { def main(args: Array[String]) { val conf = new SparkConf().setAppName("Split" + args(1)) val sc = new SparkContext(conf) sc.textFile("input/path") .map(a => (k, v)) .partitionBy(new HashPartitioner(num)) .saveAsHadoopFile("output/path", classOf[String], classOf[String], classOf[RDDMultipleTextOutputFormat]) spark.stop() } }
sc.makeRDD(Seq((1, "a"), (1, "b"), (2, "c"))) .mapPartitionsWithIndex { (p, it) => val outputs = new MultiWriter(p.toString) for ((k, v) <- it) { outputs.write(k.toString, v) } outputs.close Nil.iterator } .foreach((x: Nothing) => ()) class MultiWriter(suffix: String) { private val writers = collection.mutable.Map[String, java.io.PrintWriter]() def write(key: String, value: Any) = { if (!writers.contains(key)) { val f = new java.io.File("output/" + key + "/" + suffix) f.getParentFile.mkdirs writers(key) = new java.io.PrintWriter(f) } writers(key).println(value) } def close = writers.values.foreach(_.close) }
import org.apache.spark.rdd.RDD import org.apache.spark.sql.SQLContext implicit class PimpedRDD[T1, T2](rdd: RDD[(T1, T2)]) { def writeAsMultiple(prefix: String, codec: String, keyName: String = "key") (implicit sqlContext: SQLContext): Unit = { import sqlContext.implicits._ rdd.toDF(keyName, "_2").write.partitionBy(keyName) .format("text").option("codec", codec).save(prefix) } } val myRdd = sc.makeRDD(Seq((1, "a"), (1, "b"), (2, "c"))) myRdd.writeAsMultiple("prefix", "org.apache.hadoop.io.compress.GzipCodec")
myRdd.writeAsMultiple("prefix", "org.apache.hadoop.io.compress.GzipCodec")
myRdd.writeAsMultiple("prefix", "org.apache.hadoop.io.compress.GzipCodec", "foo")
implicit class PimpedDataset[T](dataset: Dataset[T]) { def writeAsMultiple(prefix: String, codec: String, field: String): Unit = { dataset.write.partitionBy(field) .format("text").option("codec", codec).save(prefix) } }
import org.apache.hadoop.mapred.lib.MultipleTextOutputFormat class KeyBasedOutput[T >: Null, V <: AnyRef] extends MultipleTextOutputFormat[T , V] { override def generateFileNameForKeyValue(key: T, value: V, leaf: String) = { key.toString } override protected def generateActualKey(key: T, value: V) = { null } }
import org.apache.spark.Partitioner class IdentityIntPartitioner(maxKey: Int) extends Partitioner { def numPartitions = maxKey def getPartition(key: Any): Int = key match { case i: Int if i < maxKey => i } }
val rdd = sc.makeRDD(Seq((1, "a"), (1, "b"), (2, "c"), (7, "d"), (7, "e"))) val partitioner = new IdentityIntPartitioner(10) val prefix = "hdfs: val partitionedRDD = rdd.partitionBy(partitioner) partitionedRDD.saveAsHadoopFile(prefix, classOf[Integer], classOf[String], classOf[KeyBasedOutput[Integer, String]])
val byKey = dataRDD.groupByKey().collect() val rddByKey = byKey.map{case (k,v) => k->sc.makeRDD(v.toSeq)} val rddByKey.foreach{ case (k,rdd) => rdd.saveAsText(prefix+k}
import org.apache.hadoop.mapred.lib.MultipleTextOutputFormat; import org.apache.spark.SparkConf; import org.apache.spark.api.java.JavaSparkContext; import scala.Tuple2; import java.util.Arrays; class RDDMultipleTextOutputFormat<A, B> extends MultipleTextOutputFormat<A, B> { @Override protected String generateFileNameForKeyValue(A key, B value, String name) { return key.toString(); } } public class Main { public static void main(String[] args) { SparkConf conf = new SparkConf() .setAppName("Split Job") .setMaster("local"); JavaSparkContext sc = new JavaSparkContext(conf); String[] strings = {"Abcd", "Azlksd", "whhd", "wasc", "aDxa"}; sc.parallelize(Arrays.asList(strings)) .mapToPair(s -> new Tuple2<>(s.substring(0,1).toLowerCase(), s)) .saveAsHadoopFile("output/", String.class, String.class, RDDMultipleTextOutputFormat.class); sc.stop(); } }
import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.FileSystem; import org.apache.hadoop.fs.Path; val hadoopconf = new Configuration(); val fs = FileSystem.get(hadoopconf); @serializable object processGroup { def apply(groupName:String, records:Iterable[String]): Unit = { val outFileStream = fs.create(new Path("/output_dir/"+groupName)) for( line <- records ) { outFileStream.writeUTF(line+"\n") } outFileStream.close() } } val infile = sc.textFile("input_file") val dateGrouped = infile.groupBy( _.split(",")(0)) dateGrouped.foreach( (x) => processGroup(x._1, x._2))
people_df.write.partitionBy("number").text("people")
people_rdd = sc.parallelize([(1,"2016-12-26", "alice"), (1,"2016-12-25", "alice"), (1,"2016-12-25", "tom"), (1, "2016-12-25","bob"), (2,"2016-12-26" ,"charlie")]) df = people_rdd.toDF(["number", "date","name"]) df.coalesce(1).write.partitionBy("number").mode("overwrite").format( [root@namenode people] . ├── number=1 │?? └── part-r-00000-6bd1b9a8-4092-474a-9ca7-1479a98126c2.csv ├── number=2 │?? └── part-r-00000-6bd1b9a8-4092-474a-9ca7-1479a98126c2.csv └── _SUCCESS [root@namenode people] 2016-12-26,alice 2016-12-25,alice 2016-12-25,tom 2016-12-25,bob [root@namenode people] 2016-12-26,charlie
class RDDMultipleTextOutputFormat<K, V> extends MultipleTextOutputFormat<K, V> { @Override protected String generateFileNameForKeyValue(K key, V value, String name) { return key.toString(); } /** The following 4 functions are only for visibility purposes (they are used in the class MyRecordWriter) **/ protected String generateLeafFileName(String name) { return super.generateLeafFileName(name); } protected V generateActualValue(K key, V value) { return super.generateActualValue(key, value); } protected String getInputFileBasedOutputFileName(JobConf job, String name) { return super.getInputFileBasedOutputFileName(job, name); } protected RecordWriter<K, V> getBaseRecordWriter(FileSystem fs, JobConf job, String name, Progressable arg3) throws IOException { return super.getBaseRecordWriter(fs, job, name, arg3); } /** Use my custom RecordWriter **/ @Override RecordWriter<K, V> getRecordWriter(final FileSystem fs, final JobConf job, String name, final Progressable arg3) throws IOException { final String myName = this.generateLeafFileName(name); return new MyRecordWriter<K, V>(this, fs, job, arg3, myName); } }
class MyRecordWriter<K, V> implements RecordWriter<K, V> { private RDDMultipleTextOutputFormat<K, V> rddMultipleTextOutputFormat; private final FileSystem fs; private final JobConf job; private final Progressable arg3; private String myName; TreeMap<String, RecordWriter<K, V>> recordWriters = new TreeMap(); MyRecordWriter(RDDMultipleTextOutputFormat<K, V> rddMultipleTextOutputFormat, FileSystem fs, JobConf job, Progressable arg3, String myName) { this.rddMultipleTextOutputFormat = rddMultipleTextOutputFormat; this.fs = fs; this.job = job; this.arg3 = arg3; this.myName = myName; } @Override void write(K key, V value) throws IOException { String keyBasedPath = rddMultipleTextOutputFormat.generateFileNameForKeyValue(key, value, myName); String finalPath = rddMultipleTextOutputFormat.getInputFileBasedOutputFileName(job, keyBasedPath); Object actualValue = rddMultipleTextOutputFormat.generateActualValue(key, value); RecordWriter rw = this.recordWriters.get(finalPath); if(rw == null) { rw = rddMultipleTextOutputFormat.getBaseRecordWriter(fs, job, finalPath, arg3); this.recordWriters.put(finalPath, rw); } List<String> lines = (List<String>) actualValue; for (String line : lines) { rw.write(null, line); } } @Override void close(Reporter reporter) throws IOException { Iterator keys = this.recordWriters.keySet().iterator(); while(keys.hasNext()) { RecordWriter rw = (RecordWriter)this.recordWriters.get(keys.next()); rw.close(reporter); } this.recordWriters.clear(); } }
List<String> lines = (List<String>) actualValue; for (String line : lines) { rw.write(null, line); }
javaPairRDD.saveAsHadoopFile(path, String.class, List.class, RDDMultipleTextOutputFormat.class);
if ! ztcp localhost 5554; then echo "[ZSH] Start emulator" emulator \ -avd Nexus-One \ -no-boot-anim \ 1>~/Library/Logs/${PROJECT_NAME}-${0:t:r}.out \ 2>~/Library/Logs/${PROJECT_NAME}-${0:t:r}.err & disown else ztcp -c "${REPLY}" fi;
IFF %@Connect[localhost 5554] lt 0 THEN ECHO [TCC] Start emulator DETACH emulator -avd Nexus-One -no-boot-anim ENDIFF
import scala.sys.process.ProcessIO val pio = new ProcessIO(_ => (), stdout => scala.io.Source.fromInputStream(stdout) .getLines.foreach(println), _ => ()) pb.run(pio)
/** Run a command, collecting the stdout, stderr and exit status */ def run(in: String): (List[String], List[String], Int) = { val qb = Process(in) var out = List[String]() var err = List[String]() val exit = qb ! ProcessLogger((s) => out ::= s, (s) => err ::= s) (out.reverse, err.reverse, exit) }
def { val process = Process (command) val io = new ProcessIO ( in => {in.write (hereDoc getBytes "UTF-8"); in.close}, out => {scala.io.Source.fromInputStream(out).getLines.foreach(println)}, err => {scala.io.Source.fromInputStream(err).getLines.foreach(println)}) process run io }
s/^(package com.example.project.*)\.(\w+)/$1\npackage $2/g
scala> def listToArray[T](ls: List[T]): Array[T] = ls.toArray <console>:5: error: could not find implicit value for evidence parameter of type scala.reflect.ClassManifest[T] def listToArray[T](ls: List[T]): Array[T] = ls.toArray ^
scala> def listToArray[T: Manifest](ls: List[T]): Array[T] = ls.toArray listToArray: [T](ls: List[T])(implicit evidence$1: Manifest[T])Array[T] scala> def listToArray[T](ls: List[T])(implicit m: Manifest[T]): Array[T] = ls.toArray listToArray: [T](ls: List[T])(implicit m: Manifest[T])Array[T]
scala> collection.Map(1 -> 2): Map[Int, Int] <console>:6: error: type mismatch; found : scala.collection.Map[Int,Int] required: Map[Int,Int] collection.Map(1 -> 2): Map[Int, Int] ^
object Predef { type Map[A, B] = collection.immutable.Map[A, B] val Map = collection.immutable.Map }
scala> case class Foo(a: Int, b: String) defined class Foo scala> Foo(1, "a").copy(b = "b") res1: Foo = Foo(1,b)
package com.mystuff.java.wrappers import java.net._
package com.mystuff.factories { package lightbulbs { ... } }
def takesArray(arr: Array[AnyRef]) {…} def usesVarArgs(obs: AnyRef*) { takesArray(obs) }
def usesVarArgs(obs: AnyRef*) { takesArray(obs.toArray) }
[scalac] found : (String) => Ordered[String] [scalac] required: Ordering[String] [scalac] TreeMap[String, Any](map.toList: _*)(stringToCaseInsensitiveOrdered _)
abstract class MyAbstract case class MyFirst extends MyAbstract case class MySecond extends MyAbstract case class MyThird extends MyAbstract val x: MyAbstract = MyFirst x match { case a: MyFirst => doSomething() case b: MySecond => doSomething() case _ => doSomethingElse() }
x match { case a @ (MyFirst | MySecond) => doSomething() case _ => doSomethingElse() }
pattern type is incompatible with expected type; [error] found : object MyFirst [error] required: MyAbstract
abstract class MyAbstract case class MyFirst() extends MyAbstract case class MySecond() extends MyAbstract val x: MyAbstract = MyFirst() x match { case aOrB @ (MyFirst() | MySecond()) => doSomething(aOrB) case _ => doSomethingElse() }
x match { case aOrB @ (_:MyFirst | _:MySecond) => doSomething(aOrB) case _ => doSomethingElse() }
x match { case _:MyFirst | _:MySecond => doSomething(x) case _ => doSomethingElse(x) }
abstract class MyAbstract case object MyFirst extends MyAbstract case object MySecond extends MyAbstract val x: MyAbstract = MyFirst x match { case aOrB @ (MyFirst | MySecond) => doSomething() case _ => doSomethingElse() }
val entries = Menu(Loc("Home", "/", "Home")) :: Menu(Loc("Foo", "/badger", "Foo")) :: Menu(Loc("Directory Foo", "/something/foo", "Directory Foo")) :: Nil LiftRules.setSiteMap(SiteMap(entries:_*))
:~/bin/sbt/bin$ ls classes sbt sbt-launch.jar target jansi.jar sbt.bat sbt-launch-lib.bash win-sbt
No command Command Command Command Command Command Command Command Command
$ sbt -help Usage: sbt [options] -h | -help print this message ...
dataFrame.select("YOUR_COLUMN_NAME").rdd.map(r => r(0)).collect()
import org.apache.spark.sql.SparkSession val spark = SparkSession.builder.getOrCreate import spark.implicits._ val df = Seq( ("first", 2.0), ("test", 1.5), ("choose", 8.0) ).toDF("id", "val")
df.select("id").map(r => r.getString(0)).collect.toList
sqlContext.sql(" select filename from tempTable").rdd.map(r => r(0)).collect.toList.foreach(out_streamfn.println)
import org.apache.spark.sql.types.{ StructType, StructField, StringType, IntegerType} import org.apache.spark.sql.Row val schema = StructType( StructField("k", StringType, true) :: StructField("v", IntegerType, false) :: Nil) spark.createDataFrame(sc.emptyRDD[Row], schema)
import spark.implicits._ Seq.empty[(String, Int)].toDF("k", "v")
case class KV(k: String, v: Int) Seq.empty[KV].toDF
scala> case class Person(id: Int, name: String) defined class Person
scala> import spark.implicits._ import spark.implicits._
scala> spark.emptyDataset[Person] res0: org.apache.spark.sql.Dataset[Person] = [id: int, name: string]
scala> val id = $"id".int id: org.apache.spark.sql.types.StructField = StructField(id,IntegerType,true) scala> val name = $"name".string name: org.apache.spark.sql.types.StructField = StructField(name,StringType,true) scala> import org.apache.spark.sql.types.StructType import org.apache.spark.sql.types.StructType scala> val mySchema = StructType(id :: name :: Nil) mySchema: org.apache.spark.sql.types.StructType = StructType(StructField(id,IntegerType,true), StructField(name,StringType,true)) scala> import org.apache.spark.sql.Row import org.apache.spark.sql.Row scala> val emptyDF = spark.createDataFrame(sc.emptyRDD[Row], mySchema) emptyDF: org.apache.spark.sql.DataFrame = [id: int, name: string] scala> emptyDF.printSchema root |-- id: integer (nullable = true) |-- name: string (nullable = true)
import scala.reflect.runtime.{universe => ru} def createEmptyDataFrame[T: ru.TypeTag] = hiveContext.createDataFrame(sc.emptyRDD[Row], ScalaReflection.schemaFor(ru.typeTag[T].tpe).dataType.asInstanceOf[StructType] ) case class RawData(id: String, firstname: String, lastname: String, age: Int) val sourceDF = createEmptyDataFrame[RawData]
import org.apache.spark.SparkConf import org.apache.spark.SparkContext import org.apache.spark.sql._ import org.apache.spark.sql.Row import org.apache.spark.sql.SparkSession import org.apache.spark.sql.types.StructType import org.apache.spark.sql.types.StructField import org.apache.spark.sql.types.IntegerType import org.apache.spark.sql.types.BooleanType import org.apache.spark.sql.types.LongType import org.apache.spark.sql.types.StringType object EmptyTable extends App { val conf = new SparkConf; val sc = new SparkContext(conf) val sparkSession = SparkSession.builder().enableHiveSupport().getOrCreate() val schema = StructType( StructField("Emp_ID", LongType, true) :: StructField("Emp_Name", StringType, false) :: StructField("Emp_Salary", LongType, false) :: Nil) var dataRDD = sc.emptyRDD[Row] val newDFSchema = sparkSession.createDataFrame(dataRDD, schema) newDFSchema.createOrReplaceTempView("tempSchema") sparkSession.sql("create table Finaltable AS select * from tempSchema") }
from pyspark.sql import SQLContext sc = spark.sparkContext schema = StructType([StructField( sqlContext.createDataFrame(sc.emptyRDD(), schema)
public Dataset<Row> emptyDataSet(){ SparkSession spark = SparkSession.builder().appName("Simple Application") .config("spark.master", "local").getOrCreate(); Dataset<Row> emptyDataSet = spark.createDataFrame(new ArrayList<>(), getSchema()); return emptyDataSet; } public StructType getSchema() { String schemaString = “column1 column2 column3 column4 column5”; List<StructField> fields = new ArrayList<>(); StructField indexField = DataTypes.createStructField(“column0”, DataTypes.LongType, true); fields.add(indexField); for (String fieldName : schemaString.split(" ")) { StructField field = DataTypes.createStructField(fieldName, DataTypes.StringType, true); fields.add(field); } StructType schema = DataTypes.createStructType(fields); return schema; }
object Performance { import scala.annotation.tailrec @tailrec def gcd(x:Int,y:Int):Int = { if (x == 0) y else gcd(y%x,x) } val p = 1009 val q = 3643 val t = (p-1)*(q-1) val es = (2 until t).filter(gcd(_,t) == 1) def main(args:Array[String]) { println(es.length) } }
class Performance{ static{ } public static void main(String[] args){ } }
rdd.mapPartitionsWithIndex { (idx, iter) => if (idx == 0) iter.drop(1) else iter }
data = sc.textFile( header = data.first() data = data.filter(row => row != header)
val spark = SparkSession.builder.config(conf).getOrCreate()
val dataFrame = spark.read.format("CSV").option("header","true").load(csvfilePath)
contentRDD = sc.textfile(<filepath>) filterDD = contentRDD.filter(lambda l: not l.startswith(<first column name>) for i in filterDD.take(5) : print (i)
context = new org.apache.spark.sql.SQLContext(sc) var data = context.read.option("header","true").csv("<path>")
schema = StructType([ StructField( StructField( df = sqlContext.read.format( options(header= delimiter="\t", treatEmptyValuesAsNulls=True, mode="DROPMALFORMED").load(input_file,schema=schema)
df = spark.read.option("header","true").format("csv").schema(myManualSchema).load("maestraDestacados.csv")
val fileNameHeader = sc.binaryFiles("E:\\sss\\*.txt",1).map{ case (fileName, stream)=> val header = new BufferedReader(new InputStreamReader(stream.open())).readLine() (fileName, header) }.collect().toMap val fileNameHeaderBr = sc.broadcast(fileNameHeader) sc.textFile("E:\\sss\\*.txt",1).mapPartitions(iter => if(iter.hasNext){ val firstLine = iter.next() println(s"Comparing with firstLine $firstLine") if(firstLine == fileNameHeaderBr.value.head._2) new WrappedIterator(null, iter) else new WrappedIterator(firstLine, iter) } else { iter } ).collect().foreach(println) class WrappedIterator(firstLine:String,iter:Iterator[String]) extends Iterator[String]{ var isFirstIteration = true override def hasNext: Boolean = { if (isFirstIteration && firstLine != null){ true } else{ iter.hasNext } } override def next(): String = { if (isFirstIteration){ println(s"For the first time $firstLine") isFirstIteration = false if (firstLine != null){ firstLine } else{ println(s"Every time $firstLine") iter.next() } } else { iter.next() } } }
sc = spark.sparkContext lines = sc.textFile("s3: parts = lines.map(lambda l: l.split(",")) parts.zipWithIndex().filter(lambda tup: tup[1] > 14).map(lambda x:x[0])
parts.withColumn("index",monotonically_increasing_id()).filter(index > 14)
val a: Array[Int] = Array(1,2,4,5) val b: Array[Int] = Array(1,2,4,5) a==b
val string = "one493two483three" val pattern = """two(\d+)three""".r pattern.findAllIn(string).foreach(println)
val pattern = """one.*two(\d+)three""".r val pattern(aMatch) = string println(aMatch)
val string = "one493two483three" val pattern = """two(\d+)three""".r pattern.findAllIn(string).matchData foreach { m => println(m.group(1)) }
val string = "one493two483three" val pattern = """(?<=two)\d+(?=three)""".r pattern.findAllIn(string).foreach(println)
val string = "one493two483three" val pattern = """.*two(\d+)three.*""".r string match { case pattern(a483) => println(a483) case _ => }
def extractFileNameFromHttpFilePathExpression(expr: String) = { val regex = "http4.*\\/(\\w+.(xlsx|xls|zip))$".r regex.findFirstMatchIn(expr) match { case Some(i) => i.group(1) case None => "regex_error" } } extractFileNameFromHttpFilePathExpression( "http4:
val l = List(List(1,2,3), List(2,3,4)) println(l.map(_.toString)) println(l.flatMap(x => x))
lines.map(line => line split "\\W+") lines.flatMap(line => line split "\\W+")
for {line <- lines word <- line split "\\W+"} yield word.length
lines.flatMap(line => line.split("\\W+").map(word => word.length))
scala> "Finding needle in haystack" contains "needle" res0: Boolean = true scala> "Finding needle in haystack" indexOf "needle" res1: Int = 8
scala> "needle".r.findAllIn("Finding needle in haystack").length res2: Int = 1
scala> "I have a needle in my haystack" matches ".*needle.*" res10: Boolean = true
scala> val l = List(1, 2, 3) l: List[Int] = List(1, 2, 3) scala> l.map(_ + 1) res0: List[Int] = List(2, 3, 4)
val conf = new SparkConf().setAppName("DemoDF").setMaster("local") val sc = new SparkContext(conf) val logData = sc.textFile("File.txt") logData.count()
16/02/26 18:29:33 INFO SparkContext: Created broadcast 0 from textFile at FrameDemo.scala:13 16/02/26 18:29:34 ERROR Shell: Failed to locate the winutils binary in the hadoop binary path java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries. at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278) at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300) at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293) at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76) at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362) at <br>org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015) at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015) at <br>org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176) at <br>org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)<br> at scala.Option.map(Option.scala:145)<br> at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)<br> at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)<br> at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)<br> at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)<br> at scala.Option.getOrElse(Option.scala:120)<br> at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)<br> at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)<br> at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)<br> at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)<br> at scala.Option.getOrElse(Option.scala:120)<br> at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)<br> at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)<br> at org.apache.spark.rdd.RDD.count(RDD.scala:1143)<br> at com.org.SparkDF.FrameDemo$.main(FrameDemo.scala:14)<br> at com.org.SparkDF.FrameDemo.main(FrameDemo.scala)<br>
File workaround = new File("."); System.getProperties().put("hadoop.home.dir", workaround.getAbsolutePath()); new File("./bin").mkdirs(); new File("./bin/winutils.exe").createNewFile();
System.setProperty("hadoop.home.dir", "D:\\hadoop");
1) Download winutils.exe from https: 2) Create a directory In windows "C:\winutils\bin 3) Copy the winutils.exe inside the above bib folder . 4) Set the environmental property in the code System.setProperty("hadoop.home.dir", "file: 5) Create a folder "file: 6) Add config property in spark Session ".config("spark.sql.warehouse.dir", "file:
import akka.actor.{Props, Actor} import scala.concurrent.duration._ import akka.pattern.ask class TellActor extends Actor { val recipient = context.actorOf(Props[ReceiveActor]) def receive = { case "Start" => recipient ! "Hello" case reply => println(reply) } } class AskActor extends Actor { val recipient = context.actorOf(Props[ReceiveActor]) def receive = { case "Start" => implicit val timeout = 3 seconds val replyF = recipient ? "Hello" replyF.onSuccess{ case reply => println(reply) } } } class ReceiveActor extends Actor { def receive = { case "Hello" => sender ! "And Hello to you!" } }
def main(args:Array[String]) { <some nice code here> }
package greeter object Hello extends App { println("Hello, World!") }
package greeter object Hello { def main(args:Array[String]) { println("Hello, World") } }
$ sbt > eclipse [info] About to create Eclipse project files for your project(s). [info] Updating {file:/...path-to-your-project}root... [info] Resolving jline [info] Done updating. [info] Successfully created Eclipse project files for project(s): [info] your-project-name
package main.scala object Main { def main(args: Array[String]){ println("Hello, I am the main object") } }
val appender:List[Int] => List[Int] = List(1,2,3) ::: List(3,4,5).foreach {println}
List(1,2,3) map(_*2) filter(_>2) (List(1,2,3) map(_*2)).reverse List(1,3,5) zip List(2,4,6)
case class MyBool(x: Boolean) { def !!! = MyBool(!x) def or(other: MyBool): MyBool = if(x) other else this def justMethod0() = this def justMethod2(a: MyBool, b: MyBool) = this override def toString = if(x) "true" else "false" }
val b1 = MyBool(true) no! no! val b2 = MyBool(true).no!(no!) Vector(1,2,3) toList map(_*2)
val c1 = MyBool(true) or b1 or MyBool(true) val c2 = MyBool(true).or(b1).or(MyBool(true)) c1 == c2
val d1 = MyBool(true) justMethod2(b1, c1) or b1 justMethod0() justMethod2(c1, b1) val d2 = MyBool(true).justMethod2(b1,c1).or(b1).justMethod0().justMethod2(c1, b1) d1 == d2 List(1,2,3) filter(_>1) map(_*2)
case class MyBool(value: Boolean) { def negated = new MyBool(!value) } val b1 = MyBool( true ) val b2 = b1 negated
String[] strings = {"foo"}; Object[] objects = strings; objects[0] = new Object();
(gear, steer, accel, pssngers) --------|---------|----------|--------- (1st, left, foot down, none) (neutral, straight, off, the kids)
scala> def foo[T](count: Int, value: T): Array[T] = Array.fill[T](count)(value) <console>:7: error: No ClassTag available for T def foo[T](count: Int, value: T): Array[T] = Array.fill[T](count)(value) ^
def foo[T:ClassTag](count: Int, value: T): Array[T] = Array.fill[T](count)(value)
class Ping(count: int, pong: Pong) extends Actor { def act() { pong ! receive { case } } }
object NewMain extends Thing{ def f1 = 10 def f2 {10} def f3 = {10} def f4() = 10 def f5() {10} def f6() = {10} def f7 = () => 10 def f8 = () => {10} def f9 = {() => {10}} def main(args: Array[String]){ println(f1) println(f2) println(f3) println(f4) println(f4()) println(f5) println(f5()) println(f6) println(f6()) println(f7) println(f7()) println(f8) println(f8()) println(f9) println(f9()) } }
def f() = 10 is sytactic sugar for def f() = { 10 }
val list = List(1,2,3) def inc(x: Int) = x+1 val inc2 = (x: Int) => x+1 println(list.map(inc)) println(list.map(inc2))
object NewMain extends Thing{ def f1 = 10 def f3 = {10} def f4() = 10 def f6() = {10} def f7 = () => 10 def f8 = () => {10} def f9 = {() => {10}} def main(args: Array[String]){ println(f1) println(f3) println(f4()) println(f6()) println(f7) println(f7()) println(f8) println(f8()) println(f9) println(f9()) } }
def sqrGtX (n:Int, x: Int) = { val sqr = n * n if (sqr > x) sqr / 2 else x / 2 }
def foo (n:Int, x: Int) = if (n > x) { val bar = x * x + n * n println (bar) bar - 2 } else x - 2
def removeMaxCool(xs: List[Int]) = { val maxIndex = xs.indexOf(xs.max); xs.take(maxIndex) ::: xs.drop(maxIndex+1) }
def removeMaxFast(xs: List[Int]) = { var res = ArrayBuffer[Int]() var max = xs.head var first = true; for (x <- xs) { if (first) { first = false; } else { if (x > max) { res.append(max) max = x } else { res.append(x) } } } res.toList }
val max = xs.max val (before, _ :: after) = xs span (max !=) before ::: after
def removeOneMax (xs: List [Int]) : List [Int] = xs match { case x :: Nil => Nil case a :: b :: xs => if (a < b) a :: removeOneMax (b :: xs) else b :: removeOneMax (a :: xs) case Nil => Nil }
import annotation.tailrec @tailrec def removeOneMax (xs: List [Int], carry: List [Int] = List.empty) : List [Int] = xs match { case a :: b :: xs => if (a < b) removeOneMax (b :: xs, a :: carry) else removeOneMax (a :: xs, b :: carry) case x :: Nil => carry case Nil => Nil }
((Nil : List[Int], xs(0)) /: xs.tail) ((p, x)=> if (p._2 > x) (x :: p._1, p._2) else ((p._2 :: p._1), x))._1
object PerfRemMax { def timed (name: String, xs: List [Int]) (f: List [Int] => List [Int]) = { val a = System.currentTimeMillis val res = f (xs) val z = System.currentTimeMillis val delta = z-a println (name + ": " + (delta / 1000.0)) res } def main (args: Array [String]) : Unit = { val n = args(0).toInt val funs : List [(String, List[Int] => List[Int])] = List ( "indexOf/take-drop" -> adrian1 _, "arraybuf" -> adrian2 _, "paradigmatic1" -> pm1 _, /**/ "paradigmatic2" -> pm2 _, "tailrec match" -> uu2 _, "foldLeft" -> uu3 _, "buf-=buf.max" -> soc1 _, "for/yield" -> soc2 _, "splitAt" -> daniel1, "ListBuffer" -> daniel2 ) val r = util.Random val xs = (for (x <- 1 to n) yield r.nextInt (n)).toList funs.foreach (f => { (1 to 10) foreach (i => { timed (f._1, xs.take (n/10 * i)) (f._2) compat.Platform.collectGarbage }); println () }) }
scala -Dserver PerfRemMax 2000000 indexOf/take-drop: 0.882 arraybuf: 1.681 paradigmatic1: 0.55 paradigmatic2: 1.13 tailrec match: 0.812 foldLeft: 1.054 buf-=buf.max: 1.185 for/yield: 0.725 splitAt: 1.127 ListBuffer: 0.61
splitAt: 0.109 splitAt: 0.118 splitAt: 0.129 splitAt: 0.139 splitAt: 0.157 splitAt: 0.166 splitAt: 0.749 splitAt: 0.752 splitAt: 1.444 splitAt: 1.127
def removeMax1( xs: List[Int] ) = { def rec( max: Int, rest: List[Int], result: List[Int]): List[Int] = { if( rest.isEmpty ) result else if( rest.head > max ) rec( rest.head, rest.tail, max :: result) else rec( max, rest.tail, rest.head :: result ) } rec( xs.head, xs.tail, List() ) }
def removeMax2( xs: List[Int] ) = { val result = xs.tail.foldLeft( xs.head -> List[Int]() ) { (acc,x) => val (max,res) = acc if( x > max ) x -> ( max :: res ) else max -> ( x :: res ) } result._2 }
def removeMax3( xs: List[Int] ) = { val max = xs.max xs.filterNot( _ == max ) }
def removeMaxCool(xs: List[Int]): List[Int] = { val maxIndex = xs.indexOf(xs.max); xs.take(maxIndex) ::: xs.drop(maxIndex+1) }
def removeMaxCool(xs: List[Int]): List[Int] = { xs.tail.foldLeft(xs.head -> List[Int]()) { case ((max, ys), x) => if (x > max) (x, max :: ys) else (max, x :: ys) }._2 }
def splitAt(n: Int): (Repr, Repr) = { val l, r = newBuilder l.sizeHintBounded(n, this) if (n >= 0) r.sizeHint(this, -n) var i = 0 for (x <- this) { (if (i < n) l else r) += x i += 1 } (l.result, r.result) }
def removeMax(xs: List[Int]) = { val buf = xs.toBuffer buf -= (buf.max) }
def removeMax(xs: List[Int]) = { var max = xs.head for ( x <- xs.tail ) yield { if (x > max) { val result = max; max = x; result} else x } }
(myList.foldLeft((List[Int](), None: Option[Int]))) { case ((_, None), x) => (List(), Some(x)) case ((Nil, Some(m), x) => (List(Math.min(x, m)), Some(Math.max(x, m)) case ((l, Some(m), x) => (Math.min(x, m) :: l, Some(Math.max(x, m)) })._1
interface Function<T, R> { R apply(T t); } class Pair<A, B> { ... } <State> State fold(List<A> list, State s0, Function<Pair<A, State>, State> f) { State s = s0; for (A a: list) { s = f.apply(new Pair<A, State>(a, s)); } return s; }
myList.fold(0)((partialSum, element) => partialSum + element)
def shareTail(xs: List[Int]): List[Int] = { var res = ListBuffer[Int]() var maxTail = xs var first = true; var x = xs while ( x != Nil ) { if (x.head > maxTail.head) { while (!(maxTail.head == x.head)) { res += maxTail.head maxTail = maxTail.tail } } x = x.tail } res.prependToList(maxTail.tail) }
package code.array object SliceArrays { def main(args: Array[String]): Unit = { println(removeMaxCool(Vector(1,2,3,100,12,23,44))) } def removeMaxCool(xs: Vector[Int]) = xs.filter(_ < xs.max) }
package code.array { object SliceArrays extends Object { def main(args: Array[String]): Unit = scala.Predef.println(SliceArrays.this.removeMaxCool(scala.`package`.Vector().apply(scala.Predef.wrapIntArray(Array[Int]{1, 2, 3, 100, 12, 23, 44})).$asInstanceOf[scala.collection.immutable.Vector]())); def removeMaxCool(xs: scala.collection.immutable.Vector): scala.collection.immutable.Vector = xs.filter({ ((x$1: Int) => SliceArrays.this.$anonfun$removeMaxCool$1(xs, x$1)) }).$asInstanceOf[scala.collection.immutable.Vector](); final <artifact> private[this] def $anonfun$removeMaxCool$1(xs$1: scala.collection.immutable.Vector, x$1: Int): Boolean = x$1.<(scala.Int.unbox(xs$1.max(scala.math.Ordering$Int))); def <init>(): code.array.SliceArrays.type = { SliceArrays.super.<init>(); () } } }
def list[T](list: List[T]) = "foobar" implicit def array2list[T](array: Array[T]) = array.toList
list(Array()) => error: polymorphic expression cannot be instantiated to expected type; found : [T]Array[T] required: List[?] list(Array()) ^
val ar1 = Array[String]("1", "2", "3") val ar2 = Array[String]("1", "2", "3", "4")
List.range(0, ar1.size).foreach(i => println(ar1(i)+ar2(i)))
ar1.zipWithIndex.foreach{ case(x,i) => println(x+ar2(i)) }
(0 until (ar1.size min ar2.size)).foreach(i => println(ar1(i)+ar2(i)))
{ var i=-1; ar1.foreach{ x => i += 1; println(x+ar2(i)) } }
scala> List("A", "B", "C").zipWithIndex foreach { case(el, i) => | println(i + ": " + el) | } 0: A 1: B 2: C
scala> val arr1 = Array("1", "2", "3") arr1: Array[java.lang.String] = Array(1, 2, 3) scala> val arr2 = Array("1", "2", "3", "4") arr2: Array[java.lang.String] = Array(1, 2, 3, 4) scala> (arr1, arr2).zipped.map(_ + _) foreach println 11 22 33
val ar1 = Array("1", "2", "3") val ar2 = Array("1", "2", "3", "4")
def optionalValue[T](l: List[T], index: Int) = { if (l.size < (index+1)) None else Some(l(index)) }
scala> List(1,2,3).lift res0: Int => Option[Int] = <function1> scala> List(1,2,3).lift(9) res1: Option[Int] = None
val r = (1 until 1000).view.filter(n => n % 3 == 0 || n % 5 == 0).sum
scala> (1 to 1000000000).filter(_ % 2 == 0).take(10).toList java.lang.OutOfMemoryError: GC overhead limit exceeded
scala> (1 to 1000000000).view.filter(_ % 2 == 0).take(10).toList res2: List[Int] = List(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)
>>> letters = [ >>> ints = [0, 1, 2, 3] >>> [l + str(i) for l in letters for i in ints if i % 2 == 0] [
scala> val letters = List( scala> val ints = List(0, 1, 2, 3) scala> for (l <- letters; i <- ints if i % 2 == 0) yield l.toString + i res0: List[java.lang.String] = List(a0, a2, b0, b2, c0, c2, d0, d2)
for v1 in gen1: if expr1: for v2 in gen2: if expr2: yield expr
gen1.withFilter(expr1).flatMap(v1 => gen2.withFilter(expr2).map(v2 => expr))
val res = for { i <- 1 to 20; i2 = i*i j <- 1 to 20; j2 = j*j k <- 1 to 20; k2 = k*k if i2 + j2 == k2 } yield (i, j, k)
scala> val list = List(Some(1), None, Some(2)) scala> for (Some(i) <- list) yield i res2: List[Int] = List(1, 2)
def foo(msf: String, o: Any, os: Any*) = { println( String.format(msf, o :: List(os:_*)) ) }
def foo(msf: String, o: Any, os: Any*) = { println( String.format(msf, (o :: List(os:_*))).toArray ) }
println(String.format(msg, (o :: List(os:_*)) :_* ))
def foo(msf: String, o: AnyRef, os: AnyRef*) = println( String.format(msf, (o :: os.toList).toArray : _* ))
def foo(msf: String, o: AnyRef, os: AnyRef*) = println( String.format(msf, o :: os.toList : _* ) )
def foo(msf: String, o: AnyRef, os: AnyRef*) = println( msf format (o :: os.toList : _* ) )
abstract class Shape case class Rectangle(width: Int, height: Int) extends Shape case class Location(x: Int, y: Int, shape: Shape) extends Shape case class Circle(radius: Int) extends Shape case class Group(shape: Shape*) extends Shape
object BoundingBox { def boundingBox(s: Shape): Location = s match { case Circle(c)=> new Location(-c,-c,s) case Rectangle(_, _) => new Location(0, 0, s) case Location(x, y, shape) => { val b = boundingBox(shape) Location(x + b.x, y + b.y, b.shape) } case Group(shapes @ _*) => ( /: shapes) { } } }
(var1: Type1, var2: Type2, ..., varN: TypeN) => (var1, var2, ..., varN) => var1 =>
(x: Double, y: Double, z: Double) => Math.sqrt(x*x + y*y + z*z) val f:(Double,Double)=>Double = (x,y) => x*y + Math.exp(-x*y) val neg:Double=>Double = x => -x
scala> List("How","long","are","we?") map (s => s.length) res0: List[Int] = List(3, 4, 3, 3) scala> List("How","capitalized","are","we?") map (s => s.toUpperCase) res1: List[java.lang.String] = List(HOW, CAPITALIZED, ARE, WE?) scala> List("How","backwards","are","we?") map (s => s.reverse) res2: List[scala.runtime.RichString] = List(woH, sdrawkcab, era, ?ew)
scala> List("How","long","is","longest?").foldLeft(0)((i,s) => i max s.length) res3: Int = 8 scala> List("How","long","is","everyone?").foldLeft(0)((i,s) => i + s.length) res4: Int = 18
scala> List("Who","is","longest?").foldLeft((0,""))((i,s) => | if (i._1 < s.length) (s.length,s) | else i | ) res5: (Int, java.lang.String) = (8,longest?)
scala> List("Who","is","longest?").reduceLeft((s1,s2) => | if (s2.length > s1.length) s2 | else s1 | ) res6: java.lang.String = longest?
scala> List("How","long","are","we?") map (_.length) res7: List[Int] = List(3, 4, 3, 3) scala> (0 /: List("How","long","are","we","all?"))(_ + _.length) res8: Int = 16
shapes.tail.foldLeft(boundingBox(shapes.head)) { case (box, shape) if box contains shape => box case (box, shape) if shape contains box => shape case (box, shape) => boxBounding(box, shape) }
abstract class Shape { def contains(s: Shape): Boolean } case class Rectangle(width: Int, height: Int) extends Shape { def contains(s: Shape): Boolean = s match { case Rectangle(w2, h2) => width >= w2 && height >= h2 case Location(x, y, s) => case Circle(radius) => width >= radius && height >= radius case Group(shapes @ _*) => shapes.forall(this.contains(_)) } } case class Location(x: Int, y: Int, shape: Shape) extends Shape { def contains(s: Shape): Boolean = } case class Circle(radius: Int) extends Shape { def contains(s: Shape): Boolean = s match { case Rectangle(width, height) => radius >= width && radius >= height case Location(x, y) => case Circle(r2) => radius >= r2 case Group(shapes @ _*) => shapes.forall(this.contains(_)) } } case class Group(shapes: Shape*) extends Shape { def contains(s: Shape): Boolean = shapes.exists(_ contains s) }
val bigBox = blist reduceLeft( (box1,box2) => combineBoxes(box1,box2) )
val number = 1 <plain>This is { number } string</plain> text
val height = 1.9d val name = "James" println(f"$name%s is $height%2.2f meters tall")
scala> "%d %d" format (1, 2) res0: String = 1 2 scala> "%2$d %1$d" format (1, 2) res1: String = 2 1
scala> val map = Map("number" -> 1) map: scala.collection.immutable.Map[java.lang.String,Int] = Map((number,1)) scala> val getGroup = (_: scala.util.matching.Regex.Match) group 1 getGroup: (util.matching.Regex.Match) => String = <function1> scala> val pf = getGroup andThen map.lift andThen (_ map (_.toString)) pf: (util.matching.Regex.Match) => Option[java.lang.String] = <function1> scala> val pat = " pat: scala.util.matching.Regex = scala> pat replaceSomeIn ("This is res43: String = This is 1 string
scala> implicit def RichFormatter(string: String) = new { | def richFormat(replacement: Map[String, Any]) = | (string /: replacement) {(res, entry) => res.replaceAll(" | } RichFormatter: (string: String)java.lang.Object{def richFormat(replacement: Map[String,Any]): String} scala> "This is res43: String = This is 1 string
val template = "Hello val replacements = Map( "name" -> "Aldo" ) replacements.foldLeft(template)((s:String, x:(String,String)) => ( "
% scalac -Xprint:typer test.scala [[syntax trees at end of typer]] package <empty> { @serializable case class A extends java.lang.Object with ScalaObject with Product { .. override def hashCode(): Int = ScalaRunTime.this._hashCode(A.this); ... override def equals(x$1: Any): Boolean = A.this.eq(x$1).||(x$1 match { case (i: Int,s: String)A((i$1 @ _), (s$1 @ _)) if i$1.==(i).&&(s$1.==(s)) => x$1.asInstanceOf[A].canEqual(A.this) case _ => false }); override def canEqual(x$1: Any): Boolean = x$1.$isInstanceOf[A]() }; }
def _hashCode(x: Product): Int = { val arr = x.productArity var code = arr var i = 0 while (i < arr) { val elem = x.productElement(i) code = code * 41 + (if (elem == null) 0 else elem.hashCode()) i += 1 } code }
override <synthetic> def hashCode(): Int = { <synthetic> var acc: Int = -889275714; acc = scala.runtime.Statics.mix(acc, i); acc = scala.runtime.Statics.mix(acc, scala.runtime.Statics.anyHash(s)); scala.runtime.Statics.finalizeHash(acc, 2) };
override <synthetic> def equals(x$1: Any): Boolean = A.this.eq(x$1.asInstanceOf[Object]).||(x$1 match { case (_: A) => true case _ => false }.&&({ <synthetic> val A$1: A = x$1.asInstanceOf[A]; A.this.i.==(A$1.i).&&(A.this.s.==(A$1.s)).&&(A$1.canEqual(A.this)) })) };
using System.Numerics; namespace ExtensionTest { public static class MyExtensions { public static BigInteger Square(this BigInteger n) { return n * n; } static void Main(string[] args) { BigInteger two = new BigInteger(2); System.Console.WriteLine("The square of 2 is " + two.Square()); } }}
object MyExtensions { implicit def richInt(i: Int) = new { def square = i * i } } object App extends Application { import MyExtensions._ val two = 2 println("The square of 2 is " + two.square) }
object MyExtensions { class RichInt(i: Int) { def square = i * i } implicit def richInt(i: Int) = new RichInt(i) }
implicit class RichInt(i: Int) { def square = i * i }
implicit class RichInt(val i: Int) extends AnyVal { def square = i * i }
object MyExtensions { class RichInt( i: Int ) { def square = i * i } implicit def richInt( i: Int ) = new RichInt( i ) def main( args: Array[String] ) { println("The square of 2 is: " + 2.square ) } }
illegal start of simple expression """),_display_(Seq[Any]( var)),format.raw (""" title : String = "Home"
@(listFromController: List[MyObject]) @filteredList = @{listFromController.filter(_.color == "red")} @for(myObject <- filteredList){ ... }
@(title:String)(implicit session:play.api.mvc.Session) @import java.math.BigInteger; var i=1; var k=1 ^ <div id= ^ <div id= ^ </div>
@(title: String = "Home page") <h1>Welcome on @title</h1>
def index = Action{ Ok(views.html.index("Other title")) }
public static Result index(){ return ok(views.html.index.render("Some default value...")); }
@{ val title = "Home" <h1>Welcome on {title}</h1> }
... Seq[Any](format.raw ("""<!DOCTYPE html> <html lang="en"> <head> <meta charset="UTF-8"> <title>Basic Twirl</title> </head> <body> """),_display_( { val title = "Home" <h1>Welcome on {title}</h1> }),format.raw ( ),format.raw ( )) } } } ...
@isExcel= {@Boolean.valueOf(java.lang.System.getProperty(SettingsProperties.isExcel))}
@random = @{ new Random().nextInt } <div id="@random"></div> <div id="@random"></div>
@defining(new Random().nextInt){ random => <div id="@random"></div> <div id="@random"></div> }
case class Edge(a:Strl, b:Strl) case class EdgeQA(a:Strl, b:Strl, right:Int, asked:Int ) extends Edge(a,b)
case class Edge(a:Strl, b:Strl) case class EdgeQA(private val a1:Strl, private val b1:Strl, right:Int, asked:Int ) extends Edge(a,b)
trait Edge{ def a:Strl def b:Strl } case class EdgeQA(override val a:Strl, override val b:Strl, right:Int, asked:Int ) extends Edge
trait BaseEdge { def a: Strl def b: Strl } case class Edge(a:Strl, b:Strl) extends BaseEdge case class EdgeQA(a:Strl, b:Strl, right:Int, asked:Int ) extends BaseEdge
case class Foo[A,B]( a: A, b: B )( implicit ev: A =:= B ) scala> Foo( 1, 2 ) res3: Foo[Int,Int] = Foo(1,2) scala> Foo( 1, "2" ) <console>:10: error: Cannot prove that Int =:= java.lang.String.
sealed class =!=[A,B] trait LowerPriorityImplicits { implicit def equal[A]: =!=[A, A] = sys.error("should not be called") } object =!= extends LowerPriorityImplicits { implicit def nequal[A,B](implicit same: A =:= B = null): =!=[A,B] = if (same != null) sys.error("should not be called explicitly with same type") else new =!=[A,B] } case class Foo[A,B](a: A, b: B)(implicit e: A =!= B)
Foo(1f, 1.0) Foo("", 1.0) Foo("", 1) Foo("Fish", Some("Fish"))
sealed class =!=[A,B] trait LowerPriorityImplicits { /** do not call explicitly! */ implicit def equal[A]: =!=[A, A] = sys.error("should not be called") } object =!= extends LowerPriorityImplicits { /** do not call explicitly! */ implicit def nequal[A,B]: =!=[A,B] = new =!=[A,B] }
trait =!=[A, B] implicit def neq[A, B] : A =!= B = null implicit def neqAmbig1[A] : A =!= A = null implicit def neqAmbig2[A] : A =!= A = null
case class Foo[A,B](a : A, b : B)(implicit ev: A =!= B) new Foo(1, "1") new Foo("foo", Some("foo"))
type ¬[T] = T => Nothing implicit def neg[T, U](t : T)(implicit ev : T =!= U) : ¬[U] = null def notString[T <% ¬[String]](t : T) = t
scala> val ns1 = notString(1) ns1: Int = 1 scala> val ns2 = notString(1.0) ns2: Double = 1.0 scala> val ns3 = notString(Some("foo")) ns3: Some[java.lang.String] = Some(foo) scala> val ns4 = notString("foo") <console>:14: error: No implicit view available from java.lang.String => (String) => Nothing. val ns4 = notString2("foo") ^
<console>:10: error: ambiguous implicit values: both method neqAmbig1 in object =!= of type [A]=> =!=[A,A] and method neqAmbig2 in object =!= of type [A]=> =!=[A,A] match expected type =!=[String,String] f[String] ^
@annotation.implicitNotFound(msg = "Cannot prove that ${A} =!= ${B}.") trait =!=[A,B] object =!= { class Impl[A, B] object Impl { implicit def neq[A, B] : A Impl B = null implicit def neqAmbig1[A] : A Impl A = null implicit def neqAmbig2[A] : A Impl A = null } implicit def foo[A,B]( implicit e: A Impl B ): A =!= B = null }
scala> f[String] <console>:10: error: Cannot prove that String =!= String. f[String] ^
@annotation.implicitNotFound(msg = "Cannot prove that ${A} <:!< ${B}.") trait <:!<[A,B] object <:!< { class Impl[A, B] object Impl { implicit def nsub[A, B] : A Impl B = null implicit def nsubAmbig1[A, B>:A] : A Impl B = null implicit def nsubAmbig2[A, B>:A] : A Impl B = null } implicit def foo[A,B]( implicit e: A Impl B ): A <:!< B = null } type IsNotSub[B] = { type λ[A] = A <:!< B }
@annotation.implicitNotFound(msg = "Cannot prove that ${A} <%!< ${B}.") trait <%!<[A,B] object <%!< { class Impl[A, B] object Impl { implicit def nconv[A, B] : A Impl B = null implicit def nconvAmbig1[A<%B, B] : A Impl B = null implicit def nconvAmbig2[A<%B, B] : A Impl B = null } implicit def foo[A,B]( implicit e: A Impl B ): A <%!< B = null } type IsNotView[B] = { type λ[A] = A <%!< B }
case class Foo[A, B <: A, C <: A]( a: B, b: C)(implicit f: AnyVal <:< A) scala> Foo(1f, 1.0) res75: Foo[AnyVal,Float,Double] = Foo(1.0,1.0) scala> Foo("", 1.0) res76: Foo[Any,java.lang.String,Double] = Foo(,1.0) scala> Foo(1f, 1f) <console>:10: error: Cannot prove that AnyVal <:< Float. Foo(1f, 1f) ^ scala> Foo("", "") <console>:10: error: Cannot prove that AnyVal <:< java.lang.String. Foo("", "") ^ scala> Foo("", 1) res79: Foo[Any,java.lang.String,Int] = Foo(,1)
class =!=[A, B] private () extends NotNull object =!= { implicit def notMeantToBeCalled1[A, B >: A, C >: B <: A]: =!=[B, A] = error("should not be called") implicit def notMeantToBeCalled2[A, B >: A, C >: B <: A]: =!=[B, A] = error("should not be called") implicit def unambigouslyDifferent[A, B](implicit same: A =:= B = null): =!=[A, B] = if (same != null) error("should not be called explicitly with the same type") else new =!= } case class Foo[A, B](a: A, b: B)(implicit ev: A =!= B)
Foo(1f, 1.0) Foo("", 1.0) Foo("", 1) Foo("Fish", Some("Fish"))
class Foo[A, B] private (a: A, b: B) object Foo { def apply[A, B <: A, C >: A <: B](a: A, b: B)(implicit nothing: Nothing) = nothing def apply[A, B >: A, C >: B <: A](a: A, b: B)(implicit nothing: Nothing, dummy: DummyImplicit) = nothing def apply[A, B](a: A, b: B): Foo[A, B] = new Foo(a, b) }
Foo(1f, 1.0) Foo("", 1.0) Foo("", 1) Foo("Fish", Some("Fish"))
class AreEqual[A, B] trait LowerPriorityImplicits { implicit def toNo[A : Manifest, B : Manifest]: No[A, B] = No[A, B] } object AreEqual extends LowerPriorityImplicits { implicit def toYes[A, B](implicit ev: A =:= B, m1: Manifest[A], m2: Manifest[B]): Yes[A, B] = Yes[A, B] } case class Yes[A : Manifest, B : Manifest]() extends AreEqual[A, B] { override def toString: String = "Yes(%s, %s)" format (manifest[A].toString, manifest[B].toString) } case class No[A : Manifest, B : Manifest]() extends AreEqual[A, B] { override def toString: String = "No(%s, %s)" format (manifest[A].toString, manifest[B].toString) }
scala> implicitly[AreEqual[String, Option[String]]] res0: AreEqual[String,Option[String]] = No(java.lang.String, scala.Option[java.lang.String]) scala> implicitly[AreEqual[String, String]] res1: AreEqual[String,String] = Yes(java.lang.String, java.lang.String)
scala> val aSymbol = aSymbol: Symbol = scala> assert("thisIsASymbol" == aSymbol.name)
java -Dsbt.log.noformat=true $JAVA_OPTS -jar "${HOME}/bin/sbt-launch.jar" "$@"
object MyAppBuild extends Build { import Dependencies._ lazy val basicSettings = Seq[Setting[_]]( organization := "com.my", version := "0.1", description := "Blah", scalaVersion := "2.9.1", scalacOptions := Seq("-deprecation", "-encoding", "utf8"), resolvers ++= Dependencies.resolutionRepos ) lazy val myAppProject = Project("my-app-name", file(".")) .settings(basicSettings: _*) [...]
lazy val root = (project in file(".")). enablePlugins(BuildInfoPlugin). settings( buildInfoKeys := Seq[BuildInfoKey](name, version, scalaVersion, sbtVersion), buildInfoPackage := "foo" )
sourceGenerators in Compile <+= (sourceManaged in Compile, version, name) map { (d, v, n) => val file = d / "info.scala" IO.write(file, """package foo |object Info { | val version = "%s" | val name = "%s" |} |""".stripMargin.format(v, n)) Seq(file) }
val p = getClass.getPackage val name = p.getImplementationTitle val version = p.getImplementationVersion
scala>import scala.util.parsing.json.JSON._ import scala.util.parsing.json.JSON._ scala> import net.liftweb.http.js._ import net.liftweb.http.js._ scala> import net.liftweb.http.js.JE._ import net.liftweb.http.js.JE._ scala> val json = JsObj(("foo", 4), ("bar", "baz")).toJsCmd json: String = { scala> parseFull(json) res3: Option[Any] = None
scala> import net.liftweb.json.JsonAST import net.liftweb.json.JsonAST scala> import net.liftweb.json.JsonDSL._ import net.liftweb.json.JsonDSL._ scala> import net.liftweb.json.Printer._ import net.liftweb.json.Printer._ scala> val json1 = ("foo" -> 4) ~ ("bar" -> "baz") json1: net.liftweb.json.JsonAST.JObject = JObject(List(JField(foo,JInt(4)), JField(bar,JString(baz)))) scala> compact(JsonAST.render(json1)) res0: String = {"foo":4,"bar":"baz"} scala> val json2 = List(1,2,3) json2: List[Int] = List(1, 2, 3) scala> compact(JsonAST.render(json2)) res1: String = [1,2,3] scala> val json3 = ("foo", 4) ~ ("bar", List(1,2,3)) json3: net.liftweb.json.JsonAST.JObject = JObject(List(JField(foo,JInt(4)), JField(bar,JArray(List(JInt(1), JInt(2), JInt(3)))))) scala> compact(JsonAST.render(json3)) res2: String = {"foo":4,"bar":[1,2,3]}
scala> import scala.xml.dtd.PublicID import scala.xml.dtd.PublicID scala> import net.liftweb.json._ import net.liftweb.json._ scala> import net.liftweb.json.JsonAST._ import net.liftweb.json.JsonAST._ scala> import net.liftweb.json.JsonDSL._ import net.liftweb.json.JsonDSL._ scala> implicit val formats = DefaultFormats formats: net.liftweb.json.DefaultFormats.type = net.liftweb.json.DefaultFormats$@7fa27edd scala> val jsonAst = ("publicId1" -> "idString") ~ ("systemId" -> "systemIdStr") jsonAst: net.liftweb.json.JsonAST.JObject = JObject(List(JField(publicId,JString(idString)), JField(systemId,JString(systemIdStr)))) scala> jsonAst.extract[PublicID] res0: scala.xml.dtd.PublicID = PUBLIC "idString" "systemIdStr"
scala>import scala.util.parsing.json.JSON._ import scala.util.parsing.json.JSON._ scala> parseFull("{\"foo\" : 4 }") res1: Option[Any] = Some(Map(foo -> 4.0)) scala> parseFull("[ 1,2,3 ]") res2: Option[Any] = Some(List(1.0, 2.0, 3.0)) scala> parseFull("{ res3: Option[Any] = None
scala> import net.liftweb.util.JSONParser._ import net.liftweb.util.JSONParser._ scala> parse("{\"foo\" : 4 }") res1: net.liftweb.common.Box[Any] = Full(Map(foo -> 4.0)) scala> parse("[ 1,2,3 ]") res2: net.liftweb.common.Box[Any] = Full(List(1.0, 2.0, 3.0)) scala> parse("{ res3: net.liftweb.common.Box[Any] = Full(Map(foo -> 4.0))
scala> import net.liftweb.json._ import net.liftweb.json._ scala> import net.liftweb.json.JsonParser._ import net.liftweb.json.JsonParser._ scala> parse("{\"foo\" : 4 }") res1: net.liftweb.json.JsonAST.JValue = JObject(List(JField(foo,JInt(4)))) scala> parse("[ 1,2,3 ]") res2: net.liftweb.json.JsonAST.JValue = JArray(List(JInt(1), JInt(2), JInt(3))) scala> parse("{ net.liftweb.json.JsonParser$ParseException: unknown token ' Near: { at net.liftweb.json.JsonParser$Parser.fail(JsonParser.scala:216) at net.liftweb.json.JsonParser$Parser.nextToken(JsonParser.scala:308) at net.liftweb.json.JsonParser$$anonfun$1.apply(JsonParser.scala:172) at net.liftweb.json.JsonParser$$anonfun$1.apply(JsonParser.scala:129) at net.liftweb.json.JsonParse...
scala> import net.liftweb.http.js._ import net.liftweb.http.js._ scala> import net.liftweb.http.js.JE._ import net.liftweb.http.js.JE._ scala> JsObj(("foo", 4), ("bar", "baz")).toJsCmd res0: String = { scala> JsArray(1,2,3).toJsCmd res1: String = [1, 2, 3] scala> JsObj(("foo", 4), ("bar", JsArray(1,2,3))).toJsCmd res2: String = { }
scala> import net.liftweb.http.js._ import net.liftweb.http.js._ scala> import net.liftweb.http.js.JE._ import net.liftweb.http.js.JE._ scala> JsObj(("foo", 4), ("bar", "baz")).toJsCmd res0: String = {"foo": 4, "bar": "baz"} scala> JsArray(1,2,3).toJsCmd res1: String = [1, 2, 3] scala> JsObj(("foo", 4), ("bar", JsArray(1,2,3))).toJsCmd res3: String = {"foo": 4, "bar": [1, 2, 3] }
scala> import scala.util.parsing.json._ import scala.util.parsing.json._ scala> JSONObject (Map ("foo" -> 4, "bar" -> JSONArray (1 :: 2 :: 3 :: Nil))) .toString() res0: String = {"foo" : 4, "bar" : [1, 2, 3]}
def f(ab:(Int, Int)) : Int = { val (a, b) = ab a + b } val d = (1, 2) f(d)
scala> val f: ((Int, Int)) => Int = { case (a,b) => a+b } f: ((Int, Int)) => Int scala> f(1, 2) res0: Int = 3
scala> def f(ab: (Int, Int)): Int = ab match { case (a,b) => a+b } f: (ab: (Int, Int))Int scala> f(1, 2) res1: Int = 3
scala> val f: (Int, Int) => Int = _+_ f: (Int, Int) => Int = <function2> scala> val g = f.tupled g: ((Int, Int)) => Int = <function1> scala> g(1, 2) res10: Int = 3 scala> def f(a: Int, b: Int): Int = a+b f: (a: Int, b: Int)Int scala> val g = (f _).tupled g: ((Int, Int)) => Int = <function1> scala> g(1, 2) res11: Int = 3 scala> val f: ((Int,Int)) => Int = Function.tupled(_+_) f: ((Int, Int)) => Int = <function1> scala> f(1, 2) res12: Int = 3
object RandomExperiments extends App{ def takeTuple(t:(Int,Int))=print (s"$t ${t._1}\n") takeTuple(1,3) takeTuple((1,3)) takeTuple(((1,3))) }
scala> Array("1","2","3").foldLeft(0)(_ + _.toInt) res6: Int = 6
scala> Array("1","2","3").fold(0)(_ + _.toInt) <console>:8: error: value toInt is not a member of Any Array("1","2","3").fold(0)(_ + _.toInt) ^
List(1,2,3,4,5).foldLeft(0)(_ + _) 0+1 = 1 1+2 = 3 3+3 = 6 6+4 = 10 10 + 5 = 15 15 List(1,2,3,4,5).fold(0)(_ + _) 0+1 = 1 0+3 = 3 0+5 = 5 1+2 = 3 3+4 = 7 5 3 + 7=10 5 10 + 5 = 15 15
Array("1","2","3").foldLeft(0)(_ + _.toInt) = ((0 + "1".toInt) + "2".toInt) + "3".toInt
Array("1","2","3").fold(0)(_ + _.toInt) = ((0 + "1".toInt) + "2".toInt) + "3".toInt or (0 + "1".toInt) + ("2" + "3".toInt).toInt or "1" + ("2" + ("3" + 0.toInt).toInt).toInt
fold[A1 >: A](z: A1)(op: (A1, A1) => A1): A1 foldLeft[B](z: B)(f: (B, A) => B): B
def aggregate[B](z: B)(seqop: (B, A) => B, combop: (B, B) => B): B
case class TrackInt(v: Int) { val log = collection.mutable.Buffer.empty[Int] def plus(that: TrackInt) = { this.log += that.v that.log += this.v new TrackInt(this.v + that.v) } }
val xs = (1 to 10).map(TrackInt(_)).par val zero = TrackInt(0)
scala> xs.foldLeft(zero)(_ plus _) res0: TrackInt = TrackInt(55) scala> zero.log res1: scala.collection.mutable.Buffer[Int] = ArrayBuffer(1)
scala> zero.log.clear() scala> xs.fold(zero)(_ plus _) res2: TrackInt = TrackInt(55) scala> zero.log res3: scala.collection.mutable.Buffer[Int] = ArrayBuffer(1, 6, 2, 7, 8)
fold[A1 >: A](z: A1)(op: (A1, A1) ⇒ A1): A1 foldLeft[B](z: B)(f: (B, A) ⇒ B): B
def fold[A1 >: A](z: A1)(op: (A1, A1) => A1): A1 = foldLeft(z)(op)
def fold[U >: T](z: U)(op: (U, U) => U): U = { executeAndWaitResult(new Fold(z, op, splitter)) }
trait T{ } object X extends T object Y extends T { }
object X{ def x = 5 } object Y{ import X._ val y = x }
object X { } object Y { def a = 5 } implicit def xToY(x: X.type) = Y println(X.a)
val A = "a" val b = "b" "a" match { case b => println("b") case A => println("A") }
"a" match { case `b` => println("b") case A => println("A") }
class WatchActor extends Actor { val child = context.actorOf(Props.empty, "child") ... def receive = { ... case Terminated(`child`) ⇒ ... } }
import akka.actor.{Actor, ActorSystem, Props} case object FromActor3 /** * forward method: Forwards the message and passes the original sender actor as the sender. */ object ActorForward extends App { class ActorExample extends Actor { def receive = { case message: String => println(s"Message received from ${sender.path.name}, message = $message") val child = context.actorOf(Props[Actor2], "ChildActor") child ! message case FromActor3 => println("Response when forwarded by Actor2 to Actor3") } } class Actor2 extends Actor { def receive = { case message: String => println(s"Message received from ${sender.path.name}, message = $message") val child = context.actorOf(Props[Actor3], "ChildActor") println("forwarding...") child forward message case _ => println("Unknown message") } } class Actor3 extends Actor { def receive = { case message: String => println(s"Message received from ${sender.path.name}, message = $message") sender ! FromActor3 case _ => println("Unknown message") } } val actorSystem = ActorSystem("ActorSystem") val actor = actorSystem.actorOf(Props[ActorExample], "RootActor") actor ! "Hello" }
def echo(args: String*) = for (arg <- args) println(arg) val arr = Array("What echo(arr: _*)
def multiply(x:Int, y:Int) = { x * y; } val operands = (2, 4) multiply (operands : _*)
def multiply(x:Int, y:Int) = { x*y; } val operands = (2, 4) multiply _ tupled operands
object Main { private [this] val TAG = classOf [Main].getName; }
scala> Main.getClass res1: java.lang.Class[_] = class Main$
addSbtPlugin("com.typesafe.play" % "sbt-plugin" % "2.3.2")
$ ggrep --help | grep -i Perl -P, --perl-regexp PATTERN is a Perl regular expression
$ find . -name "plugins.sbt" -exec ggrep -PHin --color=always
-P, --perl-regexp PATTERN is a Perl regular expression -i, --ignore-case ignore case distinctions -n, --line-number print line number with output lines -H, --with-filename print file name with output lines
case class thing(id: Int) val rand = new java.util.Random val distribution = Map(thing(0) -> 0.5, thing(1) -> 0.5) val perturbed = distribution mapValues { _ + 0.1 * rand.nextGaussian } val sumProbs = perturbed.map{_._2}.sum val newDistribution = perturbed mapValues { _ / sumProbs }
scala> val xs = Map("a" -> 1, "b" -> 2) xs: scala.collection.immutable.Map[java.lang.String,Int] = Map(a -> 1, b -> 2) scala> val ys = xs.mapValues(_ + Random.nextInt).map(identity) ys: scala.collection.immutable.Map[java.lang.String,Int] = Map(a -> 1315230132, b -> 1614948101) scala> ys res7: scala.collection.immutable.Map[java.lang.String,Int] = Map(a -> 1315230132, b -> 1614948101)
def n_rands(n : Int) = { val r = new scala.util.Random 1 to n map { _ => r.nextInt(100) } }
import util.Random.nextInt Stream.continually(nextInt(100)).take(10)
scala> val pf: PartialFunction[String, String] = { case "a" => "b" } pf: PartialFunction[String,String] = <function1> scala> val pf: PartialFunction[String, String] = { } <console>:5: error: type mismatch; found : Unit required: PartialFunction[String,String] val pf: PartialFunction[String, String] = { } ^
val undefined: PartialFunction[Any, Nothing] = Map.empty
val emptyPf = PartialFunction.empty[String, String]
scala> def pfEmpty[A, B] = new PartialFunction[A, B] { | def apply(a: A): B = sys.error("Not supported") | def isDefinedAt(a: A) = false | } pfEmpty: [A, B]=> java.lang.Object with PartialFunction[A,B] scala> val f = pfEmpty[String, String] f: java.lang.Object with PartialFunction[String,String] = <function1> scala> f.lift res26: (String) => Option[String] = <function1> scala> res26("Hola") res27: Option[String] = None
scala> object Undefined extends PartialFunction[Any, Nothing] { | def isDefinedAt(a: Any) = false | def apply(a: Any): Nothing = sys.error("undefined") | } defined module Undefined scala> val f: PartialFunction[String, String] = Undefined f: PartialFunction[String,String] = <function1> scala> f.lift apply "Hola" res29: Option[String] = None
val undefined : PartialFunction[Any, Nothing] = {case _ if false => sys.error("undefined") }
case class Complex(real: Double = 0, imaginary: Double = 0) { def ++: @Complex = { assign copy(real = real + 1) }
import scalaz._ import Scalaz._ case class IncLens[S,N](lens: Lens[S,N], num : Numeric[N]) { def ++ = lens.mods(num.plus(_, num.one)) } implicit def incLens[S,N:Numeric](lens: Lens[S,N]) = IncLens[S,N](lens, implicitly[Numeric[N]]) val i = Lens[Int,Int](identity, (x, y) => y) val imperativeProgram = for { _ <- i := 0; _ <- i++; _ <- i++; x <- i++ } yield x def runProgram = imperativeProgram ! 0
implicit class RichInt2(n: Int) { def isOdd: Boolean = if (n % 2 == 1) true else false def isEven: Boolean = if (n % 2 == 0) true else false def ++ : Int = n + 1 def -- : Int = n - 1 }
import scala.language.postfixOps /* * my custom int class which can do ++ and -- */ class int(value: Int) { var mValue = value def ++(): int = { val toReturn = new int(mValue) mValue += 1 return toReturn } def --(): int = { val toReturn = new int(mValue) mValue -= 1 return toReturn } override def toString(): String = { return mValue.toString } } def ++(n: int): int = { n.mValue += 1 return n; } def --(n: int): int = { n.mValue -= 1 return n; } def *(n: int): Int = { return n.mValue }
scala>var num = new int(4) num: int = 4 scala>num++ res0: int = 4 scala>num res1: int = 5 scala>++(num) res2: int = 6 scala>num res3: int = 6 scala>++(num)++ res4: int = 7 scala>num res5: int = 8 scala>*(num) + *(num) res6: Int = 16
class IntPostOp(val i: Int) { def apply(op: Unit) = { op; i } } implicit def int2IntPostOp(i: Int): IntPostOp = new IntPostOp(i)
class PlusPlusInt(i: Int){ def ++ = i+1 } implicit def int2PlusPlusInt(i: Int) = new PlusPlusInt(i) val a = 5++
scala> class Foo defined class Foo scala> trait FooTrait extends Foo defined trait FooTrait scala> val good = new Foo with FooTrait good: Foo with FooTrait = $anon$1@773d3f62 scala> class Bar defined class Bar scala> val bad = new Bar with FooTrait <console>:10: error: illegal inheritance; superclass Bar is not a subclass of the superclass Foo of the mixin trait FooTrait val bad = new Bar with FooTrait ^
val xs = List.tabulate(5)(_ + 1) val ys = xs.view map { x => println(x); x * x }
case class Transform(n: Int) { println("Transform "+n)} val list = List(1,2,3,4,5) list.view.map(v => Transform(v)).collectFirst{case Transform(3) => println("found")}
list.map(v => Transform(v)).collectFirst{case Transform(3) => println("found")}
Transform 1 Transform 2 Transform 3 Transform 4 Transform 5 found
def cancellable[T](f: Future[T])(customCode: => Unit): (() => Unit, Future[T]) = { val p = Promise[T] val first = Future firstCompletedOf Seq(p.future, f) val cancellation: () => Unit = { () => first onFailure { case e => customCode} p failure new Exception } (cancellation, first) }
val f = callReturningAFuture() val (cancel, f1) = cancellable(f) { cancelTheCallReturningAFuture() } if (condition) cancel() else println(Await.result(f1))
import java.util.concurrent.{Callable, FutureTask} import scala.concurrent.{ExecutionContext, Promise} import scala.util.Try class Cancellable[T](executionContext: ExecutionContext, todo: => T) { private val promise = Promise[T]() def future = promise.future private val jf: FutureTask[T] = new FutureTask[T]( new Callable[T] { override def call(): T = todo } ) { override def done() = promise.complete(Try(get())) } def cancel(): Unit = jf.cancel(true) executionContext.execute(jf) } object Cancellable { def apply[T](todo: => T)(implicit executionContext: ExecutionContext): Cancellable[T] = new Cancellable[T](executionContext, todo) }
class Cancellable[T](executionContext: ExecutionContext, todo: => T) { private val jf: FutureTask[T] = new FutureTask[T]( new Callable[T] { override def call(): T = todo } ) executionContext.execute(jf) implicit val _: ExecutionContext = executionContext val future: Future[T] = Future { jf.get } def cancel(): Unit = jf.cancel(true) } object Cancellable { def apply[T](todo: => T)(implicit executionContext: ExecutionContext): Cancellable[T] = new Cancellable[T](executionContext, todo) }
case class Monoid[A](m0: A) implicit def s[T] : Monoid[Set[T]] = Monoid(Set.empty[T]) implicit def l[T] : Monoid[List[T]] = Monoid(List.empty[T]) def mzero[A](implicit m: Monoid[A]) : A = m.m0
scala> mzero : List[Int] <console>:24: error: ambiguous implicit values: both method s of type [T]=> Monoid[Set[T]] and method l of type [T]=> Monoid[List[T]] match expected type Monoid[A] mzero : List[Int] ^
def i[A](implicit a : A) : A = a scala> i : Monoid[List[Int]] res18: Monoid[List[Int]] = Monoid(List())
case class Monoid[A](m0: A) implicit def s[T] : Monoid[Set[T]] = Monoid(Set.empty[T]) implicit def l[T] : Monoid[List[T]] = Monoid(List.empty[T]) def mzero[A]()(implicit m: Monoid[A]) : A = m.m0 val zero = mzero[List[Int]]() val zero2: List[Int] = mzero()
import collection.breakOut val l2: List[Object] = list.groupBy(_.property).map(_._2.head)(breakOut)
list.foldRight((List[Object](), Set[Property]())) { case (o, cum@(objects, props)) => if (props(o.property)) cum else (o :: objects, props + o.property)) }._1
import scala.collection.IterableLike import scala.collection.generic.CanBuildFrom class RichCollection[A, Repr](xs: IterableLike[A, Repr]){ def distinctBy[B, That](f: A => B)(implicit cbf: CanBuildFrom[Repr, A, That]) = { val builder = cbf(xs.repr) val i = xs.iterator var set = Set[B]() while (i.hasNext) { val o = i.next val b = f(o) if (!set(b)) { set += b builder += o } } builder.result } } implicit def toRich[A, Repr](xs: IterableLike[A, Repr]) = new RichCollection(xs)
scala> list.distinctBy(_.property) res7: List[Obj] = List(Obj(1), Obj(2), Obj(3))
list.filterNot{ var set = Set[Property]() obj => val b = set(obj.property); set += obj.property; b}
@tailrec def collectUnique(l: List[Object], s: Set[Property], u: List[Object]): List[Object] = l match { case Nil => u.reverse case (h :: t) => if (s(h.property)) collectUnique(t, s, u) else collectUnique(t, s + h.prop, h :: u) }
List(("a", 2), ("b", 2), ("a", 5)).distinctBy(_._1) List(("a", 2.7), ("b", 2.1), ("a", 5.4)).distinctBy(_._2.floor)
def distinctBy[L, E](list: List[L])(f: L => E): List[L] = list.foldLeft((Vector.empty[L], Set.empty[E])) { case ((acc, set), item) => val key = f(item) if (set.contains(key)) (acc, set) else (acc :+ item, set + key) }._1.toList distinctBy(list)(_.property)
def distinctBy[T, P, From[X] <: TraversableLike[X, From[X]]](collection: From[T])(property: T => P): From[T] = { val uniqueValues: Set[T] = collection.groupBy(property).map(_._2.head)(breakOut) collection.filter(uniqueValues) }
scala> distinctBy(List(redVolvo, bluePrius, redLeon))(_.color) res0: List[Car] = List(redVolvo, bluePrius)
def distinctBy[A, B](xs: List[A])(f: A => B): List[A] = scala.reflect.internal.util.Collections.distinctBy(xs)(f)
case class FirstCC { def name: String = ... } case class SecondCC extends FirstCC val one = FirstCC() val two = SecondCC()
case class FirstCC { def name = productPrefix } case class SecondCC extends FirstCC val one = FirstCC() val two = SecondCC() one.name two.name
class Example { private def className[A](a: A)(implicit m: Manifest[A]) = m.toString override def toString = className(this) }
import scala.reflect.runtime.universe._ object TypeString { def typeString[T :TypeTag]: String = { def work(t: Type): String = { t match { case TypeRef(pre, sym, args) => val ss = sym.toString.stripPrefix("trait ").stripPrefix("class ").stripPrefix("type ") val as = args.map(work) if (ss.startsWith("Function")) { val arity = args.length - 1 "(" + (as.take(arity).mkString(",")) + ")" + "=>" + as.drop(arity).head } else { if (args.length <= 0) ss else (ss + "[" + as.mkString(",") + "]") } } } work(typeOf[T]) } def typeString[T :TypeTag](x: T): String = typeString[T] }
WS .url(url) .get .map { response => response.status match { case 200 => Right(response.json) case status => Left(s"Problem accessing api, status } }
import play.api.libs.concurrent.Execution.Implicits._
class Foo @Inject()()(implicit ec:ExecutionContext) { def bar() = { WS.url(url) .get .map { response => response.status match { case 200 => Right(response.json) case status => Left(s"Problem accessing api, status } } }
import scala.concurrent.ExecutionContext.Implicits.global
implicit class RichBoolean(val b: Boolean) extends AnyVal { final def option[A](a: => A): Option[A] = if (b) Some(a) else None }
scala> (Option(true).collect { case true => 3 }, Option(false).collect { case true => 3 }) res3: (Option[Int], Option[Int]) = (Some(3),None)
implicit class BoolToOption(val self: Boolean) extends AnyVal { def toOption[A](value: => A): Option[A] = if (self) Some(value) else None }
scala> true.toOption("hi") res5: Option[String] = Some(hi) scala> false.toOption("hi") res6: Option[String] = None
scala> PartialFunction.condOpt(5) { case x if true => x } res9: Option[Int] = Some(5) scala> PartialFunction.condOpt(5) { case x if false => x } res10: Option[Int] = None
implicit class RichOptionCompanion(val self: Option.type) extends AnyVal { def when[A](cond: Boolean)(value: => A): Option[A] = if(cond) Some(value) else None }
class RichBool[T](a: Boolean, res:=> T) { def toOption: Option[T] = if (a) Some(res) else None } implicit def boolToRichBool[T](tp: (Boolean, T)): RichBool[T] = new RichBool(tp._1, tp._2);
val bool: Boolean = ??? val result = 1337 Option(bool).withFilter(identity).map(_ => result)
def sum(f: Int => Int) = (a: Int, b: Int) => f(a) + f(b) def sum2(f: Int => Int, a: Int, b: Int): Int = f(a) + f(b) def sum3(f: Int => Int)(a: Int, b: Int): Int = f(a) + f(b) val ho = sum({identity}) val partial = sum2({ identity }, _, _) val currying = sum3({ identity }) val a = currying(2, 2) val b = partial(2, 2) val c = ho(2, 2)
def max[T](xs: List[T])(compare: (T, T) => Boolean)
def sum4(a: Int, b: Int)(f: Int => Int): Int = f(a) + f(b) val d = sum4(2, 2) { x => x * x }
scala> :paste -raw package Foo class Bar scala> import Foo._ import Foo._ scala> new Bar res1: Foo.Bar = Foo.Bar@3ee2cf81
val src = ... pushElement(x1, src) pushElement(x2, src)
case class Weather(zipCode : String, temperature : Double, raining : Boolean) val bufferSize = 100 val overflowStrategy = akka.stream.OverflowStrategy.dropHead val queue = Source.queue(bufferSize, overflowStrategy) .filter(!_.raining) .to(Sink foreach println) .run() queue offer Weather("02139", 32.0, true)
val ref = Source.actorRef[Weather](Int.MaxValue, fail) .filter(!_.raining) .to(Sink foreach println ) .run() ref ! Weather("02139", 32.0, true)
object WeatherForwarder { def props : Props = Props[WeatherForwarder] } class WeatherForwarder extends Actor {...} val actorRef = actorSystem actorOf WeatherForwarder.props actorRef ! Weather("02139", 32.0, true) val stream = Source(ActorPublisher[Weather](actorRef)).runWith{...}
val (ref: ActorRef, publisher: Publisher[Int]) = Source.actorRef[Int](bufferSize = 1000, OverflowStrategy.fail) .toMat(Sink.asPublisher(true))(Keep.both).run() ref ! 1 val source = Source.fromPublisher(publisher) ref ! 2 Thread.sleep(1000) ref ! 3 source.runForeach(println) ref ! 4 Thread.sleep(1000) ref ! 5
-> /ApplicationA -> /project -> /build.sbt -> /CoreLibrary -> /project -> /build.sbt
val core = Project( id = "platform-core", base = file("../CoreLibrary")) val main = Project(id = "application, base = file(".")).dependsOn(core)
java.lang.AssertionError: assertion failed: Directory C:\git\CoreLibrary is not contained in build root C:\git\ApplicationA
lazy val core = RootProject(file("../CoreLibrary")) val main = Project(id = "application", base = file(".")).dependsOn(core)
-> /project/ -> Build.scala -> /ApplicationA -> /project -> /build.sbt -> /CoreLibrary -> /project -> /build.sbt
ProjectRef(file("../util-library"), "util-library")
lazy val core = RootProject(file("../CoreLibrary")) val main = Project(id = "application", base = file(".")).dependsOn(core)
public class A { public static int f() { return 10; } } public class B extends A { public static int f() { return 5; } } public class Main { public static void main(String[] args) { A a = new A(); System.out.println(a.f()); B b = new B(); System.out.println(b.f()); A ba = new B(); System.out.println(ba.f()); } }
import scalaz._ import Scalaz._ def even(x: Int) : Validation[NonEmptyList[String], Int] = if (x % 2 ==0) x.success else "not even: %d".format(x).wrapNel.fail println( even(3) <|*|> even(5) )
def <|*|>[B](b: M[B])(implicit t: Functor[M], a: Apply[M]): M[(A, B)] = <**>(b, (_: A, _: B))
def <**>[B, C](b: M[B], z: (A, B) => C)(implicit t: Functor[M], a: Apply[M]): M[C] = a(t.fmap(value, z.curried), b)
trait MA[M[_], A] { val value: M[A] def <**>[B, C](b: M[B], z: (A, B) => C)(implicit t: Functor[M], a: Apply[M]): M[C] = ... }
object Scalaz { implicit def ValidationMA[A, E](v: Validation[E, A]): MA[PartialApply1Of2[Validation, E] }
def validation[A, B](a: A, b: B) = ... def partialApply1Of2[A, B C](f: (A, B) => C, a: A): (B => C) = (b: B) => f(a, b)
val os: Option[String] = Some("a") val oi: Option[Int] = Some(2) val result1 = (os <**> oi) { (s: String, i: Int) => s * i } assert(result1 == Some("aa")) val result2 = (os <**> (None: Option[Int])) { (s: String, i: Int) => s * i } assert(result2 == None)
val result3 = oi flatMap { i => os map { s => s * i } } val result4 = for {i <- oi; s <- os} yield s * i
implicit def ValidationApply[X: Semigroup]: Apply[PartialApply1Of2[Validation, X] def apply[A, B](f: Validation[X, A => B], a: Validation[X, A]) = (f, a) match { case (Success(f), Success(a)) => success(f(a)) case (Success(_), Failure(e)) => failure(e) case (Failure(e), Success(_)) => failure(e) case (Failure(e1), Failure(e2)) => failure(e1 ⊹ e2) } }
def classStream(clazz: Class[_]): Stream[Class[_]] = clazz match { case null => Stream.empty case _ => ( clazz ) }
def classStream(clazz: Class[_]): Stream[Class[_]] = clazz match { case null => Stream.empty case _ => ( clazz ) }
scala> def foo(i: Int): Stream[Int] = i foo: (i: Int)Stream[Int] scala> foo(5) foreach println 5 4 3 2 1 0
scala> val v = Array(( v: Array[(Char, Int)] = Array((a,2), (b,1)) scala> scala.util.Sorting.stableSort(v, | (e1: (Char, Int), e2: (Char, Int)) => e1._2 < e2._2) scala> v res11: Array[(Char, Int)] = Array((b,1), (a,2))
scala> val arr = Array(("One",1),("Two",2),("Four",4),("Three",3)) arr: Array[(java.lang.String, Int)] = Array((One,1), (Two,2), (Four,4), (Three,3)) scala> arr.sortBy(_._2) res0: Array[(java.lang.String, Int)] = Array((One,1), (Two,2), (Three,3), (Four,4)) scala>
scala> val a = Array(1, 3, 2, 5) a: Array[Int] = Array(1, 3, 2, 5) scala> a.sortWith(_ > _) res6: Array[Int] = Array(5, 3, 2, 1) scala> a res7: Array[Int] = Array(1, 3, 2, 5)
scala> val a = Array(( a: Array[(Char, Int)] = Array((a,1), (b,4), (c,5), (d,2)) scala> a.sortWith(_._2 > _._2) res4: Array[(Char, Int)] = Array((c,5), (b,4), (d,2), (a,1)) scala> a res5: Array[(Char, Int)] = Array((a,1), (b,4), (c,5), (d,2))
val v = Array(( scala.util.Sorting.stableSort(v)(manifest[(Char, Int)], Ordering.by(_._2))
scala.util.Sorting.stableSort(v)(manifest[(Char, Int)], Ordering.by(_.swap))
(Array((2,3), (4,2), (1,5)).toList.sort (_._2 < _._2)).toArray
val l = List((2, 1), (3, 2), (0, 3)) l sort { case(a, b) => a > b }
<RelativeLayout android:id="@+id/map_layout" android:layout_width="match_parent" android:layout_height="300dp"> <fragment android:id="@+id/mapview" android:layout_width="match_parent" android:layout_height="match_parent" android:layout_marginTop="-100dp" android:layout_marginBottom="-100dp" android:name="com.google.android.gms.maps.MapFragment"/> <ImageView android:id="@+id/transparent_image" android:layout_width="match_parent" android:layout_height="match_parent" android:src="@color/transparent" /> </RelativeLayout>
ScrollView mainScrollView = (ScrollView) findViewById(R.id.main_scrollview); ImageView transparentImageView = (ImageView) findViewById(R.id.transparent_image); transparentImageView.setOnTouchListener(new View.OnTouchListener() { @Override public boolean onTouch(View v, MotionEvent event) { int action = event.getAction(); switch (action) { case MotionEvent.ACTION_DOWN: mainScrollView.requestDisallowInterceptTouchEvent(true); return false; case MotionEvent.ACTION_UP: mainScrollView.requestDisallowInterceptTouchEvent(false); return true; case MotionEvent.ACTION_MOVE: mainScrollView.requestDisallowInterceptTouchEvent(true); return false; default: return true; } } });
public class CustomScrollView extends ScrollView { List<View> mInterceptScrollViews = new ArrayList<View>(); public CustomScrollView(Context context) { super(context); } public CustomScrollView(Context context, AttributeSet attrs) { super(context, attrs); } public CustomScrollView(Context context, AttributeSet attrs, int defStyle) { super(context, attrs, defStyle); } public void addInterceptScrollView(View view) { mInterceptScrollViews.add(view); } public void removeInterceptScrollView(View view) { mInterceptScrollViews.remove(view); } @Override public boolean onInterceptTouchEvent(MotionEvent event) { if (mInterceptScrollViews.size() > 0) { int x = (int) event.getX(); int y = (int) event.getY(); Rect bounds = new Rect(); for (View view : mInterceptScrollViews) { view.getHitRect(bounds); if (bounds.contains(x, y + scrollY)) { return false; } } } return super.onInterceptTouchEvent(event); } }
class MyScrollView(c:Context, a:AttributeSet) extends ScrollView(c,a) { val parent = c.asInstanceOf[MyActivity] override def onInterceptTouchEvent(ev:MotionEvent):Boolean = { var bound:Rect = new Rect() parent.mMap.getHitRect(bound) if(bound.contains(ev.getX.toInt,ev.getY.toInt)) false else super.onInterceptTouchEvent(ev) } }
import com.google.android.gms.maps.MapView; import android.content.Context; import android.util.AttributeSet; import android.view.MotionEvent; import android.view.View; import android.widget.ScrollView; public class ScrollViewWithMap extends ScrollView { public MapView mapView; public ScrollViewWithMap(Context context, AttributeSet attrs) { super(context, attrs); } @Override public boolean onInterceptTouchEvent(MotionEvent ev) { if (mapView == null) return super.onInterceptTouchEvent(ev); if (inRegion(ev.getRawX(), ev.getRawY(), mapView)) return false; return super.onInterceptTouchEvent(ev); } private boolean inRegion(float x, float y, View v) { int[] mCoordBuffer = new int[] { 0, 0 }; v.getLocationOnScreen(mCoordBuffer); return mCoordBuffer[0] + v.getWidth() > x && mCoordBuffer[1] + v.getHeight() > y && mCoordBuffer[0] < x && mCoordBuffer[1] < y; } }
public class InterceptableScrollView extends ScrollView { List<View> mInterceptScrollViews = new ArrayList<View>(); public InterceptableScrollView(Context context) { super(context); } public InterceptableScrollView(Context context, AttributeSet attrs) { super(context, attrs); } public InterceptableScrollView(Context context, AttributeSet attrs, int defStyle) { super(context, attrs, defStyle); } public void addInterceptScrollView(View view) { mInterceptScrollViews.add(view); } public void removeInterceptScrollView(View view) { mInterceptScrollViews.remove(view); } private int getRelativeTop(View myView) { if (myView.getParent() == this) return myView.getTop(); else return myView.getTop() + getRelativeTop((View) myView.getParent()); } private int getRelativeLeft(View myView) { if (myView.getParent() == this) return myView.getLeft(); else return myView.getLeft() + getRelativeLeft((View) myView.getParent()); } @Override public boolean onInterceptTouchEvent(MotionEvent event) { if (mInterceptScrollViews.size() > 0) { int x = (int) event.getX(); int y = (int) event.getY(); /* int actionBarHeight = 0; TypedValue tv = new TypedValue(); if (getContext().getTheme().resolveAttribute(android.R.attr.actionBarSize, tv, true)) { actionBarHeight = TypedValue.complexToDimensionPixelSize(tv.data,getResources().getDisplayMetrics()); } */ int viewLocationY = 0; int viewLocationX = 0; int relativeTop = 0; int relativeLeft = 0; for (View view : mInterceptScrollViews) { relativeTop = getRelativeTop((View) view.getParent()); relativeLeft = getRelativeLeft((View) view.getParent()); viewLocationY = relativeTop - getScrollY(); viewLocationX = relativeLeft - getScrollX(); if (view.getHeight() + viewLocationY > y && y > viewLocationY && view.getWidth() + viewLocationX > x && x > viewLocationX) { return false; } } } return super.onInterceptTouchEvent(event); } }
final ScrollView mainScrollView = (ScrollView) rootView.findViewById(R.id.scrollView); (rootView.findViewById(R.id.fixTouchMap)).setOnTouchListener(new View.OnTouchListener() { @Override public boolean onTouch(View v, MotionEvent event) { int action = event.getAction(); switch (action) { case MotionEvent.ACTION_DOWN: mainScrollView.requestDisallowInterceptTouchEvent(true); return false; case MotionEvent.ACTION_UP: mainScrollView.requestDisallowInterceptTouchEvent(false); return true; case MotionEvent.ACTION_MOVE: mainScrollView.requestDisallowInterceptTouchEvent(true); return false; default: return true; } } });
<fragment android:id="@+id/map_with_scroll_fix" android:name="com.myapplication.maputil.GoogleMapWithScrollFix" android:layout_width="match_parent" android:layout_height="match_parent" />
package com.myapplication.maputil; import android.content.Context; import android.os.Bundle; import android.view.LayoutInflater; import android.view.MotionEvent; import android.view.View; import android.view.ViewGroup; import android.widget.FrameLayout; import com.google.android.gms.maps.SupportMapFragment; public class GoogleMapWithScrollFix extends SupportMapFragment { private OnTouchListener mListener; @Override public View onCreateView(LayoutInflater layoutInflater, ViewGroup viewGroup, Bundle savedInstance) { View layout = super.onCreateView(layoutInflater, viewGroup, savedInstance); TouchableWrapper touchableWrapper = new TouchableWrapper(getActivity()); touchableWrapper.setBackgroundColor(getResources().getColor(android.R.color.transparent)); ((ViewGroup) layout).addView(touchableWrapper, new ViewGroup.LayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.MATCH_PARENT)); return layout; } public void setListener(OnTouchListener listener) { mListener = listener; } public interface OnTouchListener { void onTouch(); } public class TouchableWrapper extends FrameLayout { public TouchableWrapper(Context context) { super(context); } @Override public boolean dispatchTouchEvent(MotionEvent event) { switch (event.getAction()) { case MotionEvent.ACTION_DOWN: mListener.onTouch(); break; case MotionEvent.ACTION_UP: mListener.onTouch(); break; } return super.dispatchTouchEvent(event); } } }
((GoogleMapWithScrollFix) getSupportFragmentManager() .findFragmentById(R.id.map_with_scroll_fix)).getMapAsync(new OnMapReadyCallback() { @Override public void onMapReady(GoogleMap googleMap) { ScrollView mScrollView = findViewById(R.id.scrollview); ((GoogleMapWithScrollFix) getSupportFragmentManager() .findFragmentById(R.id.map_with_scroll_fix)).setListener(new GoogleMapWithScrollFix.OnTouchListener() { @Override public void onTouch() { mScrollView.requestDisallowInterceptTouchEvent(true); } }); } });
val a=scala.io.StdIn.readInt() println("The value of a is "+ a)
import java.util.Scanner val input = "Joe 33 200.0" val line = new Scanner(input) val name = line.next val age = line.nextInt val weight = line.nextDouble
object InputTest extends App{ println("Type something : ") val input = scala.io.StdIn.readLine() println("Did you type this ? " + input) }
val scanner = new java.util.Scanner(System.in) scala> println("What is your name") What is your name scala> val name = scanner.nextLine() name: String = VIRAJ scala> println(s"My Name is $name") My Name is VIRAJ
val name = readLine("What is your name ") What is your name name: String = Viraj
import java.io._ object Test { def main(args: Array[String]) { var writer = new PrintWriter(new File("output.txt")) print("Enter the number of lines to read in: ") val x: Int = scala.io.StdIn.readLine.toInt var i=0 while (i < x) { var str: String = scala.io.StdIn.readLine writer.write(str + "\n") i = i + 1 } writer.close } }
[input] Enter the number of lines to read in: 2 one two [output] output.txt one two
scala> case class Foo(x:Int) defined class Foo scala> Foo(40) :: List(Foo(2)) res2: List[Foo] = List(Foo(40), Foo(2))
scala -Xprint:typer -e "1 :: Nil" val r: List[Int] = { <synthetic> val x$1: Int = 1; immutable.this.Nil.::[Int](x$1) };
List(1,2) match { case x :: xs => println(x + " " + xs) case _ => println("") }
final case class ::[B](private var hd: B, private[scala] var tl: List[B])
scala> class A[T] { var t: T = _ } defined class A scala> new A[String].t res0: String = null scala> new A[Object].t res1: java.lang.Object = null scala> new A[Int].t res2: Int = 0 scala> new A[Byte].t res3: Byte = 0 scala> new A[Boolean].t res4: Boolean = false scala> new A[Any].t res5: Any = null
scala> class A[T] { var t: T = null } <console>:5: error: type mismatch; found : Null(null) required: T class A[T] { var t: T = null }
scala> class A[T](implicit ev: Null <:< T) { var t: T = null } defined class A
a match { case None => Console.println("not here") case Some(value) => Console.println("got: "+value) }
scala> def foo = {} foo: Unit scala> def baz() = {} baz: ()Unit scala> def test(arg: () => Unit) = { arg } test: (arg: () => Unit)() => Unit scala> test(foo) <console>:10: error: type mismatch; found : Unit required: () => Unit test(foo) ^ scala> test(baz) res1: () => Unit = <function0>
scala> def foo() {} foo: ()Unit scala> def bar {} bar: Unit scala> foo scala> bar() <console>:12: error: Unit does not take parameters bar() ^
scala> def baz(f: () => Unit) {} baz: (f: () => Unit)Unit scala> def bat(f: => Unit) {} bat: (f: => Unit)Unit scala> baz(foo) scala> baz(bar) <console>:13: error: type mismatch; found : Unit required: () => Unit baz(bar) ^ scala> bat(foo) scala> bat(bar)
scala> def foo = println("foo!") foo: Unit scala> def test(arg: () => Unit) = { arg } test: (arg: () => Unit)() => Unit scala> test(foo _) res10: () => Unit = <function0> scala> test(foo _)() foo! scala>
def foo(): Unit = someCodeReturningUnit() private def bar() = someCodeReturningUnit()
def logs: Array[String] = { def props: Option[Map[String, Any]] = configAdmin.map{ ca => val config = ca.getConfiguration(PID, null) config.properties getOrElse immutable.Map.empty } def checkType(any: Any): Option[Array[String]] = any match { case a: Array[String] => Some(a) case _ => None } def lookup: Either[(Symbol, String), Array[String]] = for {val properties <- props.toRight( val logsParam <- properties.get("logs").toRight( val array <- checkType(logsParam).toRight( yield array lookup.fold(failure => { failure match { case ( case ( case _ => }; new Array[String](0) }, success => success) }
def throwableToLeft[T](block: => T): Either[java.lang.Throwable, T] = try { Right(block) } catch { case ex => Left(ex) }
var s = "hello" throwableToLeft { s.toUpperCase } match { case Right(s) => println(s) case Left(e) => e.printStackTrace } s = null throwableToLeft { s.toUpperCase } match { case Right(s) => println(s) case Left(e) => e.printStackTrace }
val s: Validation[String, Int] = 1.success val f: Validation[String, Int] = "error".fail val result: String = s.fold(e => "got error: " + e, s => "got success: " + s.toString) s match { case Success(a) => "success" case Failure(e) => "fail" } val k1 = for { i <- s j <- s } yield i + j k1.toOption assert_≟ Some(2) val k2 = for { i <- f j <- f } yield i + j k2.fail.toOption assert_≟ Some("error") val k4 = (fNel <**> fNel){ _ + _ } k4.fail.toOption assert_≟ some(nel1("error", "error"))
result match { case Right(res) => ... case Left(res) => ... }
val list = ( library \\ "books" map (book => if (book \ "author" isEmpty) Left(book) else Right((book \ "author" toList) map (_ text)) ) )
val authorCount = ( (Map[String,Int]() /: (list filter (_ isRight) map (_.right.get))) ((map, author) => map + (author -> (map.getOrElse(author, 0) + 1))) toList ) val problemBooks = list flatMap (_.left.toSeq)
def primeStream(s: Stream[Int]): Stream[Int] = Stream.cons(s.head, primeStream(s.tail filter { _ % s.head != 0 })) val primes = primeStream(Stream.from(2))
val stringOps = List( (s:String) => if (s.length>10) Some(s.length.toString) else None , (s:String) => if (s.length==0) Some("empty") else None , (s:String) => if (s.indexOf(" ")>=0) Some(s.trim) else None );
def transform(input: String, ops: List[String=>Option[String]]) = { ops.toStream.map( _(input) ).find(_ isDefined).getOrElse(None) }
scala> transform("This is a really long string",stringOps) res0: Option[String] = Some(28) scala> transform("",stringOps) res1: Option[String] = Some(empty) scala> transform(" hi ",stringOps) res2: Option[String] = Some(hi) scala> transform("no-match",stringOps) res3: Option[String] = None
val stringOps = List( (s:String) => {println("1"); if (s.length>10) Some(s.length.toString) else None }, (s:String) => {println("2"); if (s.length==0) Some("empty") else None }, (s:String) => {println("3"); if (s.indexOf(" ")>=0) Some(s.trim) else None } ); scala> transform("This is a really long string",stringOps) 1 res0: Option[String] = Some(28) scala> transform("no-match",stringOps) 1 2 3 res1: Option[String] = None
import shapeless._ trait AllSingletons[A, C <: Coproduct] { def values: List[A] } object AllSingletons { implicit def cnilSingletons[A]: AllSingletons[A, CNil] = new AllSingletons[A, CNil] { def values = Nil } implicit def coproductSingletons[A, H <: A, T <: Coproduct](implicit tsc: AllSingletons[A, T], witness: Witness.Aux[H] ): AllSingletons[A, H :+: T] = new AllSingletons[A, H :+: T] { def values = witness.value :: tsc.values } }
sealed trait Foo case object Bar extends Foo case object Baz extends Foo
scala> implicitly[AllSingletons[Foo, Bar.type :+: Baz.type :+: CNil]].values res0: List[Foo] = List(Bar, Baz)
trait EnumerableAdt[A] { def values: Set[A] } object EnumerableAdt { implicit def fromAllSingletons[A, C <: Coproduct](implicit gen: Generic.Aux[A, C], singletons: AllSingletons[A, C] ): EnumerableAdt[A] = new EnumerableAdt[A] { def values = singletons.values.toSet } }
<console>:17: shapeless.this.Witness.apply is not a valid implicit value for shapeless.Witness.Aux[Baz.type] because: Type argument Baz.type is not a singleton type implicitly[EnumerableAdt[Foo]] ^ <console>:17: this.AllSingletons.coproductSingletons is not a valid implicit value for AllSingletons[Foo,shapeless.:+:[Baz.type,shapeless.CNil]] because: hasMatchingSymbol reported error: could not find implicit value for parameter witness: shapeless.Witness.Aux[Baz.type] implicitly[EnumerableAdt[Foo]] ^ <console>:17: this.AllSingletons.coproductSingletons is not a valid implicit value for AllSingletons[Foo,this.Repr] because: hasMatchingSymbol reported error: could not find implicit value for parameter tsc: AllSingletons[Foo,shapeless.:+:[Baz.type,shapeless.CNil]] implicitly[EnumerableAdt[Foo]] ^ <console>:17: this.EnumerableAdt.fromAllSingletons is not a valid implicit value for EnumerableAdt[Foo] because: hasMatchingSymbol reported error: could not find implicit value for parameter singletons: AllSingletons[Foo,C] implicitly[EnumerableAdt[Foo]] ^ <console>:17: error: could not find implicit value for parameter e: EnumerableAdt[Foo] implicitly[EnumerableAdt[Foo]] ^
implicit val barSingleton = Witness[Bar.type] implicit val bazSingleton = Witness[Baz.type]
scala> implicitly[EnumerableAdt[Foo]].values res1: Set[Foo] = Set(Bar, Baz)
[error] /path/to/app/conf/routes: Unused import [error] /path/to/app/conf/routes: Unused import [error] /path/to/app/conf/routes:1: Unused import [error] GET /document/:id my.app.controllers.MyController.getById(id: Int)
lazy val optimizeRoutesImports = taskKey[Unit]("Remove unused imports from generated routes sources.") optimizeRoutesImports := { def removeUnusedImports(targetFiles: (File) => PathFinder, linesToRemove: Set[String], linesToReplace: Map[String, String]) = { val files = targetFiles(crossTarget.value).get files foreach { file => val lines = sbt.IO.readLines(file) val updatedLines = lines map { line => linesToReplace.getOrElse(line, line) } filterNot { line => linesToRemove.contains(line.trim) } sbt.IO.writeLines(file, updatedLines, append = false) } } removeUnusedImports( _ / "routes" / "main" / "controllers" / "ReverseRoutes.scala", Set("import ReverseRouteContext.empty"), Map( "import play.api.mvc.{ QueryStringBindable, PathBindable, Call, JavascriptLiteral }" -> "import play.api.mvc.{ QueryStringBindable, PathBindable, Call }", "import play.core.routing.{ HandlerDef, ReverseRouteContext, queryString, dynamicString }" -> "import play.core.routing.{ ReverseRouteContext, queryString, dynamicString }" ) ) removeUnusedImports( _ / "routes" / "main" / "controllers" / "javascript" / "JavaScriptReverseRoutes.scala", Set( "import play.core.routing.{ HandlerDef, ReverseRouteContext, queryString, dynamicString }", "import ReverseRouteContext.empty" ), Map( "import play.api.mvc.{ QueryStringBindable, PathBindable, Call, JavascriptLiteral }" -> "import play.api.mvc.{ QueryStringBindable, PathBindable }" ) ) removeUnusedImports( _ / "routes" / "main" / "router" / "Routes.scala", Set("import play.core.j._"), Map()) }
optimizeRoutesImports := (optimizeRoutesImports dependsOn (play.sbt.routes.RoutesKeys.routes in Compile)).value compile := ((compile in Compile) dependsOn optimizeRoutesImports).value
TwirlKeys.templateImports := Seq("play.api.mvc._", "play.api.i18n.Messages", "controllers.routes")
removeUnusedImports( _ / "twirl" ** "*.template.scala", Set("import play.twirl.api.TemplateMagic._"), Map())
val silencerVersion = "1.2.1" libraryDependencies ++= Seq( compilerPlugin("com.github.ghik" %% "silencer-plugin" % silencerVersion), "com.github.ghik" %% "silencer-lib" % silencerVersion % Provided )
scalacOptions += "-P:silencer:globalFilters=Unused import"
import CustomGenerator._ import play.sbt.routes.RoutesKeys RoutesKeys.routesImport := Seq.empty routesGenerator := ModifiedInjectedRoutesGenerator
object CustomGenerator { object ModifiedInjectedRoutesGenerator extends play.routes.compiler.RoutesGenerator { import play.routes.compiler._ import play.routes.compiler.RoutesCompiler.RoutesCompilerTask def generate(task: RoutesCompilerTask, namespace: Option[String], rules: List[Rule]): Seq[(String, String)] = { play.routes.compiler.InjectedRoutesGenerator.generate(task, namespace, rules) map { case(key, value) => var v = value if(key.endsWith("/ReverseRoutes.scala")) { v = v.replace("import ReverseRouteContext.empty", "implicit val empty = ReverseRouteContext(Map())") v = v.replace("import play.core.routing.{ HandlerDef, ReverseRouteContext, queryString, dynamicString }", "import play.core.routing.{ ReverseRouteContext, queryString }") v = v.replace("import play.api.mvc.{ QueryStringBindable, PathBindable, Call, JavascriptLiteral }", "import play.api.mvc.{ QueryStringBindable, Call }") } if(key.endsWith("migrations/ReverseRoutes.scala")) { v = v.replace("import play.api.mvc.{ QueryStringBindable, Call }", "import play.api.mvc.{ Call }") v = v.replace("import play.core.routing.{ ReverseRouteContext, queryString }", "import play.core.routing.{ ReverseRouteContext }") } if(key.endsWith("/JavaScriptReverseRoutes.scala")) { v = v.replace("import ReverseRouteContext.empty", "") v = v.replace("import play.api.mvc.{ QueryStringBindable, PathBindable, Call, JavascriptLiteral }", "import play.api.mvc.{ QueryStringBindable, JavascriptLiteral }") v = v.replace("import play.core.routing.{ HandlerDef, ReverseRouteContext, queryString, dynamicString }", "") } if(key.endsWith("migrations/javascript/JavaScriptReverseRoutes.scala")) { v = v.replace("import play.api.mvc.{ QueryStringBindable, JavascriptLiteral }", "") } if(key.endsWith("/Routes.scala")) { v = v.replace("import play.core.routing.HandlerInvokerFactory._", "") v = v.replace("import play.core.j._", "") v = v.replace("import ReverseRouteContext.empty", "implicit val empty = ReverseRouteContext(Map())") } (key, v) } } def id: String = "injected+" } }
def doMatch(list: List[Int]): Unit = list match { case last :: Nil => println("Final element.") case head :: tail => println("Recursing..."); doMatch(tail) }
def doMatch(seq: Seq[Int]): Unit = seq match { case last +: Seq() => println("Final element.") case head +: tail => println("Recursing..."); doMatch(tail) }
def doMatch(seq: Seq[Int]): Unit = seq match { case Seq(x) => println("Final element " + x) case Seq(x, xs@_*) => println("Recursing..." + x); doMatch(xs) }
def doMatch(seq: Seq[Int]): Unit = seq match { case last +: Seq() => println("Final element.") case head +: tail => println("Recursing..."); doMatch(tail) } doMatch(List(1, 2))
List(1, 2) match { case init :+ last => last } List(1, 2) match { case head +: tail => tail } Vector(1, 2) match { case init :+ last => last } Vector(1, 2) match { case head +: tail => tail }
object +: { def unapply[T](s: Seq[T]) = if(s.nonEmpty) Some(s.head, s.tail) else None } scala> val h +: t = Seq(1,2,3) h: Int = 1 t: Seq[Int] = List(2, 3)
def doMatch(seq: Seq[Int]) { if (seq.size == 1) println("final element " + seq(0)) else { println("recursing") doMatch(seq.tail) } } doMatch(1 to 10)
object SEQ { def unapply[A](s:Seq[A]):Option[(A, Seq[A])] = { if (s.size == 0) None else { Some((s.head, s.tail)) } } } def doMatch(seq: Seq[Int]) { seq match { case SEQ(head, Seq()) => println("final") case SEQ(head, tail) => { println("recursing") doMatch(tail) } } }
def doMatch (list: List[Int]): Unit = list match { case last :: Nil => println ("Final element.") case head :: tail => println ("Recursing..."); doMatch (tail) case Nil => println ("only seen for empty lists") } def doMatchSeq (seq: Seq[Int]) : Unit = doMatch (seq.toList) doMatch (List(3, 4, 5)) doMatchSeq (3 to 5)
import scala.concurrent._ import ExecutionContext.Implicits.global val firstOccurence: Future[Int] = future { val source = scala.io.Source.fromFile("myText.txt") source.toSeq.indexOfSlice("myKeyword") } firstOccurence onSuccess { case idx => println("The keyword first appears at position: " + idx) } firstOccurence onFailure { case t => println("Could not process file: " + t.getMessage) }
import org.jboss.netty.util.{HashedWheelTimer, TimerTask, Timeout} import java.util.concurrent.TimeUnit import scala.concurrent.duration.Duration import scala.concurrent.Promise import java.util.concurrent.TimeoutException object TimeoutScheduler{ val timer = new HashedWheelTimer(10, TimeUnit.MILLISECONDS) def scheduleTimeout(promise:Promise[_], after:Duration) = { timer.newTimeout(new TimerTask{ def run(timeout:Timeout){ promise.failure(new TimeoutException("Operation timed out after " + after.toMillis + " millis")) } }, after.toNanos, TimeUnit.NANOSECONDS) } }
import scala.concurrent.{Future, ExecutionContext, Promise} import scala.concurrent.duration.Duration def withTimeout[T](fut:Future[T])(implicit ec:ExecutionContext, after:Duration) = { val prom = Promise[T]() val timeout = TimeoutScheduler.scheduleTimeout(prom, after) val combinedFut = Future.firstCompletedOf(List(fut, prom.future)) fut onComplete{case result => timeout.cancel()} combinedFut }
package model import scala.concurrent._ import scala.concurrent.duration._ import play.libs.Akka import play.api.libs.concurrent.Execution.Implicits._ object TimeoutFuture { def apply[A](timeout: FiniteDuration)(block: => A): Future[A] = { val prom = promise[A] Akka.system.scheduler.scheduleOnce(timeout) { prom tryFailure new java.util.concurrent.TimeoutException } Future { prom success block } prom.future } }
val future = TimeoutFuture(10 seconds) { } future onComplete { case Success(stuff) => case Failure(exception) => }
package justinhj.concurrency import java.util.concurrent.TimeoutException import java.util.{Timer, TimerTask} import scala.concurrent.duration.FiniteDuration import scala.concurrent.{ExecutionContext, Future, Promise} import scala.language.postfixOps object FutureUtil { val timer: Timer = new Timer(true) /** * Returns the result of the provided future within the given time or a timeout exception, whichever is first * This uses Java Timer which runs a single thread to handle all futureWithTimeouts and does not block like a * Thread.sleep would * @param future Caller passes a future to execute * @param timeout Time before we return a Timeout exception instead of future * @return Future[T] */ def futureWithTimeout[T](future : Future[T], timeout : FiniteDuration)(implicit ec: ExecutionContext): Future[T] = { val p = Promise[T] val timerTask = new TimerTask() { def run() : Unit = { p.tryFailure(new TimeoutException()) } } timer.schedule(timerTask, timeout.toMillis) future.map { a => if(p.trySuccess(a)) { timerTask.cancel() } } .recover { case e: Exception => if(p.tryFailure(e)) { timerTask.cancel() } } p.future } }
private def get(): Future[Option[Boolean]] = { val timeoutFuture = Promise.timeout(None, Duration("1s")) val mayBeHaveData = Future{ Some(true) } Future.firstCompletedOf(List(mayBeHaveData, timeoutFuture)) }
import scala.concurrent.Future sealed class TimeoutException extends RuntimeException object FutureTimeout { import scala.concurrent.ExecutionContext.Implicits.global implicit class FutureTimeoutLike[T](f: Future[T]) { def withTimeout(ms: Long): Future[T] = Future.firstCompletedOf(List(f, Future { Thread.sleep(ms) throw new TimeoutException })) lazy val withTimeout: Future[T] = withTimeout(2000) } }
val timeout = akka.pattern.after(10 seconds, system.scheduler)(Future.failed(new TimeoutException(s"timed out during..."))) Future.firstCompletedOf(Seq(promiseRef.future, timeout))
import monix.execution.Scheduler.Implicits.global import monix.eval._ import scala.concurrent.duration._ import scala.concurrent.TimeoutException val source = Task("Hello!").delayExecution(10.seconds) val timedOut = source.timeout(3.seconds) timedOut.runOnComplete(r => println(r))
object TimeoutFuture { def apply[A](system: ActorSystem, timeout: FiniteDuration)(block: => A): Future[A] = { implicit val executionContext = system.dispatcher val prom = Promise[A] system.scheduler.scheduleOnce(timeout) { prom tryFailure new java.util.concurrent.TimeoutException } Future { try { prom success block } catch { case t: Throwable => prom tryFailure t } } prom.future } }
for { r1 <- future1 r2 <- future2 r3 <- future3 } yield (r1+r2+r3)
future1.flatMap(r1 => future2.flatMap(r2 => future3.map(r3 => r1 + r2 + r3) ) )
val res = for { r1 <- computationReturningFuture1(...) r2 <- computationReturningFuture2(...) r3 <- computationReturningFuture3(...) } yield (r1+r2+r3)
computationReturningFuture1(...).flatMap(r1 => computationReturningFuture2(...).flatMap(r2 => computationReturningFuture3(...).map(r3 => r1 + r2 + r3) ) )
val future1 = computationReturningFuture1(...) val future2 = computationReturningFuture2(...) val future3 = computationReturningFuture3(...) val res = for { r1 <- future1 r2 <- future2 r3 <- future3 } yield (r1+r2+r3)
scala> def createIntegers = Future{ println("INT "+ Thread.currentThread().getName+" Begin.") val returnValue = List.range(1, 256) println("INT "+ Thread.currentThread().getName+" End.") returnValue } createIntegers: createIntegers: scala.concurrent.Future[List[Int]]
scala> def createAsciiChars = Future{ println("CHAR "+ Thread.currentThread().getName+" Begin.") val returnValue = new ListBuffer[Char] for (i <- 1 to 256){ returnValue += i.toChar } println("CHAR "+ Thread.currentThread().getName+" End.") returnValue } createAsciiChars: scala.concurrent.Future[scala.collection.mutable.ListBuffer[Char]]
scala> val result = for{ i <- createIntegers s <- createAsciiChars } yield i.zip(s) Await.result(result, Duration.Inf) result: scala.concurrent.Future[List[(Int, Char)]] = Future(<not completed>)
scala> INT scala-execution-context-global-27 Begin. INT scala-execution-context-global-27 End. CHAR scala-execution-context-global-28 Begin. CHAR scala-execution-context-global-28 End.
private def test(some:String*){ } private def call () { val some = Array("asd", "zxc") test(some) }
def test(some:String*){} def call () { val some = Array("asd", "zxc") test(some: _*) }
val arr:Array[Int] = Array[Int](1,2,3) val arr2:Array[Any] = arr arr2(0) = 2.54
trait Animal { def makeSound: String } class Cat extends Animal { def makeSound = "meow" def jump = } class Dog extends Animal { def makeSound = "bark" }
def mindlessFunc(xs: MutableList[Animal]) = { xs += new Dog() }
val cats = MutableList[Cat](cat1, cat2) val horror = mindlessFunc(cats)
def apply(i: Int): T def update(i: Int, x: T): Unit
final JavaRDD<String> File = sc.textFile(Filename).cache(); final JavaRDD<String> lines = File.flatMap(new FlatMapFunction<String, String>() { @Override public Iterable<String> call(String s) { return Arrays.asList(EOL.split(s)); } }); final String heading=lines.first().toString();
user, topic, hits om, scala, 120 daniel, spark, 80 3754978, spark, 1
class SimpleCSVHeader(header:Array[String]) extends Serializable { val index = header.zipWithIndex.toMap def apply(array:Array[String], key:String):String = array(index(key)) }
val csv = sc.textFile("file.csv") val data = csv.map(line => line.split(",").map(elem => elem.trim)) val header = new SimpleCSVHeader(data.take(1)(0)) val rows = data.filter(line => header(line,"user") != "user") val users = rows.map(row => header(row,"user") val usersByHits = rows.map(row => header(row,"user") -> header(row,"hits").toInt) ...
import org.apache.spark.sql.SQLContext SQLContext sqlContext = new SQLContext(sc); HashMap<String, String> options = new HashMap<String, String>(); options.put("header", "true"); options.put("path", "cars.csv"); DataFrame df = sqlContext.load("com.databricks.spark.csv", options);
val header = scala.io.Source.fromInputStream( hadoop.fs.FileSystem.get(new java.net.URI(filename), sc.hadoopConfiguration) .open(new hadoop.fs.Path(path))) .getLines.head val columnIndex = header.split(",").indexOf(columnName) sc.textFile(path).mapPartitions(iterator => { val head = iterator.next() if (head == header) iterator else Iterator(head) ++ iterator }) .map(_.split(",", -1)(columnIndex))
libraryDependencies += "com.databricks" % "spark-csv_2.10" % "1.2.0"
val sc = new SparkContext(conf) val sqlContext = new SQLContext(sc) val csvInPath = "/path/to/csv/abc.csv" val df = sqlContext.read.format("com.databricks.spark.csv").option("header","true").load(csvInPath)
val aDf = sqlContext.createDataFrame(rddData,StructType(Array(StructField("colANew",StringType,true)))) aDF.write.format("com.databricks.spark.csv").option("header","true").save("/csvOutPath/aCSVOp")
def main(args: Array[String]): Unit = { val csv = sc.textFile("/path/to/your/file.csv") val headerAndRows = csv.map(line => line.split(",").map(_.trim)) val header = headerAndRows.first val data = headerAndRows.filter(_(0) != header(0)) val maps = data.map(splits => header.zip(splits).toMap) val result = maps.filter(map => map("user") != "me") result.foreach(println) }
val uri = new java.net.URI(filename) val conf = sc.hadoopConfiguration val fs = hadoop.fs.FileSystem.get(uri, conf) val path = new hadoop.fs.Path(filename) val stream = fs.open(path) val source = scala.io.Source.fromInputStream(stream) val header = source.getLines.head
val csvRDD = sc.textFile(filename).filter(_ != header)
val idx = header.split(",").indexOf(columnName) val columnRDD = csvRDD.map(_.split(",")(idx))
val rows = sc.textFile(path) .mapPartitionsWithIndex({ (index: Int, rows: Iterator[String]) => val results = new ArrayBuffer[(String, Int)] var first = true while (rows.hasNext) { if (index == 0 && first) { first = false rows.next } else { results += rows.next } } results.toIterator }, true) rows.flatMap { row => row.split(",") }
val Delimeter = "," val textFile = sc.textFile("data.csv").map(line => line.split(Delimeter))
val sqlContext = new org.apache.spark.sql.SQLContext(sc) val rawdata = sc.textFile("hdfs: val header = rawdata.first() val tbldata = rawdata.filter(_(0) != header(0))
JavaRDD<Person> people = sc.textFile("examples/src/main/resources/people.txt").map( new Function<String, Person>() { public Person call(String line) throws Exception { String[] parts = line.split(","); Person person = new Person(); person.setName(parts[0]); person.setAge(Integer.parseInt(parts[1].trim())); return person; } });
val df = spark.read .option("header", "true") .csv("file:
user,topic,hits om,scala,120 daniel,spark,80 3754978,spark,1
import org.apache.spark.sql.functions._ import spark.implicits._ val rawData = spark.read .option("header", "true") .csv("file: val grouped = rawData.groupBy($"topic").agg(sum($"hits)) val collected = grouped.collect grouped.write.parquet("hdfs: grouped.coalesce(1) .write .option("header", "true") .csv("hdfs:
build .classpath .project .settings org.scala-ide.sdt.core/META-INF/MANIFEST.MF org.scala-ide.sdt.update-site/site.xml`
trait SuchThat[F[_], G[_]] { def apply[A:G]: F[A] }
import scalaz._; import Scalaz._ type ShowUnbox[A] = ({type f[S] = S => A}) sealed trait ShowBox { def apply[B](f: ShowUnbox[B]): B } object ShowBox { def apply[S: Show](s: => S): ShowBox = new ShowBox { def apply[B](f: ShowUnbox[B]) = f[S].apply(s) } def unapply(b: ShowBox): Option[String] = b(new ShowUnbox[Option[String]] { def apply[S:Show] = s => some(s.shows) }) } val heteroList: List[ShowBox] = List(ShowBox(()), ShowBox(5), ShowBox(true))
scala> heteroList map { case ShowBox(x) => x } res6: List[String] = List((), 5, true)
sealed trait ShowBox case class SB[S:Show](s: S) extends ShowBox { override def toString = Show[S].shows(s) }
scala> val heteroList = List(ShowBox(()), ShowBox(5), ShowBox(true)) heteroList: List[ShowBox] = List((), 5, true)
var dataDF = sc.textFile("path/file").toDF() val rowDF = sc.parallelize(1 to DataDF.count().toInt).toDF("ID") dataDF = dataDF.withColumn("ID", rowDF("ID"))
sqlContext.textFile(file). zipWithIndex(). map(case(d, i)=>i.toString + delimiter + d). map(_.split(delimiter)). map(s=>Row.fromSeq(s.toSeq))
val df = df1.withColumn("newCol", df1("col") + 1) val df = df1.withColumn("newCol", df2("col") + 1)
import sqlContext.implicits._ import org.apache.spark.sql.functions._ df.withColumn("newName",lit("newValue"))
val rdd = df.rdd.zipWithIndex() .map(indexedRow => Row.fromSeq(indexedRow._2.toString +: indexedRow._1.toSeq)) val newstructure = StructType(Seq(StructField("Row number", StringType, true)).++(df.schema.fields)) sqlContext.createDataFrame(rdd, newstructure ).show
df.withColumn("ID", row_number() over Window.orderBy("any column name in the dataframe"))
val m = rdd1.collectAsMap val rdd_joined = rdd2.map({case ((t,w), u) => ((t,w), u, m.get(t))})
val distinct_w = rdd2.map({case ((t,w), u) => w}).distinct val rdd_joined = rdd1.cartesian(distinct_w).join(rdd2)
val rdd1 = sc.parallelize(Seq((1, "A"), (2, "B"), (3, "C"))) val rdd2 = sc.parallelize(Seq(((1, "Z"), 111), ((1, "ZZ"), 111), ((2, "Y"), 222), ((3, "X"), 333))) val rdd1Broadcast = sc.broadcast(rdd1.collectAsMap()) val joined = rdd2.mapPartitions({ iter => val m = rdd1Broadcast.value for { ((t, w), u) <- iter if m.contains(t) } yield ((t, w), (u, m.get(t).get)) }, preservesPartitioning = true)
rdd1.join(rdd2.map { case ((t, w), u) => (t, (w, u)) }).map { case (t, (v, (w, u))) => ((t, w), (u, v)) }.collect()
res1: Array[((Int, java.lang.String), (Int, java.lang.String))] = Array(((1,Z),(111,A)), ((1,ZZ),(111,A)), ((2,Y),(222,B)), ((3,X),(333,C)))
import org.apache.spark.HashPartitioner class RDD2Partitioner(partitions: Int) extends HashPartitioner(partitions) { override def getPartition(key: Any): Int = key match { case k: Tuple2[Int, String] => super.getPartition(k._1) case _ => super.getPartition(key) } } val numSplits = 8 val rdd1 = sc.parallelize(Seq((1, "A"), (2, "B"), (3, "C"))).partitionBy(new HashPartitioner(numSplits)) val rdd2 = sc.parallelize(Seq(((1, "Z"), 111), ((1, "ZZ"), 111), ((1, "AA"), 123), ((2, "Y"), 222), ((3, "X"), 333))).partitionBy(new RDD2Partitioner(numSplits)) val result = rdd2.zipPartitions(rdd1)( (iter2, iter1) => { val m = iter1.toMap for { ((t: Int, w), u) <- iter2 if m.contains(t) } yield ((t, w), (u, m.get(t).get)) } ).partitionBy(new HashPartitioner(numSplits)) result.glom.collect
def reportState = { val _this = this synchronized { val msg = "%s Received request to report state with %d items in mailbox".format( _this, mailboxSize) log.info(msg) } Actor.actor { _this ! ReportState } }
def main(args: Array[String]) { val f = { if (args.length < 1) Left("No filename given") else { val file = new File(args(0)) if (!file.exists) Left("File does not exist: "+args(0)) else Right(file) } } }
val numbers = "1 2 3 fish 5 6" val tried = numbers.split(" ").map(s => Try(s.toInt)) val good = tried.collect{ case Success(n) => n }
no UH , , it PRP was VBD n monday NNP . . the DT equity NN market NN was VBD illiquid JJ . .
List((no,UH), (,,,), (it,PRP), (was,VBD), (n List((the,DT), (equity,NN), (market,NN), (was,VBD), (illiquid,JJ), (.,.)
import java.io.{ BufferedReader, File, FileReader } import scalaz._, Scalaz._, effect.IO import iteratee.{ Iteratee => I, _ } type ErrorOr[A] = EitherT[IO, Throwable, A] def tryIO[A, B](action: IO[B]) = I.iterateeT[A, ErrorOr, B]( EitherT(action.catchLeft).map(I.sdone(_, I.emptyInput)) ) def enumBuffered(r: => BufferedReader) = new EnumeratorT[String, ErrorOr] { lazy val reader = r def apply[A] = (s: StepT[String, ErrorOr, A]) => s.mapCont(k => tryIO(IO(Option(reader.readLine))).flatMap { case None => s.pointI case Some(line) => k(I.elInput(line)) >>== apply[A] } ) } def enumFile(f: File) = new EnumeratorT[String, ErrorOr] { def apply[A] = (s: StepT[String, ErrorOr, A]) => tryIO( IO(new BufferedReader(new FileReader(f))) ).flatMap(reader => I.iterateeT[String, ErrorOr, A]( EitherT( enumBuffered(reader).apply(s).value.run.ensuring(IO(reader.close())) ) )) }
def sentence: IterateeT[String, ErrorOr, List[(String, String)]] = { import I._ def loop(acc: List[(String, String)])(s: Input[String]): IterateeT[String, ErrorOr, List[(String, String)]] = s( el = _.trim.split(" ") match { case Array(form, pos) => cont(loop(acc :+ (form, pos))) case Array("") => cont(done(acc, _)) case pieces => val throwable: Throwable = new Exception( "Invalid line: %s!".format(pieces.mkString(" ")) ) val error: ErrorOr[List[(String, String)]] = EitherT.left( throwable.point[IO] ) IterateeT.IterateeTMonadTrans[String].liftM(error) }, empty = cont(loop(acc)), eof = done(acc, eofInput) ) cont(loop(Nil)) }
val action = I.consume[List[(String, String)], ErrorOr, List] %= sentence.sequenceI &= enumFile(new File("example.txt"))
scala> action.run.run.unsafePerformIO().foreach(_.foreach(println)) List((no,UH), (,,,), (it,PRP), (was,VBD), (n List((the,DT), (equity,NN), (market,NN), (was,VBD), (illiquid,JJ), (.,.))
import scalaz.std.vector._ import scalaz.syntax.traverse._ import scalaz.std.string._ val action = linesR("example.txt").map(_.trim). splitOn("").flatMap(_.traverseU { s => s.split(" ") match { case Array(form, pos) => emit(form -> pos) case _ => fail(new Exception(s"Invalid input $s")) }})
implicit class EnhancedFoo(foo: Foo) { def bar() { } }
class Meters(val value: Int) extends AnyVal { ... } class RichMeters(val value: Int) extends AnyVal { ... } object RichMeters { implicit def wrap(m: Meter) = new RichMeter(m.value) }
implicit class RichFoo[T](foo: Foo[T])(implicit ord: Ordering[T]) { def bar(otherFoo: Foo[T]) = }
implicit class RichFoo[T](foo: Foo[T]) extends AnyVal { def bar(otherFoo: Foo[T])(implicit ord: Ordering[T]) = }
object Test { def main(args:Array[String]){ println("hello") } }
val root: PartialFunction[Double,Double] = { case d if (d >= 0) => math.sqrt(d) } scala> root.isDefinedAt(-1) res0: Boolean = false scala> root(3) res1: Double = 1.7320508075688772
scala> List(0.5, -0.2, 4).collect(root) res2: List[Double] = List(0.7071067811865476, 2.0)
def add(i: Int, j: Int) = i + j val add5 = add(_: Int,5)
scala> List((1,2), (4,5), (3,8)).map(addTupled) res4: List[Int] = List(3, 9, 11)
val addCurried = (add _).curried scala> List(1,4,3).map(addCurried) res5: List[Int => Int] = List(<function1>, <function1>, <function1>) scala> res5.head(2) res6: Int = 3 scala> res5.tail.head(5) res7: Int = 9 scala> res5.last(8) res8: Int = 11
scala> import java.nio.file.{Paths, Files} import java.nio.file.{Paths, Files} scala> Files.exists(Paths.get("/tmp")) res0: Boolean = true
scala> new java.io.File("/tmp").exists res0: Boolean = true
val t = 5 val m = t match { 0 until 10 => true _ => false }
val m = t match { case x if 0 until 10 contains x => true case _ => false }
val m = t match { case x if (0 <= x && x < 10) => true case _ => false }
trait Inspector[-C, -T] { def contains(collection: C, value: T): Boolean } implicit def seqInspector[T, C <: SeqLike[Any, _]] = new Inspector[C, T]{ override def contains(collection: C, value: T): Boolean = collection.contains(value) } implicit def setInspector[T, C <: Set[T]] = new Inspector[C, T] { override def contains(collection: C, value: T): Boolean = collection.contains(value) } implicit class MemberOps[T](t: T) { def in[C](coll: C)(implicit inspector: Inspector[C, T]) = inspector.contains(coll, t) }
2 in List(1, 2, 4) 2 in List("foo", 2) 2 in Set("foo", 2) 2 in Set(1, 3) 2 in Set("foo", "foo") 2 in List("foo", "foo") 2 in (0 to 10)
val m = t match { case x if ((0 to 10).contains(x)) => true case _ => false }
object ComparisonExt { implicit class IntComparisonOps(private val x : Int) extends AnyVal { def between(range: Range) = x >= range.head && x < range.last def between(from: Int, to: Int) = x >= from && x < to } } object CallSite { import ComparisonExt._ val t = 5 if (t between(0 until 10)) println("matched") if (!(20 between(0 until 10))) println("not matched") if (t between(0, 10)) println("matched") if (!(20 between(0, 10))) println("not matched") }
class CollegeStudent extends Student with Worker with Underpaid with Young
class CollegeStudent extends Student new CollegeStudent with Worker with Underpaid with NotSoYoungAnymore
trait Base { override def toString = "Base" } class A extends Base { override def toString = "A->" + super.toString } trait B extends Base { override def toString = "B->" + super.toString } trait C extends Base { override def toString = "C->" + super.toString } class D extends A with B with C { override def toString = "D->" + super.toString }
Class class = Class.forName("Foo"); Object foo = class.newInstance(); Method method = class.getMethod("hello", null); method.invoke(foo, null);
class Foo { def hello(name: String): String = "Hello there, %s".format(name) } object FooMain { def main(args: Array[String]) { val foo = Class.forName("Foo").newInstance.asInstanceOf[{ def hello(name: String): String }] println(foo.hello("Walter")) } }
class Obj { private def foo(x: Int, y: String): Long = x + y.length }
import scala.reflect.Invocation._ (new Obj) o val x: Long = (new Obj) oo
class Test[T](implicit m : Manifest[T]) { val testVal = m.erasure.newInstance().asInstanceOf[T] }
scala> new Test[Set[String]] java.lang.InstantiationException: scala.collection.immutable.Set at java.lang.Class.newInstance0(Class.java:340)
classOf[ClassName].getMethod("main", classOf[Array[String]])
scala> class A { | def foo_=(foo: Boolean) = "bar" | } defined class A scala>val a = new A a: A = A@1f854bd scala>a.getClass.getMethod(decode("foo_="), classOf[Boolean]).invoke(a, java.lang.Boolean.TRUE) res15: java.lang.Object = bar
package com.example.mytest import scala.reflect.runtime.universe class MyTest object MyTest { def target(i: Int) = println(i) def invoker(objectName: String, methodName: String, arg: Any) = { val runtimeMirror = universe.runtimeMirror(getClass.getClassLoader) val moduleSymbol = runtimeMirror.moduleSymbol( Class.forName(objectName)) val targetMethod = moduleSymbol.typeSignature .members .filter(x => x.isMethod && x.name.toString == methodName) .head .asMethod runtimeMirror.reflect(runtimeMirror.reflectModule(moduleSymbol).instance) .reflectMethod(targetMethod)(arg) } def main(args: Array[String]): Unit = { invoker("com.example.mytest.MyTest$", "target", 5) } }
import scala.reflect.runtime.universe case class Case(foo: Int) { println("Case Case Instantiated") } class Class { println("Class Instantiated") } object Inst { def apply(className: String, arg: Any) = { val runtimeMirror: universe.Mirror = universe.runtimeMirror(getClass.getClassLoader) val classSymbol: universe.ClassSymbol = runtimeMirror.classSymbol(Class.forName(className)) val classMirror: universe.ClassMirror = runtimeMirror.reflectClass(classSymbol) if (classSymbol.companion.toString() == "<none>") { println(s"Info: $className has no companion object") val constructors = classSymbol.typeSignature.members.filter(_.isConstructor).toList if (constructors.length > 1) { println(s"Info: $className has several constructors") } else { val constructorMirror = classMirror.reflectConstructor(constructors.head.asMethod) constructorMirror() } } else { val companionSymbol = classSymbol.companion println(s"Info: $className has companion object $companionSymbol") } } } object app extends App { val c = Inst("Class", "") val cc = Inst("Case", "") }
lazy val reflection = (project in file(".")) .settings( scalaVersion := "2.11.7", libraryDependencies ++= Seq( "org.scala-lang" % "scala-compiler" % scalaVersion.value % "provided", "org.scala-lang" % "scala-library" % scalaVersion.value % "provided" ) )
scala> case class Person(name: String, age: Int) {} defined class Person
scala> val b = Person("Kevin", 100) b: Person = Person(Kevin,100)
scala> b match { | case p @ Person(_, age) => println("age") | case _ => println("none") | } age
scala> b match { | case Person(_, age) => println("age") | case _ => println("none") | } age
that match{ case p @ Person(_, age) if p != bill => age case Person(_, age) => age - 15 case _ => println("Not a person") }
case class Employee(name: String, id: Int, technology: String)
case e @ Employee(_, _, "scala") => e.name case x: Employee => x.name case e: Employee(_, _, "scala") => e.name
import scala.collection.JavaConverters._ val myJavaIterable = someExpr() val myScalaIterable = myJavaIterable.asScala
import scala.collection.JavaConversions._ val myJavaIterable = someExpr() for (magicValue <- myJavaIterable) yield doStuffWith(magicValue)
import java.lang.{Iterable => JavaItb} import java.util.{Iterator => JavaItr} implicit def jitb2sitb[T](jit: JavaItb[T]): Iterable[T] = new SJIterable(jit); implicit def jitr2sitr[A](jit: JavaItr[A]): Iterator[A] = new SJIterator(jit)
class SJIterable[T](private val jitb: JavaItr[T]) extends Iterable[T] { def elements(): Iterator[T] = jitb.iterator() } class SJIterator[T](private val jit: JavaItr[T]) extends Iterator[T] { def hasNext: Boolean = jit hasNext def next: T = jit next }
case class Foo(foo:String, bar:Int) val (str, in) = Foo.unapply(Foo("test", 123)).get()
import shapeless._ import shapeless.syntax.std.product._ case class Fnord(a: Int, b: String) List(Fnord(1, "z - last"), Fnord(1, "a - first")).sortBy(_.productElements.tupled)
res0: List[Fnord] = List(Fnord(1,a - first), Fnord(1,z - last))
scala> Fnord(1, "z - last").productElements res1: Int :: String :: shapeless.HNil = 1 :: z - last :: HNil
scala> Fnord(1, "z - last").productElements.tupled res2: (Int, String) = (1,z - last)
case class Foo(foo: String, bar: Int) val testFoo = Foo("a string", 1) val (str, in) = testFoo match { case Foo(f, b) => (f, b) }
scala> i warning: there were deprecation warnings; re-run with -deprecation for details res28: Integer = 3 scala> i > 3 <console>:6: error: value > is not a member of Integer i > 3 ^
scala> j res30: Int = 3 scala> j > 3 res31: Boolean = false
/** @deprecated use <code>java.lang.Integer</code> instead */ @deprecated type Integer = java.lang.Integer
<repository> <id>Spark repository</id> <url>http: </repository>
<dependency> <groupId>spark</groupId> <artifactId>spark</artifactId> <version>1.2.0</version> </dependency>
echo" import org.apache.spark.sql.* ssc = new SQLContext(sc) ssc.sql("select * from mytable").collect " > spark.input
scala> :help All commands can be abbreviated, e.g., :he instead of :help. :edit <id>|<line> edit history :help [command] print this summary or command-specific help :history [num] show the history (optional num is commands to show) :h? <string> search the history :imports [name name ...] show import history, identifying sources of names :implicits [-v] show the implicits in scope :javap <path|class> disassemble a file or class name :line <id>|<line> place line(s) at the end of history :load <path> interpret lines in a file :paste [-raw] [path] enter paste mode or paste a file :power enable power user mode :quit exit the interpreter :replay [options] reset the repl and replay all previous commands :require <path> add a jar to the classpath :reset [options] reset the repl to its initial state, forgetting all session entries :save <path> save replayable session to a file :sh <command line> run a shell command (result is implicitly => List[String]) :settings <options> update compiler options, if possible; see reset :silent disable/enable automatic printing of results :type [-v] <expr> display the type of an expression without evaluating it :kind [-v] <expr> display the kind of expression :warnings show the suppressed warnings from the most recent line which had any
def isAllDigits(x: String) = x.map(Character.isDigit(_)).reduce(_&&_)
def isAllDigits(x: String) = x forall Character.isDigit
import scala.util.control.Exception.allCatch def isLongNumber(s: String): Boolean = (allCatch opt s.toLong).isDefined def isDoubleNumber(s: String): Boolean = (allCatch opt s.toDouble).isDefined
val onlyDigitsRegex = "^\\d+$".r def isAllDigits(x: String) = x match { case onlyDigitsRegex() => true case _ => false }
implicit def AllDigits(x: String) = new { def isAllDigits = x.matches("^\\d+$") } "12345".isAllDigits "12345foobar".isAllDigits
import scala.util.Try object NumCruncher { def isShort(aString: String): Boolean = Try(aString.toLong).isSuccess def isInt(aString: String): Boolean = Try(aString.toInt).isSuccess def isLong(aString: String): Boolean = Try(aString.toLong).isSuccess def isDouble(aString: String): Boolean = Try(aString.toDouble).isSuccess def isFloat(aString: String): Boolean = Try(aString.toFloat).isSuccess /** * * @param x the string to check * @return true if the parameter passed is a Java primitive number */ def isNumber(x: String): Boolean = { List(isShort(x), isInt(x), isLong(x), isDouble(x), isFloat(x)) .foldLeft(false)(_ || _) } }
scala> import scala.util.Try scala> Try{ "123x".toInt } res4: scala.util.Try[Int] = Failure(java.lang.NumberFormatException: For input string: "123x") scala> Try{ "123x".toInt }.isSuccess res5: Boolean = false
import scala.util.Try val doubleConverter: (String => Try[Double]) = (s: String) => Try{ s.map(c => if ((Character.isDigit(c) == true) || (c == val d1: Try[Double] = doubleConverter("+ 1234.0%") val d2: Try[Double] = doubleConverter("+ 1234..0%")
"324.56".toDoubleOption.isDefined "4.06e3".toDoubleOption.isDefined "9w01.1".toDoubleOption.isDefined
"324".toIntOption.isDefined "à32".toIntOption.isDefined "024".toIntOption.isDefined
val m = Map[String, Int]("a" -> 1, "b" -> 2, "c" -> 3) m.foreach((key: String, value: Int) => println(">>> key=" + key + ", value=" + value))
error: type mismatch found : (String, Int) => Unit required: (String, Int) => ?
m.foreach(p => println(">>> key=" + p._1 + ", value=" + p._2))
m.foreach { case (key, value) => println(">>> key=" + key + ", value=" + value) }
m.foreach((e: (String, Int)) => println(e._1 + "=" + e._2))
m.foreach{ case (key: String, value: Int) => println(">>> key=" + key + ", value=" + value)}
scala> m.foreach[Unit] {(key: String, value: Int) => println(">>> key=" + key + ", value=" + value)} <console>:16: error: type mismatch; found : (String, Int) => Unit required: (String, Int) => Unit m.foreach[Unit] {(key: String, value: Int) => println(">>> key=" + key + ", value=" + value)} ^
Map(1 -> 1, 2 -> 2).foreach(tuple => println(tuple._1 +" " + tuple._2)))
Map(1 -> 1, 2 -> 2).foreach(((x: Int, y: Int) => ???).tupled)
def parseDouble(s: String) = try { Some(s.toDouble) } catch { case _ => None }
case class ParseOp[T](op: String => T) implicit val popDouble = ParseOp[Double](_.toDouble) implicit val popInt = ParseOp[Int](_.toInt) def parse[T: ParseOp](s: String) = try { Some(implicitly[ParseOp[T]].op(s)) } catch {case _ => None} scala> parse[Double]("1.23") res13: Option[Double] = Some(1.23) scala> parse[Int]("1.23") res14: Option[Int] = None scala> parse[Int]("1") res15: Option[Int] = Some(1)
scala> "34.5".parseDouble res34: scalaz.Validation[NumberFormatException,Double] = Success(34.5) scala> "34.bad".parseDouble res35: scalaz.Validation[NumberFormatException,Double] = Failure(java.lang.NumberFormatException: For input string: "34.bad")
scala> "34.bad".parseDouble.toOption res36: Option[Double] = None
scala> import scala.util.Try import scala.util.Try scala> def parseDouble(s: String): Option[Double] = Try { s.toDouble }.toOption parseDouble: (s: String)Option[Double] scala> parseDouble("3.14") res0: Option[Double] = Some(3.14) scala> parseDouble("hello") res1: Option[Double] = None
import util.control.Exception._ catching(classOf[NumberFormatException]) either "12.W3".toDouble
class SafeParsePrimitive(s: String) { private def nfe[T](t: => T) = { try { Some(t) } catch { case nfe: NumberFormatException => None } } def booleanOption = s.toLowerCase match { case "yes" | "true" => Some(true) case "no" | "false" => Some(false) case _ => None } def byteOption = nfe(s.toByte) def doubleOption = nfe(s.toDouble) def floatOption = nfe(s.toFloat) def hexOption = nfe(java.lang.Integer.valueOf(s,16)) def hexLongOption = nfe(java.lang.Long.valueOf(s,16)) def intOption = nfe(s.toInt) def longOption = nfe(s.toLong) def shortOption = nfe(s.toShort) } implicit def string_parses_safely(s: String) = new SafeParsePrimitive(s)
def parseDouble(s: String)(implicit nf: NumberFormat) = { val pp = new ParsePosition(0) val d = nf.parse(s, pp) if (pp.getErrorIndex == -1) Some(d.doubleValue) else None }
implicit val formatter = NumberFormat.getInstance(Locale.ENGLISH) Console println parseDouble("184.33") Console println parseDouble("hello, world")
"5.7".toDoubleOption "abc".toDoubleOption "abc".toDoubleOption.getOrElse(-1d)
def strTimesTen (s: String) = for (d <- Try(s.toDouble)) yield d * 10 strTimesTen("0.1") match { Success(d) => println( s"It is $d" ) Failure(ex) => println( "I }
var total = orders .Where(o => o.Customer == "myCustomer") .SelectMany(o => o.OrderItems) .Aggregate(0, (sum, current) => sum + current.Price * current.Count);
val total = orders .filter(o => o.customer == "myCustomer") .flatMap(o => o.orderItems) .foldLeft(0)((s, c) => s + c.price * c.count)
@table("COFFEES") case class Coffee( @column("COF_NAME") name: String, @column("SUP_ID") supID: Int, @column("PRICE") price: Double ) val coffees = Queryable[Coffee] val l = for { c <- coffees if c.supID == 101 } yield (c.name, c.price) backend.result( l, session ) .foreach { case (n, p) => println(n + ": " + p) }
def findURLs(xml: NodeSeq): Seq[URL] = for { a <- xml \\ "a" href <- a attribute "href" url <- href.text } yield URL(url)
val q4c = for { u <- Users o <- Orders if o.userID is u.id } yield u.first ~ o.orderID
scala> implicit def intWithTimes(n: Int) = new { | def times(f: => Unit) = 1 to n foreach {_ => f} | } intWithTimes: (n: Int)java.lang.Object{def times(f: => Unit): Unit} scala> 5 times { | println("Hello World") | } Hello World Hello World Hello World Hello World Hello World
scala> import scalaz._; import Scalaz._; import effects._; import scalaz._ import Scalaz._ import effects._ scala> 5 times "foo" res0: java.lang.String = foofoofoofoofoo scala> 5 times List(1,2) res1: List[Int] = List(1, 2, 1, 2, 1, 2, 1, 2, 1, 2) scala> 5 times 10 res2: Int = 50 scala> 5 times ((x: Int) => x + 1).endo res3: scalaz.Endo[Int] = <function1> scala> res3(10) res4: Int = 15 scala> 5 times putStrLn("Hello, World!") res5: scalaz.effects.IO[Unit] = scalaz.effects.IO$$anon$2@36659c23 scala> res5.unsafePerformIO Hello, World! Hello, World! Hello, World! Hello, World! Hello, World!
scala> putStrLn("Foo") replicateM_ 5 res6: scalaz.effects.IO[Unit] = scalaz.effects.IO$$anon$2@8fe8ee7
scala> { System.exit(0) } replicateM_ 5 <console>:15: error: value replicateM_ is not a member of Unit
class TimesRepeat(n:Int) { def timesRepeat(block: => Unit): Unit = (1 to n) foreach { i => block } } object TimesRepeat { implicit def toTimesRepeat(n:Int) = new TimesRepeat(n) } import TimesRepeat._ 3.timesRepeat(println("foo"))
scala> def times(n:Int)( code: => Unit ) { for (i <- 1 to n) code } times: (n: Int)(code: => Unit)Unit scala> times(5) {println("here")} here here here here here
def foo(x: Any) { println("any") } def foo(x: String) { println("string") } def main(args: Array[String]) { val a: Any = new Object val s = "string" foo(a) foo(s) foo(s: Any) foo(a.asInstanceOf[String]) foo(a: String) }
if (x.isInstanceOf[String]) { val s = x.asInstanceOf[String] s.length } else ...
def checkFoo(x: Any) = x match { case s: String => s.length case m: Int => m case _ => 0 }
class Parent() { def method() {} } class Child1 extends Parent() { def method1() {} } class Child2 extends Parent() { def method2() {} } def getChild1() : Parent = new Child1() def getChild2() : Parent = new Child2() def getChild() : Child1 = new Child1() (getChild1().asInstanceOf[Child1]).method1() (getChild1().asInstanceOf[Child2]).method2() (getChild1() : Child2).method2() (getChild2() : Child2).method2() (getChild() : Parent).method1() (getChild()).method() getChild1().asInstanceOf[String] getChild1().asInstanceOf[Int]
def prt(p: Parent) = println("parent") def prt(ch: Child1) = println("child") prt(new Parent()) prt((new Child1()) : Parent) prt(new Child1()) prt(new Parent().asInstanceOf[Child1]) prt(new Child1().asInstanceOf[Parent])
implicit def toChild1(p: Parent) : Child1 = new Child1() implicit def toChild2(p: Parent) : Child2 = new Child2() (getChild1() : Child2).method2() (getChild2() : Child2).method2() (getChild2()).method1() (getChild2()).method2() (getChild2() : Parent).method() (getChild() : Parent).method1() getChild1().asInstanceOf[Int]
scala> var a :Seq[String] = Seq("one", "two") a: Seq[String] = List(one, two) scala> a.size res6: Int = 2 scala> a.length res7: Int = 2
/** The size of this $coll, equivalent to `length`. * * $willNotTerminateInf */ override def size = length
found : scala.collection.mutable.IndexedSeq[(Int, Entity)] required: (Int, Entity)
val timestamp: Long = System.currentTimeMillis / 1000
import java.time.Instant unixTimestamp : Long = Instant.now.getEpochSecond
val l = Array(1,2,3).toList val l = Array(1,2,3).toList()
val leastOrNone = seq.reduceOption { (best, current) => if (current.something < best.something) current else best }
case class Foo(a: Int, b: Int) val seq = Seq(Foo(1,1),Foo(2,0),Foo(0,3)) val ord = Ordering.by((_: Foo).b) seq.reduceOption(ord.min)
def minOptionBy[A, B: Ordering](seq: Seq[A])(f: A => B) = seq reduceOption Ordering.by(f).min
import util.control.Exception._ allCatch opt seq.minBy(_.something)
catching(classOf[UnsupportedOperationException]) opt seq.minBy(_.something)
import collection._ class TraversableOnceExt[CC, A](coll: CC, asTraversable: CC => TraversableOnce[A]) { def minOption(implicit cmp: Ordering[A]): Option[A] = { val trav = asTraversable(coll) if (trav.isEmpty) None else Some(trav.min) } def minOptionBy[B](f: A => B)(implicit cmp: Ordering[B]): Option[A] = { val trav = asTraversable(coll) if (trav.isEmpty) None else Some(trav.minBy(f)) } } implicit def extendTraversable[A, C[A] <: TraversableOnce[A]](coll: C[A]): TraversableOnceExt[C[A], A] = new TraversableOnceExt[C[A], A](coll, identity) implicit def extendStringTraversable(string: String): TraversableOnceExt[String, Char] = new TraversableOnceExt[String, Char](string, implicitly) implicit def extendArrayTraversable[A](array: Array[A]): TraversableOnceExt[Array[A], A] = new TraversableOnceExt[Array[A], A](array, implicitly)
case class Point(longitude0: String, latitude0: String) extends Ordered [Point]{ def this(point: Point) = this(point.original_longitude,point.original_latitude) val original_longitude = longitude0 val original_latitude = latitude0 val longitude = parseDouble(longitude0).get val latitude = parseDouble(latitude0).get override def toString: String = "longitude: " +original_longitude +", latitude: "+ original_latitude def parseDouble(s: String): Option[Double] = try { Some(s.toDouble) } catch { case _ => None } def distance(other: Point): Double = sqrt(pow(longitude - other.longitude, 2) + pow(latitude - other.latitude, 2)) override def compare(that: Point): Int = { if (longitude < that.longitude) return -1 else if (longitude == that.longitude && latitude < that.latitude) return -1 else return 1 } }
var points = Seq[Point]() val maxPoint = points.max val minPoint = points.min
case class Foo(num: Int) val foos: Seq[Foo] = Seq(Foo(1), Foo(2), Foo(3)) val noFoos: Seq[Foo] = Seq.empty def minByOpt(foos: Seq[Foo]): Option[Foo] = foos.foldLeft(None: Option[Foo]) { (acc, elem) => Option((elem +: acc.toSeq).minBy(_.num)) }
scala> minByOpt(foos) res0: Option[Foo] = Some(Foo(1)) scala> minByOpt(noFoos) res1: Option[Foo] = None
least f x | Seq.null x = Nothing | otherwise = Just (Seq.minimumBy f x)
val val val + = 1 val &+ = 1 val &2 = 1 val £2 = 1 val ¬ = 1
val ! val simpleName = 1 val withDigitsAndUnderscores_ab_12_ab12 = 1 val wordEndingInOpChars_! val !^©® = 1 val abcαβγ_!^©® = 1
val val val + = 1 val &+ = 1 val &2 = 1 val £2 = 1 val ¬ = 1
def fib(n: Int) = if(n <= 1) 1 else fib(n-1) + fib(n-2) println(fib(100))
case class Memo[A,B](f: A => B) extends (A => B) { private val cache = mutable.Map.empty[A, B] def apply(x: A) = cache getOrElseUpdate (x, f(x)) } val fib: Memo[Int, BigInt] = Memo { case 0 => 0 case 1 => 1 case n => fib(n-1) + fib(n-2) } println(fib(100))
def foo(n: Int) = { val fib: Memo[Int, BigInt] = Memo { case 0 => 0 case 1 => 1 case n => fib(n-1) + fib(n-2) } fib(n) }
/** * Subset sum algorithm - can we achieve sum t using elements from s? * * @param s set of integers * @param t target * @return true iff there exists a subset of s that sums to t */ def subsetSum(s: Seq[Int], t: Int): Boolean = { val max = s.scanLeft(0)((sum, i) => (sum + i) max sum) val min = s.scanLeft(0)((sum, i) => (sum + i) min sum) val dp: Memo[(Int, Int), Boolean] = Memo { case (_, 0) => true case (0, _) => false case (i, x) if min(i) <= x && x <= max(i) => dp(i-1, x - s(i-1)) || dp(i-1, x) case _ => false } dp(s.length, t) }
def memoize[I, O](f: I => O): I => O = new mutable.HashMap[I, O]() { override def apply(key: I) = getOrElseUpdate(key, f(key)) }
lazy val fib: Int => BigInt = memoize { case 0 => 0 case 1 => 1 case n => fib(n-1) + fib(n-2) }
lazy val c: ((Int, Int)) => BigInt = memoize { case (_, 0) => 1 case (n, r) if r > n/2 => c(n, n - r) case (n, r) => c(n - 1, r - 1) + c(n - 1, r) }
def isSubsetSumAchievable(s: Vector[Int], t: Int) = { lazy val f: ((Int, Int)) => Boolean = memoize { case (_, 0) => true case (0, _) => false case (i, j) => val k = i - 1 f(k, j - s(k)) || f(k, j) } f(s.length, t) }
def memoize[I, O](f: I => O): I => O = new mutable.HashMap[I, O]() {self => override def apply(key: I) = self.synchronized(getOrElseUpdate(key, f(key))) }
private val fib: Memo[Int, BigInt] = Memo { case 0 => 0 case 1 => 1 case n => fib(n-1) + fib(n-2) } def foo(n: Int) = { fib(n) }
import scalaz.Memo lazy val fib: Int => BigInt = Memo.mutableHashMapMemo { case 0 => 0 case 1 => 1 case n => fib(n-2) + fib(n-1) }
def memoize[I,O](memo: Map[I, O], formula: (I => O, I) => O): I => O
def memoize[I, O](map: Map[I, O], formula: (I => O, I) => O): I => O = { var memo = map def recur(n: I): O = { if( memo contains n) { memo(n) } else { val result = formula(recur, n) memo += (n -> result) result } } recur }
import java.util.Random val rand = new Random(System.currentTimeMillis()) val random_index = rand.nextInt(A.length) val result = A(random_index)
import scala.util.Random val A = Array("please", "help", "me") Random.shuffle(A.toList).head
import scala.util.Random val A = List(1, 2, 3, 4, 5, 6) A(Random.nextInt(A.size))
implicit class ListOps[A](list: List[A]) { def getRandomElement: Option[A] = list match { case Nil => None case _ => list.lift(scala.util.Random.nextInt(list.size)) } def randomChoice(n: Int): Option[List[A]] = (1 to n).toList.foldLeft(Option(List[A]()))((acc, e) => getRandomElement.flatMap(r => acc.map(a => a :+ r))) }
val randomElement: Option[String] = List("this", "is", "a", "list").getRandomElement
randomElement match { case None => ??? case Some(result) => ???
import scala.util.Random object sample { def arr[T](items:Array[T]):T = { items(Random.nextInt(items.length)) } }
def getRandElemO[T](arr: Array[T]): Option[T] = if (arr.isEmpty) None else arr lift util.Random.nextInt(arr.length)
val list = 1 :: 2 ::3 :: 4 :: List() list.replace(2, 5)
scala> val list = List(1, 2, 3, 4) list: List[Int] = List(1, 2, 3, 4) scala> list.patch(2, Seq(5), 1) res0: List[Int] = List(1, 2, 5, 4) scala> list.patch(2, Seq(5), 2) res1: List[Int] = List(1, 2, 5) scala> list.patch(2, Seq(5), 0) res2: List[Int] = List(1, 2, 5, 3, 4)
@ list res20: List[Int] = List(1, 2, 3, 4, 4, 5, 4) @ list.map(e => if(e==4) 0 else e) res21: List[Int] = List(1, 2, 3, 0, 0, 5, 0)
scala> var l = List(11,20,24,31,35) l: List[Int] = List(11, 20, 24, 31, 35) scala> l.patch(2,List(27),1) res35: List[Int] = List(11, 20, 27, 31, 35)
scala> val original: List[String] = List("a","b") original: List[String] = List(a, b) scala> val replace = original.map(x => if(x.equals("a")) "c" else x) replace: List[String] = List(c, b)
def fn[A <% B](arg: A) = ... def fn[A](arg: A)(implicit ev: A => B) = ... def fn[A : Numeric](arg: A) = ... def fn[A](arg: A)(implicit ev: Numeric[A]) = ...
scala> s.toList res1: List[Char] = List(T, e, s, t)
scala> s.toArray res2: Array[Char] = Array(T, e, s, t)
"Test".map(_.toString) "Test".sliding(1).toList "Test".sliding(1).toArray
def UTF32point(s: String, idx: Int = 0, found: List[Int] = Nil): List[Int] = { if (idx >= s.length) found.reverse else { val point = s.codePointAt(idx) UTF32point(s, idx + java.lang.Character.charCount(point), point :: found) } } UTF32point("Test")
"Test".map(lines=>lines+"") res34: scala.collection.immutable.IndexedSeq[String] = Vector(T, e, s, t)
val l = List((1, "blue"), (5, "red"), (2, "green"))
val m = l.filter(item => { val (n, s) = item n != 2 }
val l = List((1, "blue"), (5, "red"), (2, "green")) val m = l.filter(_._1 != 2)
for (x <- l; (n,s) = x if (n != 2)) yield x l.collect{ case x @ (n,s) if (n != 2) => x } l.filter{ case (n,s) => n != 2 } l.unzip.zipped.map((n,s) => n != 2).zip
object unTuple { def apply[A, B, X](f: (A, B) => X): (Tuple2[A, B] => X) = { (t: Tuple2[A, B]) => f(t._1, t._2) } def apply[A, B, C, X](f: (A, B, C) => X): (Tuple3[A, B, C] => X) = { (t: Tuple3[A, B, C]) => f(t._1, t._2, t._3) } } val list = List( ("a",1), ("b",2) ) val list2 = List( ("a",1,true), ("b",2,false) ) list foreach unTuple( (k: String, v: Int) => println(k, v) ) list2 foreach unTuple( (k: String, v: Int, b: Boolean) => println(k, v, b) )
val m = l.filter( unTuple( (n:Int,color:String) => n != 2 ))
scala> def addUmm(x: String) = x + " umm" scala> def addAhem(x: String) = x + " ahem" val ummThenAhem = addAhem(_).compose(addUmm(_))
<console>:7: error: missing parameter type for expanded function ((x$1) => addAhem(x$1).compose(((x$2) => addUmm(x$2)))) val ummThenAhem = addAhem(_).compose(addUmm(_)) ^ <console>:7: error: missing parameter type for expanded function ((x$2) => addUmm(x$2)) val ummThenAhem = addAhem(_).compose(addUmm(_)) ^ <console>:7: error: type mismatch; found : java.lang.String required: Int val ummThenAhem = addAhem(_).compose(addUmm(_))
val ummThenAhem = x => addAhem(x).compose(y => addUmm(y))
scala> val ummThenAhem = (addAhem _).compose(addUmm _) ummThenAhem: String => java.lang.String = <function1>
scala> addAhem _ res0: String => java.lang.String = <function1>
protected val _response = new DynamicVariable[HttpServletResponse](null) protected val _request = new DynamicVariable[HttpServletRequest](null)
dynamicVariable.withValue(value){ valueInContext => }
dynamicVariable.withValue(value){ valueInContext => spawn{ } }
def noisy() { println("robot human robot human") } noisy() val ps = new java.io.PrintStream("/tmp/mylog") scala.Console.withOut(ps) { noisy() }
val dyn = new DynamicVariable[String]("withoutValue") def print=println(dyn.value) print dyn.withValue("withValue") { print } print
def allStrings(expr: => String): List[String] = expr match { case null => Nil case w => w :: allStrings(expr) }
error: could not optimize @tailrec annotated method: it contains a recursive call not in tail position def allStrings(expr: => String): List[String] =
def allStrings(expr: => String, acc: List[String] = Nil): List[String] = expr match { case null => acc case w => allStrings(expr, w :: acc) }
def allStrings(expr: => String) = { def iter(expr: => String, acc: List[String]): List[String] = expr match { case null => acc case w => iter(expr, w :: acc) } iter(expr, Nil) }
def allStrings(expr: => String) = { @tailrec def inner(expr: => String, acc: List[String]): List[String] = expr match { case null => acc case w => inner(expr, w :: acc) } inner(expr, Nil) }
val b = 1 : Byte val f = 1 : Float val d = 1 : Double
def f(args: String*) = ... val list = List("a", "b", "c") f(list : _*)
scala> def countAttendees(attendees: String*) = println("Number of attendees: " + attendees.size) scala> val firstMeetingAttendees = List("Alex", "Bob", "Cathy") scala> val secondMeetingAttendees = "Alex" scala> countAttendees(firstMeetingAttendees: _*) Number of attendees: 3 scala> countAttendees(secondMeetingAttendees) Number of attendees: 1
"Build: sync MyProjName: syncing... dump project structure from sbt"
IDE: IntelliJ IDEA (build OS: Windows 7 (6.1, amd64) JRE: 1.8.0_152-release-1024-b6 (JetBrains s.r.o) JVM: 25.152-b6 (OpenJDK 64-Bit Server VM)
import coursier.Keys._ classpathTypes += "maven-plugin"
class AggregatedPerson extends HashSet[PersonRecord] { def mostFrequentName: String = { type NameCount = (String, Int) def moreFirst(a: NameCount, b: NameCount) = a._2 > b._2 def countOccurrences(nameGroup: (String, List[PersonRecord])) = (nameGroup._1, nameGroup._2.size) iterator.toList.groupBy(_.fullName). map(countOccurrences).iterator.toList. sortWith(moreFirst).head._1 } }
[[syntax trees at end of cleanup]] package <empty> { class AggregatedPerson extends scala.collection.mutable.HashSet with ScalaObject { def mostFrequentName(): java.lang.String = AggregatedPerson.this.iterator().toList().groupBy({ (new AggregatedPerson$$anonfun$mostFrequentName$1(AggregatedPerson.this): Function1) }).map({ { (new AggregatedPerson$$anonfun$mostFrequentName$2(AggregatedPerson.this): Function1) } }, collection.this.Map.canBuildFrom()).$asInstanceOf[scala.collection.MapLike]().iterator().toList().sortWith({ { (new AggregatedPerson$$anonfun$mostFrequentName$3(AggregatedPerson.this): Function2) } }).$asInstanceOf[scala.collection.IterableLike]().head().$asInstanceOf[Tuple2]()._1().$asInstanceOf[java.lang.String](); final def moreFirst$1(a: Tuple2, b: Tuple2): Boolean = scala.Int.unbox(a._2()).>(scala.Int.unbox(b._2())); final def countOccurrences$1(nameGroup: Tuple2): Tuple2 = new Tuple2(nameGroup._1(), scala.Int.box(nameGroup._2().$asInstanceOf[scala.collection.SeqLike]().size())); def this(): AggregatedPerson = { AggregatedPerson.super.this(); () } }; @SerialVersionUID(0) @serializable final <synthetic> class AggregatedPerson$$anonfun$mostFrequentName$1 extends scala.runtime.AbstractFunction1 { final def apply(x$1: PersonRecord): java.lang.String = x$1.fullName(); final <bridge> def apply(v1: java.lang.Object): java.lang.Object = AggregatedPerson$$anonfun$mostFrequentName$1.this.apply(v1.$asInstanceOf[PersonRecord]()); def this($outer: AggregatedPerson): AggregatedPerson$$anonfun$mostFrequentName$1 = { AggregatedPerson$$anonfun$mostFrequentName$1.super.this(); () } }; @SerialVersionUID(0) @serializable final <synthetic> class AggregatedPerson$$anonfun$mostFrequentName$2 extends scala.runtime.AbstractFunction1 { final def apply(nameGroup: Tuple2): Tuple2 = AggregatedPerson$$anonfun$mostFrequentName$2.this.$outer.countOccurrences$1(nameGroup); <synthetic> <paramaccessor> private[this] val $outer: AggregatedPerson = _; final <bridge> def apply(v1: java.lang.Object): java.lang.Object = AggregatedPerson$$anonfun$mostFrequentName$2.this.apply(v1.$asInstanceOf[Tuple2]()); def this($outer: AggregatedPerson): AggregatedPerson$$anonfun$mostFrequentName$2 = { if ($outer.eq(null)) throw new java.lang.NullPointerException() else AggregatedPerson$$anonfun$mostFrequentName$2.this.$outer = $outer; AggregatedPerson$$anonfun$mostFrequentName$2.super.this(); () } }; @SerialVersionUID(0) @serializable final <synthetic> class AggregatedPerson$$anonfun$mostFrequentName$3 extends scala.runtime.AbstractFunction2 { final def apply(a: Tuple2, b: Tuple2): Boolean = AggregatedPerson$$anonfun$mostFrequentName$3.this.$outer.moreFirst$1(a, b); <synthetic> <paramaccessor> private[this] val $outer: AggregatedPerson = _; final <bridge> def apply(v1: java.lang.Object, v2: java.lang.Object): java.lang.Object = scala.Boolean.box(AggregatedPerson$$anonfun$mostFrequentName$3.this.apply(v1.$asInstanceOf[Tuple2](), v2.$asInstanceOf[Tuple2]())); def this($outer: AggregatedPerson): AggregatedPerson$$anonfun$mostFrequentName$3 = { if ($outer.eq(null)) throw new java.lang.NullPointerException() else AggregatedPerson$$anonfun$mostFrequentName$3.this.$outer = $outer; AggregatedPerson$$anonfun$mostFrequentName$3.super.this(); () } } }
object NestBench { def countRaw() = { var sum = 0 var i = 0 while (i<1000) { sum += i i += 1 var j = 0 while (j<1000) { sum += j j += 1 var k = 0 while (k<1000) { sum += k k += 1 sum += 1 } } } sum } def countClosure() = { var sum = 0 var i = 0 def sumI { sum += i i += 1 var j = 0 def sumJ { sum += j j += 1 var k = 0 def sumK { def sumL { sum += 1 } sum += k k += 1 sumL } while (k<1000) sumK } while (j<1000) sumJ } while (i<1000) sumI sum } def countInner() = { var sum = 0 def whileI = { def whileJ = { def whileK = { def whileL() = 1 var ksum = 0 var k = 0 while (k<1000) { ksum += k; k += 1; ksum += whileL } ksum } var jsum = 0 var j = 0 while (j<1000) { jsum += j; j += 1 jsum += whileK } jsum } var isum = 0 var i = 0 while (i<1000) { isum += i; i += 1 isum += whileJ } isum } whileI } def countFunc() = { def summer(f: => Int)() = { var sum = 0 var i = 0 while (i<1000) { sum += i; i += 1 sum += f } sum } summer( summer( summer(1) ) )() } def nsPerIteration(f:() => Int): (Int,Double) = { val t0 = System.nanoTime val result = f() val t1 = System.nanoTime (result , (t1-t0)*1e-9) } def main(args: Array[String]) { for (i <- 1 to 5) { val fns = List(countRaw _, countClosure _, countInner _, countFunc _) val labels = List("raw","closure","inner","func") val results = (fns zip labels) foreach (fl => { val x = nsPerIteration( fl._1 ) printf("Method %8s produced %d; time/it = %.3f ns\n",fl._2,x._1,x._2) }) } } }
scala> NestBench.main(Array[String]()) Method raw produced -1511174132; time/it = 0.422 ns Method closure produced -1511174132; time/it = 2.376 ns Method inner produced -1511174132; time/it = 0.402 ns Method func produced -1511174132; time/it = 0.836 ns Method raw produced -1511174132; time/it = 0.418 ns Method closure produced -1511174132; time/it = 2.410 ns Method inner produced -1511174132; time/it = 0.399 ns Method func produced -1511174132; time/it = 0.813 ns Method raw produced -1511174132; time/it = 0.411 ns Method closure produced -1511174132; time/it = 2.372 ns Method inner produced -1511174132; time/it = 0.399 ns Method func produced -1511174132; time/it = 0.813 ns Method raw produced -1511174132; time/it = 0.411 ns Method closure produced -1511174132; time/it = 2.370 ns Method inner produced -1511174132; time/it = 0.399 ns Method func produced -1511174132; time/it = 0.815 ns Method raw produced -1511174132; time/it = 0.412 ns Method closure produced -1511174132; time/it = 2.357 ns Method inner produced -1511174132; time/it = 0.400 ns Method func produced -1511174132; time/it = 0.817 ns
import com.google.caliper.SimpleBenchmark class Benchmark extends SimpleBenchmark { def timeRaw(reps: Int) = { var i = 0 var result = 0L while (i < reps) { result += 0xc37e ^ (i * 0xd5f3) i = i + 1 } result } def normal(i: Int): Long = 0xc37e ^ (i * 0xd5f3) def timeNormal(reps: Int) = { var i = 0 var result = 0L while (i < reps) { result += normal(i) i = i + 1 } result } def timeInner(reps: Int) = { def inner(i: Int): Long = 0xc37e ^ (i * 0xd5f3) var i = 0 var result = 0L while (i < reps) { result += inner(i) i = i + 1 } result } def timeClosure(reps: Int) = { var i = 0 var result = 0L val closure = () => result += 0xc37e ^ (i * 0xd5f3) while (i < reps) { closure() i = i + 1 } result } def normal(i: Int, j: Int, k: Int, l: Int): Long = i ^ j ^ k ^ l def timeUnboxed(reps: Int) = { var i = 0 var result = 0L while (i < reps) { result += normal(i,i,i,i) i = i + 1 } result } val closure = (i: Int, j: Int, k: Int, l: Int) => (i ^ j ^ k ^ l).toLong def timeBoxed(reps: Int) = { var i = 0 var result = 0L while (i < reps) { closure(i,i,i,i) i = i + 1 } result } }
benchmark ns linear runtime Normal 0.576 = Raw 0.576 = Inner 0.576 = Closure 0.532 = Unboxed 0.893 = Boxed 15.210 ==============================
benchmark ns linear runtime Raw 0.574 = Normal 0.576 = Inner 0.575 = Closure 0.645 = Unboxed 0.889 = Boxed 15.107 ==============================
java version "1.7.0_51" Java(TM) SE Runtime Environment (build 1.7.0_51-b13) Java HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)
Scala compiler version 2.10.3 -- Copyright 2002-2013, LAMP/EPFL
val (a, b) = (1, 2) val Array(a, b) = Array(1, 2) val h :: t = List(1, 2) val List(a, Some(b)) = List(1, Option(2))
var x: Int = _ var y: Int = _ val (a, b) = (1, 2) x = a y = b (1,2) match { case (a,b) => x = a; y = b case _ => }
case class P(var x:Int, var y:Int) { def update(xy:(Int, Int)) { x = xy._1 y = xy._2 } } val p = P(1,2) p() = (3,4)
scala> import scala.reflect.runtime._ import scala.reflect.runtime scala> val cm = universe.runtimeMirror(getClass.getClassLoader) cm @ 41d0fe80: reflect.runtime.universe.Mirror = JavaMirror with scala.tools.nsc.interpreter.IMain$TranslatingClassLoader... scala> import scala.tools.reflect.ToolBox import scala.tools.reflect.ToolBox scala> val tb = cm.mkToolBox() tb: scala.tools.reflect.ToolBox[reflect.runtime.universe.type] = scala.tools.reflect.ToolBoxFactory$ToolBoxImpl@3a962da5 scala> tb.runExpr(tb.parseExpr("class C; scala.reflect.classTag[C].runtimeClass")) res2: Any = class __wrapper$1$f9d572ca0d884bca9333e251c64e980d$C$1
scala> val build = scala.reflect.runtime.universe.build build: reflect.runtime.universe.BuildApi = scala.reflect.internal.BuildUtils$BuildImpl@50d5afff scala> val x = build.setTypeSignature(build.newFreeTerm("x", 2), typeOf[Int]) x: reflect.runtime.universe.FreeTermSymbol = free term x scala> tb.runExpr(Apply(Select(Ident(x), newTermName("$plus")), List(Literal(Constant(2))))) res0: Any = 4
<IntelliJ IDEA installation folder>/bin/idea64.vmoptions
object Retry { def apply[A](times: Int, pause: Duration)(code: ⇒ A): A = { var result: Option[A] = None var remaining = times while (remaining > 0) { remaining -= 1 try { result = Some(code) remaining = 0 } catch { case _ if remaining > 0 ⇒ Thread.sleep(pause.toMillis) } } result.get } }
SendCommandToService is already defined as case class SendCommandToService case class SendCommandToService(service: String, commandName: String, keys: Array[String], values: Array[String]) ^
scala> def test1(str: String) = str + str; test1: (str: String)java.lang.String scala> test1("ab") res0: java.lang.String = abab
scala> val test2 = test1 <console>:6: error: missing arguments for method test1 in object $iw; follow this method with `_ val test2 = test1 ^
scala> val test2 = test1 _ test2: (String) => java.lang.String = <function1> scala> test2("ab") res1: java.lang.String = abab
scala> val test3 = (str: String) => str + str test3: (String) => java.lang.String = <function1> scala> test3("ab") res2: java.lang.String = abab scala> val test4 = test3 test4: (String) => java.lang.String = <function1>
scala> def test1 = (str: String) => str + str test1: (String) => java.lang.String scala> val test2 = test1 test2: (String) => java.lang.String = <function1> scala> val test3 = (str: String) => str + str test3: (String) => java.lang.String = <function1> scala> val test4 = test2 test4: (String) => java.lang.String = <function1>
scala> def test5(str: String) = str + str test5: (str: String)java.lang.String
scala> def test1(str: String) = str + str; test1: (str: String)java.lang.String scala> val f1 = test1 _ f1: (String) => java.lang.String = <function1>
scala> val f2 = f1 _ f2: () => (String) => java.lang.String = <function0>
scala> def add(i: Int, j: Int) = i + j add: (i: Int,j: Int)Int scala> val addF = add(_, _) addF: (Int, Int) => Int = <function2> scala> val addF2 = add _ addF2: (Int, Int) => Int = <function2>
if (opt.isDefined) println(opt.get) opt foreach println
for { op1 <- opt1 op2 <- opt2 op3 <- opt3 } println(op1+op2+op3)
val nestedOption = Some(Some(Some(1))) for { opt1 <- nestedOption opt2 <- opt1 opt3 <- opt2 } println(opt3)
val x: Option[Int] = foo() val y = x.map(_+1) val z = x.get + 1
GET / controllers.Application.index GET /hello controllers.Application.sayHello GET /assets/*file controllers.Assets.versioned(path="/public", file: Asset)
package controllers import play.api.mvc._ import play.api.data._ import play.api.data.Forms._ import views._ class Application extends Controller { val helloForm = Form( tuple( "name" -> nonEmptyText, "repeat" -> number(min = 1, max = 100), "color" -> optional(text) ) ) def index = Action { Ok(html.index(helloForm)) } def sayHello = Action { implicit request => helloForm.bindFromRequest.fold( formWithErrors => BadRequest(html.index(formWithErrors)), {case (name, repeat, color) => Ok(html.hello(name, repeat.toInt, color))} ) } }
@(helloForm: Form[(String,Int,Option[String])]) @import helper._ @main(title = "The <h1>Configure your @form(action = routes.Application.sayHello, args = @inputText( field = helloForm("name"), args = ) @inputText( field = helloForm("repeat"), args = ) @select( field = helloForm("color"), options = options( "" -> "Default", "red" -> "Red", "green" -> "Green", "blue" -> "Blue" ), args = ) <p class="buttons"> <input type="submit" id="submit"> <p> } }
import play.api.Play.current import play.api.i18n.Messages.Implicits._
@(helloForm: Form[(String,Int,Option[String])])(implicit messages: Messages) @import helper._ @main(title = "The <h1>Configure your ...
package controllers import play.api.mvc._ import play.api.data._ import play.api.data.Forms._ import javax.inject.Inject import play.api.i18n.I18nSupport import play.api.i18n.MessagesApi import views._ class Application @Inject()(val messagesApi: MessagesApi) extends Controller with I18nSupport { val helloForm = Form( tuple( "name" -> nonEmptyText, "repeat" -> number(min = 1, max = 100), "color" -> optional(text) ) ) def index = Action { Ok(html.index(helloForm)) } def sayHello = Action { implicit request => helloForm.bindFromRequest.fold( formWithErrors => BadRequest(html.index(formWithErrors)), {case (name, repeat, color) => Ok(html.hello(name, repeat.toInt, color))} ) } }
@(contacts: List[models.Contact], form: Form[models.Contact])(implicit messages: Messages)
import play.api.data.Forms._ import javax.inject.Inject import play.api.i18n.I18nSupport import play.api.i18n.MessagesApi
class Application @Inject()(val messagesApi: MessagesApi) extends Controller with I18nSupport {
import slick.driver.H2Driver.api._ import shapeless._ import slickless._ class LargeTable(tag: Tag) extends Table[Large](tag, "large") { def a = column[Int]("a") def b = column[Int]("b") def c = column[Int]("c") def u = column[Int]("u") def v = column[Int]("v") def w = column[Int]("w") def * = (a :: b :: c :: :: u :: v :: w :: HNil) .mappedWith(Generic[Large]) }
class Demo(val field1: String, val field2: Int, val field23: String) extends Product with Serializable { def canEqual(that: Any) = that.isInstanceOf[Demo] def productArity = 23 def productElement(idx: Int) = idx match { case 0 => field1 case 1 => field2 case 22 => field23 } }
case class MyClass(street: String, city: String, state: String, zip: Integer)
case class User(name: Name, email: String) case class Name(first: String, last: String)
import org.apache.spark.sql.SparkSession case class SimpleTuple(id: Int, desc: String) object DatasetTest { val dataList = List( SimpleTuple(5, "abc"), SimpleTuple(6, "bcd") ) def main(args: Array[String]): Unit = { val sparkSession = SparkSession.builder. master("local") .appName("example") .getOrCreate() val dataset = sparkSession.createDataset(dataList) } }
val sparkSession: SparkSession = ??? import sparkSession.implicits._ val dataset = sparkSession.createDataset(dataList)
object DatasetTest { case class SimpleTuple(id: Int, desc: String) val dataList = List( SimpleTuple(5, "abc"), SimpleTuple(6, "bcd") ) def main(args: Array[String]): Unit = { val sparkSession = SparkSession.builder .master("local") .appName("example") .getOrCreate() val dataset = sparkSession.createDataset(dataList) } }
object DatasetTest { case class SimpleTuple(id: Int, desc: String) val dataList = List( SimpleTuple(5, "abc"), SimpleTuple(6, "bcd") ) def main(args: Array[String]): Unit = { val sparkSession = SparkSession.builder .master("local") .appName("example") .getOrCreate() import sparkSession.implicits._ val dataset = sparkSession.createDataset(dataList) } }
case class SimpleTuple(id: Int, desc: String) object DatasetTest { val dataList = List( SimpleTuple(5, "abc"), SimpleTuple(6, "bcd") ) def main(args: Array[String]): Unit = { val sparkSession = SparkSession.builder .master("local") .appName("example") .getOrCreate() import sparkSession.implicits._ val dataset = sparkSession.createDataset(dataList) } }
import org.apache.spark.sql._ import org.apache.spark.sql.types._ import scala.collection.JavaConverters._ val simpleSchema = StructType( StructField("a", StringType) :: StructField("b", IntegerType) :: StructField("c", IntegerType) :: StructField("d", IntegerType) :: StructField("e", IntegerType) :: Nil) val data = List( Row("001", 1, 0, 3, 4), Row("001", 3, 4, 1, 7), Row("001", null, 0, 6, 4), Row("003", 1, 4, 5, 7), Row("003", 5, 4, null, 2), Row("003", 4, null, 9, 2), Row("003", 2, 3, 0, 1) ) val df = spark.createDataFrame(data.asJava, simpleSchema)
scala> val myDouble = 25.7 myDouble: Double = 25.7 scala> val myInt = 5 myInt: Int = 5 scala> val divide = (myDouble / myInt).asInstanceOf[Int] divide: Int = 5
val items = List("a", "b", "c") sqlContext.sql("select c1 from table") .filter($"c1".isin(items)) .collect .foreach(println)
Exception in thread "main" java.lang.RuntimeException: Unsupported literal type class scala.collection.immutable.$colon$colon List(a, b, c) at org.apache.spark.sql.catalyst.expressions.Literal$.apply(literals.scala:49) at org.apache.spark.sql.functions$.lit(functions.scala:89) at org.apache.spark.sql.Column$$anonfun$isin$1.apply(Column.scala:642) at org.apache.spark.sql.Column$$anonfun$isin$1.apply(Column.scala:642) at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35) at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) at scala.collection.AbstractTraversable.map(Traversable.scala:104) at org.apache.spark.sql.Column.isin(Column.scala:642)
val items = List("a", "b", "c").mkString("\"","\",\"","\"") sqlContext.sql("select c1 from table") .filter($"c1".isin(items)) .collect .foreach(println)
val items = List("a", "b", "c") sqlContext.sql("select c1 from table") .filter($"c1".isin(items:_*)) .collect .foreach(println)
.isin(sampleListName.stream().toArray(String[]::new))));
isin(java.lang.Object... list) A boolean expression that is evaluated to true if the value of this expression is contained by the evaluated values of the arguments.
val df_subset = data.randomSplit(Array(0.00000001, 0.01), seed = 12345)(0)
def repeatChar(char:Char, n: Int) = List.fill(n)(char).mkString def repeatString(char:String, n: Int) = List.fill(n)(char).mkString repeatChar( repeatString("abc",3)
def repeatChar(char:Char, n: Int) : String = { var result = "" for(_ <- 1 to n){ result += "" + char } result }
class C { @tailrec def fact(n: Int, result: Int): Int = if(n == 0) result else fact(n - 1, n * result) }
scala> class C { def fact(n: Int, result: Int): Int = if(n == 0) result else fact(n - 1, n * result) } defined class C scala> (new C).fact(5, 1) res11: Int = 120
scala> class C2 extends C { override def fact(n: Int, result: Int): Int = 2 * super.fact(n, result) } defined class C2 scala> (new C).fact(5, 1) res12: Int = 120 scala> (new C2).fact(5, 1)
class Pretty { def recursivePrinter(a: Any): String = { a match { case xs: List[_] => xs.map(recursivePrinter).mkString("L[",",","]") case xs: Array[_] => xs.map(recursivePrinter).mkString("A[",",","]") case _ => a.toString }} } class Prettier extends Pretty { override def recursivePrinter(a: Any): String = { a match { case s: Set[_] => s.map(recursivePrinter).mkString("{",",","}") case _ => super.recursivePrinter(a) }} } scala> (new Prettier).recursivePrinter(Set(Set(0,1),1)) res8: String = {{0,1},1}
import org.apache.spark.sql.functions.udf val df = Seq( (1L, 3.0, "a"), (2L, -1.0, "b"), (3L, 0.0, "c") ).toDF("x", "y", "z") case class Foobar(foo: Double, bar: Double) val foobarUdf = udf((x: Long, y: Double, z: String) => Foobar(x * y, z.head.toInt * y)) val df1 = df.withColumn("foobar", foobarUdf($"x", $"y", $"z")) df1.show df1.printSchema
import org.apache.spark.sql.types._ import org.apache.spark.sql.Row def foobarFunc(x: Long, y: Double, z: String): Seq[Any] = Seq(x * y, z.head.toInt * y) val schema = StructType(df.schema.fields ++ Array(StructField("foo", DoubleType), StructField("bar", DoubleType))) val rows = df.rdd.map(r => Row.fromSeq( r.toSeq ++ foobarFunc(r.getAs[Long]("x"), r.getAs[Double]("y"), r.getAs[String]("z")))) val df2 = sqlContext.createDataFrame(rows, schema) df2.show
val df = sc.parallelize(List(("Mike,1986,Toronto", 30), ("Andre,1980,Ottawa", 36), ("jill,1989,London", 27))).toDF("infoComb", "age") df.show +------------------+---+ | infoComb|age| +------------------+---+ |Mike,1986,Toronto| 30| | Andre,1980,Ottawa| 36| | jill,1989,London| 27| +------------------+---+
df.select(expr("(split(infoComb, +-----+----------+-------+---+ | name|yearOfBorn| city|age| +-----+----------+-------+---+ |Mike| 1986|Toronto| 30| |Andre| 1980| Ottawa| 36| | jill| 1989| London| 27| +-----+----------+-------+---+
val newDf = myDf.withColumn("newCol1", myFun(myDf("originalColumn"))) .withColumn("newCol2", myFun2(myDf("originalColumn")) .drop(myDf("originalColumn"))
def myFun= udf( (originalColumnContent : String) => { } )
implicit class DfOperations(df: DataFrame) { def flattenColumn(col: String) = { def addColumns(df: DataFrame, cols: Array[String]): DataFrame = { if (cols.isEmpty) df else addColumns( df.withColumn(col + "_" + cols.head, df(col + "." + cols.head)), cols.tail ) } val field = df.select(col).schema.fields(0) val newCols = field.dataType.asInstanceOf[StructType].fields.map(x => x.name) addColumns(df, newCols).drop(col) } def withColumnMany(colName: String, col: Column) = { df.withColumn(colName, col).flattenColumn(colName) } }
case class MyClass(a: Int, b: Int) val df = sc.parallelize(Seq( (0), (1) )).toDF("x") val f = udf((x: Int) => MyClass(x*2,x*3)) df.withColumnMany("test", f($"x")).show()
df4.groupBy("year").pivot("course").sum("earnings").collect()
scala myScript.scala a a a scala myScript.scala a b c
val evalResults: List[Boolean] = List(evaluateFunc1(), evaluateFunc2(), evaluateFunc3(), evaluateFunc4(), evaluateFunc5()) evalResults.forall(result => result == true)
type mismatch; found : String required: Option[String]
scala> case class Foo(v:Int) defined class Foo scala> class Bar(v: Int, val x: Int) extends Foo(v) defined class Bar scala> new Bar(1, 1) == new Bar(1, 1) res25: Boolean = true scala> new Bar(1, 1) == new Bar(1, 2) res26: Boolean = true
scala> new Bar(1,1) == Foo(1) res27: Boolean = true scala> class Baz(v: Int) extends Foo(v) defined class Baz scala> new Baz(1) == new Bar(1,1) res29: Boolean = true scala> println (new Bar(1,1)) Foo(1) scala> new Bar(1,2).copy() res49: Foo = Foo(1)
trait A { def foo(i: Int) = ??? def abstractBar(i: Int): Int } trait B { def baz(i: Int) = ??? } class C extends A with B { override def abstractBar(i: Int) = ??? }
interface T { default int m() { return 1 } static int m$(T $this) { <invokespecial $this.m()> } } class C implements T { public int m() { return T.m$(this) } }
scala> val iterable: Iterable[Int] = 1 to 4 iterable: Iterable[Int] = Range(1, 2, 3, 4) scala> iterable.take(2) res8: Iterable[Int] = Range(1, 2) scala> iterable.take(2) res9: Iterable[Int] = Range(1, 2) scala> val iterator = iterable.iterator iterator: Iterator[Int] = non-empty iterator scala> if (iterator.hasNext) iterator.next res23: AnyVal = 1 scala> if (iterator.hasNext) iterator.next res24: AnyVal = 2 scala> if (iterator.hasNext) iterator.next res25: AnyVal = 3 scala> if (iterator.hasNext) iterator.next res26: AnyVal = 4 scala> if (iterator.hasNext) iterator.next res27: AnyVal = ()
def f[A](it: Iterator[A]) = { if (it.hasNext) { it.next val remainder = it.drop(2) remainder.take(2) } else it }
object IOErrorType extends Enumeration { val FileNotFound, DeviceError, LockedFile = Value } case class IOError(message: String, errorType: IOErrorType.Value) extends Exception(message) def doSomeIO() { throw IOError("Oops, file not found!", IOErrorType.FileNotFound) } try { doSomeIO() } catch { case IOError( msg, IOErrorType.FileNotFound ) => println("File not found, please check the path! (" + msg + ")") }
object IOErrorType extends Enumeration { val FileNotFound, DeviceError, LockedFile = Value } object IOError { def unapply(err: IOError): Option[(String, IOErrorType.Value)] = Some(err.message, err.errorType) } class IOError(val message: String, val errorType: IOErrorType.Value) extends Exception(message) def doSomeIO() { throw new IOError("Oops, file not found!", IOErrorType.FileNotFound) } try { doSomeIO() } catch { case IOError( msg, IOErrorType.FileNotFound ) => println("File not found, please check the path! (" + msg + ")") }
var o = new MyOtherClass with MyTrait o.doSomething
var o = DBHelper.loadMyEntityFromDB(primaryKey); o = o with MyTrait o.doSomething
final class Test { def f = println("foo") } trait MyTrait { def doSomething = { println("boo") } } object MyTrait { implicit def innerObj(o:MixTest) = o.obj def ::(o:Test) = new MixTest(o) final class MixTest private[MyTrait](val obj:Test) extends MyTrait }
import MyTrait._ val a = new Test val b = a :: MyTrait b.doSomething b.f
val o = DBHelper.loadMyEntityFromDB(primaryKey) :: MyTrait o.doSomething
object AnyTrait { implicit def innerObj[T](o: MixTest[T]):T = o.obj def ::[T](o: T) = new MixTest(o) final class MixTest[T] private[AnyTrait](val obj: T) extends MyTrait }
val a = new Test a.f val b = a :: AnyTrait b.f1 b.f val c = "say hello to %s" :: AnyTrait println(c.intern) println(c.format("MyTrait")) c.f1 val d = 1 :: AnyTrait println(d.toLong) d.toHexString d.f1
trait DynamicMixinCompanion[TT] { implicit def baseObject[OT](o: Mixin[OT]): OT = o.obj def ::[OT](o: OT): Mixin[OT] with TT class Mixin[OT] protected[DynamicMixinCompanion](val obj: OT) } trait OtherTrait { def traitOperation = println("any trait") } object OtherTrait extends DynamicMixinCompanion[OtherTrait] { def ::[T](o: T) = new Mixin(o) with OtherTrait } object Main { def main(args: Array[String]) { val a = "some string" val m = a :: OtherTrait m.traitOperation println(m.length) } }
final class Test { def f = "Just a Test" ...some other method } trait MyTrait { def doSomething = { println("boo") } } object HelperObject { implicit def innerObj(o:MixTest) = o.obj def mixWith(o:Test) = new MixTest(o) final class MixTest private[HelperObject](obj:Test) extends MyTrait }
val a = new Test import HelperObject._ val b = HelperObject.mixWith(a) println(b.f) b.doSomething
import HelperObject._ val o = mixWith(DBHelper.loadMyEntityFromDB(primaryKey)); o.doSomething
trait MyTrait { ..some method } object MyTrait { implicit def innerObj(o:MixTest) = o.obj def ::(o:Test) = new MixTest(o) final class MixTest private[MyTrait](obj:Test) extends MyTrait } val a = new Test val b = a :: MyTrait b.doSomething b.f val o = DBHelper.loadMyEntityFromDB(primaryKey) :: MyTrait o.doSomething
trait MyTrait { def traitFunction = println("trait function executed") } class MyClass { /** * This inner class must be in scope wherever an instance of MyClass * should be used as an instance of MyTrait. Depending on where you place * and use the implicit class you must import it into scope with * "import mypackacke.MyImplictClassLocation" or * "import mypackage.MyImplicitClassLocation._" or no import at all if * the implicit class is already in scope. * * Depending on the visibility and location of use this implicit class an * be placed inside the trait to mixin, inside the instances class, * inside the instances class * use or call the class * implicit class can even reside inside a package object. It also can be * declared private to reduce visibility. It all depends on the structure * of your API. */ implicit class MyImplicitClass(instance: MyClass) extends MyTrait /** * Usage */ new MyClass().traitFunction }
trait MyTrait { def doSomething = { println("boo") } } class MyClass() extends MyTrait implicit def dbEntityToMyClass(in: DBEntity): MyClass = new MyClass()
implicit class ConvertDBEntity(in: DBEntity) extends MyTrait
def sum(xs: List[Int]): Int = { val num = List(xs.head) if(!xs.isEmpty) { sum(xs.tail) } 0 }
def sum(xs: List[Int]): Int = { xs match { case x :: tail => x + sum(tail) case Nil => 0 } }
def sum(xs: List[Int]): Int = { @tailrec def inner(xs: List[Int], accum: Int): Int = { xs match { case x :: tail => inner(tail, accum + x) case Nil => accum } } inner(xs, 0) }
val l = List(1, 3, 5, 11, -1, -3, -5) l.foldLeft(0)(_ + _)
def sumList(xs: List[Int]) = { if (xs.isEmpty) 0 else xs.head + sumList(xs.tail) }
def sum(xs: List[Int]): Int = { if(xs.isEmpty) 0 else xs.head + sum(xs.tail) }
def sum(xs:List[Int]) = xs match { case Nil => 0 case x::xs => x + sum(xs) }
def sum(xs: List[Int]): Int = { if (xs.isEmpty) throw new IllegalArgumentException("Empty list provided for sum operation") def inner(xs: List[Int]): Int = { xs match { case Nil => 0 case x :: tail => xs.head + inner(xs.tail) } } return inner(xs) }
def sum(xs: List[Int]): Int = if (xs.isEmpty) throw new IllegalArgumentException("sum of empty list") else if (xs.tail.isEmpty) xs.head else xs.head + sum(xs.tail)
def sum(xs: List[Int]): Int = { def loop(accum: Int, xs: List[Int]): Int = { if (xs.isEmpty) accum else loop(accum + xs.head, xs.tail) } loop(0,xs) }
def sum(xs: List[Int]): Int = { if (xs.isEmpty) throw new Exception @tailrec def go(l: List[Int], acc: Int): Int = { if (l.tail == Nil) l.head + acc else go(l.tail, l.head + acc) } go(xs, 0) }
def sum(xs: List[Int]): Int = xs.sum scala> sum(List(1,3,7,5)) res1: Int = 16 scala> sum(List()) res2: Int = 0
def sum(xs: List[Int]) = { val listSize = xs.size def loop(a:Int,b:Int):Int={ if(a==0||xs.isEmpty) b else loop(a-1,xs(a-1)+b) } loop(listSize,0) }
import org.scalatest.{ FlatSpec, Matchers, ParallelTestExecution } import org.scalatest.concurrent.ScalaFutures import org.apache.thrift.TApplicationException class Test extends FlatSpec with Matchers with ScalaFutures with ParallelTestExecution { it should "throw org.apache.thrift.TApplicationException for invalid Ids" in { val future: Future[Response] = ThriftClient.thriftRequest whenReady(future) { res => { intercept[TApplicationException] { } } } } }
import org.scalatest.{ FlatSpec, Matchers, ParallelTestExecution } import org.scalatest.concurrent.{ ScalaFutures, AsyncAssertions, PatienceConfiguration } import concurrent.Future import concurrent.ExecutionContext.Implicits._ import util._ class Test extends FlatSpec with Matchers with ScalaFutures with ParallelTestExecution with AsyncAssertions { it should "throw for invalid Ids" in { val f: Future[Int] = new Goof().goof val w = new Waiter f onComplete { case Failure(e) => w(throw e); w.dismiss() case Success(_) => w.dismiss() } intercept[UnsupportedOperationException] { w.await } } }
import concurrent.Future import concurrent.ExecutionContext.Implicits._ class Goof { def goof(delay: Int = 1): Future[Int] = Future { Thread sleep delay * 1000L throw new UnsupportedOperationException } def goofy(delay: Int = 1): Future[Int] = Future { Thread sleep delay * 1000L throw new NullPointerException } def foog(delay: Int = 1): Future[Int] = Future { Thread sleep delay * 1000L 7 } }
class Test extends FlatSpec with Matchers with ScalaFutures with ParallelTestExecution with AsyncAssertions { it should "throw for invalid Ids" in { val f: Future[Int] = new Goof().goof import Helper._ f.failing[UnsupportedOperationException] } } object Helper { implicit class Failing[A](val f: Future[A]) extends Assertions with AsyncAssertions { def failing[T <: Throwable](implicit m: Manifest[T]) = { val w = new Waiter f onComplete { case Failure(e) => w(throw e); w.dismiss() case Success(_) => w.dismiss() } intercept[T] { w.await } } } }
trait FailHelper extends Assertions with AsyncAssertions with PatienceConfiguration { def failingWith[T <: Throwable : Manifest](fs: Future[_]*)(implicit p: PatienceConfig) { val count = new java.util.concurrent.atomic.AtomicInteger(fs.size) val w = new Waiter for (f <- fs) f onComplete { case Success(i) => w(intercept[T](i)) println(s"Bad success $i") w.dismiss() case Failure(e: T) => println(s"Failed $e OK, count ${count.get}") w(intercept[T](throw e)) if (count.decrementAndGet == 0) w.dismiss() case Failure(e) => println(s"Failed $e Bad") w(intercept[T](throw e)) w.dismiss() } w.await()(p) } }
class Test extends FlatSpec with Matchers with ScalaFutures with ParallelTestExecution with FailHelper { it should "throw for invalid Ids" in { val sut = new Goof() import sut._ val patienceConfig = null implicit val p = PatienceConfig(timeout = 10 seconds) failingWith[UnsupportedOperationException](goof(), goof(2), goof(3)) } }
test("some test") { val f: Future[Something] = someObject.giveMeAFuture ScalaFutures.whenReady(f.failed) { e => e shouldBe a [SomeExceptionType] } }
test("some test") { val f: Future[Something] = someObject.giveMeAFuture ScalaFutures.whenReady(f) { s => } }
import org.scalatest.{AsyncFlatSpec, Matchers} import scala.concurrent.Future class ScratchSpec extends AsyncFlatSpec with Matchers { def thriftRequest = Future { throw new Exception() } it should "throw exception" in { recoverToSucceededIf[Exception] { thriftRequest } } }
import scalaz._, Scalaz._ case class IncLens[S,N](lens: Lens[S,N], num: Numeric[N]) { def ++ = lens.mods(num.plus(_, num.one)) } implicit def incLens[S,N: Numeric](lens: Lens[S,N]) = IncLens[S,N](lens, implicitly[Numeric[N]]) val i = Lens.lensu[Int,Int]((x, y) => y, identity) val imperativeProgram = for { _ <- i++; _ <- i++; x <- i++ } yield x def runProgram = imperativeProgram exec 0
public class Incrementable { private int n; public Incrementable(int n) { this.n = n; } public void incr() { n++; } @Override public String toString() { return "Incrementable("+n+")"; } }
public class DemoIncrementable { static public void main(String[] args) { Incrementable i = new Incrementable(0); System.out.println(i); i.incr(); System.out.println(i); } }
public class DemoIncrementable { static public void main(String[] args) { Incrementable i = new Incrementable(0); Incrementable j = i; int k = 0; int l = 0; System.out.println("i\t\tj\t\tk\tl"); System.out.println(i+"\t"+j+"\t"+k+"\t"+l); i.incr(); k++; System.out.println(i+"\t"+j+"\t"+k+"\t"+l); } }
i j k l Incrementable(0) Incrementable(0) 0 0 Incrementable(1) Incrementable(1) 1 0
public Incrementable incr() { return new Incrementable(n + 1); }
i j k l Incrementable(0) Incrementable(0) 0 0 Incrementable(0) Incrementable(0) 1 0
implicit def toIncr(Int &n) = { def ++ = { val tmp = n; n += 1; tmp } def prefix_++ = { n += 1; n } }
def f(l: List[Int]): Int = { var sum = 0 l foreach { n => sum += n } sum }
public int f(scala.collection.immutable.List); Code: 0: new 3: dup 4: iconst_0 5: invokespecial 8: astore_2 9: aload_1 10: new 13: dup 14: aload_0 15: aload_2 16: invokespecial 19: invokeinterface 24: aload_2 25: getfield 28: ireturn
def f(l: List[Int]): Int = { var sum = 0 var next = l while (next.nonEmpty) { sum += next.head next = next.tail } sum }
public int f(scala.collection.immutable.List); Code: 0: iconst_0 1: istore_2 2: aload_1 3: astore_3 4: aload_3 5: invokeinterface 10: ifeq 38 13: iload_2 14: aload_3 15: invokeinterface 20: invokestatic 23: iadd 24: istore_2 25: aload_3 26: invokeinterface 31: checkcast 34: astore_3 35: goto 4 38: iload_2 39: ireturn
trait Incrementer { def ++ : Int } implicit def withPp(i:Int):Incrementer = macro withPpImpl def withPpImpl(c:Context)(i:c.Expr[Int]):c.Expr[Incrementer] = { import c.universe._ val id = i.tree val f = c.Expr[()=>Unit](Function( List(), Assign( id, Apply( Select( id, newTermName("$plus") ), List( Literal(Constant(1)) ) ) ) )) reify(new Incrementer { def ++ = { val res = i.splice f.splice.apply res } }) }
scala> case class IncInt(var self: Int = 0) { def ++ { self += 1 } } defined class IncInt scala> val i = IncInt() i: IncInt = IncInt(0) scala> i++ scala> i++ scala> i res28: IncInt = IncInt(2)
Query(AbilitiesTable).filter((ab: AbilitiesTable.type) => ab.id === ability_id).map((ab: AbilitiesTable.type) => (ab.verb, ab.subject)).update("edit", "doc")
val map = Query(AbilitiesTable) .filter(_.id === ability_id) .map(ab => ab.verb ~ ab.context) map.update(("", ""))
Users.filter(_.id === filterId) .map(x => (x.name, x.age)) .update(("john", 99))
(all letters) | ^ & = ! < > : + - * / % (all other special characters)
for ( Object item : collection ) { if ( condition1(item) && condition2(item) ) { return true; } } return false;
return collection.find { condition1(it) && condition2(it) } != null
scala> val collection = List(1,2,3,4,5) collection: List[Int] = List(1, 2, 3, 4, 5) scala> collection.filter(x => (x % 2 == 0) && (x > 3)) res1: List[Int] = List(4) scala> res1.isEmpty res2: Boolean = false scala> collection.filter(x => (x % 2 == 0) && (x > 5)) res3: List[Int] = List() scala> res3.isEmpty res4: Boolean = true
scala> collection.exists( x => x % 2 == 0 ) res6: Boolean = true
scala> val l=(1 to 4) toList l: List[Int] = List(1, 2, 3, 4) scala> l exists (_>5) res1: Boolean = false scala> l exists (_<2) res2: Boolean = true scala> l exists (a => a<2 || a>5) res3: Boolean = true
scala> l find (_ < 3) res5: Option[Int] = Some(1) scala> l.find(_ < 3) isDefined res6: Boolean = true
collection.exists(item => condition1(item) && condition2(item))
collection.stream().anyMatch(item -> condition1(item) && condition2(item));
sealed trait Option[+A] final case class Some[+A] extends Option[A] object None extends Option[Nothing]
sealed trait Duo case class One(i:Int) extends Duo case class Two(i:Int, j:Int) extends Duo def test(d:Duo) { match { case One(x) => println(x) } }
def isIdentityFun(term: Term): Boolean = term match { case Fun(x, Var(y)) if x == y => true case _ => false }
case Fun(x, Var(y)) if x == y => true case Fun(x, Var(y)) if true => false case Fun(x, Var(y)) => false
def boundedInt(min:Int, max: Int): Int => Int = { case n if n>max => max case n if n<min => min case n => n }
num match { case 0 => "Zero" case n if n > -1 =>"Positive number" case _ => "Negative number" }
def func(x: Int, y: Int): String = (x, y) match { case (_, 0) | (0, _) => "Zero" case (x, _) if x > -1 => "Positive number" case (_, y) if y < 0 => "Negative number" case (_, _) => "Could not classify" } println(func(10,-1)) println(func(-10,1)) println(func(-10,0))
scala> val foo = 1 foo: Int = 1 scala> foo.toString res0: String = 1 scala> val bar: java.lang.Integer = 2 bar: Integer = 2 scala> bar.toString res1: String = 2
implicit def intToString(i: Int) = i.toString def foo(s: String) = println(s) foo(3)
trait A { def aValue = 1 } trait B { def bValue = 1 } trait C { a : A, b : B => def total = a.aValue + b.bValue } class T extends C with A with B { ...
trait A { def aValue = 1 } trait B { def bValue = 1 } trait C { self: A with B => def total = aValue + bValue } class ABC extends A with B with C
trait C { self: { def aValue: Int def bValue: Int } => def total = aValue + bValue } class ABC extends C { def aValue = 1 def bValue = 1 }
trait C extends A with B{ def total = aValue + bValue }
trait C { def aValue: Int def bValue: Int def total = aValue + bValue }
new StringBuilder()).append("ab").append(BoxesRunTime.boxToInteger(x)).append("c").toString()
val example = Seq("11111", "2222", "333", "444444") val result = example.mkString println(result)
scala> def f (i : Int, j : Int) = i + j f: (Int,Int)Int scala> val ff = f _ ff: (Int, Int) => Int = <function> scala> val fft = Function.tupled(ff) fft: ((Int, Int)) => Int = <function>
scala> def f (i : Int, j : Int) = i + j f: (i: Int,j: Int)Int scala> val ff = f _ ff: (Int, Int) => Int = <function2> scala> val fft = ff.tupled fft: ((Int, Int)) => Int = <function1>
scala> def f (i: Int, j: Int) = i + j f: (i: Int, j: Int)Int scala> val ff = f _ ff: (Int, Int) => Int = <function2> scala> val p = (3,4) p: (Int, Int) = (3,4) scala> ff.tupled(p) res0: Int = 7
scala> def f (i: Int, j: Int) = i + j f: (i: Int, j: Int)Int scala> val p = (3,4) p: (Int, Int) = (3,4) scala> val ft = (f _).tupled ft: ((Int, Int)) => Int = <function1> scala> ft apply(p) res0: Int = 7
def length: Int = ... def multiply(other: Foo): Foo = ... def hypotenuse(a: Double, b: Double): Double = { def square(x: Double) = x * x math.sqrt(square(a) + square(b)) }
if (foo) ... foo.doSomething(bar) foo doSomething bar foo + bar
lazy val foo = calculateFoo def square(x: Int) = x * x
val x = foo.length val y = bar.coefficient foo.reverse()
def sum(list: List[Int]): Int = if (!list.isEmpty) list reduceLeft (_ + _) else 0 val sum = ( getItems reduceLeft (_ + _) )
val squares = for (x <- numbers) yield x * x val cells = for { x <- columns y <- rows if x != y } yield Cell(x, y) val cells = for (x <- columns; y <- rows; if x != y) yield Cell(x, y)
def factorial(n: Int): Int = { def fact(n: Int, acc: Int): Int = n match { case 0 => acc case x => fact(x - 1, x * acc) } fact(n, 1) }
import scala.Math.Pi val pi = Pi def isPi(n: Double): Boolean = n match { case Pi => println("I got a true Pi."); true case pi => println("I got "+pi+" and bounded it to an identifier named pi."); false }
scala> (3,4).map(_*2) error: value map is not a member of (Int, Int) (3,4).map(_*2) ^ scala> (3,4).productIterator.map(_*2) error: value * is not a member of Any (3,4).productIterator.map(_*2) ^ scala> (3,4).productIterator.map(_.asInstanceOf[Int]*2) res4: Iterator[Int] = non-empty iterator scala> (3,4).productIterator.map(_.asInstanceOf[Int]*2).toList res5: List[Int] = List(6, 8)
scala> import shapeless._ ; import Tuples._ import shapeless._ import Tuples._ scala> object double extends (Int -> Int) (_*2) defined module double scala> (3, 4).hlisted.map(double).tupled res0: (Int, Int) = (6,8)
scala> object frob extends Poly1 { | implicit def caseInt = at[Int](_*2) | implicit def caseString = at[String]("!"+_+"!") | implicit def caseBoolean = at[Boolean](!_) | } defined module frob scala> (23, "foo", false, "bar", 13).hlisted.map(frob).tupled res1: (Int, String, Boolean, String, Int) = (46,!foo!,true,!bar!,26)
scala> import shapeless._, poly._, syntax.std.tuple._ import shapeless._ import poly._ import syntax.std.tuple._ scala> object double extends (Int -> Int) (_*2) defined module double scala> (3, 4) map double res0: (Int, Int) = (6,8) scala> object frob extends Poly1 { | implicit def caseInt = at[Int](_*2) | implicit def caseString = at[String]("!"+_+"!") | implicit def caseBoolean = at[Boolean](!_) | } defined module frob scala> (23, "foo", false, "bar", 13) map frob res1: (Int, String, Boolean, String, Int) = (46,!foo!,true,!bar!,26)
scala> def map[A, B](as: (A, A))(f: A => B) = as match { case (a1, a2) => (f(a1), f(a2)) } map: [A,B](as: (A, A))(f: (A) => B)(B, B) scala> val p = (1, 2) p: (Int, Int) = (1,2) scala> map(p){ _ * 2 } res1: (Int, Int) = (2,4)
scala> import scalaz._ import scalaz._ scala> import Scalaz._ import Scalaz._ scala> val f = (_: Int) * 2 f: (Int) => Int = <function1> scala> val g = (_: String) * 2 g: (String) => String = <function1> scala> f <-: (1, "1") :-> g res12: (Int, String) = (2,11)
def bimap[A, B, C, D](fa: A => C, fb: B => D): Tuple2[C, D]
akka { event-handlers = ["akka.event.slf4j.Slf4jEventHandler"] loglevel = "DEBUG" }
<pattern>%d{HH:mm:ss.SSS} | %-5level | %thread | %X{akkaSource} | %logger{1} | %m%n%rEx</pattern>
import akka.event.Logging val system = ActorSystem("HelloSystem", ConfigFactory.load.getConfig("akka")) val log = Logging.getLogger(system, this) log.info("Hi!")
this.log = akka.event.Logging.getLogger(actorSystem, this);
private val log = LoggerFactory.getLogger(YourClass.getClass)
/** * If we wanted to confirm that the list uniquely contains `Foo` or any * subtype of `Foo`, we could first use `unifySubtypes` to upcast any * subtypes of `Foo` in the list to `Foo`. * * The following would not compile, for example: */
import shapeless._ implicit class Uniqueable[L <: HList](l: L) { def unique[A](implicit ev: FilterAux[L, A, A :: HNil]) = ev(l).head }
implicitly[FilterAux[Char :: Char :: HNil, Char, Char :: HNil]]
def assertNoInstanceOf[T](implicit instance: T = null) = assert(instance == null)
assertNoInstanceOf[FilterAux[Char :: Char :: HNil, Char, Char :: HNil]]
/** For testing compiler internals directly. * Each source code string in "sources" will be compiled, and * the check function will be called with the source code and the * resulting CompilationUnit. The check implementation should * test for what it wants to test and fail (via assert or other * exception) if it is not happy. */
import scala.tools.reflect.ToolBox object TestUtils { def eval(code: String, compileOptions: String = "-cp target/classes"): Any = { val tb = mkToolbox(compileOptions) tb.eval(tb.parse(code)) } def mkToolbox(compileOptions: String = ""): ToolBox[_ <: scala.reflect.api.Universe] = { val m = scala.reflect.runtime.currentMirror m.mkToolBox(options = compileOptions) } }
def result = TestUtils.eval( """|import ee.ui.events.Event |import ee.ui.events.ReadOnlyEvent | |val myObj = new { | private val writableEvent = Event[Int] | val event:ReadOnlyEvent[Int] = writableEvent |} | | |myObj.event.fire |""".stripMargin) result must throwA[ToolBoxError].like { case e => e.getMessage must contain("value fire is not a member of ee.ui.events.ReadOnlyEvent[Int]") }
trait Foo { var foo: String } class Bar (foo: String) extends Foo { }
class X(protected val s: String, private var i: Int)
trait Foo { var foo: String = _ } class Bar(foo0: String) extends Foo { foo = foo0 }
trait Foo { def foo: String def foo_=(s: String): Unit } class Bar(var foo: String) extends Foo {}
def intersect(that: GenSet[A]): Repr = this filter that
def filter(p: A => Boolean): Repr = { val b = newBuilder for (x <- this) if (p(x)) b += x b.result }
case class MyClass(val name: String) { override def equals(o: Any) = o match { case that: MyClass => that.name.equalsIgnoreCase(this.name) case _ => false } override def hashCode = name.toUpperCase.hashCode } Set(MyClass("xx"), MyClass("XY"), MyClass("xX")) res1: scala.collection.immutable.Set[MyClass] = Set(MyClass(xx), MyClass(XY))
override def equals(o: Any) = super.equals(o) override def hashCode = super.hashCode
Set(MyClass("x"), MyClass("x")) res2: scala.collection.immutable.Set[MyClass] = Set(MyClass(x), MyClass(x))
final def == (that: Any): Boolean = if (null eq this) {null eq that} else {this equals that}
> set testOptions in YourProjectName += Tests.Argument("-oF")
scala> try { throw new Exception } catch { case e => e } res1: java.lang.Throwable = java.lang.Exception scala> res1.printStackTrace java.lang.Exception at $line2.$read$$iw$$iw$.liftedTree1$1(<console>:8) at $line2.$read$$iw$$iw$.<init>(<console>:8) at $line2.$read$$iw$$iw$.<clinit>(<console>) ...
val zeroOne : PartialFunction[Float, Float] = { case 0 => 1 } val sinc = zeroOne orElse ((x) => sin(x)/x)
def foo(f : (Int)=>Int) { print(f(1)) } val bar = new PartialFunction[Int, Int] { def apply(x : Int) = x/2 def isDefinedAt(x : Int) = x%2 == 0 } foo(bar)
def func2Partial[A,R](f : A => R) : PartialFunction[A,R] = {case x => f(x)} val pf : PartialFunction[Int, String] = {case 1 => "one"} val g = pf orElse func2Partial{_ : Int => "default"} scala> g(1) res0: String = one scala> g(2) res1: String = default
scala> val pf: PartialFunction[String, String] = { case "a" => "foo" } pf: PartialFunction[String,String] = <function> scala> pf orElse { case x => "default" } <console>:6: error: missing parameter type for expanded function ((x0$1) => x0$1 match { case (x @ _) => "default" })
scala> pf orElse ({ case x => "default" } : PartialFunction[String,String]) res5: PartialFunction[String,String] = <function>
scala> implicit def f2pf[T,R](f: Function1[T,R]): PartialFunction[T,R] = new PartialFunction[T,R] { def apply(x: T) = f(x) def isDefinedAt(x: T) = true } f2pf: [T,R](f: (T) => R)PartialFunction[T,R]
scala> pf orElse ((x: String) => "default") res7: PartialFunction[String,String] = <function> scala> println(res7("a") + " " + res7("quux")) foo default
import sbt._ import Keys._ import KeyRanks.DTask import xsbti.{Reporter, Problem, Position, Severity} private lazy val compilerReporter = TaskKey[xsbti.Reporter]( "compilerReporter", "Experimental hook to listen (or send) compilation failure messages.", DTask ) val ignoreWarnings = Seq( compilerReporter in (Compile, compile) := new xsbti.Reporter { private val buffer = collection.mutable.ArrayBuffer.empty[Problem] def reset(): Unit = buffer.clear() def hasErrors: Boolean = buffer.exists(_.severity == Severity.Error) def hasWarnings: Boolean = buffer.exists(_.severity == Severity.Warn) def printSummary(): Unit = { print("\033c") if (problems.nonEmpty) { problems.foreach{ p => println("=====================================================") println(p.position) println(p.message) println() println() } } } def problems: Array[Problem] = buffer.toArray def log(problem: Problem): Unit = { if (problem.severity == Severity.Error) { buffer.append(problem) } } def log(pos: Position, msg: String, sev: Severity): Unit = { log(new Problem { def category: String = "foo" def severity: Severity = sev def message: String = msg def position: Position = pos }) } def comment(pos: xsbti.Position, msg: String): Unit = () } )
class SparkExample with Logging { val someRDD = ... someRDD.map { rddElement => logInfo(s"$rddElement will be processed.") doSomething(rddElement) } }
import org.apache.log4j.Logger import org.apache.spark._ object Main { def main(args: Array[String]) { new LoggingTestWithRDD().doTest() } } class LoggingTestWithRDD extends Serializable { val log = Logger.getLogger(getClass.getName) def doTest(): Unit = { val conf = new SparkConf().setMaster("local[4]").setAppName("LogTest") val spark = new SparkContext(conf) val someRdd = spark.parallelize(List(1, 2, 3)) someRdd.map { element => log.info(s"$element will be processed") element + 1 } spark.stop() }
object Holder extends Serializable { @transient lazy val log = Logger.getLogger(getClass.getName) } val someRdd = spark.parallelize(List(1, 2, 3)).foreach { element => Holder.log.info(element) }
"org.apache.logging.log4j" % "log4j-api" % "2.x.x" "org.apache.logging.log4j" % "log4j-core" % "2.x.x" "org.apache.logging.log4j" %% "log4j-api-scala" % "2.x.x"
import org.slf4j.LoggerFactory val LOG = LoggerFactory.getLogger(getClass)
rdd.mapPartition { it => val log = ??? it.map { x => log.info(x) x + 1 } }
import org.apache.log4j.Level object MyClass extends Serializable{ val log = org.apache.log4j.LogManager.getLogger("name of my spark log") log.setLevel(Level.INFO) def main(args:Array[String]) { rdd.map(t=> val log =MyClass.log log.INFO("count"+rdd.count) ) } }
trait Intf { type Rep[+T] type M[+T] = Rep[Maybe[T]] val __match: Matcher abstract class Matcher { def runOrElse[T, U](in: Rep[T])(matcher: Rep[T] => M[U]): Rep[U] def zero: M[Nothing] def one[T](x: Rep[T]): M[T] def guard[T](cond: Rep[Boolean], then: => Rep[T]): M[T] def isSuccess[T, U](x: Rep[T])(f: Rep[T] => M[U]): Rep[Boolean] } abstract class Maybe[+A] { def flatMap[B](f: Rep[A] => M[B]): M[B] def orElse[B >: A](alternative: => M[B]): M[B] } implicit def proxyMaybe[A](m: M[A]): Maybe[A] implicit def repInt(x: Int): Rep[Int] implicit def repBoolean(x: Boolean): Rep[Boolean] implicit def repString(x: String): Rep[String] def test = 7 match { case 5 => "foo" case _ => "bar" } } trait Impl extends Intf { type Rep[+T] = String object __match extends Matcher { def runOrElse[T, U](in: Rep[T])(matcher: Rep[T] => M[U]): Rep[U] = ("runOrElse("+ in +", ?" + matcher("?") + ")") def zero: M[Nothing] = "zero" def one[T](x: Rep[T]): M[T] = "one("+x.toString+")" def guard[T](cond: Rep[Boolean], then: => Rep[T]): M[T] = "guard("+cond+","+then+")" def isSuccess[T, U](x: Rep[T])(f: Rep[T] => M[U]): Rep[Boolean] = ("isSuccess("+x+", ?" + f("?") + ")") } implicit def proxyMaybe[A](m: M[A]): Maybe[A] = new Maybe[A] { def flatMap[B](f: Rep[A] => M[B]): M[B] = m + ".flatMap(? =>"+ f("?") +")" def orElse[B >: A](alternative: => M[B]): M[B] = m + ".orElse("+ alternative +")" } def repInt(x: Int): Rep[Int] = x.toString def repBoolean(x: Boolean): Rep[Boolean] = x.toString def repString(x: String): Rep[String] = x } object Test extends Impl with Intf with App { println(test) }
scala> Test.main(null) runOrElse(7, ?guard(false,?).flatMap(? =>one(foo)).orElse(one(bar)))
scala> implicit def ordering[T](implicit conv: T => Ordered[T], res: Ordering[Ordered[T]]) = Ordering.by(conv) ordering: [T](implicit conv: (T) => Ordered[T],implicit res: Ordering[Ordered[T]])scala.math.Ordering[T] scala> def foo[T <% Ordered[T]](s : Seq[T]) = s.sorted <console>:6: error: diverging implicit expansion for type Ordering[T] starting with method ordering in object $iw def foo[T <% Ordered[T]](s : Seq[T]) = s.sorted ^
var first:Array[Float] ... var second:Array[Float] ... var sum=0f; for (ix<-0 until first.length) sum += first(ix) * second(ix);
sum = first.zip(second).map{ case (a,b) => a*b }.reduceLeft(_+_)
sum = first.zip(second).foldLeft(0f) { case (a, (b, c)) => a + b * c }
sum = first.view.zip(second).map{ case (a,b) => a*b }.reduceLeft(_+_)
sum = (first,second).zipped.map{ case (a,b) => a*b }.reduceLeft(_+_)
class FastFloatOps(a: Array[Float]) { def fastMapOnto(f: Float => Float) = { var i = 0 while (i < a.length) { a(i) = f(a(i)); i += 1 } this } def fastMapWith(b: Array[Float])(f: (Float,Float) => Float) = { val len = a.length min b.length val c = new Array[Float](len) var i = 0 while (i < len) { c(i) = f(a(i),b(i)); i += 1 } c } def fastReduce(f: (Float,Float) => Float) = { if (a.length==0) Float.NaN else { var r = a(0) var i = 1 while (i < a.length) { r = f(r,a(i)); i += 1 } r } } } implicit def farray2fastfarray(a: Array[Float]) = new FastFloatOps(a)
def multiply_and_sum(l1:List[Int], l2:List[Int], sum:Int):Int = { if (l1 != Nil && l2 != Nil) { multiply_and_sum(l1.tail, l2.tail, sum + (l1.head * l2.head)) } else { sum } } val first = Array(1,2,3,4,5) val second = Array(6,7,8,9,10) multiply_and_sum(first.toList, second.toList, 0)
let dot xs ys = Array.zip xs ys |> Array.map (fun (x, y) -> x * y) -> Array.reduce ( * )
let dot xs ys = Array.fold2 (fun t x y -> t + x * y) 0.0 xs ys
def multiplyAndSum (l1: Array[Int], l2: Array[Int]) : Int = { def productSum (idx: Int, sum: Int) : Int = if (idx < l1.length) productSum (idx + 1, sum + (l1(idx) * l2(idx))) else sum if (l2.length == l1.length) productSum (0, 0) else error ("lengths don } val first = (1 to 500).map (_ * 1.1) toArray val second = (11 to 510).map (_ * 1.2) toArray def loopi (n: Int) = (1 to n).foreach (dummy => multiplyAndSum (first, second)) println (timed (loopi (100*1000)))
scala> val la = sc.parallelize(List(12,4,5,3,4,4,6,781)) scala> la.collect 15/01/28 09:57:24 INFO SparkContext: Starting job: collect at <console>:15 15/01/28 09:57:24 INFO DAGScheduler: Got job 3 (collect at <console>:15) with 1 output ... 15/01/28 09:57:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 3) 15/01/28 09:57:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 626 bytes result sent to driver 15/01/28 09:57:24 INFO DAGScheduler: Stage 3 (collect at <console>:15) finished in 0.002 s 15/01/28 09:57:24 INFO DAGScheduler: Job 3 finished: collect at <console>:15, took 0.020061 s res5: Array[Int] = Array(12, 4, 5, 3, 4, 4, 6, 781)
scala> val la = sc.parallelize(List(12,4,5,3,4,4,6,781)) scala> la.collect res5: Array[Int] = Array(12, 4, 5, 3, 4, 4, 6, 781)
spark-submit \ ... --files prop/file/location \ --conf --conf jar/location \ [application arguments]
import org.apache.log4j.{Level, Logger} Logger.getLogger("org").setLevel(Level.ERROR) Logger.getLogger("akka").setLevel(Level.ERROR)
object Main { def main(args: Array[String]) { val x = "AA" checkType(x) } def checkType(cls: AnyRef) { cls match { case String => println("is a String") case Date => println("is a Date") case _ => println("others") } } }
if(cls.isInstanceOf[String]) { ... } else if(cls.isInstanceOf[Date]) { ... } else { ... }
def checkType(cls: AnyRef) { cls match { case s: String => println("is a String") case d: Date => println("is a Date") case _ => println("others") } }
def checkType(cls: AnyRef) = cls match { case _: String => println("is a String") case _: Date => println("is a Date") case _ => println("others") }
object Main { def main(args: Array[String]) { val x = "AA" checkType(x) } def checkType(cls: AnyRef) { cls match { case x: String => println("is a String:"+ x) case x: Date => println("is a Date:" + x) case _ => println("others") } } }
def unit[A](block: => A) : Future[A] def bind[A, B](fa: Future[A])(f: A => Future[B]) : Future[B]
import scala.concurrent.Future import scala.concurrent.ExecutionContext.Implicits._ def twoEffects = ( Future { println("hello") }, Future { println("hello") } )
scala> twoEffects hello hello scala> twoEffects hello hello
lazy val anEffect = Future { println("hello") } def twoEffects = (anEffect, anEffect)
import scala.concurrent.Future import scala.concurrent.ExecutionContext.Implicits._ def unit[A] (block: => A) : Future[A] = Future(block) def bind[A, B] (fa: Future[A]) (f: A => Future[B]) : Future[B] = fa flatMap f lazy val effect = Future { println("hello") }
scala> effect hello scala> bind(effect) { unit(_) }
object Future { def apply[T] (body: ⇒ T) (implicit executor: ExecutionContext) : Future[T] } trait Future { flatMap[S] (f: T ⇒ Future[S]) (implicit executor: ExecutionContext) : Future[S] }
import scalaz.concurrent.Task import scalaz.IList import scalaz.syntax.traverse._ def twoEffects = IList( Task delay { println("hello") }, Task delay { println("hello") }).sequence_
lazy val anEffect = Task delay { println("hello") } def twoEffects = IList(anEffect, anEffect).sequence_
import concurrent. { ExecutionContext, Future, Promise } import util.Try import scalaz.\/ import scalaz.concurrent.Task def fromScalaDeferred[A] (future: => Future[A]) (ec: ExecutionContext) : Task[A] = Task .delay { unsafeFromScala(future)(ec) } .flatMap(identity) def unsafeToScala[A] (task: Task[A]) : Future[A] = { val p = Promise[A] task.runAsync { res => res.fold(p failure _, p success _) } p.future } private def unsafeFromScala[A] (future: Future[A]) (ec: ExecutionContext) : Task[A] = Task.async( handlerConversion .andThen { future.onComplete(_)(ec) }) private def handlerConversion[A] : ((Throwable \/ A) => Unit) => Try[A] => Unit = callback => { t: Try[A] => \/ fromTryCatch t.get } .andThen(callback)
import scala.concurrent.Future import scala.concurrent.ExecutionContext.Implicits._ def unit[A](block: => A): Future[A] = Future(block) def bind[A, B](fut: Future[A])(fun: A => Future[B]): Future[B] = fut.flatMap(fun)
def unit[A](x: A): Future[A] = Future.successful(x) def bind[A, B](m: Future[A])(fun: A => Future[B]): Future[B] = fut.flatMap(fun)
((t: Tree) => { print(t.value); for (c <- t.children) thisMethod(c) })(root)
scala> def fix[A,B](f: (A=>B)=>(A=>B)): A=>B = f(fix(f))(_) fix: [A,B](f: ((A) => B) => (A) => B)(A) => B scala> val fact = fix[Int,Int](f => a => if(a<=0) 1 else f(a-1) * a) fact: (Int) => Int = <function1> scala> fact(12) res0: Int = 479001600
val fact = new Function1[Int,Int]{ def apply(x:Int):Int = if(x==1) x else x * apply(x-1) }
val fact = new ((Int) => Int){ def apply(x:Int):Int = if(x==1) x else x * apply(x-1) }
({(input) => object next { def apply(y:Int):Int = ...body... } next(input) })
import asia.blip.ymacro.YMacro._ (y[BigInt,BigInt]((xx) => (y) => if(y==1) 1 else y * xx(y-1)))(2000)
res0: BigInt = 33162750924506332411753933805763240382811...
val fact = { (x: Int) => def f(x: Int): Int = if (x == 0) 1 else x * f(x-1) f(x) } (1 to 5).map { (x: Int) => def f(x: Int): Int = if (x == 0) 1 else x * f(x-1) f(x) }
val one: Int = 1 val two: Int = 2 val three: Int = 3 val greaterThan2: (Int => Int) = (x: Int) => x > two List(one,two,three).filter(greaterThan2)
import scala.collection.mutable.{_, Map => _, Set => _}
error: import scala.collection.mutable.{_, Map => _, Set => _}
import scala.collection.mutable.{Map => _, Set => _, _}
import scala.collection.mutable.{Map=>ScalaMutableMap, Set => _, _}
object Main { def main(args: Array[String]) { val x = 10 print(x="Hello World") print(x) } }
object Predef { def print(x: Any) = Console.print(x) }
scala> import collection.immutable.ListMap import collection.immutable.ListMap scala> ListMap(1 -> 2) + (3 -> 4) res31: scala.collection.immutable.ListMap[Int,Int] = Map(1 -> 2, 3 -> 4) scala> res31 + (6 -> 9) res32: scala.collection.immutable.ListMap[Int,Int] = Map(1 -> 2, 3 -> 4, 6 -> 9)
scala> import scalaz._, Scalaz._, Liskov._ import scalaz._ import Scalaz._ import Liskov._ scala> :paste implicit def seqW[A](xs: Seq[A]) = new SeqW(xs) class SeqW[A](xs: Seq[A]) { def toListMap[B, C](implicit ev: A <~< (B, C)): ListMap[B, C] = { ListMap(co[Seq, A, (B, C)](ev)(xs) : _*) } } seqW: [A](xs: Seq[A])SeqW[A] defined class SeqW scala> Seq((2, 4), (11, 89)).toListMap res33: scala.collection.immutable.ListMap[Int,Int] = Map(2 -> 4, 11 -> 89)
import scala.concurrent._ val ec = scala.concurrent.ExecutionContext.Implicits.global (0 to 100) foreach { n => Future { println("starting Future: " + n) blocking { Thread.sleep(3000) } println("ending Future: " + n) }(ec) }
import java.util.concurrent.Executors val executorService = Executors.newFixedThreadPool(4) val ec = ExecutionContext.fromExecutorService(executorService) (0 to 100) foreach { n => Future { println("starting Future: " + n) blocking { Thread.sleep(3000) } println("ending Future: " + n) }(ec) }
BlockContext.current.blockOn(body)(scala.concurrent.AwaitPermission)
object Eny extends Enumeration { type Eny = Value val FOO, BAR, WOOZLE, DOOZLE = Value }
val en = BAR val num = en match { case FOO => 4 case BAR => 5 case WOOZLE => 6 case DOOZLE => 7 }
object Eny extends Enumeration { type Eny = Value val FOO, BAR, WOOZLE, DOOZLE = Value } import Eny._ class EnumTest { def doit(en: Eny) = { val num = en match { case FOO => 4 case BAR => 5 case WOOZLE => 6 case DOOZLE => 7 } num } } object EnumTest { def main(args: Array[String]) = { println("" + new EnumTest().doit(WOOZLE)) } }
val obj = new Concrete1.setOption(...).setOption(...)
abstract class Abstract0 { type Self <: Abstract0 } class Concrete1 extends Abstract0 { type Self = Concrete1 }
scala> abstract class Abstract0 { | def setOption(j: Int): this.type | } defined class Abstract0 scala> class Concrete0 extends Abstract0 { | var i: Int = 0 | def setOption(j: Int) = {i = j; this} | } defined class Concrete0 scala> (new Concrete0).setOption(1).setOption(1) res72: Concrete0 = Concrete0@a50ea1
abstract class Abstract0 { type Self <: Abstract0 var i = 0 def copy(i: Int) : Self def setOption(j: Int): Self = copy(j) } class Concrete0(i: Int) extends Abstract0 { type Self = Concrete0 def copy(i: Int) = new Concrete0(i) }
trait Abstract0Builder[To] { def setOption(j: Int) def result: To } trait CanBuildAbstract0[From, To] { def apply(from: From): Abstract0Builder[To] } abstract class Abstract0 { type Self <: Abstract0 def self = this.asInstanceOf[Self] def setOption[To <: Abstract0](j: Int)(implicit cbf: CanBuildAbstract0[Self, To]): To = { val builder = cbf(self) builder.setOption(j) builder.result } } class Concrete0(i: Int) extends Abstract0 { type Self = Concrete0 } object Concrete0 { implicit def cbf = new CanBuildAbstract0[Concrete0, Concrete0] { def apply(from: Concrete0) = new Abstract0Builder[Concrete0] { var i = 0 def setOption(j: Int) = i = j def result = new Concrete0(i) } } } object Main { def main(args: Array[String]) { val c = new Concrete0(0).setOption(1) println("c is " + c.getClass) } }
trait Abstract0[+Self <: Abstract0[_]] { } class Concrete0 extends Abstract0[Concrete0] { } class RefinedConcrete0 extends Concrete0 with Abstract0[RefinedConcrete0] { }
val name = "World" val template = "Hello $name" val message = s(template)
StringContext("Here is text ", " and more text").whatever(identifier)
class PrintCounter { var i = 0 override def toString = { val ans = i.toString; i += 1; ans } } val pc = new PrintCounter def pr[A](a: A) { println(s"$pc: $a") } scala> List("salmon","herring").foreach(pr) 1: salmon 2: herring
val name = "World" val template = name=>s"Hello $name" val message = template(name)
implicit class JsonHelper(val sc: StringContext) extends AnyVal { def json(args: Any*): JSONObject = { ... } }
import play.api.libs.json._ sealed trait Foo case class Bar(i: Int) extends Foo case class Baz(f: Float) extends Foo implicit val barFmt = Json.format[Bar] implicit val bazFmt = Json.format[Baz]
implicit val barFmt = Json.format[Bar] implicit val bazFmt = Json.format[Baz] object Foo { def unapply(foo: Foo): Option[(String, JsValue)] = { val (prod: Product, sub) = foo match { case b: Bar => (b, Json.toJson(b)(barFmt)) case b: Baz => (b, Json.toJson(b)(bazFmt)) } Some(prod.productPrefix -> sub) } def apply(`class`: String, data: JsValue): Foo = { (`class` match { case "Bar" => Json.fromJson[Bar](data)(barFmt) case "Baz" => Json.fromJson[Baz](data)(bazFmt) }).get } } sealed trait Foo case class Bar(i: Int ) extends Foo case class Baz(f: Float) extends Foo implicit val fooFmt = Json.format[Foo]
val in: Foo = Bar(33) val js = Json.toJson(in) println(Json.prettyPrint(js)) val out = Json.fromJson[Foo](js).getOrElse(sys.error("Oh no!")) assert(in == out)
implicit val fooFmt: Format[Foo] = new Format[Foo] { def reads(json: JsValue): JsResult[Foo] = json match { case JsObject(Seq(("class", JsString(name)), ("data", data))) => name match { case "Bar" => Json.fromJson[Bar](data)(barFmt) case "Baz" => Json.fromJson[Baz](data)(bazFmt) case _ => JsError(s"Unknown class } case _ => JsError(s"Unexpected JSON value $json") } def writes(foo: Foo): JsValue = { val (prod: Product, sub) = foo match { case b: Bar => (b, Json.toJson(b)(barFmt)) case b: Baz => (b, Json.toJson(b)(bazFmt)) } JsObject(Seq("class" -> JsString(prod.productPrefix), "data" -> sub)) } }
implicit val format: Format[Foo] = Variants.format[Foo]
sealed trait Foo case class Bar(x: Int) extends Foo case class Baz(s: String) extends Foo case class Bah(s: String) extends Foo
val bahJson = Json.obj("s" -> "hello", "$variant" -> "Bah") val bazJson = Json.obj("s" -> "bye", "$variant" -> "Baz") val barJson = Json.obj("x" -> "42", "$variant" -> "Bar")
def reads(json: JsValue): JsResult[Foo] = { def from(name: String, data: JsObject): JsResult[Foo] = name match { case "Bar" => Json.fromJson[Bar](data)(barFmt) case "Baz" => Json.fromJson[Baz](data)(bazFmt) case _ => JsError(s"Unknown class } for { name <- (json \ "class").validate[String] data <- (json \ "data").validate[JsObject] result <- from(name, data) } yield result }
object Foo{ implicit val jsonFormat: OFormat[Foo] = derived.oformat[Foo]() }
def +:[B >: A, That](elem: B)(implicit bf: CanBuildFrom[List[A], B, That]): That def ::[B >: A](x: B): List[B]
def ::[B >: A] (x: B): List[B] = new scala.collection.immutable.::(x, this)
override def +:[B >: A, That](elem: B)(implicit bf: CanBuildFrom[List[A], B, That]): That = bf match { case _: List.GenericCanBuildFrom[_] => (elem :: this).asInstanceOf[That] case _ => super.+:(elem)(bf) }
scala> Range(1,4).+:(0) res7: scala.collection.immutable.IndexedSeq[Int] = Vector(0, 1, 2, 3)
scala> val baos = new java.io.ByteArrayOutputStream baos: java.io.ByteArrayOutputStream = scala> val ps = new java.io.PrintStream(baos) ps: java.io.PrintStream = java.io.PrintStream@6c5ac4 scala> System.setOut(ps) scala> println("hello") hello scala> new String(baos.toByteArray) res2: java.lang.String = "" scala> System.out.println("hello") scala> new String(baos.toByteArray) res7: java.lang.String = "hello "
scala> val baos = new java.io.ByteArrayOutputStream baos: java.io.ByteArrayOutputStream = scala> Console.withOut(baos)(print("hello")) scala> println(baos) hello
val (left, right) = List(1,2,3,4).splitAt(2) left: List[Int] = List(1, 2) right: List[Int] = List(3, 4)
"communism is sharing => resource saver".takeRight(3)
val t = List(1,2,3,4,5); t.takeRight(3); res1: List[Int] = List(3,4,5)
val t = List(4,5); t.takeRight(3); res1: List[Int] = List(4,5)
def joinLeft [A1 >: A, B1 >: B, C] (implicit ev: <:<[A1, Either[C, B1]]): Either[C, B1] Joins an Either through Left. def joinRight [A1 >: A, B1 >: B, C] (implicit ev: <:<[B1, Either[A1, C]]): Either[A1, C] Joins an Either through Right. def left : LeftProjection[A, B] Projects this Either as a Left. def right : RightProjection[A, B] Projects this Either as a Right.
joinLeft [A1 >: A, B1 >: B, C] (implicit ev: <:<[A1, Either[C, B1]]): Either[C, B1]
joinLeft(e) = e.left.flatMap(identity) e.left.flatMap(f) = e.left.map(f).joinLeft
val result = opReturningEither val better = result.left map {_.getMessage}
scala> val e: Either[Either[String, Int], Int] = Left(Left("foo")) e: Either[Either[String,Int],Int] = Left(Left(foo)) scala> e.joinLeft res2: Either[String,Int] = Left(foo)
def joinLeft[A, B](es: Either[Either[A, B], B]) = es.left.flatMap(x => x)
implicit class EitherRichClass[A, B](thisEither: Either[A, B]) { def map[C](f: B => C): Either[A, C] = thisEither match { case Left(l) => Left[A, C](l) case Right(r) => Right[A, C](f(r)) } def flatMap[C](f: B => Either[A, C]): Either[A, C] = thisEither match { case Left(l) => Left[A, C](l) case Right(r) => (f(r)) } }
object getReq { def LeftError[B](str: String) = Left[HResponse, B](HttpError(str)) def apply(line1: String, in: java.io.BufferedReader): Either[HResponse, HttpReq] = { def loop(acc: Seq[(String, String)]): Either[HResponse, Seq[(String, String)]] = { val ln = in.readLine if (ln == "") Right(acc) else ln.splitOut( } val words: Seq[String] = line1.lowerWords for { a3 <- words match { case Seq("get", b, c) => Right[HResponse, (ReqType.Value, String, String)]((ReqType.HGet, b, c)) case Seq("post", b, c) => Right[HResponse, (ReqType.Value, String, String)]((ReqType.HPost, b, c)) case Seq(methodName, b, c) => LeftError("405" -- methodName -- "method not Allowed") case _ => LeftError("400 Bad Request: Bad Syntax in Status Line") } val (reqType, target, version) = a3 fields <- loop(Nil) val optLen = fields.find(_._1 == "content-length") pair <- optLen match { case None => Right((0, fields)) case Some(("content-length", second)) => second.filterNot(_.isWhitespace) match { case s if s.forall(_.isDigit) => Right((s.toInt, fields.filterNot(_._1 == "content-length"))) case s => LeftError("400 Bad Request: Bad Content-Length SyntaxLine") } } val (bodyLen, otherHeaderPairs) = pair val otherHeaderFields = otherHeaderPairs.map(pair => HeaderField(pair._1, pair._2)) val body = if (bodyLen > 0) (for (i <- 1 to bodyLen) yield in.read.toChar).mkString else "" } yield (HttpReq(reqType, target, version, otherHeaderFields, bodyLen, body)) } }
import scala.concurrent.ExecutionContext.Implicits.global import scala.concurrent.Future val f = Future( List("A", "B", "C") ) for { list <- f e <- list } yield (e -> 1)
error: type mismatch; found : List[(String, Int)] required: scala.concurrent.Future[?] e <- list ^
scala> val list = List(1, 2, 3) list: List[Int] = List(1, 2, 3) scala> for (a <- list) yield for (b <- list) yield (a, b) res0: List[List[(Int, Int)]] = List(List((1,1), (1,2), (1,3)), List((2,1 ), (2,2), (2,3)), List((3,1), (3,2), (3,3))) scala> for (a <- list; b <- list) yield (a, b) res1: List[(Int, Int)] = List((1,1), (1,2), (1,3), (2,1), (2,2), (2,3), (3,1), (3,2), (3,3))
scala> for (a <- Some(3); b <- list) yield (a, b) <console>:9: error: type mismatch; found : List[(Int, Int)] required: Option[?] for (a <- Some(3); b <- list) yield (a, b) ^
scala> for { | list <- f | } yield for { | e <- list | } yield (e -> 1) res3: scala.concurrent.Future[List[(String, Int)]] = scala.concurrent.im pl.Promise$DefaultPromise@4f498585
for { list <- f e <- Future( list ) } yield (e -> 1)
for { list1 <- f list2 <- Future.successful( list1.map( _ -> 1) ) list3 <- Future.successful( list2.filter( _._2 == 1 ) ) } yield list3
import scala.concurrent.ExecutionContext.Implicits.global import scala.concurrent.Future val f = Future( List("A", "B", "C") ) def longRunning( l:List[(String, Int)] ) = Future.successful( l.map(_._2) ) for { list <- f e = list.map( _ -> 1 ) s <- longRunning( e ) } yield s
for (vs <- future(data); xs = for (x <- vs) yield g(x) ) yield xs
f.map((vs: List[Int]) => (vs, for (x <- vs) yield g(x))).map(_._2)
def isDivisibleBy(k: Int): Int => Boolean = i => i % k == 0
def isDivisibleBy(k: Int): Int => Boolean = i => i % k == 0
def isDivisibleBy(k: Int): Int => Boolean = { println("evaluating isDivisibleBy") i => i % k == 0 }
def isEven = isDivisibleBy(2) List(1,2,3).filter(isEven)
val isEven = isDivisibleBy(2) List(1,2,3).filter(isEven)
def assert(assertion: Boolean) { if (!assertion) throw new java.lang.AssertionError("assertion failed") } def assume(assumption: Boolean) { if (!assumption) throw new java.lang.AssertionError("assumption failed") } def require(requirement: Boolean) { if (!requirement) throw new IllegalArgumentException("requirement failed") }
def addNaturals(nats: List[Int]): Int = { require(nats forall (_ >= 0), "List contains negative numbers") nats.foldLeft(0)(_ + _) } ensuring(_ >= 0)
class Person(name: String, age: Int) { def say = "My name is " + name + ", age " + age }
class Person(val name: String, val age: Int) { def say = "My name is " + name + ", age " + age }
class Person(var name: String, var age: Int) { age = happyBirthday(5) def happyBirthday(n: Int) { println("happy " + n + " birthday") n } }
scala> class Person(name: String, age: Int) { | def say = "My name is " + name + ", age " + age | } scala> val x = new Person("Hitman", 40) scala> x.name <console>:10: error: value name is not a member of Person x.name
class Person { public Person(String name, int age) { } }
class Person { String name; int age; public Person(String name, int age) { this.name = name; this.age = age; } }
class Person(name: String, age: Int) { def say = "My name is " + name + ", age " + age } class PersonVal(val name: String, val age: Int) { def say = "My name is " + name + ", age " + age } class PersonVar(var name: String, var age: Int) { age = happyBirthday(5) def happyBirthday(n: Int) = { println("happy " + n + " birthday") n } }
>>javap Person.class Compiled from "Person.scala" public class Person { public java.lang.String say(); public Person(java.lang.String, int); }
>>javap PersonVal.class public class PersonVal { public java.lang.String name(); public int age(); public java.lang.String say(); public PersonVal(java.lang.String, int); }
>>javap PersonVar.class public class PersonVar { public java.lang.String name(); public void name_$eq(java.lang.String); public int age(); public void age_$eq(int); public int happyBirthday(int); public PersonVar(java.lang.String, int); }
class MyController needs to be abstract, since method authorizationHandler in trait AuthorizationCheck of type => controllers.authapi.AuthorizationHandler is not defined [error] class MyController @Inject() (authorizationHandler: AuthorizationHandler) extends Controller with AuthorizationCheck { [error] ^ [error] one error found
class MyController @Inject()(val authorizationHandler: AuthorizationHandler) extends Controller with AuthorizationCheck { def myAction = AuthenticatedAction { implicit request => ... } }
Exception in thread "7048009@qtp-3179125-12" java.lang.OutOfMemoryError: PermGen space 2009-09-15 19:41:38.629::WARN: handle failed java.lang.OutOfMemoryError: PermGen space
export MAVEN_OPTS="-XX:+CMSClassUnloadingEnabled -XX:PermSize=256M -XX:MaxPermSize=512M" mvn jetty:run
set "MAVEN_OPTS=-XX:+CMSClassUnloadingEnabled -XX:PermSize=256M -XX:MaxPermSize=512M" mvn jetty:run
def sequence[A, B](s: Seq[Either[A, B]]): Either[A, Seq[B]] = s.foldRight(Right(Nil): Either[A, List[B]]) { (e, acc) => for (xs <- acc.right; x <- e.right) yield x :: xs } scala> sequence(List(Right(1), Right(2), Right(3))) res2: Either[Nothing,Seq[Int]] = Right(List(1, 2, 3)) scala> sequence(List(Right(1), Left("error"), Right(3))) res3: Either[java.lang.String,Seq[Int]] = Left(error)
val xs: List[Either[String, Int]] = List(Right(1), Right(2), Right(3)) scala> xs.sequenceU res0: scala.util.Either[String,List[Int]] = Right(List(1, 2, 3))
xs collectFirst { case x@Left(_) => x } getOrElse Right(xs collect {case Right(x) => x})
val lefts = xs collect {case Left(x) => x } def rights = xs collect {case Right(x) => x} if(lefts.isEmpty) Right(rights) else Left(lefts)
def unfoldRes[A](x: Seq[Either[String, A]]) = x partition {_.isLeft} match { case (Seq(), r) => Right(r map {_.right.get}) case (l, _) => Left(l map {_.left.get} mkString "\n") }
def partitionEithers[A, B](es: Seq[Either[A, B]]): (Seq[A], Seq[B]) = es.foldRight (Seq.empty[A], Seq.empty[B]) { case (e, (as, bs)) => e.fold (a => (a +: as, bs), b => (as, b +: bs)) }
def unroll[A, B](es: Seq[Either[A, B]]): Either[Seq[A], Seq[B]] = { val (as, bs) = partitionEithers(es) if (!as.isEmpty) Left(as) else Right(bs) }
eithers.partitionWith(identity) match { case (Nil, rights) => Right(rights) case (firstLeft :: _, _) => Left(firstLeft) }
List(Right(1), Left("error1"), Right(3), Left("error2")).partitionWith(identity)
def condense [A] (sesa: Seq [Either [String, A]]): Either [String, Seq [A]] = { val l = sesa.find (e => e.isLeft) if (l == None) Right (sesa.map (e => e.right.get)) else Left (l.get.left.get) } condense (List (Right (3), Right (4), Left ("missing"), Right (2))) condense (List (Right (3), Right (4), Right (1), Right (2)))
scala> :paste def partitionEitherSeq[A,B](eitherSeq: Seq[Either[A,B]]): (Seq[A], Seq[B]) = eitherSeq.foldLeft(Seq.empty[A], Seq.empty[B]) { (acc, next) => val (lefts, rights) = acc next.fold(error => (lefts :+ error, rights), result => (lefts, rights :+ result)) } partitionEitherSeq: [A, B](eitherSeq: Seq[Either[A,B]])(Seq[A], Seq[B]) scala> partitionEitherSeq(Seq(Right("Result1"), Left("Error1"), Right("Result2"), Right("Result3"), Left("Error2"))) res0: (Seq[java.lang.String], Seq[java.lang.String]) = (List(Error1, Error2),List(Result1, Result2, Result3))
javaHome := Some(file("/opt/jdk/jdk1.7.0")) fork := true
~/code/scratch/20111009 sbt -java-home /Library/Java/JavaVirtualMachines/openjdk-1.7-x86_64/Contents/Home Starting sbt: invoke with -help for other options [info] Loading global plugins from /Users/jason/.sbt/plugins [info] Set current project to default-3e990a (in build file:/Users/jason/code/scratch/20111009/) > console [info] Compiling 1 Scala source to /Users/jason/code/scratch/20111009/target/scala-2.9.1/classes... [info] Starting scala interpreter... [info] Welcome to Scala version 2.9.1.final (OpenJDK 64-Bit Server VM, Java 1.7.0-internal). Type in expressions to have them evaluated. Type :help for more information. scala> java.util.Objects.equals(null, null) res0: Boolean = true
class User extends Record[User] { val name = "name".TEXT.NOT_NULL val admin = "admin".BOOLEAN.NOT_NULL.DEFAULT( } object User extends Table[User] { def byName(n: String): Seq[User] = criteria.add(this.name LIKE n).list } class Account extends Record[Account] { val accountNumber = "acc_number".BIGINT.NOT_NULL val user = "user_id".REFERENCES(User).ON_DELETE(CASCADE) val amount = "amount".NUMERIC(10,2).NOT_NULL } object Account extends Table[Account]
import javax.persistence.Entity; import javax.persistence.GeneratedValue; import javax.persistence.Id; @Entity { val name = "Users" } class User { @Id @GeneratedValue var userid:Long = _ var login:String = _ var password:String = _ var firstName:String = _ var lastName:String = _ }
class Product(val name: String, val attributes: Set[Attribute]) class Attribute(val name: String, val value: String) ... val product = new Product("blue jean", Set(new Attribute("colour", "blue"), new Attribute("size", "medium"))) val inserted = mapperDao.insert(ProductEntity, product) println("%d : %s".format(inserted.id,inserted))
val o=OrderEntity import Query._ val orders = query(select from o where o.totalAmount >= 20.0 and o.totalAmount <= 30.0) println(orders)
/* Corresponding table: CREATE TABLE `users` ( `id` int(11) NOT NULL auto_increment, `name` varchar(255) default NULL, `admin` tinyint(1) default PRIMARY KEY (`id`) ) */ import _root_.javax.persistence._ @Entity @Table{val name="users"} class User { @Id @Column{val name="id"} var id: Long = _ @Column{val name="name"} var name: String = _ @Column{val name="admin"} var isAdmin: Boolean = _ override def toString = "UserId: " + id + " isAdmin: " + isAdmin + " Name: " + name }
object Test { def main(args: Array[String]): Unit = { val c = DriverManager.getConnection("jdbc:h2:~/test", "sa", ""); val f = new Factory(c, SQLDialect.H2); val x = T_AUTHOR as "x" for (r <- f select ( T_BOOK.ID * T_BOOK.AUTHOR_ID, T_BOOK.ID + T_BOOK.AUTHOR_ID * 3 + 4, T_BOOK.TITLE || " abc" || " xy" ) from T_BOOK leftOuterJoin ( f select (x.ID, x.YEAR_OF_BIRTH) from x limit 1 asTable x.getName() ) on T_BOOK.AUTHOR_ID === x.ID where (T_BOOK.ID <> 2) or (T_BOOK.TITLE in ("O Alquimista", "Brida")) fetch ) { println(r) } } }
trait F[A] { type R; def value: R } object F { type Aux[A,RR] = F[A] { type R = RR } }
trait F[A,R] { def value: R } implicit def fint = new F[Int,Long] { val value = 1L } implicit def ffloat = new F[Float,Double] { val value = 2.0D } def f[T,R](t:T)(implicit f: F[T,R]): R = f.value f(100) f(100.0f)
import shapeless._, ops.hlist.Length def sameLength[A <: HList, B <: HList, N <: Nat](a: A, b: B)(implicit al: Length.Aux[A, N], bl: Length.Aux[B, N] ) = ()
def sameLength[A <: HList, B <: HList, N <: Nat](a: A, b: B)(implicit al: Length[A] { type Out = N }, bl: Length[B] { type Out = N } ) = ()
def converter[A](implicit gen: Generic[A]): A => gen.Repr = a => gen.to(a)
case class Foo(i: Int, s: String) val fooToHList = converter[Foo]
def converter[A, R](implicit gen: Generic[A, R]): A => R = a => gen.to(a)
val fooToHList = converter[Foo, Int :: String :: HNil]
scala> case class Foo warning: there were deprecation warnings; re-run with -deprecation for details defined class Foo scala> (new Foo: Any) match { case Foo => true; case _ => false } res10: Boolean = false
scala> (new Foo: Any) match { case _: Foo => true; case _ => false } res11: Boolean = true
scala> case object Bar defined module Bar scala> (Bar: Any) match { case Bar => true; case _ => false } res12: Boolean = true
scala> case class Foo() defined class Foo scala> Foo res0: Foo.type = <function0> scala> Foo() res1: Foo = Foo() scala> case class Bar warning: there were deprecation warnings; re-run with -deprecation for details defined class Bar scala> Bar res2: Bar.type = <function0> scala> Bar() res3: Bar = Bar() scala> Bar.apply res4: Bar = Bar()
scala> :javap List Failed: Could not find class bytes for
scala> assert <console>:8: error: ambiguous reference to overloaded definition, both method assert in object Predef of type (assertion: Boolean, message: => Any)Unit and method assert in object Predef of type (assertion: Boolean)Unit match expected type ? assert ^
scala> 5 res63: Int = 5 scala> :type 5 Int scala> 5.getClass res64: java.lang.Class[Int] = int
scala> Predef res65: type = scala.Predef$@3cd41115 scala> :type Predef type scala> Predef.getClass res66: java.lang.Class[_ <: object Predef] = class scala.Predef$
scala> `::` res77: collection.immutable.::.type = :: scala> :type `::` collection.immutable.::.type scala> `::`.getClass res79: java.lang.Class[_ <: object scala.collection.immutable.::] = class scala.collection.immutable.$colon$colon$ scala> classOf[`::`] <console>:8: error: type :: takes type parameters classOf[`::`] ^ scala> classOf[`::`[Int]] res81: java.lang.Class[::[Int]] = class scala.collection.immutable.$colon$colon
scala> import scala.reflect.runtime.{universe => u} import scala.reflect.runtime.{universe=>u} scala> val t = u.typeOf[List[_]] t: reflect.runtime.universe.Type = List[Any] scala> t.declarations res10: Iterable[reflect.runtime.universe.Symbol] = SynchronizedOps(constructor List, method companion, method isEmpty, method head, method tail, method ::, method :::, method reverse_:::, method mapConserve, method ++, method +:, method toList, method take, method drop, method slice, method takeRight, method splitAt, method takeWhile, method dropWhile, method span, method reverse, method stringPrefix, method toStream, method removeDuplicates)
scala> u reify { List(1,2,3) map (_+1) } res14: reflect.runtime.universe.Expr[List[Int]] = Expr[List[Int]](immutable.this.List.apply(1, 2, 3).map(((x$1) => x$1.$plus(1)))(immutable.this.List.canBuildFrom)) scala> import scala.tools.reflect.ToolBox import scala.tools.reflect.ToolBox scala> import scala.reflect.runtime.{currentMirror => m} import scala.reflect.runtime.{currentMirror=>m} scala> val tb = m.mkToolBox() tb: scala.tools.reflect.ToolBox[reflect.runtime.universe.type] = scala.tools.reflect.ToolBoxFactory$ToolBoxImpl@32f7fa37 scala> tb.parseExpr("List(1,2,3) map (_+1)") res16: tb.u.Tree = List(1, 2, 3).map(((x$1) => x$1.$plus(1))) scala> tb.runExpr(res16) res18: Any = List(2, 3, 4)
import org.expecty.Expecty case class Person(name: String = "Fred", age: Int = 42) { def say(words: String*) = words.mkString(" ") } val person = Person() val expect = new Expecty() expect { person.name == "Fred" person.age * 2 == 84 person.say("Hi", "from", "Expecty!") == "Hi from Expecty!" } val word1 = "ping" val word2 = "pong" expect { person.say(word1, word2) == "pong pong" } /* Output: java.lang.AssertionError: person.say(word1, word2) == "pong pong" | | | | | | | ping pong false | ping pong Person(Fred,42) */
scala> :javap scala.collection.immutable.List Compiled from "List.scala" public abstract class scala.collection.immutable.List extends scala.collection.AbstractSeq implements scala.collection.immutable.LinearSeq,scala.Product,scala.collection.LinearSeqOptimized{ ...
scala> `::`.getClass res79: java.lang.Class[_ <: object scala.collection.immutable.::] = class scala.collection.immutable.$colon$colon$
scala> classOf[`::`[Int]] res81: java.lang.Class[::[Int]] = class scala.collection.immutable.$colon$colon
scala> "abc". + asInstanceOf charAt codePointAt codePointBefore codePointCount compareTo compareToIgnoreCase concat contains contentEquals endsWith equalsIgnoreCase getBytes getChars indexOf intern isEmpty isInstanceOf lastIndexOf length matches offsetByCodePoints regionMatches replace replaceAll replaceFirst split startsWith subSequence substring toCharArray toLowerCase toString toUpperCase trim scala> "abc".compareTo compareTo compareToIgnoreCase scala> "abc".compareTo def compareTo(String): Int
scala> classOf[List[_]] res2: java.lang.Class[List[_]] = class scala.collection.immutable.List
d:\bin\scala\scala-2.9.1-1\lib>javap -classpath scala-library.jar "scala.collection.immutable.List"
class Person(val id: Int) extends Dynamic { def _select_(name: String) = { val sql = "select " + name + " from Person where id = " id; } def _invoke_(name: String)(args: Any*) = { val Pattern = "(findBy[a-zA-Z])".r val sql = name match { case Pattern(col) => "select * from Person where " + col + "= case ... } } }
val person = new Person(1) val name = person.name val person2 = person.findByName("Bob")
class DynamicMap[K, V] extends Dynamic { val self = scala.collection.mutable.Map[K, V]() def _select_(key: String) = self.apply(key) def _invoke_(key: String)(value: Any*) = if (value.nonEmpty) self.update(key, value(0).asInstanceOf[V]) else throw new IllegalArgumentException } val map = new DynamicMap[String, String]() map.foo("bar") map.foo
val map = new Map[String, String]() map("foo") = "bar" map("foo")
analyzer.namerFactory: SubComponent, analyzer.typerFactory: SubComponent, superAccessors, pickler, refchecks, translate nested objects liftcode, uncurry, classes tailCalls, explicitOuter, eliminate pattern matching erasure, interfaces for traits lambdaLift, constructors, flatten, mixer, cleanup, genicode, inliner, inlineExceptionHandlers, closureElimination, deadCode, if (forMSIL) genMSIL else genJVM,
def removeMaxCool(xs: List[Int]) = { val maxIndex = xs.indexOf(xs.max); xs.take(maxIndex) ::: xs.drop(maxIndex+1) }
def removeMaxFast(xs: List[Int]) = { var res = ArrayBuffer[Int]() var max = xs.head var first = true; for (x <- xs) { if (first) { first = false; } else { if (x > max) { res.append(max) max = x } else { res.append(x) } } } res.toList }
def factorial(n:Int) = (BigInt(1) /: (1 to n)) (_*_)
(1 to 100) takeWhile (factorial(_) <= Long.MaxValue) last
val s = Stream.continually(1).zipWithIndex.map(p => p._1 + p._2)
Stream.from(1) takeWhile (factorial(_) <= Long.MaxValue) last
Iterator.from(1).dropWhile( factorial(_) <= Long.MaxValue).next - 1
scala> Iterator.from(1).sliding(2).dropWhile(_.tail.head < 10).next.head res12: Int = 9
scala> val it = Iterator.iterate((1,BigInt(1))){case (i,f) => (i+1,f*(i+1))} it: Iterator[(Int, scala.math.BigInt)] = non-empty iterator
scala> it.find(_._2 >= Long.MaxValue).map(_._1).get - 1 res0: Int = 22
scala> val it = Iterator.iterate((1,1)){case (a,b) => (b,a+b)}.map(_._1) it: Iterator[Int] = non-empty iterator
println( "count: " + (f takeWhile (_<Long.MaxValue)).length )
name := "A Project" version := "0.1" scalaVersion := "2.9.1" libraryDependencies ++= Seq( "org.scalatest" %% "scalatest" % "1.6.1" % "test" )
> set name := "MyProject" > set version := "1.0" > set scalaVersion := "2.9.0" > session save > exit
$ sbt $ np name:my-project org:com.mypackage version:0.1.0-SNAPSHOT
addSbtPlugin("com.typesafe.sbteclipse" % "sbteclipse-plugin" % "2.1.0")
$ sbt new eed3si9n/hello.g8 .... name [hello]: scala_version [2.11.8]: Template applied in ./hello
scala> class Foo(val i: Int) { | if(i < 0) | throw new IllegalArgumentException("the number must be non-negative.") | } defined class Foo scala> new Foo(3) res106: Foo = Foo@3bfdb2 scala> new Foo(-3) java.lang.IllegalArgumentException: the number must be positive.
class Foo(val i: Int) { require(i >= 0, "the number must be non-negative.") }
scala> :paste class Foo private(val i: Int) object Foo { def apply(i: Int) = { if(i < 0) failure("number must be non-negative.") else success(new Foo(i)) } } defined class Foo defined module Foo scala> Foo(3) res108: scalaz.Validation[java.lang.String,Foo] = Success(Foo@114b3d5) scala> Foo(-3) res109: scalaz.Validation[java.lang.String,Foo] = Failure(number must be non-negative.)
scala> class Foo(arg: Int) { | require (arg == 0) | } defined class Foo scala> new Foo(0) res24: Foo = Foo@61ecb73c scala> new Foo(1) java.lang.IllegalArgumentException: requirement failed
scala> import PartialFunction._ import PartialFunction._ scala> cond("abc") { case "def" => true } res0: Boolean = false scala> condOpt("abc") { case x if x.length == 3 => x + x } res1: Option[java.lang.String] = Some(abcabc) scala> condOpt("abc") { case x if x.length == 4 => x + x } res2: Option[java.lang.String] = None
var value:Int = 23 val command:String = ... command match { case "duplicate" => value = value * 2 case "negate" => value = -value case "increment" => value = value + 1 case _ => } println("Result: " + value)
val value:Int = 23 val command:String = ... val result:Int = command match { case "duplicate" => value * 2 case "negate" => -value case "increment" => value + 1 case _ => value } println("Result: " + result)
class Matches(m: Any) { def matches[R](f: PartialFunction[Any, R]) { if (f.isDefinedAt(m)) f(m) } } implicit def any2matches(m: Any) = new Matches(m) scala> scala> 2 matches { case x: Int => println("Int") } Int
val pattern = value for (pattern <- object providing map/flatMap/filter/withFilter/foreach) ... value match { case ... => ... }
val f: Any => Unit = { case i: Int => println(i) } val pf: PartialFunction[Any, Unit] = { case i: Int => println(i) }
case x case x: X case x @ pattern case X case `x` case (x, y, ..., z) case extractor() case extractor(x) case extractor(x, y, ..., z) case x extractor y case x | y | ... | z
def matches[A](a:A)(f:PartialFunction[A, Unit]) = f.isDefinedAt(a) if (matches(a){case ... =>}) { }
class AnyWrapper[A](wrapped: A) { def matches(f: PartialFunction[A, Unit]) = f.isDefinedAt(wrapped) } implicit def any2wrapper[A](wrapped: A) = new AnyWrapper(wrapped)
val a = "a" :: Nil if (a matches { case "a" :: Nil => }) { println("match") }
def ifMatch(f: PartialFunction[A, Unit]): Unit = if (f.isDefinedAt(wrapped)) f(wrapped)
import scala.concurrent.duration._ import scala.concurrent.ExecutionContext.Implicits.global val tasks: Seq[Future[Int]] = for (i <- 1 to 10) yield future { println("Executing task " + i) Thread.sleep(i * 1000L) i * i } val aggregated: Future[Seq[Int]] = Future.sequence(tasks) val squares: Seq[Int] = Await.result(aggregated, 15.seconds) println("Squares: " + squares)
import scala.actors.Futures._ val tasks = for (i <- 1 to 10) yield future { println("Executing task " + i) Thread.sleep(i * 1000L) i * i } val squares = awaitAll(20000L, tasks: _*) println("Squares: " + squares)
class MyActor extends Actor { def receive = { case "test" => println("received test") case _ => println("received unknown message") }} val myActor = Actor.actorOf[MyActor] myActor.start
* Thread-based * Event-based * Work-stealing * HawtDispatch-based event-driven
class MyActor extends Actor { self.dispatcher = Dispatchers.newExecutorBasedEventDrivenDispatcher("thread-pool-dispatch") .withNewThreadPoolWithBoundedBlockingQueue(100) .setCorePoolSize(10) .setMaxPoolSize(10) .setKeepAliveTimeInMillis(10000) .build }
import java.util.concurrent.Executors import scala.concurrent.{ExecutionContext, Await, Future} import scala.concurrent.duration._ val numJobs = 50000 var numThreads = 10 implicit val ec = ExecutionContext.fromExecutor(Executors.newFixedThreadPool(numThreads)) val tasks = for (i <- 1 to numJobs) yield Future { i } val aggregated = Future.sequence(tasks) val oneToNSum = Await.result(aggregated, 15.seconds).sum
trait AbstractCurrency { def disappearInGreece(): Unit } abstract class Economy { type Currency <: AbstractCurrency def curr: Currency def shake(): Unit = curr.disappearInGreece() }
trait RadioactiveBeef class NiceTry(val curr: RadioactiveBeef) extends Economy { type Currency = RadioactiveBeef }
trait Euro extends AbstractCurrency class Angela(val curr: Euro) extends Economy { type Currency = Euro }
case class myApiClass[param <: BaseParameter](requestBody: String, parameter: param)
case object Parameter1 extends BaseParameter case object Parameter2 extends BaseParameter case object Parameter3
scala> val x = List(1,2,3,4) x: List[Int] = List(1, 2, 3, 4) scala> x foreach println 1 2 3 4
scala> x foreach println(_ + 1) <console>:6: error: missing parameter type for expanded function ((x$1) =>x$1.$plus(1)) x foreach println(_ + 1) ^
def f(a: Int, b: Int, c: Int) = a + b + c val g: Int => Int = f(_, 2, 3) g(1)
val h: Int => Int = _ + 1 val i: Int => Int = (_ + 1) val j: Int => Int = 1 + (_ + 1) val k: Int => Int = 1 + ((_: Int) + 1)
def findKeywords(keywords: List[String], sentence: List[String]) = sentence.filter(keywords contains _.map(_.toLowerCase))
def findKeywords(keywords: List[String], sentence: List[String]) = (x$1, x$2) => sentence.filter(keywords contains x$1.map(x$2.toLowerCase))
List(1,2,3,4) foreach println(_) List(1,2,3,4) foreach (println(_)) List(1,2,3,4) foreach (println(_ + 1))
x.foreach(new Function1[Any,Unit] { def apply(x$1: Any): Unit = Console.println(x$1) })
<console>:6: error: missing parameter type x foreach println (y => y + 1)
x foreach( println((y:Int) => y + 1)) <console>:6: error: type mismatch; found : Unit required: (Int) => Unit x foreach( println((y:Int) => y + 1))
scala> for(x <- List(1,2,3,4)) println(x + 1) 2 3 4 5
scala> List(1) map(1+_) res3: List[Int] = List(2) scala> Some(1) map (1+(1+_)) <console>:5: error: missing parameter type for expanded function ((x$1) => 1.+(x$1)) Some(1) map (1+(1+_)) ^
Welcome to Scala version 2.8.0.Beta1-prerelease (Java HotSpot(TM) Client VM, Java 1.6.0_17). Type in expressions to have them evaluated. Type :help for more information. scala> val l1 = List(1, 2, 3) l1: List[Int] = List(1, 2, 3) scala> scala> l1.foreach(println(_)) 1 2 3
mystuff = mystuff.filter(x => (x.isX && x.name == "xyz"))
mystuff = mystuff.filter(_.isX).filter(_.name == "xyz")
case class And[A]( p1: A=>Boolean, p2: A=>Boolean ) extends (A=>Boolean) { def apply( a: A ) = p1(a) && p2(a) }
scala> (0 until 20) filter And( _ > 10, _ % 2 == 1 ) res3: scala.collection.immutable.IndexedSeq[Int] = Vector(11, 13, 15, 17, 19)
val a = "some random test message" val words = a.split(" ") val keys = Set("hi","random","test") words.exists(keys contains _)
val allApis = mySequence.filter(_.isInstanceOf[String])
val allApis = mySequence.filter(_.isInstanceOf[List[String]])
mySequence.filter( _ match { case xs: List[_] => xs.forall( _ match { case _: String => true; case _ => false }) case _ => false })
import scala.reflect.runtime.universe.{TypeTag, typeTag} def add[A](xs: List[(Any, TypeTag[_])], a: A)(implicit tt: TypeTag[A]) = (a, tt) :: xs val mySequence = add(add(add(Nil, List(42)), true), List("fish")) mySequence.filter(_._2.tpe weak_<:< typeTag[List[String]].tpe)
val v = 1 ::"abc" :: true :: Nil v : List[Any] = List(1,abc,true)
import shapeless._ import HList._ val s = 1 :: "abc" :: true: HNil s : shapeless.::[Int,shapeless.::[String,shapelsss.::[Boolean,shapeless.HNil]]] = 1 :: abc :: true :: HNil
21:32:00.836 [qtp1687101938-55] ERROR o.fusesource.scalate.TemplateEngine - Compilation failed: error: error while loading CharSequence, class file (class java.lang.RuntimeException/bad constant pool tag 18 at byte 10) error: error while loading ConcurrentMap, class file (class java.lang.RuntimeException/bad constant pool tag 18 at byte 61) two errors found 21:38:03.616 [qtp1687101938-56] ERROR o.fusesource.scalate.TemplateEngine - Compilation failed: error: error while loading AnnotatedElement, class file (class java.lang.RuntimeException/bad constant pool tag 18 at byte 76) one error found
<dependency> <groupId>org.scala-lang</groupId> <artifactId>scala-library</artifactId> <version>2.10.2-RC2</version> </dependency>
name := "ScalaTelemetryManagerApi" version := "1.0" scalaVersion := "2.10.4" scalacOptions := Seq("-unchecked", "-deprecation", "-encoding", "utf8") libraryDependencies ++= { Seq( "io.spray" % "spray-can" % "1.3.1", "io.spray" % "spray-routing" % "1.3.1", "io.spray" % "spray-testkit" % "1.3.1", "com.typesafe.akka" %% "akka-actor" % "2.3.2", "com.typesafe.akka" %% "akka-testkit" % "2.3.2", "org.specs2" %% "specs2-core" % "3.6", "com.github.seratch" %% "awscala" % "0.5.+", "org.scalaz" %% "scalaz-core" % "7.2.14" ) } resolvers += "Scalaz Bintray Repo" at "https: Revolver.settings retrieveManaged := true
wget www.scala-lang.org/files/archive/scala-2.11.7.deb
scala> val r = List((ArrayBuffer(1, 2, 3, 4),10)) scala> r.foldLeft(ArrayBuffer(1,2,4,5))((x,y) => x -- y._1) scala> res28: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(5) scala> r.fold(ArrayBuffer(1,2,4,5))((x,y) => x -- y._1) <console>:11: error: value _1 is not a member of Serializable with Equals r.fold(ArrayBuffer(1,2,4,5))((x,y) => x -- y._1)
r.aggregate(ArrayBuffer(1, 2, 4, 5))({ (x, y) => x -- y._1 }, (x, y) => x intersect y)
trait FooService trait FooRemoting { this : FooService => } trait FooPersistence { this : FooService => } object Services extends FooService with FooRemoting with FooPersistence
trait Iterator[T] { def hasNext : boolean def next : T } trait InfiniteIterator[T] extends Iterator[T] { def hasNext = true }
trait PublicInterface { this: HelperTrait => } trait HelperTrait { def helperMethod = } class ImplementationClass extends PublicInterface with HelperTrait
trait A { self: X => def a = reuseme} trait B { self: X => def b = a } class X extends A with B { def reuseme=null }
trait Animal { def stop():Unit = println("stop moving") } class Dog extends Animal { def bark:String = "Woof!" } val goodboy:Dog = new Dog goodboy.bark
trait Security { this: Animal => def lookout:Unit = { stop(); println("looking out!") } }
val guardDog = new Dog with Security guardDog.lookout
val guardDog2:Dog = new Dog with Security guardDog2.lookout
trait Patient { this: Reader => def isQuite:Boolean = isReading def isSlow:Boolean = true } trait Reader { this: Patient => def read():Unit = if(isSlow) println("Reading Slow...") else println("Reading Fast...") def isReading = true } val person = new Patient with Reader
trait Patient extends Reader { /** code **/} trait Reader extends Patient { /** code **/ }
trait Human { def isGoodForSports:Boolean } trait Programmer extends Human { def readStackOverflow():Unit = println("Reading...") override def isGoodForSports: Boolean = false } trait Sportsman extends Human { def play():Unit = println("Playing something") override def isGoodForSports: Boolean = true } val foo = new Programmer with Sportsman foo.isGoodForSports val bar = new Sportsman with Programmer bar.isGoodForSports
$ git push heroku master Counting objects: 3, done. Delta compression using up to 4 threads. Compressing objects: 100% (3/3), done. Writing objects: 100% (3/3), 531 bytes | 0 bytes/s, done. Total 3 (delta 0), reused 0 (delta 0) remote: Compressing source files... done. remote: Building source: remote: remote: ! No default language could be detected for this app. remote: HINT: This occurs when Heroku cannot detect the buildpack to use for this application automatically. remote: See https: remote: remote: ! Push failed remote: Verifying deploy.... remote: remote: ! Push rejected to salty-coast-14102. remote: To https: ! [remote rejected] master -> master (pre-receive hook declined) error: failed to push some refs to
heroku git:remote -a herokuAppName git push heroku master
java -noverify -javaagent:/home/username/path/to/jrebel/jrebel/jrebel.jar -Drebel.lift_plugin=true -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=512m -Xmx512M -Xss2M -jar `dirname $0`/sbt-launch.jar "$@"
1. Where there is no end user involved (grant_type: client_credential) 2. Where end-user can consume these APIs on multiple Application (Owned by your Org) (grant_type: implicit/password) 3. Where end-user can consume these APIs via third Party Applications.(authrization_code)
3-Legged OAuth GET /authorize authorize{entry point/ initiate oauth} Sample Call: http: GET /login login (Call Page for login App, 302 redirected from /authorize) Sample Call: http: POST /dologin consentPage http: Submit the credential, On success, render the application page POST /grantpermission consentSubmission http: Permission has been granted/declined. Send a 302 to generate authorization_code GET /code AuthorizationCode {To generate auth code} Sample Call: http: POST /token GenerateAccessToken http: Sample call: http: Header: Authorization: Basic R0cxSWJTdHpINDVhang5Y0VlSUxxalFj its generated with apps Api Key & Secret. Payload: grant_type=authorization_code&scope=x&redirect_uri=www.google.com&code=abc123
I post code: package controllers; import ...; @Security.Authenticated(Secured.class) public class ExampleController extends Controller { public static String currentUserEmail() { ... return json after checking that }
package controllers; import ...; public class Secure extends Security.Authenticator { @Override public String getUserId(Http.Context context) { return context.session().get("user_id"); } ... }
val lock = new ReentrantReadWriteLock lock withReadLock { }
describe("MyCoolClass") { it("should do cool stuff") { val c = new MyCoolClass c.prop should be ("cool") } }
scala> "abc" map (x => (x + 1).toChar) res1: scala.runtime.RichString = bcd
"abc" map (x => (x + 1)) res2: scala.collection.immutable.Vector[Int] = Vector(98, 99, 100)
case class Gather(finishOnKey: Char = numDigits: Int = Integer.MAX_VALUE, callbackUrl: Option[String] = None, timeout: Int = 5 ) extends Verb
Gather(numDigits = 4, callbackUrl = Some("http: Gather(numDigits = 4, callbackUrl = "http: Gather(numDigits = 4)
implicit def string2Option(s: String) : Option[String] = Some(s)
case class Gather(finishOnKey: Char = numDigits: Int = Integer.MAX_VALUE, callbackUrl: String = null, timeout: Int = 5 ) extends Verb
class Opt[T] private (val option: Option[T]) object Opt { implicit def any2opt[T](t: T): Opt[T] = new Opt(Option(t)) implicit def option2opt[T](o: Option[T]): Opt[T] = new Opt(o) implicit def opt2option[T](o: Opt[T]): Option[T] = o.option } case class Gather(finishOnKey: Char = numDigits: Opt[Int] = None, callbackUrl: Opt[String] = None, timeout: Int = 5 ) extends Verb Gather(numDigits = 4, callbackUrl = "http: Gather(numDigits = 4, callbackUrl = Some("http: Gather(callbackUrl = maybeNullString())
sealed trait NumDigits { } sealed trait FallbackUrl { } case object NoNumDigits extends NumDigits { } case object NofallbackUrl extends FallbackUrl { } implicit def int2numd(i : Int) = new NumDigits { } implicit def str2fallback(s : String) = new FallbackUrl { } class Gather(finishOnKey: Char = numDigits: NumDigits = NoNumDigits, fallbackUrl: FallbackUrl = NoFallbackUrl, timeout: Int = 5
case class Gather(url: String) { def this() = { ... } ... } val gather = url match { case Some(u) => Gather(u) case _ => Gather() }
implicit def any2Option[T](x: T): Option[T] = Some(x)
class Foo { def bar = 5 } trait Spam { def eggs = 10 } object Main { def main(args: Array[String]) = { println((new Foo with Spam).eggs) } }
Compiled from "mixin.scala" public final class Main$$anon$1 extends Foo implements Spam{ public int eggs(); public Main$$anon$1(); }
import scala.tools.nsc._; import scala.reflect.Manifest object DynamicClassLoader { private var id = 0 def uniqueId = synchronized { id += 1; "Klass" + id.toString } } class DynamicClassLoader extends java.lang.ClassLoader(getClass.getClassLoader) { def buildClass[T, V](implicit t: Manifest[T], v: Manifest[V]) = { val id = DynamicClassLoader.uniqueId val classDef = "class %s extends %s with %s". format(id, t.toString, v.toString) println(classDef) val settings = new Settings(null) val interpreter = new Interpreter(settings) interpreter.compileAndSaveRun("<anon>", classDef) val bytes = interpreter.classLoader.getBytesForClass(id) defineClass(id, bytes, 0, bytes.length).asInstanceOf[Class[T with V]] } } val loader = new DynamicClassLoader val instance = loader.buildClass[Foo, Spam].newInstance instance.bar instance.eggs
<?xml version="1.0" encoding="UTF-8"?> <beans xmlns="http: xmlns:xsi="http: xmlns:context="http: xmlns:scala="http: xsi:schemaLocation=...> <scala:bean class="org.cakesolutions.scala.services.UserService" > <scala:with trait="org.cakesolutions.scala.services.Mixin1" /> <scala:with trait="org.cakesolutions.scala.services.Mixin2" /> <scala:property name="dependency" value="Injected" /> <scala:bean> </beans>
class ScalaBeanFactory(private val beanType: Class[_ <: AnyRef], private val mixinTypes: Seq[Class[_ <: AnyRef]]) { val loader = new DynamicClassLoader val clazz = loader.buildClass(beanType, mixinTypes) def getTypedObject[T] = getObject.asInstanceOf[T] def getObject = { clazz.newInstance() } def getObjectType = null def isSingleton = true object DynamicClassLoader { private var id = 0 def uniqueId = synchronized { id += 1; "Klass" + id.toString } } class DynamicClassLoader extends java.lang.ClassLoader(getClass.getClassLoader) { def buildClass(t: Class[_ <: AnyRef], vs: Seq[Class[_ <: AnyRef]]) = { val id = DynamicClassLoader.uniqueId val classDef = new StringBuilder classDef.append("class ").append(id) classDef.append(" extends ").append(t.getCanonicalName) vs.foreach(c => classDef.append(" with %s".format(c.getCanonicalName))) val settings = new Settings(null) settings.usejavacp.value = true val interpreter = new IMain(settings) interpreter.compileString(classDef.toString()) val r = interpreter.classLoader.getResourceAsStream(id) val o = new ByteArrayOutputStream val b = new Array[Byte](16384) Stream.continually(r.read(b)).takeWhile(_ > 0).foreach(o.write(b, 0, _)) val bytes = o.toByteArray defineClass(id, bytes, 0, bytes.length) } }
class ScalaBeanFactorySpec extends Specification { "getTypedObject mixes-in the specified traits" in { val f1 = new ScalaBeanFactory(classOf[Cat], Seq(classOf[Speaking], classOf[Eating])) val c1 = f1.getTypedObject[Cat with Eating with Speaking] c1.isInstanceOf[Cat with Eating with Speaking] must_==(true) c1.speak c1.eat c1.meow } }
val assmbleFeatures: VectorAssembler = new VectorAssembler() .setInputCols(featureColumns) .setOutputCol("featuresRaw") val labelIndexer: StringIndexer = new StringIndexer() .setInputCol("TARGET") .setOutputCol("indexedLabel") val rf: RandomForestClassifier = new RandomForestClassifier() .setLabelCol("indexedLabel") .setFeaturesCol("featuresRaw") .setMaxBins(30) val paramGrid = new ParamGridBuilder() .addGrid(rf.numTrees, Array(5)) .addGrid(rf.maxDepth, Array(5)) .build() val evaluator = new BinaryClassificationEvaluator() .setMetricName("areaUnderROC") .setLabelCol("indexedLabel")
val prePipeline = new Pipeline().setStages(Array(labelIndexer, assmbleFeatures)).fit(dfTrain) val dfTrainT = prePipeline.transform(dfTrain) val columnsToDrop = dfTrainT.columns.filter(col => !Array("featuresRaw", "indexedLabel").contains(col)) val dfTrainRdy = dfTrainT.drop(columnsToDrop:_*) val mainPipeline = new Pipeline().setStages(Array(rf)) val cv = new CrossValidator() .setEstimator(mainPipeline) .setEvaluator(evaluator) .setEstimatorParamMaps(paramGrid) .setNumFolds(2) val bestModel = cv.fit(dfTrainRdy).bestModel.asInstanceOf[PipelineModel]
val pipeline = new Pipeline() .setStages(Array(labelIndexer, assmbleFeatures, rf)) val cv = new CrossValidator() .setEstimator(pipeline) .setEvaluator(evaluator) .setEstimatorParamMaps(paramGrid) .setNumFolds(2) val bestModel = cv.fit(dfTrain).bestModel.asInstanceOf[PipelineModel]
import org.apache.spark.sql.types.DoubleType import org.apache.spark.ml.classification.RandomForestClassifier import org.apache.spark.ml.{Pipeline, PipelineModel, PipelineStage} import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator import org.apache.spark.ml.feature._ import org.apache.spark.sql._ import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder} val df = spark.read.option("header", true).option("inferSchema", true).csv("/path/to/dataset/golub_merged.csv").drop("_c0").repartition(100) val colsToDrop = df.columns.take(5000) val dfValid = df.withColumn("TARGET", df("TARGET_REAL").cast(DoubleType)).drop("TARGET_REAL").drop(colsToDrop:_*) val Array(dfTrain, dfTest) = dfValid.randomSplit(Array(0.7, 0.3)) val featureColumns = dfTrain.columns.filter(col => col != "TARGET")
import org.apache.spark.sql.SparkSession import org.apache.spark.sql.functions._ import org.apache.spark.sql.{SQLContext, Row, DataFrame, Column} import org.apache.spark.ml.feature.VectorAssembler import org.apache.spark.ml.{Pipeline, PipelineModel} val exampleDF = spark.createDataFrame(Seq( (1, 1, 2, 3, 8, 4, 5, 1, 3, 2, 0, 4, 2, 8, 1, 1, 2, 3, 8, 4, 5), (2, 4, 3, 8, 7, 9, 8, 2, 3, 3, 2, 6, 5, 4, 2, 4, 3, 8, 7, 9, 8), (3, 6, 1, 9, 2, 3, 6, 3, 8, 5, 1, 2, 3, 5, 3, 6, 1, 9, 2, 3, 6), (4, 7, 8, 6, 9, 4, 5, 4, 9, 8, 2, 4, 9, 2, 4, 7, 8, 6, 9, 4, 5), (5, 9, 2, 7, 8, 7, 3, 5, 3, 4, 8, 0, 6, 2, 5, 9, 2, 7, 8, 7, 3), (6, 1, 1, 4, 2, 8, 4, 6, 3, 9, 8, 8, 9, 3, 6, 1, 1, 4, 2, 8, 4) )).toDF("uid", "col1", "col2", "col3", "col4", "col5", "col6", "col7", "col8", "col9", "colA", "colB", "colC", "colD", "colE", "colF", "colG", "colH", "colI", "colJ", "colK") val Array(colList1, colList2, colList3, colList4) = exampleDF.columns.filter(_ != "uid").sliding(5,5).toArray val colList1_assembler = new VectorAssembler().setInputCols(colList1).setOutputCol("colList1_vec") val colList2_assembler = new VectorAssembler().setInputCols(colList2).setOutputCol("colList2_vec") val colList3_assembler = new VectorAssembler().setInputCols(colList3).setOutputCol("colList3_vec") val colList4_assembler = new VectorAssembler().setInputCols(colList4).setOutputCol("colList4_vec") val features_assembler = new VectorAssembler().setInputCols(Array("colList1_vec","colList2_vec","colList3_vec","colList4_vec")).setOutputCol("features") val pipeline = new Pipeline().setStages(Array(colList1_assembler,colList2_assembler,colList3_assembler,colList4_assembler,features_assembler)) val featuresDF = pipeline.fit(exampleDF).transform(exampleDF) val featureLength = (featuresDF.schema(featuresDF.schema.fieldIndex("features")).metadata.getMetadata("ml_attr").getLong("num_attrs")) print(featureLength)
class DefaultListMap[A, B <: List[B]] extends HashMap[A, B] { override def default(key: A) = List[B]() }
scala> val m = Map[Int, List[String]]().withDefaultValue(List()) m: scala.collection.immutable.Map[Int,List[String]] = Map() scala> m(123) res1: List[String] = List()
scala> val myMap = Map(1 -> List(10), 2 -> List(20, 200)).withDefaultValue(Nil) myMap: scala.collection.immutable.Map[Int,List[Int]] = Map((1,List(10)), (2,List(20, 200))) scala> myMap(2) res0: List[Int] = List(20, 200) scala> myMap(3) res1: List[Int] = List()
val m = Map(1L->List("a","b"), 3L->List("x","y","z")) println(m.getOrElse(1L, List("c"))) println(m.getOrElse(2L, List("y")))
/** The same map with a given default function. * Note: `get`, `contains`, `iterator`, `keys`, etc are not affected * by `withDefault`. * * Invoking transformer methods (e.g. `map`) will not preserve the default value. * * @param d the function mapping keys to values, used for non-present keys * @return a wrapper of the map with a default value */ def withDefault[B1 >: B](d: A => B1): immutable.Map[A, B1]
scala> def intToString(i: Int) = s"Integer $i" intToString: (i: Int)String scala> val x = Map[Int, String]().withDefault(intToString) x: scala.collection.immutable.Map[Int,String] = Map() scala> x(1) res5: String = Integer 1 scala> x(2) res6: String = Integer 2
object Joda { implicit def dateTimeOrdering: Ordering[DateTime] = Ordering.fromLessThan(_ isBefore _) } import Joda._ dateTimes.sorted
libraryDependencies += "com.github.nscala-time" %% "nscala-time" % "1.8.0"
import com.github.nscala_time.time.OrderingImplicits._
import com.github.nscala_time.time.OrderingImplicits.DateTimeOrdering
val x = Seq(1, 2) val y = List( val z = x cross y assert z == ((1,
implicit class Crossable[X](xs: Traversable[X]) { def cross[Y](ys: Traversable[Y]) = for { x <- xs; y <- ys } yield (x, y) } val xs = Seq(1, 2) val ys = List("hello", "world", "bye")
scala> xs cross ys res0: Traversable[(Int, String)] = List((1,hello), (1,world), ...
scala> xs cross ys cross List( res2: Traversable[((Int, String), Symbol)] = List(((1,hello),
val cross = x_list.flatMap(x => y_list.map(y => (x, y)))
def crossJoin[T](list: Traversable[Traversable[T]]): Traversable[Traversable[T]] = list match { case xs :: Nil => xs map (Traversable(_)) case x :: xs => for { i <- x j <- crossJoin(xs) } yield Traversable(i) ++ j } crossJoin( List( List(3, "b"), List(1, 8), List(0, "f", 4.3) ) ) res0: Traversable[Traversable[Any]] = List(List(3, 1, 0), List(3, 1, f), List(3, 1, 4.3), List(3, 8, 0), List(3, 8, f), List(3, 8, 4.3), List(b, 1, 0), List(b, 1, f), List(b, 1, 4.3), List(b, 8, 0), List(b, 8, f), List(b, 8, 4.3))
class CartesianProduct(product: Traversable[Traversable[_ <: Any]]) { override def toString(): String = { product.toString } def *(rhs: Traversable[_ <: Any]): CartesianProduct = { val p = product.flatMap { lhs => rhs.map { r => lhs.toList :+ r } } new CartesianProduct(p) } } object CartesianProduct { def apply(traversable: Traversable[_ <: Any]): CartesianProduct = { new CartesianProduct( traversable.map { t => Traversable(t) } ) } } val x = CartesianProduct(Set(0, 1)) val y = List("Alice", "Bob") val z = Array(Math.E, Math.PI) println(x * y * z) val s0 = CartesianProduct(Seq(0, 0)) val s1 = Seq(0, 0) println(s0 * s1)
def cartesianProduct[T](seqs: Seq[Seq[T]]): Seq[Seq[T]] = { seqs.foldLeft(Seq(Seq.empty[T]))((b, a) => b.flatMap(i => a.map(j => i ++ Seq(j)))) }
object Foo{ private var current = 0 private def inc = {current += 1; current} } class Foo{ val i = Foo.inc println(i) }
<dependency> <groupId>commons-logging</groupId> <artifactId>commons-logging</artifactId> <version>1.1.1</version> <scope>provided</scope> </dependency>
libraryDependencies += "foo" % "bar" % "0.7.0" exclude("org.baz", "bam")
... excludeAll( ExclusionRule(organization = "org.baz") )
excludeDependencies += "commons-logging" % "commons-logging"
libraryDependencies += "foo" %% "bar" % "1.2.3" intransitive
libraryDependencies += "foo" % "bar" % "0.7.0" exclude("commons-logging","commons-logging")
libraryDependencies += "foo" % "bar" % "0.7.0" excludeAll(ExclusionRule(organization = "commons-logging"))
case class customException(smth:String) extends Exception
try{ val stateCapitals = Map( "Alabama" -> "Montgomery", "Alaska" -> "Juneau", "Wyoming" -> "Cheyenne") println("Alabama: " + stateCapitals.get("AlabamaA").get) } catch{ case x:Exception=>throw classOf[CustomException] }
found : java.lang.Class[CustomException] [INFO] required: java.lang.Throwable [INFO] case x:Exception=>throw classOf[CustomException]
case x:Exception => throw new CustomException("whatever")
case class customException(smth:String) extends Exception(smth)
~/pkg/scala-2.8.0.Beta1-prerelease$ bin/scala Welcome to Scala version 2.8.0.Beta1-prerelease (Java HotSpot(TM) Server VM, Java 1.6.0_16). Type in expressions to have them evaluated. Type :help for more information. scala> Test.hello res0: java.lang.String = Hello World
object Test { def hello = "Hello World" def goodbye = "Goodbye, Cruel World" }
scala> Test.goodbye <console>:5: error: value goodbye is not a member of object Test Test.goodbye ^ scala> import Test; <console>:1: error: import Test;
package com.tests object Test { def hello = "Hello World" def goodbye = "Goodbye, Cruel World" }
scala> Test.goodbye res0: String = Goodbye, Cruel World
scala> Array.ofDim[Double](2, 2, 2) res2: Array[Array[Array[Double]]] = Array(Array(Array(0.0, 0.0), Array(0.0, 0.0)), Array(Array(0.0, 0.0), Array(0.0, 0.0))) scala> {val (x, y) = (2, 3); Array.tabulate(x, y)( (x, y) => x + y )} res3: Array[Array[Int]] = Array(Array(0, 1, 2), Array(1, 2, 3))
case class TotalTaxResult(taxAmount:Double) case object TaxCalculationTimeout
case object DoWork ... def receive = { case DoWork => }
case class DoWorkAfter(waitTime:Long) ... def receive = { case class DoWorkAfter(time) => context.system.scheduler.scheduleOnce(time.milliseconds, self, DoWork) case DoWork => }
TaxCalculationTimeout match { case TaxCalculationTimeout => println("hello") }
scala> List(1,2,3) mkString "/" res6: String = 1/2/3
def foo : (Int, String, String) = (1, "Hello", "World")
type HelloWorld = (Int,String,String) ... def foo : HelloWorld = (1, "Hello", "World") def bar : HelloWorld = HelloWorld(1, "Hello", "World")
abstract def Apply(sym: Universe.Symbol, args: Universe.Tree*): Universe.Tree A factory method for Apply nodes.
scala> import reflect.runtime.universe._ import reflect.runtime.universe._ scala> showRaw(reify{val i = 0}.tree) res8: String = Block(List(ValDef(Modifiers(), newTermName("i"), TypeTree(), Literal(Constant(0)))), Literal(Constant(())))
09:26 ~$ parse [[syntax trees at end of parser]] package <empty> { class C extends scala.AnyRef { def <init>() = { super.<init>(); () }; def x = 2 } } PackageDef(Ident(TermName("<empty>")), List(ClassDef(Modifiers(), TypeName("C"), List(), Template(List(Select(Ident(scala), TypeName("AnyRef"))), emptyValDef, List(DefDef(Modifiers(), nme.CONSTRUCTOR, List(), List(List()), TypeTree(), Block(List(pendingSuperCall), Literal(Constant(())))), DefDef(Modifiers(), TermName("x"), List(), List(), TypeTree(), Literal(Constant(2))))))))
scala> def next(i: List[String]) = i.map {"0" + _} ::: i.reverse.map {"1" + _} next: (i: List[String])List[java.lang.String]
scala> def next(i: List[String]): List[String] = i.map {"0" + _} ::: i.reverse.map {"1" + _} next: (i: List[String])List[String]
scala> :imports 1) import java.lang._ (155 types, 160 terms) 2) import scala._ (801 types, 809 terms) 3) import scala.Predef._ (16 types, 167 terms, 96 are implicit)
scala> val s: StringBuffer = new StringBuffer s: java.lang.StringBuffer = scala> val s: String = new String s: String = ""
import scala.concurrent.duration._ def downloadPage(url: URL) = Future[List[Int]] { List(1,2,3) } val result = downloadPage("localhost") val myListInt = result.result(10 seconds)
result.onComplete({ case Success(listInt) => { } case Failure(exception) => { } })
import play.api.libs.concurrent.Execution.Implicits.defaultContext def index = Action.async { val futureInt = scala.concurrent.Future { intensiveComputation() } futureInt.map(i => Ok("Got result: " + i)) }
import scala.concurrent._ import ExecutionContext.Implicits.global import scala.util.{Try, Success, Failure} import scala.concurrent.duration._ object MyObject { def main(args: Array[String]) { val myVal: Future[String] = Future { silly() } Try(Await.result(myVal, 10 seconds)) match { case Success(extractedVal) => { println("Success Happened: " + extractedVal) } case Failure(_) => { println("Failure Happened") } case _ => { println("Very Strange") } } } def silly(): String = { Thread.sleep(5000) "Hello from silly" } }
import scala.concurrent.Future import scala.concurrent.ExecutionContext.Implicits.global object Main { def main(args:Array[String]) : Unit = { val stringFuture: Future[String] = Future.successful("hello world!") stringFuture.map { someString => Console.println(someString) } } }
val stringFuture: Future[String] = Future.successful("hello world!") val someString = Future.await(stringFuture)
ClassDecl name = Complex fields = - VarDecl name = Real type = float - VarDecl name = Imag type = float
object Demo extends App { import sext._ case class ClassDecl( kind : Kind, list : List[ VarDecl ] ) sealed trait Kind case object Complex extends Kind case class VarDecl( a : Int, b : String ) val data = ClassDecl(Complex,List(VarDecl(1, "abcd"), VarDecl(2, "efgh"))) println("treeString output:\n") println(data.treeString) println() println("valueTreeString output:\n") println(data.valueTreeString) }
treeString output: ClassDecl: - Complex - List: | - VarDecl: | | - 1 | | - abcd | - VarDecl: | | - 2 | | - efgh valueTreeString output: - kind: - list: | - - a: | | | 1 | | - b: | | | abcd | - - a: | | | 2 | | - b: | | | efgh
case class VarDecl(name: String, `type`: String) case class ClassDecl(name: String, fields: List[VarDecl]) import scala.text._ import Document._ def varDoc(x: VarDecl) = nest(4, text("- VarDecl") :/: group("name = " :: text(x.name)) :/: group("type = " :: text(x.`type`)) ) def classDoc(x: ClassDecl) = { val docs = ((empty:Document) /: x.fields) { (d, f) => varDoc(f) :/: d } nest(2, text("ClassDecl") :/: group("name = " :: text(x.name)) :/: group("fields =" :/: docs)) } def prettyPrint(d: Document) = { val writer = new java.io.StringWriter d.format(1, writer) writer.toString } prettyPrint(classDoc( ClassDecl("Complex", VarDecl("Real","float") :: VarDecl("Imag","float") :: Nil) ))
libraryDependencies += "com.lihaoyi" %% "pprint" % "0.4.1" val data = ... val str = pprint.tokenize(data).mkString println(str)
case class ClassDecl( kind : Kind, list : List[ VarDecl ] ) sealed trait Kind case object Complex extends Kind case class VarDecl( a : Int, b : String ) val data = ClassDecl(Complex,List(VarDecl(1, "abcd"), VarDecl(2, "efgh"))) import org.kiama.output.PrettyPrinter._ pretty(any(data), w=1)
ClassDecl ( Complex (), List ( VarDecl ( 1, "abcd"), VarDecl ( 2, "efgh")))
libraryDependencies += "com.googlecode.kiama" %% "kiama" % "1.8.0"
import java.lang.reflect.Field ... /** * Pretty prints case classes with field names. * Handles sequences and arrays of such values. * Ideally, one could take the output and paste it into source code and have it compile. */ def prettyPrint(a: Any): String = { def getFields(cls: Class[_]): List[Field] = Option(cls.getSuperclass).map(getFields).getOrElse(Nil) ++ cls.getDeclaredFields.toList.filterNot(f => f.isSynthetic || java.lang.reflect.Modifier.isStatic(f.getModifiers)) a match { case s: String => case (acc, (c, r)) => acc.replace(c, r) } + case xs: Seq[_] => xs.map(prettyPrint).toString case xs: Array[_] => s"Array(${xs.map(prettyPrint) mkString ", "})" case p: Product => s"${p.productPrefix}(${ (getFields(p.getClass) map { f => f setAccessible true s"${f.getName} = ${prettyPrint(f.get(p))}" }) mkString ", " })" case q => Option(q).map(_.toString).getOrElse("¡null!") } }
import scala.reflect.ClassTag import scala.reflect.runtime.universe._ object CaseClassBeautifier { def getCaseAccessors[T: TypeTag] = typeOf[T].members.collect { case m: MethodSymbol if m.isCaseAccessor => m }.toList def nice[T:TypeTag](x: T)(implicit classTag: ClassTag[T]) : String = { val instance = x.asInstanceOf[T] val mirror = runtimeMirror(instance.getClass.getClassLoader) val accessors = getCaseAccessors[T] var res = List.empty[String] accessors.foreach { z ⇒ val instanceMirror = mirror.reflect(instance) val fieldMirror = instanceMirror.reflectField(z.asTerm) val s = s"${z.name} = ${fieldMirror.get}" res = s :: res } val beautified = x.getClass.getSimpleName + "(" + res.mkString(", ") + ")" beautified } }
val data = spark.textFile(file, 2).cache() val result = data .map( .map(docWeightPar => (docWeightPar(0),docWeightPar(1)))) .flatMap(line => MyFunctions.combine(line)) .reduceByKey( _ + _)
def combine(tuples: Array[(String, String)]): IndexedSeq[(String,Double)] = for (i <- 0 to tuples.length - 2; j <- 1 to tuples.length - 1 ) yield (toKey(tuples(i)._1,tuples(j)._1),tuples(i)._2.toDouble * tuples(j)._2.toDouble)
tuples. map{ x=> (x._1, x._2.toDouble) }. combinations(2). map{ x=> (toKey(x{0}._1, x{1}._1), x{0}._2*x{1}._2) }
--master yarn-cluster --num-executors 10 --executor-cores 3 --executor-memory 4g --driver-memory 5g --conf spark.yarn.executor.memoryOverhead=409
import language.experimental.macros import scala.reflect.macros.Context class Foo class Bar extends Foo { def launchMissiles = "launching" } object FooExample { def foo: Foo = macro foo_impl def foo_impl(c: Context): c.Expr[Foo] = c.Expr[Foo](c.universe.reify(new Bar).tree) }
scala> FooExample.foo res0: Bar = Bar@4118f8dd scala> res0.launchMissiles res1: String = launching
scala> FooExample.foo <console>:8: error: type mismatch; found : Bar required: Nothing FooExample.foo ^
val ls = List("Mary", "had", "a", "little", "lamb")
scala> List("Mary", "had", "a", "little", "lamb").indexOf("little") res0: Int = 3
val ls = List("Mary", "had", "a", "little", "lamb","a") ls.indexWhere(_.size <= 3)
val ls = List("Mary", "had", "a", "little", "lamb","a") scala> ls.zipWithIndex.filter(_._1 == "a").map(_._2) res13: List[Int] = List(2, 5)
val DatePattern = """(\d{4})-(\d\d)-(\d\d)""".r val DatePattern(year, month, day) = "2009-12-30" val List(rnd1, rnd2, rnd3) = List.fill(3)(scala.util.Random.nextInt(100)) val head :: tail = List.range(1, 10) object ToInt { def unapply(s: String) = try { Some(s.toInt) } catch { case _ => None } } val DatePattern(ToInt(year), ToInt(month), ToInt(day)) = "2010-01-01"
val rnd1, rnd2, rnd3 = scala.util.Random.nextInt(100)
case object BreakException extends RuntimeException def break = throw BreakException def breakable(body: =>Unit) = try { body } catch { case BreakException => () }
breakable { while (true) { if (atTheEnd) { break } } }
src/xxx.scala:6: error: not found: value A val (A,B)= (10,20) ^ src/xxx.scala:6: error: not found: value B val (A,B)= (10,20) ^ src/xxx.scala:7: error: not found: value A println(A) ^
scala> val (y, z, e) = (1, 2, 45) y: Int = 1 z: Int = 2 e: Int = 45 scala> e res1: Int = 45
@tailrec def loop(resultSet: ResultSet, accumulator: List[String] = List()): List[String] = { if (!resultSet.next) accumulator.reverse else { val value = resultSet.getString(1) loop(resultSet, value +: accumulator) } }
new Iterator[String] { def hasNext = resultSet.next() def next() = resultSet.getString(1) }.toStream
def results[T](resultSet: ResultSet)(f: ResultSet => T) = { new Iterator[T] { def hasNext = resultSet.next() def next() = f(resultSet) } }
stmt.execute("SELECT mystr, myint FROM mytable") val it = results(stmt.resultSet) { case rs => rs.getString(1) -> 100 * rs.getInt(2) } val m = it.toMap val it = results(stmt.resultSet)(_.getString(1))
import java.sql.ResultSet object Implicits { implicit class ResultSetStream(resultSet: ResultSet) { def toStream: Stream[ResultSet] = { new Iterator[ResultSet] { def hasNext = resultSet.next() def next() = resultSet }.toStream } } }
val allIds = resultSet.toStream.map(result => result.getInt("id"))
def resultSetItr(resultSet: ResultSet): Stream[ResultSet] = { new Iterator[ResultSet] { def hasNext = resultSet.next() def next() = resultSet }.toStream }
val md = connection.getMetaData() val columnItr = resultSetItr( md.getColumns(null, null, "MyTable", null)) val columns = columnItr.map(col => { val columnType = col.getString("TYPE_NAME") val columnName = col.getString("COLUMN_NAME") val columnSize = col.getString("COLUMN_SIZE") new Column(columnName, columnType, columnSize.toInt, false) })
class ResultSetIterator[T](rs: ResultSet, nextRowFunc: ResultSet => T) extends Iterator[T] { private var nextVal: Option[T] = None override def hasNext: Boolean = { val ret = rs.next() if(ret) { nextVal = Some(nextRowFunc(rs)) } else { nextVal = None } ret } override def next(): T = nextVal.getOrElse { hasNext nextVal.getOrElse( throw new ResultSetIteratorOutOfBoundsException )} class ResultSetIteratorOutOfBoundsException extends Exception("ResultSetIterator reached end of list and next can no longer be called. hasNext should return false.") }
new Iterator[String] { private var available = resultSet.next() override def hasNext: Boolean = available override def next(): String = { val string = resultSet.getString(1) available = resultSet.next() string } }
new Iterator[ResultSet] { def hasNext = { !resultSet.isLast } def next() = { resultSet.next() resultSet } }
def fac(i: Int) = { require(i >= 0, "i must be non negative") @tailrec def loop(k: Int, result: Long = 1): Long = { assert(result == 1 || result >= k) if(k > 0) loop(k - 1, result * k) else result } loop(i) }
var keyword="helloStackoverFlow" println(keyword.takeRight(2))
val xs = Set(5,4,3,2,1) val ys = Set(1,2,3,4,5) xs sameElements ys val xs = Set(3,2,1) val ys = Set(1,2,3) xs sameElements ys
List(1,2,3) == Vector(1,2,3) List(1,2,3) != Set(1,2,3) List(1,2,3) != Array(1,2,3) Array(1,2,3) != Array(1,2,3)
val params = Foo(1, "bar", 3.14).productIterator.toList
Foo(params(0).asInstanceOf[Int], params(1).asInstanceOf[String], params(2).asInstanceOf[Double])
def bar(a: Int, b: Int, c: Int) = val list = List(1, 2, 3, 4, 5) bar(list.take(3)) bar(list(0), list(1), list(2))
case class Foo(a: Int = 0, b: String = "bar", c: Double = 3.14) { val cs = this.getClass.getConstructors def createFromList(params: List[Any]) = cs(0).newInstance(params map { _.asInstanceOf[AnyRef] } : _*).asInstanceOf[Foo] }
scala> Foo().createFromList(List(4, "foo", 9.81)) res13: Foo = Foo(4,foo,9.81)
trait Creatable[T <: Creatable[T]] { val cs = this.getClass.getConstructors def createFromList(params: List[Any]) = cs(0).newInstance(params map { _.asInstanceOf[AnyRef] } : _*).asInstanceOf[T] } case class Bar(a: Int = 0, b: String = "bar", c: Double = 3.14) extends Creatable[Bar]
scala> val bar = Bar() bar: Bar = Bar(0,bar,3.14) scala> bar == bar.createFromList(bar.productIterator.toList) res11: Boolean = true
scala> case class Foo(a: Int, b: String, c: Double) defined class Foo scala> val params = Foo(1, "bar", 3.14).productIterator.toList params: List[Any] = List(1, bar, 3.14) scala> Foo.getClass.getMethods.find(x => x.getName == "apply" && x.isBridge).get.invoke(Foo, params map (_.asInstanceOf[AnyRef]): _*).asInstanceOf[Foo] res0: Foo = Foo(1,bar,3.14) scala> Foo(1, "bar", 3.14) == res0 res1: Boolean = true
scala> case class Foo(a: Int, b: String, c: Double) defined class Foo scala> Foo.tupled((1, "bar", 3.14)) res0: Foo = Foo(1,bar,3.14)
params match { case List(x:Int, y:String, d:Double) => Foo(x,y,d) }
scala> case class A(a: Int) defined class A scala> A: (Int => A) res0: (Int) => A = <function1>
scala> case class A() defined class A scala> A.toString res12: java.lang.String = <function0>
object HasApply { def apply(a: Int) = 1 } val i = HasApply(1)
object MyClass { def apply(a1 : A1, ... aN: AN) = new MyClass(a1, ..., aN) }
object MyClass extends FunctionN[A1, ... , AN, MyClass]{ def apply(a1 : A1, ... aN: AN) = new MyClass(a1, ..., aN) }
scala> case class Foo(i : Int) defined class Foo scala> List(1, 2, 3) map Foo res0: List[Foo] = List(Foo(1), Foo(2), Foo(3))
Welcome to Scala version 2.8.0.RC3 (Java HotSpot(TM) Client VM, Java 1.6.0_20). scala> case class CC3(i: Int, b: Boolean, s: String) defined class CC3 scala> CC3 res0: CC3.type = <function3> scala> CC3.apply(1, true, "boo!") res1: CC3 = CC3(1,true,boo!) scala> CC3(1, true, "boo!") res2: CC3 = CC3(1,true,boo!)
val hdfsConfig = ConfigFactory.load("my_path/hdfs.conf")
val myCfg = ConfigFactory.parseFile(new File("my_path/hdfs.conf"))
val baseConfig = ConfigFactory.load() val config = ConfigFactory.parseFile(yourFile).withFallback(baseConfig)
val config = ConfigFactory.load("pathtoFile/FileName.propertes")
scala> import scalaz._; import Scalaz._ import scalaz._ import Scalaz._ scala> some(some("X")).join res0: Option[java.lang.String] = Some(X) scala> some(none[String]).join res1: Option[String] = None scala> none[Option[String]].join res3: Option[String] = None
val options = List(Some(Some(1)), Some(None), None) options map (_ flatMap (a => a))
val option = Some(Some(2)) val unzippedOption = option flatMap (b => b)
scala> Some(Some("foo")).get res0: Some[java.lang.String] = Some(foo) scala> Some(None).get res1: None.type = None
03-29 10:29:38.505: E/AndroidRuntime(839): java.lang.NoClassDefFoundError: upg.TestSinceInstallation.ComputeSum
package upg.TestSinceInstallation; import android.app.Activity; import android.os.Bundle; import upg.TestSinceInstallation.ComputeSum; public class TestSinceInstallationActivity extends Activity { /** Called when the activity is first created. */ @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); int a = 1; int b = 5; ComputeSum cs = new ComputeSum(a, b); if(cs.getResut() == 6) { setContentView(R.layout.main); } } }
package upg.TestSinceInstallation class ComputeSum(a: Int, b: Int) { def getResut() : Int = a + b }
package com.example.testing; import android.app.Activity import android.os.Bundle import scala.collection.mutable.Map import android.view.View import android.widget.SeekBar import android.widget.ImageButton import android.graphics.drawable.Drawable import android.widget.TextView trait ActivityUtil extends Activity { implicit def func2OnClickListener(func: (View) => Unit):View.OnClickListener = { new View.OnClickListener() { override def onClick(v: View) = func(v) } } implicit def func2OnClickListener(code: () => Unit):View.OnClickListener = { new View.OnClickListener() { override def onClick(v: View) = code() } } private var customOnPause: () => Unit = null override def onPause() = { super.onPause() if(customOnPause != null) customOnPause() } def onPause(f: =>Unit) = { customOnPause = {() => f} } private var customOnCreate: Bundle => Unit = null override def onCreate(savedInstanceState: Bundle) { super.onCreate(savedInstanceState) if(customOnCreate != null) customOnCreate(savedInstanceState) } def onCreate(f: Bundle => Unit) = { customOnCreate = f } private implicit val vMap = Map[Int, View]() private implicit val ibMap = Map[Int, ImageButton]() private implicit val sbMap = Map[Int, SeekBar]() private implicit val tvMap = Map[Int, TextView]() private implicit val dMap = Map[Int, Drawable]() def findView[A <: View](id: Int)(implicit v: Map[Int, A]): A = v.getOrElseUpdate(id, findViewById(id).asInstanceOf[A]) def findDrawable[A <: Drawable](id: Int)(implicit v: Map[Int, A]): A = v.getOrElseUpdate(id, getResources().getDrawable(id).asInstanceOf[A]) implicit class RichView(b: View) { def onClicked(f: =>Unit) = b.setOnClickListener{ () => f } } implicit def findViewImageButton(id: Int): ImageButton = findView[ImageButton](id) implicit def findViewSeekBar(id: Int): SeekBar = findView[SeekBar](id) implicit def findViewTextView(id: Int): TextView = findView[TextView](id) implicit def findDrawable(id: Int): Drawable = findDrawable[Drawable](id) implicit def findRichView(id: Int): RichView = toRichView(findView[View](id)) }
class MyActivity extends Activity with ActivityUtil { import R.id._ lazy val my_button: ImageButton = button lazy val his_button: ImageButton = button2 onCreate { savedInstanceState => setContentView(R.layout.main) my_button.setOnClickListener(myCustomReactClick _) his_button.setOnClickListener { () => } button3.onClicked { } mytextview.setText("My text") (mytextview: TextView).requestFocus() } def myCustomReactClick(v: View) = { } onPause{ } }
[warn] there were 8 unchecked warnings; re-run with -unchecked for details [warn] one warning found
scalacOptions ++= Seq("-unchecked", "-deprecation")
val m = Map("Mark" -> 100, "Jonathan" -> 350, "Bob" -> 65)
def adjust[A, B](m: Map[A, B], k: A)(f: B => B) = m.updated(k, f(m(k)))
case class Lens[A,B](get: A => B, set: (A,B) => A) extends Function1[A,B] with Immutable { def apply(whole: A): B = get(whole) def updated(whole: A, part: B): A = set(whole, part) def mod(a: A)(f: B => B) = set(a, f(this(a))) def compose[C](that: Lens[C,A]) = Lens[C,B]( c => this(that(c)), (c, b) => that.mod(c)(set(_, b)) ) def andThen[C](that: Lens[B,C]) = that compose this }
def containsKey[A,B](k: A) = Lens[Map[A,B], Option[B]]( get = (m:Map[A,B]) => m.get(k), set = (m:Map[A,B], opt: Option[B]) => opt match { case None => m - k case Some(v) => m + (k -> v) } )
sealed abstract class FooMessage case object Foo extends FooMessage case object Bar extends FooMessage class FooActor extends Actor[FooMessage] { def receive = { case Foo => () } } val fooActor = actorOf[FooActor] fooActor ! Foo fooActor ! "Hello"
object TypedActor { def apply[A](fun: PartialFunction[A, Any]): OutputChannel[A] = { val sink = new SyncVar[Channel[A]] actor { val in = new Channel[A](self) sink set in loop { in react { case any => reply(fun(any)) } } } sink.get } } sealed abstract class FooMessage case object Foo extends FooMessage case object Bar extends FooMessage object Test { val fooActor = TypedActor[FooMessage]{ case Foo => println("OK") } fooActor ! Foo fooActor ! "Hello!" }
case class Contact[T](...) case class Signal[T](contact:Contact[T], data:T)
class FooActorBuilder extends SystemBuilder { inputs(FooInput, OtherInput) FooInput.foreach(fooMessage => () ) OtherInput.foreach(...) }
val SomeOtherContact = contact[Boolean]("SomeOtherContact") SomeOtherContact.map(flag => if(flag) Foo else Bar) >> FooInput
val inputMessage = Signal(FooInput, Foo) actor ! inputMessage
trait Witness extends Serializable { type T val value: T {} } trait SingletonOps { import record._ type T def narrow: T {} = witness.value }
scala> implicitly[Int =:= Int {}] res0: =:=[Int,Int] = <function1>
scala> class Foo ; val foo = new Foo defined class Foo foo: Foo = Foo@8bd1b6a scala> val f1 = foo f1: Foo = Foo@8bd1b6a scala> val f2: foo.type = foo f2: foo.type = Foo@8bd1b6a
scala> def narrow[T <: AnyRef](t: T): t.type = t narrow: [T <: AnyRef](t: T)t.type scala> val s1 = narrow("foo") s1: String = foo scala> def narrow[T <: AnyRef](t: T): t.type {} = t narrow: [T <: AnyRef](t: T)t.type scala> val s2 = narrow("foo") s2: String("foo") = foo
trait Foo { type MyFunction = (Int,Int) => Boolean def checkInts(f: MyFunction) def checkInts(f: Option[MyFunction]) }
val m = new java.util.TreeMap[String, Int]() m.put("aa", 2) m.put("cc", 3)
val mh = collection.mutable.HashMap[Int, Int]() var ih = collection.immutable.HashMap[Int, Int]() mh += (1 -> 2) ih += (1 -> 2) mh ih
object CSV extends RegexParsers { def COMMA = "," def DQUOTE = "\"" def DQUOTE2 = "\"\"" ^^ { case _ => "\"" } def CR = "\r" def LF = "\n" def CRLF = "\r\n" def TXT = "[^\",\r\n]".r def file: Parser[List[List[String]]] = ((record~((CRLF~>record)*))<~(CRLF?)) ^^ { case r~rs => r::rs } def record: Parser[List[String]] = (field~((COMMA~>field)*)) ^^ { case f~fs => f::fs } def field: Parser[String] = escaped|nonescaped def escaped: Parser[String] = (DQUOTE~>((TXT|COMMA|CR|LF|DQUOTE2)*)<~DQUOTE) ^^ { case ls => ls.mkString("")} def nonescaped: Parser[String] = (TXT*) ^^ { case ls => ls.mkString("") } def parse(s: String) = parseAll(file, s) match { case Success(res, _) => res case _ => List[List[String]]() } } println(CSV.parse(""" "foo", "bar", 123""" + "\r\n" + "hello, world, 456" + "\r\n" + ))
import scala.util.parsing.combinator._ object CSV extends RegexParsers { override val skipWhitespace = false def COMMA = "," def DQUOTE = "\"" def DQUOTE2 = "\"\"" ^^ { case _ => "\"" } def CRLF = "\r\n" | "\n" def TXT = "[^\",\r\n]".r def SPACES = "[ \t]+".r def file: Parser[List[List[String]]] = repsep(record, CRLF) <~ (CRLF?) def record: Parser[List[String]] = repsep(field, COMMA) def field: Parser[String] = escaped|nonescaped def escaped: Parser[String] = { ((SPACES?)~>DQUOTE~>((TXT|COMMA|CRLF|DQUOTE2)*)<~DQUOTE<~(SPACES?)) ^^ { case ls => ls.mkString("") } } def nonescaped: Parser[String] = (TXT*) ^^ { case ls => ls.mkString("") } def parse(s: String) = parseAll(file, s) match { case Success(res, _) => res case e => throw new Exception(e.toString) } }
import scala.util.parsing.combinator._ object CSV extends RegexParsers { override protected val whiteSpace = .r def COMMA = "," def DQUOTE = "\"" def DQUOTE2 = "\"\"" ^^ { case _ => "\"" } def CR = "\r" def LF = "\n" def CRLF = "\r\n" def TXT = "[^\",\r\n]".r def file: Parser[List[List[String]]] = repsep(record, CRLF) <~ opt(CRLF) def record: Parser[List[String]] = rep1sep(field, COMMA) def field: Parser[String] = (escaped|nonescaped) def escaped: Parser[String] = (DQUOTE~>((TXT|COMMA|CR|LF|DQUOTE2)*)<~DQUOTE) ^^ { case ls => ls.mkString("")} def nonescaped: Parser[String] = (TXT*) ^^ { case ls => ls.mkString("") } def parse(s: String) = parseAll(file, s) match { case Success(res, _) => res case _ => List[List[String]]() } }
/* based on comments in https: import org.parboiled2._ case class Parboiled2CsvParser(input: ParserInput, delimeter: String) extends Parser { def DQUOTE = def DELIMITER_TOKEN = rule(capture(delimeter)) def DQUOTE2 = rule("\"\"" ~ push("\"")) def CRLF = rule(capture("\r\n" | "\n")) def NON_CAPTURING_CRLF = rule("\r\n" | "\n") val delims = s"$delimeter\r\n" + DQUOTE def TXT = rule(capture(!anyOf(delims) ~ ANY)) val WHITESPACE = CharPredicate(" \t") def SPACES: Rule0 = rule(oneOrMore(WHITESPACE)) def escaped = rule(optional(SPACES) ~ DQUOTE ~ (zeroOrMore(DELIMITER_TOKEN | TXT | CRLF | DQUOTE2) ~ DQUOTE ~ optional(SPACES)) ~> (_.mkString(""))) def nonEscaped = rule(zeroOrMore(TXT | capture(DQUOTE)) ~> (_.mkString(""))) def field = rule(escaped | nonEscaped) def row: Rule1[Seq[String]] = rule(oneOrMore(field).separatedBy(delimeter)) def file = rule(zeroOrMore(row).separatedBy(NON_CAPTURING_CRLF)) def parsed() : Try[Seq[Seq[String]]] = file.run() }
import scala.{specialized => sp} trait S1[@sp A, @sp B, @sp C, @sp D] { def f(p1:A): Unit }
trait Foo[@specialized(Int) A, @specialized(Int,Double) B] { }
import scala.collection.immutable.IndexedSeq def arrayToIndexedSeq[@specialized(Int) T](array: Array[T]): IndexedSeq[T] = new IndexedSeq[T] { def apply(idx: Int): T = array(idx) def length: Int = array.length }
object TradeComparator extends java.lang.Comparator[Trade] { @inline def compare(t1 : Trade, t2 : Trade) Int = t1.time compare t2.time }
class A(param: Param){ @inline def a = param.a def a2() = a * a }
$ rm -rf ~/.ivy2/cache/org.scalatest/scalatest_2.11/* $ rm -rf ~/.ivy2/cache/org.scalactic/scalactic_2.11/*
package entities case class MyDbEntity( id: String, field1: String, field2: Boolean, field3: String, field4: String, field5: String, field6: String, field7: String, field8: String, field9: String, field10: String, field11: String, field12: String, field13: String, field14: String, field15: String, field16: String, field17: String, field18: String, field19: String, field20: String, field21: String, field22: String, field23: String, ) object MyDbEntity { import play.api.libs.json.Json import play.api.data._ import play.api.data.Forms._ implicit val entityReads = Json.reads[MyDbEntity] implicit val entityWrites = Json.writes[MyDbEntity] }
implicit val entityReads: Reads[MyDbEntity] = ( (__ \ "id").read[Long] and (__ \ "field_1").read[String] ........ )(MyDbEntity.apply _) implicit val postWrites: Writes[MyDbEntity] = ( (__ \ "id").write[Long] and (__ \ "user").write[String] ........ )(unlift(MyDbEntity.unapply))
implementation restricts functions to 22 parameters value unapply is not a member of object models.MyDbEntity
class CustomFunctionalBuilder[M[_]](canBuild: FunctionalCanBuild[M]) extends FunctionalBuilder { class CustomCanBuild22[A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22](m1: M[A1 ~ A2 ~ A3 ~ A4 ~ A5 ~ A6 ~ A7 ~ A8 ~ A9 ~ A10 ~ A11 ~ A12 ~ A13 ~ A14 ~ A15 ~ A16 ~ A17 ~ A18 ~ A19 ~ A20 ~ A21], m2: M[A22]) { def ~[A23](m3: M[A23]) = new CustomCanBuild23[A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22, A23](canBuild(m1, m2), m3) def and[A23](m3: M[A23]) = this.~(m3) def apply[B](f: (A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22) => B)(implicit fu: Functor[M]): M[B] = fu.fmap[A1 ~ A2 ~ A3 ~ A4 ~ A5 ~ A6 ~ A7 ~ A8 ~ A9 ~ A10 ~ A11 ~ A12 ~ A13 ~ A14 ~ A15 ~ A16 ~ A17 ~ A18 ~ A19 ~ A20 ~ A21 ~ A22, B](canBuild(m1, m2), { case a1 ~ a2 ~ a3 ~ a4 ~ a5 ~ a6 ~ a7 ~ a8 ~ a9 ~ a10 ~ a11 ~ a12 ~ a13 ~ a14 ~ a15 ~ a16 ~ a17 ~ a18 ~ a19 ~ a20 ~ a21 ~ a22 => f(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22) }) def apply[B](f: B => (A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22))(implicit fu: ContravariantFunctor[M]): M[B] = fu.contramap(canBuild(m1, m2), (b: B) => { val (a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22) = f(b); new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(a1, a2), a3), a4), a5), a6), a7), a8), a9), a10), a11), a12), a13), a14), a15), a16), a17), a18), a19), a20), a21), a22) }) def apply[B](f1: (A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22) => B, f2: B => (A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22))(implicit fu: InvariantFunctor[M]): M[B] = fu.inmap[A1 ~ A2 ~ A3 ~ A4 ~ A5 ~ A6 ~ A7 ~ A8 ~ A9 ~ A10 ~ A11 ~ A12 ~ A13 ~ A14 ~ A15 ~ A16 ~ A17 ~ A18 ~ A19 ~ A20 ~ A21 ~ A22, B]( canBuild(m1, m2), { case a1 ~ a2 ~ a3 ~ a4 ~ a5 ~ a6 ~ a7 ~ a8 ~ a9 ~ a10 ~ a11 ~ a12 ~ a13 ~ a14 ~ a15 ~ a16 ~ a17 ~ a18 ~ a19 ~ a20 ~ a21 ~ a22 => f1(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22) }, (b: B) => { val (a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22) = f2(b); new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(new ~(a1, a2), a3), a4), a5), a6), a7), a8), a9), a10), a11), a12), a13), a14), a15), a16), a17), a18), a19), a20), a21), a22) } ) def join[A >: A1](implicit witness1: <:<[A, A1], witness2: <:<[A, A2], witness3: <:<[A, A3], witness4: <:<[A, A4], witness5: <:<[A, A5], witness6: <:<[A, A6], witness7: <:<[A, A7], witness8: <:<[A, A8], witness9: <:<[A, A9], witness10: <:<[A, A10], witness11: <:<[A, A11], witness12: <:<[A, A12], witness13: <:<[A, A13], witness14: <:<[A, A14], witness15: <:<[A, A15], witness16: <:<[A, A16], witness17: <:<[A, A17], witness18: <:<[A, A18], witness19: <:<[A, A19], witness20: <:<[A, A20], witness21: <:<[A, A21], witness22: <:<[A, A22], fu: ContravariantFunctor[M]): M[A] = apply[A]((a: A) => (a: A1, a: A2, a: A3, a: A4, a: A5, a: A6, a: A7, a: A8, a: A9, a: A10, a: A11, a: A12, a: A13, a: A14, a: A15, a: A16, a: A17, a: A18, a: A19, a: A20, a: A21, a: A22))(fu) def reduce[A >: A1, B](implicit witness1: <:<[A1, A], witness2: <:<[A2, A], witness3: <:<[A3, A], witness4: <:<[A4, A], witness5: <:<[A5, A], witness6: <:<[A6, A], witness7: <:<[A7, A], witness8: <:<[A8, A], witness9: <:<[A9, A], witness10: <:<[A10, A], witness11: <:<[A11, A], witness12: <:<[A12, A], witness13: <:<[A13, A], witness14: <:<[A14, A], witness15: <:<[A15, A], witness16: <:<[A16, A], witness17: <:<[A17, A], witness18: <:<[A18, A], witness19: <:<[A19, A], witness20: <:<[A20, A], witness21: <:<[A21, A], witness22: <:<[A22, A], fu: Functor[M], reducer: Reducer[A, B]): M[B] = apply[B]((a1: A1, a2: A2, a3: A3, a4: A4, a5: A5, a6: A6, a7: A7, a8: A8, a9: A9, a10: A10, a11: A11, a12: A12, a13: A13, a14: A14, a15: A15, a16: A16, a17: A17, a18: A18, a19: A19, a20: A20, a21: A21, a22: A22) => reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.append(reducer.unit(a1: A), a2: A), a3: A), a4: A), a5: A), a6: A), a7: A), a8: A), a9: A), a10: A), a11: A), a12: A), a13: A), a14: A), a15: A), a16: A), a17: A), a18: A), a19: A), a20: A), a21: A), a22: A))(fu) def tupled(implicit v: VariantExtractor[M]): M[(A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22)] = v match { case FunctorExtractor(fu) => apply { (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5, a6: A6, a7: A7, a8: A8, a9: A9, a10: A10, a11: A11, a12: A12, a13: A13, a14: A14, a15: A15, a16: A16, a17: A17, a18: A18, a19: A19, a20: A20, a21: A21, a22: A22) => (a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22) }(fu) case ContravariantFunctorExtractor(fu) => apply[(A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22)] { (a: (A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22)) => (a._1, a._2, a._3, a._4, a._5, a._6, a._7, a._8, a._9, a._10, a._11, a._12, a._13, a._14, a._15, a._16, a._17, a._18, a._19, a._20, a._21, a._22) }(fu) case InvariantFunctorExtractor(fu) => apply[(A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22)]({ (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5, a6: A6, a7: A7, a8: A8, a9: A9, a10: A10, a11: A11, a12: A12, a13: A13, a14: A14, a15: A15, a16: A16, a17: A17, a18: A18, a19: A19, a20: A20, a21: A21, a22: A22) => (a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22) }, { (a: (A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22)) => (a._1, a._2, a._3, a._4, a._5, a._6, a._7, a._8, a._9, a._10, a._11, a._12, a._13, a._14, a._15, a._16, a._17, a._18, a._19, a._20, a._21, a._22) })(fu) } } class CustomCanBuild23[A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22, A23](m1: M[A1 ~ A2 ~ A3 ~ A4 ~ A5 ~ A6 ~ A7 ~ A8 ~ A9 ~ A10 ~ A11 ~ A12 ~ A13 ~ A14 ~ A15 ~ A16 ~ A17 ~ A18 ~ A19 ~ A20 ~ A21 ~ A22], m2: M[A23]) { } }
implicit def customToFunctionalBuilderOps[M[_], A](a: M[A])(implicit fcb: FunctionalCanBuild[M]) = new CustomFunctionalBuilderOps[M, A](a)(fcb)
private def getItem(original: Option[${name}], json: JsObject, trackingData: TrackingData)(implicit session: scala.slick.session.Session): Try[${name}] = { preProcess("$name", columnSet, json, trackingData).flatMap(updatedJson => { ${indent(indent(indent(entityColumnsSansId.map(c => s"""val ${c.name}_Parsed = parseJsonField[${c.exposedType}](original.map(_.${c.name}), "${c.name}", updatedJson, "${c.exposedType}")""").mkString("\n"))))} val errs = Seq(${indent(indent(indent(indent(entityColumnsSansId.map(c => s"${c.name}_Parsed.map(_ => ())").mkString(", ")))))}).condenseUnit for { _ <- errs ${indent(indent(indent(indent(entityColumnsSansId.map(c => s"${c.name}_Val <- ${c.name}_Parsed").mkString("\n")))))} } yield { original.map(_.copy(${entityColumnsSansId.map(c => s"${c.name} = ${c.name}_Val").mkString(", ")})) .getOrElse(${name}.apply(id = None, ${entityColumnsSansId.map(c => s"${c.name} = ${c.name}_Val").mkString(", ")})) } }) }
private def parseField[T](name: String, json: JsObject, tpe: String)(implicit r: Reads[T]): Try[T] = { Try((json \ name).as[T]).recoverWith { case e: Exception => Failure(new IllegalArgumentException("Failed to parse " + Json.stringify(json \ name) + " as " + name + " : " + tpe)) } } def parseJsonField[T](default: Option[T], name: String, json: JsObject, tpe: String)(implicit r: Reads[T]): Try[T] = { default match { case Some(t) => if(json.keys.contains(name)) parseField(name, json, tpe)(r) else Try(t) case _ => parseField(name, json, tpe)(r) } } private def getItem(original: Option[ActivityLog], json: JsObject, trackingData: TrackingData)(implicit session: scala.slick.session.Session): Try[ActivityLog] = { preProcess("ActivityLog", columnSet, json, trackingData).flatMap(updatedJson => { val user_id_Parsed = parseJsonField[Option[Int]](original.map(_.user_id), "user_id", updatedJson, "Option[Int]") val user_name_Parsed = parseJsonField[Option[String]](original.map(_.user_name), "user_name", updatedJson, "Option[String]") val item_id_Parsed = parseJsonField[Option[String]](original.map(_.item_id), "item_id", updatedJson, "Option[String]") val item_item_type_Parsed = parseJsonField[Option[String]](original.map(_.item_item_type), "item_item_type", updatedJson, "Option[String]") val item_name_Parsed = parseJsonField[Option[String]](original.map(_.item_name), "item_name", updatedJson, "Option[String]") val modified_Parsed = parseJsonField[Option[String]](original.map(_.modified), "modified", updatedJson, "Option[String]") val action_name_Parsed = parseJsonField[Option[String]](original.map(_.action_name), "action_name", updatedJson, "Option[String]") val remote_ip_Parsed = parseJsonField[Option[String]](original.map(_.remote_ip), "remote_ip", updatedJson, "Option[String]") val item_key_Parsed = parseJsonField[Option[String]](original.map(_.item_key), "item_key", updatedJson, "Option[String]") val created_at_Parsed = parseJsonField[Option[java.sql.Timestamp]](original.map(_.created_at), "created_at", updatedJson, "Option[java.sql.Timestamp]") val as_of_date_Parsed = parseJsonField[Option[java.sql.Timestamp]](original.map(_.as_of_date), "as_of_date", updatedJson, "Option[java.sql.Timestamp]") val errs = Seq(user_id_Parsed.map(_ => ()), user_name_Parsed.map(_ => ()), item_id_Parsed.map(_ => ()), item_item_type_Parsed.map(_ => ()), item_name_Parsed.map(_ => ()), modified_Parsed.map(_ => ()), action_name_Parsed.map(_ => ()), remote_ip_Parsed.map(_ => ()), item_key_Parsed.map(_ => ()), created_at_Parsed.map(_ => ()), as_of_date_Parsed.map(_ => ())).condenseUnit for { _ <- errs user_id_Val <- user_id_Parsed user_name_Val <- user_name_Parsed item_id_Val <- item_id_Parsed item_item_type_Val <- item_item_type_Parsed item_name_Val <- item_name_Parsed modified_Val <- modified_Parsed action_name_Val <- action_name_Parsed remote_ip_Val <- remote_ip_Parsed item_key_Val <- item_key_Parsed created_at_Val <- created_at_Parsed as_of_date_Val <- as_of_date_Parsed } yield { original.map(_.copy(user_id = user_id_Val, user_name = user_name_Val, item_id = item_id_Val, item_item_type = item_item_type_Val, item_name = item_name_Val, modified = modified_Val, action_name = action_name_Val, remote_ip = remote_ip_Val, item_key = item_key_Val, created_at = created_at_Val, as_of_date = as_of_date_Val)) .getOrElse(ActivityLog.apply(id = None, user_id = user_id_Val, user_name = user_name_Val, item_id = item_id_Val, item_item_type = item_item_type_Val, item_name = item_name_Val, modified = modified_Val, action_name = action_name_Val, remote_ip = remote_ip_Val, item_key = item_key_Val, created_at = created_at_Val, as_of_date = as_of_date_Val)) } }) }
import com.fasterxml.jackson.databind.ObjectMapper import com.fasterxml.jackson.module.scala.experimental.ScalaObjectMapper import com.fasterxml.jackson.module.scala.DefaultScalaModule object JacksonUtil extends App { val mapper = new ObjectMapper with ScalaObjectMapper mapper.registerModule(DefaultScalaModule) val t23 = T23("a","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p","q","r","s","t","u","v","w") println(mapper.writeValueAsString(t23)) } case class T23(f1:String,f2:String,f3:String,f4:String,f5:String,f6:String,f7:String, f8:String,f9:String,f10:String,f11:String,f12:String,f13:String,f14:String,f15:String, f16:String,f17:String,f18:String,f19:String,f20:String,f21:String,f22:String,f23:String)
def isOrdered(l:List[Int]): Boolean = l match { case Nil => true case x :: Nil => true case x :: xs => x <= xs.head && isOrdered(xs) }
def isOrdered(l: List[Int]) = l.foldLeft((true, None:Option[Int]))((x,y) => (x._1 && x._2.map(_ <= y).getOrElse(true), Some(y)))._1
import scalaz._ import Scalaz._ case class Lte[A](v: A, b: Boolean) implicit def lteSemigroup[A:Order] = new Semigroup[Lte[A]] { def append(a1: Lte[A], a2: => Lte[A]) = { lazy val b = a1.v lte a2.v Lte(if (!a1.b || b) a1.v else a2.v, a1.b && b && a2.b) } } def isOrdered[T[_]:Traverse, A:Order](ta: T[A]) = ta.foldMapDefault(x => some(Lte(x, true))).fold(_.b, true)
scala> val b = isOrdered(List(1,3,5,7,123)) b: Boolean = true scala> val b = isOrdered(Seq(5,7,2,3,6)) b: Boolean = false scala> val b = isOrdered(Map((2 -> 22, 33 -> 3))) b: Boolean = true scala> val b = isOrdered(some("hello")) b: Boolean = true
import org.scalacheck._ scala> val p = forAll((xs: List[Int]) => (xs /== xs.sorted) ==> !isOrdered(xs)) p:org.scalacheck.Prop = Prop scala> val q = forAll((xs: List[Int]) => isOrdered(xs.sorted)) q: org.scalacheck.Prop = Prop scala> p && q check + OK, passed 100 tests.
def sorted(l:List[Int]) = l.view.zip(l.tail).forall(x => x._1 <= x._2)
def isOrdered(list: List[Int]): Boolean = ( list sliding 2 map { case List(a, b) => () => a < b } forall (_()) )
import Ordering.Implicits._ def isOrdered[A: Ordering](seq: Seq[A]): Boolean = { if (!seq.isEmpty) seq.tail.foldLeft(seq.head){(previous, current) => if (previous > current) return false; current } true }
def isOrdered[A: Ordering](seq: Seq[A]): Boolean = ! seq.sliding(2).exists{s => s.length == 2 && s(0) > s(1)}
import scalaz._ import Scalaz._ import IterV._ import math.Ordering import Ordering.Implicits._ implicit val ListEnumerator = new Enumerator[List] { def apply[E, A](e: List[E], i: IterV[E, A]): IterV[E, A] = e match { case List() => i case x :: xs => i.fold(done = (_, _) => i, cont = k => apply(xs, k(El(x)))) } } def sorted[E: Ordering] : IterV[E, Boolean] = { def step(is: Boolean, e: E)(s: Input[E]): IterV[E, Boolean] = s(el = e2 => if (is && e < e2) Cont(step(is, e2)) else Done(false, EOF[E]), empty = Cont(step(is, e)), eof = Done(is, EOF[E])) def first(s: Input[E]): IterV[E, Boolean] = s(el = e1 => Cont(step(true, e1)), empty = Cont(first), eof = Done(true, EOF[E])) Cont(first) } scala> val s = sorted[Int] s: scalaz.IterV[Int,Boolean] = scalaz.IterV$Cont$$anon$2@5e9132b3 scala> s(List(1,2,3)).run res11: Boolean = true scala> s(List(1,2,3,0)).run res12: Boolean = false
def isOrdered (l: List [Int]): Boolean = l.size/2 match { case 0 => true case m => { val low = l.take (m) val high = l.drop (m) low.last <= high.head && isOrdered (low) && isOrdered (high) } }
def isOrdered (l: List[Int]): Boolean = l.size/2 match { case 0 => true case m => { val (low, high) = l.splitAt (m) low.last <= high.head && ! List (low, high).par.exists (x => isOrdered (x) == false) } }
def isSorted[A <: Ordered[A]](sequence: List[A]): Boolean = { sequence match { case Nil => true case x::Nil => true case x::y::rest => (x < y) && isSorted(y::rest) } } Explain how it works.
def isSorted[T](l: Seq[T])(implicit ord: Ordering[T]) = (l, l.tail).zipped.forall(ord.lt(_, _))
isSorted(dataList)(Ordering.by[Post, Date](_.lastUpdateTime))
case class Person(firstName:String,lastName:String) { }
object Person { def something = "rawr" def tupled = (Person.apply _).tupled }
object Person extends((String,String) => Person) { ... }
object Person { ... def tupled = (this.apply _).tupled }
val lines = sc.textFile("data.txt") val pairs = lines.map(s => (s, 1)) val counts = pairs.reduceByKey((a, b) => a + b)
pairs.reduceByKey((accumulatedValue: Int, currentValue: Int) => accumulatedValue + currentValue)
pairs.reduce((accumulatedValue: List[(String, Int)], currentValue: (String, Int)) => { val accumAsMap = accumulatedValue.toMap accumAsMap.get(currentValue._1) match { case Some(value : Int) => (accumAsMap + (currentValue._1 -> (value + currentValue._2))).toList case None => currentValue :: accumulatedValue } })
val rdd =sparkContext.parallelize(( (1 to 20).map(x=>("key",x))), 4) rdd.reduceByKey(_ + _) rdd.collect() > Array[(String, Int)] = Array((key,210))
val f1 = Future { "Hello" + "World" } val f2 = f1 flatMap {x => Future(x.length) } val result = f2.get()
val future3 = for( x <- future1; y <- future2 ) yield ( x + y )
val future3 = future1.flatMap( x => future2.map( y => x+y ) )
val future3 = future1.map( x => future2.map( y => x+y ) )
flatMap[A](f: T => Future[A]): Future[A] map[A](f: T => A): Future[A]
/** Creates a new future by applying a function to the successful result of * this future. If this future is completed with an exception then the new * future will also contain this exception. * * $forComprehensionExamples */ def map[S](f: T => S)(implicit executor: ExecutionContext): Future[S] = { val p = Promise[S]() onComplete { v => p complete (v map f) } p.future } /** Creates a new future by applying a function to the successful result of * this future, and returns the result of the function as the new future. * If this future is completed with an exception then the new future will * also contain this exception. * * $forComprehensionExamples */ def flatMap[S](f: T => Future[S])(implicit executor: ExecutionContext): Future[S] = { import impl.Promise.DefaultPromise val p = new DefaultPromise[S]() onComplete { case f: Failure[_] => p complete f.asInstanceOf[Failure[S]] case Success(v) => try f(v) match { case dp: DefaultPromise[_] => dp.asInstanceOf[DefaultPromise[S]].linkRootOf(p) case fut => fut.onComplete(p.complete)(internalExecutor) } catch { case NonFatal(t) => p failure t } } p.future }
class <%<[-From, +To] extends (From) ⇒ To class <:<[-From, +To] extends (From) ⇒ To class =:=[From, To] extends (From) ⇒ To
sealed abstract class <:<[-From, +To] extends (From => To) implicit def conforms[A]: A <:< A = new (A <:< A) {def apply(x: A) = x}
manifest[java.util.List[String]] <:< manifest[java.util.ArrayList[String]] == false manifest[java.util.ArrayList[String]] <:< manifest[java.util.List[String]] == true
sealed abstract class <:<[-From, +To] extends (From => To) implicit def conforms[A]: A <:< A = new (A <:< A) {def apply(x: A) = x}
sealed abstract class <:<[-From, +To] extends (From => To) implicit def conforms[A]: A <:< A = new (A <:< A) {def apply(x: A) = x}
sealed class <:<[-From <: To, +To] implicit def conforms[A <: B, B]: A <:< B = new (A <:< B)
case class L[+A]( elem: A ) { def contains[B](x: B)(implicit ev: A <:< B) = elem == x } error: type arguments [A,B] do not conform to class <:< type parameter bounds [-From <: To,+To] def contains[B](x: B)(implicit ev: A <:< B) = elem == x ^
def putTheDoubleQuotes(value: Any): Any = { value match { case s: String => s case _ => s"\"$value\"" } }
scala> import org.apache.commons.lang.StringEscapeUtils.escapeJava import org.apache.commons.lang.StringEscapeUtils.escapeJava scala> escapeJava("this is a string\nover two lines") res1: java.lang.String = this is a string\nover two lines
scala> implicit class `string quoter`(val sc: StringContext) { | def q(args: Any*): String = "\"" + sc.s(args: _*) + "\"" | } defined class string$u0020quoter scala> q"hello,${" "*8}world" res0: String = "hello, world" scala> "hello, world" res1: String = hello, world scala> " hello, world " res2: String = " hello, world "
scala> val `"` = "\"" ": String = " scala> s"${`"`}" res3: String = " scala> s"hello, so-called $`"`world$`"`" res4: String = hello, so-called "world"
scala> f"%qhello, world%q" <console>:9: error: conversions must follow a splice; use %% for literal %, %n for newline
scala> s"\42hello, world\42" res12: String = "hello, world"
raw""" Inside this block you can put "as many" quotes as you "want" and even "${5 + 7}" interpolate inside the quotes """
object StringUtil{ implicit class StringImprovements(s: String) { def quoted = "\""+s+"\"" } } val myStatement = s"INSERT INTO ${tableName.quoted} ..."
val str="abc" println(s"$str") println(s"""\"$str\"""")
object StringUtil{ implicit class StringImprovements(val s: String) extends AnyVal { def dqt = "\""+s+"\"" def sqt = s" } }
import StringUtil._ abstract class Animal { ... override def toString(): String = s"Animal:${getFullName().dqt}, CanFly:$canFly, Sound:${getSound.dqt}" }
future { do_something() } ;; clojure (future (do-something))
val p = promise[Int] ... p success 10 ;; clojure (def p (promise)) (deliver p 10)
def apply[T](body: =>T): Future[T] = impl.Future(body)
def apply[T](body: =>T)(implicit executor: ExecutionContext): scala.concurrent.Future[T] = { val runnable = new PromiseCompletingRunnable(body) executor.prepare.execute(runnable) runnable.promise.future }
class PromiseCompletingRunnable[T](body: => T) extends Runnable { val promise = new Promise.DefaultPromise[T]() override def run() = { promise complete { try Success(body) catch { case NonFatal(e) => Failure(e) } } } }
def count (p: (Char) ⇒ Boolean): Int Counts the number of elements in the string which satisfy a predicate. p the predicate used to test elements. returns the number of elements satisfying the predicate p. Definition Classes TraversableOnce → GenTraversableOnce
(0 to (myTuple.productArity-1)).map(myTuple.productElement(_)).toList
def tuple2ToList[T](t: (T,T)): List[T] = List(t._1, t._2)
@ import syntax.std.tuple._ import syntax.std.tuple._ @ (1,2,3).toList res21: List[Int] = List(1, 2, 3) @ (1,2,3,4,3,3,3,3,3,3,3).toList res22: List[Int] = List(1, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3)
df .groupBy(grouping_columns) .pivot(pivot_column, [values]) .agg(aggregate_expressions)
val flights = sqlContext .read .format("csv") .options(Map("inferSchema" -> "true", "header" -> "true")) .load("flights.csv") flights .groupBy($"origin", $"dest", $"carrier") .pivot("hour") .agg(avg($"arr_delay"))
import static org.apache.spark.sql.functions.*; import org.apache.spark.sql.*; Dataset<Row> df = spark.read().format("csv") .option("inferSchema", "true") .option("header", "true") .load("flights.csv"); df.groupBy(col("origin"), col("dest"), col("carrier")) .pivot("hour") .agg(avg(col("arr_delay")));
library(dplyr) flights <- spark_read_csv(sc, "flights", "flights.csv") avg.arr.delay <- function(gdf) { expr <- invoke_static( sc, "org.apache.spark.sql.functions", "avg", "arr_delay" ) gdf %>% invoke("agg", expr, list()) } flights %>% sdf_pivot(origin + dest + carrier ~ hour, fun.aggregate=avg.arr.delay)
"year","month","day","dep_time","sched_dep_time","dep_delay","arr_time","sched_arr_time","arr_delay","carrier","flight","tailnum","origin","dest","air_time","distance","hour","minute","time_hour" 2013,1,1,517,515,2,830,819,11,"UA",1545,"N14228","EWR","IAH",227,1400,5,15,2013-01-01 05:00:00 2013,1,1,533,529,4,850,830,20,"UA",1714,"N24211","LGA","IAH",227,1416,5,29,2013-01-01 05:00:00 2013,1,1,542,540,2,923,850,33,"AA",1141,"N619AA","JFK","MIA",160,1089,5,40,2013-01-01 05:00:00 2013,1,1,544,545,-1,1004,1022,-18,"B6",725,"N804JB","JFK","BQN",183,1576,5,45,2013-01-01 05:00:00 2013,1,1,554,600,-6,812,837,-25,"DL",461,"N668DN","LGA","ATL",116,762,6,0,2013-01-01 06:00:00 2013,1,1,554,558,-4,740,728,12,"UA",1696,"N39463","EWR","ORD",150,719,5,58,2013-01-01 05:00:00 2013,1,1,555,600,-5,913,854,19,"B6",507,"N516JB","EWR","FLL",158,1065,6,0,2013-01-01 06:00:00 2013,1,1,557,600,-3,709,723,-14,"EV",5708,"N829AS","LGA","IAD",53,229,6,0,2013-01-01 06:00:00 2013,1,1,557,600,-3,838,846,-8,"B6",79,"N593JB","JFK","MCO",140,944,6,0,2013-01-01 06:00:00 2013,1,1,558,600,-2,753,745,8,"AA",301,"N3ALAA","LGA","ORD",138,733,6,0,2013-01-01 06:00:00
val countries = List("US", "UK", "Can") val numCountries = countries.length - 1 var query = "select *, " for (i <- 0 to numCountries-1) { query += " + countries(i) + " + countries(i) + ", " } query += " + countries.last + " + countries.last + " from myTable" myDataFrame.registerTempTable("myTable") val myDF1 = sqlContext.sql(query)
import org.apache.spark.sql.functions._ val countries = List("US", "UK", "Can") val countryValue = udf{(countryToCheck: String, countryInRow: String, value: Long) => if(countryToCheck == countryInRow) value else 0 } val countryFuncs = countries.map{country => (dataFrame: DataFrame) => dataFrame.withColumn(country, countryValue(lit(country), df("tag"), df("value"))) } val dfWithCountries = Function.chain(countryFuncs)(df).drop("tag").drop("value")
+--+--+---+---+ |id|US| UK|Can| +--+--+---+---+ | 1|50| 0| 0| | 1| 0|100| 0| | 1| 0| 0|125| | 2|75| 0| 0| | 2| 0|150| 0| | 2| 0| 0|175| +--+--+---+---+
dfWithCountries.groupBy("id").sum(countries: _*).show
+--+-------+-------+--------+ |id|SUM(US)|SUM(UK)|SUM(Can)| +--+-------+-------+--------+ | 1| 50| 100| 125| | 2| 75| 150| 175| +--+-------+-------+--------+
id,tag,value 1,US,50a 1,UK,100 1,Can,125 2,US,75 2,UK,150 2,Can,175
+--+---+---+---+ |id| UK| US|Can| +--+---+---+---+ | 2|150| 75|175| | 1|100|50a|125| +--+---+---+---+
def transpose(hc : HiveContext , df: DataFrame,compositeId: List[String], key: String, value: String) = { val distinctCols = df.select(key).distinct.map { r => r(0) }.collect().toList val rdd = df.map { row => (compositeId.collect { case id => row.getAs(id).asInstanceOf[Any] }, scala.collection.mutable.Map(row.getAs(key).asInstanceOf[Any] -> row.getAs(value).asInstanceOf[Any])) } val pairRdd = rdd.reduceByKey(_ ++ _) val rowRdd = pairRdd.map(r => dynamicRow(r, distinctCols)) hc.createDataFrame(rowRdd, getSchema(df.schema, compositeId, (key, distinctCols))) } private def dynamicRow(r: (List[Any], scala.collection.mutable.Map[Any, Any]), colNames: List[Any]) = { val cols = colNames.collect { case col => r._2.getOrElse(col.toString(), null) } val array = r._1 ++ cols Row(array: _*) } private def getSchema(srcSchema: StructType, idCols: List[String], distinctCols: (String, List[Any])): StructType = { val idSchema = idCols.map { idCol => srcSchema.apply(idCol) } val colSchema = srcSchema.apply(distinctCols._1) val colsSchema = distinctCols._2.map { col => StructField(col.asInstanceOf[String], colSchema.dataType, colSchema.nullable) } StructType(idSchema ++ colsSchema) }
import java.util.Date import org.apache.spark.SparkConf import org.apache.spark.SparkContext import org.apache.spark.sql.Row import org.apache.spark.sql.DataFrame import org.apache.spark.sql.types.StructType import org.apache.spark.sql.hive.HiveContext import org.apache.spark.sql.types.StructField ... ... def main(args: Array[String]): Unit = { val sc = new SparkContext(conf) val sqlContext = new org.apache.spark.sql.SQLContext(sc) val dfdata1 = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true") .load("data.csv") dfdata1.show() val dfOutput = transpose(new HiveContext(sc), dfdata1, List("id"), "tag", "value") dfOutput.show }
scala> spark.sql("select * from k_tags limit 10").show() +---------------+-------------+------+ | imsi| name| value| +---------------+-------------+------+ |246021000000000| age| 37| |246021000000000| gender|Female| |246021000000000| arpu| 22| |246021000000000| DeviceType| Phone| |246021000000000|DataAllowance| 6GB| +---------------+-------------+------+ scala> spark.sql("select * from k_tags limit 10").groupBy($"imsi").pivot("name").agg(min($"value")).show() +---------------+-------------+----------+---+----+------+ | imsi|DataAllowance|DeviceType|age|arpu|gender| +---------------+-------------+----------+---+----+------+ |246021000000000| 6GB| Phone| 37| 22|Female| |246021000000001| 1GB| Phone| 72| 10| Male| +---------------+-------------+----------+---+----+------+
for { foo <- Right(1) bar <- Left("nope") } yield (foo + bar)
for { foo <- Right[String,Int](1).right bar <- Left[String,Int]("nope").right } yield (foo + bar)
import scalaz._, Scalaz._ scala> for { | foo <- 1.right[String] | bar <- "nope".left[Int] | } yield (foo.toString + bar) res39: Either[String,java.lang.String] = Left(nope)
scala> for { | foo <- 1.right[String] | if foo > 3 | } yield foo <console>:18: error: value withFilter is not a member of Either[String,Int] foo <- 1.right[String] ^
scala> implicit def eitherW[A, B](e: Either[A, B]) = new { | def map[B1](f: B => B1) = e.right map f | def flatMap[B1](f: B => Either[A, B1]) = e.right flatMap f | } eitherW: [A, B](e: Either[A,B])java.lang.Object{def map[B1](f: B => B1): Product with Either[A,B1] with Serializable; def flatMap[B1](f: B => Either[A,B1]): Either[A,B1]} scala> for { | foo <- Right(1): Either[String, Int] | bar <- Left("nope") : Either[String, Int] | } yield (foo.toString + bar) res0: Either[String,java.lang.String] = Left(nope)
val right1: Right[Double, Int] = Right(1) val right2 = Right(2) val right3 = Right(3) val left23: Left[Double, Int] = Left(23.0) val left42 = Left(42.0) for ( a <- right1; b <- right2; c <- right3 ) yield a + b + c for ( a <- right1; b <- right2; c <- left23 ) yield a + b + c for ( a <- right1; b <- left23; c <- right2 ) yield a + b + c for ( a <- left23; b <- right1; c <- left42 ) yield a + b + c
def someFunction(x: Set, p: Int => Boolean): Boolean = someOtherFunction(x, !p)
def someOtherFunction (x: Set[Int], p: Int => Boolean):Boolean = x.forall(p) def someFunction(x: Set[Int], p: Int => Boolean): Boolean = someOtherFunction(x, !p(_)) val x = Set(1,2,3) var p: Int => Boolean = (_ > 0) someFunction(x, p) someOtherFunction(x, p) p = _ > 1 someFunction(x, p) someOtherFunction(x, p) p = _ > 3 someFunction(x, p) someOtherFunction(x, p) println
def even(x:Int):Boolean = x%2==0 def not(f: Int => Boolean): Int => Boolean = !f(_) def odd = not(even) odd(1) odd(2)
def even: Int => Boolean = _%2==0 implicit def bangy(f: Int => Boolean) = new { def unary_! : Int => Boolean = !f(_) } def odd = !even odd(1) odd(2)
int i; switch(i) { case 1: a(); break; case 2: case 15: b(); c(); break; default: foo() }
i match { case 1 => a case 2 => case 15 => { b c } case _ => foo }
i match { case 1 => a case 2 | 15 => b c case _ => foo }
i match { case x if x == 1 => a case x if (x == 2 | x == 15) => b; c; case _ => foo }
def do_function_a() { println("a"); } def do_function_b() { println("b"); } val run_function:PartialFunction[String, String] = { case "a" => do_function_a(); "b" case "b" => do_function_b(); "c" } (run_function andThen run_function)("a")
sealed trait ShipCondition case class ShipOnFire() extends ShipCondition case class FoodSucks() extends ShipCondition case class MateySnoresTooLoud() extends ShipCondition case class Ok() extends ShipCondition val condition = ShipOnFire() def checkCondition(cond: ShipCondition): Unit = { cond match { case c @ (_: ShipOnFire | _: FoodSucks) => println("Abandon Ship!") case (_: MateySnoresTooLoud | _: Ok) => println("Deal with it!") } } checkCondition(condition)
collection.parallel.ForkJoinTasks.defaultForkJoinPool.setParallelism(parlevel: Int)
scala> import scala.collection.parallel._ import scala.collection.parallel._ scala> val pc = mutable.ParArray(1, 2, 3) pc: scala.collection.parallel.mutable.ParArray[Int] = ParArray(1, 2, 3) scala> pc.tasksupport = new ForkJoinTaskSupport(new scala.concurrent.forkjoin.ForkJoinPool(2)) pc.tasksupport: scala.collection.parallel.TaskSupport = scala.collection.parallel.ForkJoinTaskSupport@4a5d484a scala> pc map { _ + 1 } res0: scala.collection.parallel.mutable.ParArray[Int] = ParArray(2, 3, 4)
scala> val c = 1 to 5 c: scala.collection.immutable.Range.Inclusive = Range(1, 2, 3, 4, 5) scala> c.grouped(2).seq.flatMap(_.par.map(_ * 2)).toList res11: List[Int] = List(2, 4, 6, 8, 10)
val i = immutable.Array("Hello") i.asInstanceOf[Array[String]](0) = "Goodbye" println( i(0) )
Manifest-Version: 1.0 Bundle-ManifestVersion: 2 Bundle-Name: Scala Hello Bundle-SymbolicName: com.test.scala.hello Bundle-Version: 1.0.0.qualifier Bundle-Vendor: drozzy Import-Package: org.osgi.framework;version="1.5.0" Bundle-Activator: com.test.scala.hello.Activator Require-Bundle: scala-library;bundle-version="2.9.1"
package com.test.scala.hello import java.lang.System import org.osgi.framework.BundleActivator import org.osgi.framework.BundleContext class Activator extends BundleActivator { def start(context: BundleContext) { System.out.println("Hello world from scala!"); } def stop(context: BundleContext){} }
$ scala -Yoverride-objects Welcome to Scala version 2.11.2 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_11). Type in expressions to have them evaluated. Type :help for more information. scala> trait A { object O } ; trait B extends A { override object O } defined trait A defined trait B scala> trait A { final object O } ; trait B extends A { override object O } <console>:8: error: overriding object O in trait A; object O cannot override final member trait A { final object O } ; trait B extends A { override object O } ^
Class not found: "xxx.xxxxx.xxx.xxxx.xxxxx.AccountRepositoryTest"
@RunWith(classOf[SpringJUnit4ClassRunner]) @ContextConfiguration(classes = Array(classOf[DataConfig], classOf[SettingsConfig])) class AccountRepositoryTest extends AssertionsForJUnit {
case class WideLoad(a: String, b: Int, c: Float, d: ActorRef, e: Date)
someVal match { case WideLoad(_, _, _, d, _) => d ! SomeMessage(...) }
someVal match { case WideLoad(d = dActor) => dActor ! SomeMessage(...) }
object WideLoadActorRef { def unapply(wl: WideLoad): Option[ActorRef] = { Some(wl.d) } } someVal match { case WideLoadActorRef(d) => d ! someMessage }
object WideLoadBnD { def unapplySeq(wl: WideLoad): Option[(Int,ActorRef)] = { Some((wl.b,wl.d)) } } someVal match { case WideLoadBnD(b, d) => d ! SomeMessage(b) }
case class Foo(a:Int, b:Int, c:String, d:java.util.Date) def f(foo:Foo) = foo match { case fo:Foo if fo.c == "X" => println("found") case _ => println("arrgh!") } f(Foo(1,2,"C",new java.util.Date())) f(Foo(1,2,"X",new java.util.Date()))
case class Bar(a: Int, b:String) case class Baz(c:java.util.Date, d:String) case class Foo(bar:Bar, baz:Baz) def f(foo:Foo) = foo match { case Foo(Bar(1,_),Baz(_,"X")) => println("found") case _ => println("arrgh!") } f(Foo(Bar(1,"c"),Baz(new java.util.Date, "X"))) f(Foo(Bar(1,"c"),Baz(new java.util.Date, "Y")))
case class WideLoad(a: String, b: Int, c: Float, d: ActorRef, e: Date) val someVal = WideLoad(...) someVal match { case w: WideLoad => w.d ! SomeMessage(...) }
class C[-A, +B] { def foo(param: A): B = ??? } class Person(val name: String) class Student(name: String, val university: String) extends Person(name) val sample: C[Student, Person] = new C[Person, Student]
def toPersisted[T](instance: T, id: Long): T with Persisted
scala> class Foo defined class Foo scala> trait Bar defined trait Bar scala> val fooWithBar = new Foo with Bar fooWithBar: Foo with Bar = $anon$1@10ef717
scala> fooWithBar.getClass res3: java.lang.Class[_ <: Foo] = class $anon$1
import tools.nsc.interpreter.IMain import tools.nsc._ import reflect.mirror._ object PersistedEnabler { def toPersisted[T <: AnyRef](instance: T, key: String) (implicit instanceTag: TypeTag[T]): T with Persisted = { val args = { val valuesMap = propertyValuesMap(instance) key :: methodParams(constructors(instanceTag.tpe).head.typeSignature) .map(_.name.decoded.trim) .map(valuesMap(_)) } persistedClass(instanceTag) .getConstructors.head .newInstance(args.asInstanceOf[List[Object]]: _*) .asInstanceOf[T with Persisted] } private val persistedClassCache = collection.mutable.Map[TypeTag[_], Class[_]]() private def persistedClass[T](tag: TypeTag[T]): Class[T with Persisted] = { if (persistedClassCache.contains(tag)) persistedClassCache(tag).asInstanceOf[Class[T with Persisted]] else { val name = generateName() val code = { val sourceParams = methodParams(constructors(tag.tpe).head.typeSignature) val newParamsList = { def paramDeclaration(s: Symbol): String = s.name.decoded + ": " + s.typeSignature.toString "val key: String" :: sourceParams.map(paramDeclaration) mkString ", " } val sourceParamsList = sourceParams.map(_.name.decoded).mkString(", ") val copyMethodParamsList = sourceParams.map(s => s.name.decoded + ": " + s.typeSignature.toString + " = " + s.name.decoded).mkString(", ") val copyInstantiationParamsList = "key" :: sourceParams.map(_.name.decoded) mkString ", " + name + """( ) extends ( ) with { override def copy( ) = new ( ) } """ } interpreter.compileString(code) val c = interpreter.classLoader.findClass(name) .asInstanceOf[Class[T with Persisted]] interpreter.reset() persistedClassCache(tag) = c c } } private lazy val interpreter = { val settings = new Settings() settings.usejavacp.value = true new IMain(settings, new NewLinePrintWriter(new ConsoleWriter, true)) } private var generateNameCounter = 0l private def generateName() = synchronized { generateNameCounter += 1 "PersistedAnonymous" + generateNameCounter.toString } private def propertyNames(t: Type) = t.members.filter(m => !m.isMethod && m.isTerm).map(_.name.decoded.trim) private def propertyValuesMap[T <: AnyRef](instance: T) = { val t = typeOfInstance(instance) propertyNames(t) .map(n => n -> invoke(instance, t.member(newTermName(n)))()) .toMap } private type MethodType = {def params: List[Symbol]; def resultType: Type} private def methodParams(t: Type): List[Symbol] = t.asInstanceOf[MethodType].params private def methodResultType(t: Type): Type = t.asInstanceOf[MethodType].resultType private def constructors(t: Type): Iterable[Symbol] = t.members.filter(_.kind == "constructor") private def fullyQualifiedName(s: Symbol): String = { def symbolsTree(s: Symbol): List[Symbol] = if (s.enclosingTopLevelClass != s) s :: symbolsTree(s.enclosingTopLevelClass) else if (s.enclosingPackageClass != s) s :: symbolsTree(s.enclosingPackageClass) else Nil symbolsTree(s) .reverseMap(_.name.decoded) .drop(1) .mkString(".") } }
import PersistedEnabler._ object Sandbox extends App { case class Artist(name: String, genres: Set[Genre]) case class Genre(name: String) val artist = Artist("Nirvana", Set(Genre("rock"), Genre("grunge"))) val persisted = toPersisted(artist, "some-key") assert(persisted.isInstanceOf[Persisted]) assert(persisted.isInstanceOf[Artist]) assert(persisted.key == "some-key") assert(persisted.name == "Nirvana") assert(persisted == artist) val copy = persisted.copy(name = "Puddle of Mudd") assert(copy.isInstanceOf[Persisted]) assert(copy.isInstanceOf[Artist]) assert(copy.asInstanceOf[Artist with Persisted].key == "some-key") assert(copy.name == "Puddle of Mudd") assert(copy != persisted) }
type Persisted = { def id: Long } class Person { def id: Long = 5 def name = "dude" } def persist(obj: Persisted) = { obj.id } persist(new Person)
object Persistable { type Compatible = { def id: Long } implicit def obj2persistable(obj: Compatible) = new Persistable(obj) } class Persistable(val obj: Persistable.Compatible) { def persist() = println("Persisting: " + obj.id) } import Persistable.obj2persistable new Person().persist()
scala> import java.util.Comparator import java.util.Comparator scala> trait Foo[T] extends Comparator[T] defined trait Foo scala> trait Foo[-T] extends Comparator[T] <console>:5: error: contravariant type T occurs in invariant position in type [-T]java.lang.Object with java.util.Comparator[T] of trait Foo trait Foo[-T] extends Comparator[T] ^ scala> import annotation.unchecked._ import annotation.unchecked._ scala> trait Foo[-T] extends Comparator[T @uncheckedVariance] defined trait Foo
trait GenericTraversableTemplate[+A, +CC[X] <: Traversable[X]] extends HasNewBuilder[A, CC[A] @uncheckedVariance]
M:\>scala -Xprint:typer -e "class C { def p[T >: Null](t: T = null) = t }" [[syntax trees at end of typer]] package <empty> { final object Main extends java.lang.Object with ScalaObject { def this(): object Main = { Main.super.this(); () }; def main(argv: Array[String]): Unit = { val args: Array[String] = argv; { final class $anon extends scala.AnyRef { def this(): anonymous class $anon = { $anon.super.this(); () }; class C extends java.lang.Object with ScalaObject { <synthetic> def p$default$1[T >: Null <: Any]: Null @scala.annotation.unchecked.uncheckedVariance = null; def this(): this.C = { C.super.this(); () }; def p[T >: Null <: Any](t: T = null): T = t } }; { new $anon(); () } } } }
HashMap<Shape, Pair<String, String>> shapeInfo = makeInfo()
val shapeInfo: HashMap[Shape, (String, String)] = makeInfo()
var stockPrice: Double = 100.0 var stockPrice = 100.0
val m = Map(1 -> "one") val t = scala.collection.immutable.TreeMap(m.toArray:_*)
import scala.collection.immutable.SortedMap val m = Map(1 -> ("one":Any)) val sorted = SortedMap[Int, Any]() ++ m
import collection.generic.CanBuildFrom import collection.immutable.TreeMap object test { class TraversableW[A](t: Traversable[A]) { def as[CC[X] <: Traversable[X]](implicit cbf: CanBuildFrom[Nothing, A, CC[A]]): CC[A] = t.map(identity)(collection.breakOut) def to[Result](implicit cbf: CanBuildFrom[Nothing, A, Result]): Result = t.map(identity)(collection.breakOut) } implicit def ToTraverseableW[A](t: Traversable[A]): TraversableW[A] = new TraversableW[A](t) List(1, 2, 3).as[Vector] List(1, 2, 3).to[Vector[Int]] List((1, 1), (2, 4), (3, 4)).to[Map[Int, Int]] List((1, 1), (2, 4), (3, 4)).to[TreeMap[Int, Int]] val tm: TreeMap[Int, Int] = List((1, 1), (2, 4), (3, 4)).to ("foo": Seq[Char]).as[Vector] } test
implicit class ToSortedMap[A,B](tuples: TraversableOnce[(A, B)]) (implicit ordering: Ordering[A]) { def toSortedMap = SortedMap(tuples.toSeq: _*) }
scala> Map("b" -> 3, "c" -> 3, "a" -> 5).toSortedMap res6: scala.collection.immutable.SortedMap[String,Int] = Map(a -> 5, b -> 3, c -> 3)
scala> List(("c", 1), ("b", 3),("a", 6)).toSortedMap res7: scala.collection.immutable.SortedMap[String,Int] = Map(a -> 6, b -> 3, c -> 1)
val m = Map(1 -> "one") var t = scala.collection.immutable.TreeMap[Int,String]() t ++= m
def ~ [U](q: => Parser[U]): Parser[~[T, U]] = { lazy val p = q (for(a <- this; b <- p) yield new ~(a,b)).named("~") }
scala> def f(p: => Int, eval : Boolean) = if (eval) println(p) f: (p: => Int, eval: Boolean)Unit scala> f(3, true) 3 scala> f(3/0, false) scala> f(3/0, true) java.lang.ArithmeticException: / by zero at $anonfun$1.apply$mcI$sp(<console>:9) ...
scala> def g(p: => Int) = println(p + p) g: (p: => Int)Unit scala> def calc = { println("evaluating") ; 10 } calc: Int scala> g(calc) evaluating evaluating 20
def getObject : QueuObject = { val response = return response }
def getObject : Option[QueueObject] = { Option(someJavaObject.getResponse) }
def getObject : Option[QueueObject] = Option(someJavaObject.getResponse)
if (getObject.isDefined) QueueManager.add(getObject.get)
val result = getObject if (result.isDefined) QueueManager.add(result.get)
val result = getObject if (result != null) QueueManager.add(result)
val returnVal = getObject ifNotNull { obj => returnSomethingFrom(obj) } otherwise { returnSomethingElse }
import sbt._ import Keys._ object HelloBuild extends Build { lazy val root = Project(id = "hello", base = file(".")) aggregate(foo, bar) lazy val foo = Project(id = "hello-foo", base = file("foo")) lazy val bar = Project(id = "hello-bar", base = file("bar")) }
base = file(".")) settings (publish := { }) aggregate(foo, bar)
publishTo := Some(Resolver.file("Unused transient repository", file("target/unusedrepo")))
lazy val root = Project( id = "root", base = file("."), aggregate = Seq(foo, bar), settings = Project.defaultSettings ++ Seq( publishLocal := {}, publish := {} ) )
settings(packageBin := { new File("") }, packageSrc := { new File("") }, packageDoc := { new File("") })
base = file(".")) settings (skip in publish := true) aggregate(foo, bar)
case n when 0...5 then "less than five" when 5...10 then "less than ten" else "a lot" end
n match { case it if 0 until 5 contains it => "less than five" case it if 5 until 10 contains it => "less than ten" case _ => "a lot" }
class Contains(r: Range) { def unapply(i: Int): Boolean = r contains i } val C1 = new Contains(3 to 10) val C2 = new Contains(20 to 30) scala> 5 match { case C1() => println("C1"); case C2() => println("C2"); case _ => println("none") } C1 scala> 23 match { case C1() => println("C1"); case C2() => println("C2"); case _ => println("none") } C2 scala> 45 match { case C1() => println("C1"); case C2() => println("C2"); case _ => println("none") } none
n match { case i if (i >= 0 && i < 5) => "less than five" case i if (i >= 5 && i < 10) => "less than ten" case _ => "a lot" }
val a = 11 (a/10) match { case 0 => println (a + " in 0-9") case 1 => println (a + " in 10-19") } 11 in 10-19
def tryProcessSource( file: File, parseLine: (Int, String) => Option[List[String]] = (index, unparsedLine) => Some(List(unparsedLine)), filterLine: (Int, List[String]) => Option[Boolean] = (index, parsedValues) => Some(true), retainValues: (Int, List[String]) => Option[List[String]] = (index, parsedValues) => Some(parsedValues), ): Try[List[List[String]]] = { ??? }
street,street2,city,state,zip 100 Main Str,,Irving,TX,75039 231 Park Ave,,Irving,TX,75039 1400 Beltline Rd,Apt 312,Dallas,Tx,75240
val tryLinesDefaults = tryProcessSource(new File("path/to/file.csv"))
Success( List( List("street,street2,city,state,zip"), List("100 Main Str,,Irving,TX,75039"), List("231 Park Ave,,Irving,TX,75039"), List("1400 Beltline Rd,Apt 312,Dallas,Tx,75240") ) )
val tryLinesParseOnly = tryProcessSource( new File("path/to/file.csv") , parseLine = (index, unparsedLine) => Some(unparsedLine.split(",").toList) )
Success( List( List("street","street2","city","state","zip"), List("100 Main Str","","Irving,TX","75039"), List("231 Park Ave","","Irving","TX","75039"), List("1400 Beltline Rd","Apt 312","Dallas","Tx","75240") ) )
val tryLinesIrvingTxNoHeader = tryProcessSource( new File("C:/Users/Jim/Desktop/test.csv") , parseLine = (index, unparsedLine) => Some(unparsedLine.split(",").toList) , filterLine = (index, parsedValues) => Some( (index != 0) && (parsedValues(2).toLowerCase == "Irving".toLowerCase) && (parsedValues(3).toLowerCase == "Tx".toLowerCase) ) )
Success( List( List("100 Main Str","","Irving,TX","75039"), List("231 Park Ave","","Irving","TX","75039"), ) )
import scala.io.Source import scala.util.Try import java.io.File def tryProcessSource( file: File, parseLine: (Int, String) => Option[List[String]] = (index, unparsedLine) => Some(List(unparsedLine)), filterLine: (Int, List[String]) => Option[Boolean] = (index, parsedValues) => Some(true), retainValues: (Int, List[String]) => Option[List[String]] = (index, parsedValues) => Some(parsedValues) ): Try[List[List[String]]] = { def usingSource[S <: Source, R](source: S)(transfer: S => R): Try[R] = try {Try(transfer(source))} finally {source.close()} def recursive( remaining: Iterator[(String, Int)], accumulator: List[List[String]], isEarlyAbort: Boolean = false ): List[List[String]] = { if (isEarlyAbort || !remaining.hasNext) accumulator else { val (line, index) = remaining.next parseLine(index, line) match { case Some(values) => filterLine(index, values) match { case Some(keep) => if (keep) retainValues(index, values) match { case Some(valuesNew) => recursive(remaining, valuesNew :: accumulator) case None => recursive(remaining, accumulator, isEarlyAbort = true) } else recursive(remaining, accumulator) case None => recursive(remaining, accumulator, isEarlyAbort = true) } case None => recursive(remaining, accumulator, isEarlyAbort = true) } } } Try(Source.fromFile(file)).flatMap( bufferedSource => usingSource(bufferedSource) { source => recursive(source.getLines().buffered.zipWithIndex, Nil).reverse } ) }
def tryProcessSource2[A <: AnyRef]( file: File, parseLine: (Int, String) => Option[List[String]] = (index, unparsedLine) => Some(List(unparsedLine)), filterLine: (Int, List[String]) => Option[Boolean] = (index, parsedValues) => Some(true), transformLine: (Int, List[String]) => Option[A] = (index, parsedValues) => Some(parsedValues) ): Try[List[A]] = { ??? }
Exception() Exception(String message) Exception(String message, Throwable cause) Exception(Throwable cause)
val e1 = new RuntimeException() e.getCause e.getMessage val cause = new RuntimeException("cause msg") val e2 = new RuntimeException(cause) e.getMessage()
class MyException(message: String = null, cause: Throwable = null) extends RuntimeException(MyException.defaultMessage(message, cause), cause) object MyException { def defaultMessage(message: String, cause: Throwable) = if (message != null) message else if (cause != null) cause.toString() else null } new MyException(cause = myCause)
class MissingConfigurationException private(ex: RuntimeException) extends RuntimeException(ex) { def this(message:String) = this(new RuntimeException(message)) def this(message:String, throwable: Throwable) = this(new RuntimeException(message, throwable)) } object MissingConfigurationException { def apply(message:String) = new MissingConfigurationException(message) def apply(message:String, throwable: Throwable) = new MissingConfigurationException(message, throwable) }
class MyException (message: String, cause: Throwable) extends RuntimeException(message) { if (cause != null) initCause(cause) def this(message: String) = this(message, null) }
class MyRuntimeException ( val optionMessage: Option[String], val optionCause: Option[Throwable], val isEnableSuppression: Boolean, val isWritableStackTrace: Boolean ) extends RuntimeException( optionMessage match { case Some(string) => string case None => null }, optionCause match { case Some(throwable) => throwable case None => null }, isEnableSuppression, isWritableStackTrace ) { def this() = this(None, None, false, false) def this(message: String) = this(Some(message), None, false, false) def this(cause: Throwable) = this(None, Some(cause), false, false) def this(message: String, cause: Throwable) = this(Some(message), Some(cause), false, false) }
object MyRuntimeException { def apply: MyRuntimeException = MyRuntimeException() def apply(message: String): MyRuntimeException = MyRuntimeException(optionMessage = Some(message)) def apply(cause: Throwable): MyRuntimeException = MyRuntimeException(optionCause = Some(cause)) def apply(message: String, cause: Throwable): MyRuntimeException = MyRuntimeException(optionMessage = Some(message), optionCause = Some(cause)) def apply( optionMessage: Option[String] = None, optionCause: Option[Throwable] = None, isEnableSuppression: Boolean = false, isWritableStackTrace: Boolean = false ): MyRuntimeException = new MyRuntimeException( optionMessage, optionCause, isEnableSuppression, isWritableStackTrace ) }
object MyRuntimeException { def apply: MyRuntimeException = MyRuntimeException() def apply(message: String): MyRuntimeException = MyRuntimeException(optionMessage = Some(message)) def apply(cause: Throwable): MyRuntimeException = MyRuntimeException(optionCause = Some(cause)) def apply(message: String, cause: Throwable): MyRuntimeException = MyRuntimeException(optionMessage = Some(message), optionCause = Some(cause)) def apply( optionMessage: Option[String] = None, optionCause: Option[Throwable] = None, isEnableSuppression: Boolean = false, isWritableStackTrace: Boolean = false ): MyRuntimeException = new MyRuntimeException( optionMessage, optionCause, isEnableSuppression, isWritableStackTrace ) } class MyRuntimeException private[MyRuntimeException] ( val optionMessage: Option[String], val optionCause: Option[Throwable], val isEnableSuppression: Boolean, val isWritableStackTrace: Boolean ) extends RuntimeException( optionMessage match { case Some(string) => string case None => null }, optionCause match { case Some(throwable) => throwable case None => null }, isEnableSuppression, isWritableStackTrace )
trait FailedPreconditionObject[F <: FailedPrecondition] { def apply: F = apply() def apply(message: String): F = apply(optionMessage = Some(message)) def apply(cause: Throwable): F = apply(optionCause = Some(cause)) def apply(message: String, cause: Throwable): F = apply(optionMessage = Some(message), optionCause = Some(cause)) def apply( optionMessage: Option[String] = None , optionCause: Option[Throwable] = None , isEnableSuppression: Boolean = false , isWritableStackTrace: Boolean = false ): F } abstract class FailedPrecondition ( val optionMessage: Option[String], val optionCause: Option[Throwable], val isEnableSuppression: Boolean, val isWritableStackTrace: Boolean ) extends RuntimeException( optionMessage match { case Some(string) => string case None => null }, optionCause match { case Some(throwable) => throwable case None => null }, isEnableSuppression, isWritableStackTrace )
object FailedPreconditionMustBeNonEmptyList extends FailedPreconditionObject[FailedPreconditionMustBeNonEmptyList] { def apply( optionMessage: Option[String] = None , optionCause: Option[Throwable] = None , isEnableSuppression: Boolean = false , isWritableStackTrace: Boolean = false ): FailedPreconditionMustBeNonEmptyList = new FailedPreconditionMustBeNonEmptyList( optionMessage , optionCause , isEnableSuppression , isWritableStackTrace ) } final class FailedPreconditionMustBeNonEmptyList private[FailedPreconditionMustBeNonEmptyList] ( optionMessage: Option[String] , optionCause: Option[Throwable] , isEnableSuppression: Boolean , isWritableStackTrace: Boolean ) extends FailedPrecondition( optionMessage , optionCause , isEnableSuppression , isWritableStackTrace )
object FailedPreconditionsException { def apply(failedPrecondition: FailedPrecondition): FailedPreconditionsException = FailedPreconditionsException(List(failedPrecondition)) def apply(failedPreconditions: List[FailedPrecondition]): FailedPreconditionsException = tryApply(failedPreconditions).get def tryApply(failedPrecondition: FailedPrecondition): Try[FailedPreconditionsException] = tryApply(List(failedPrecondition)) def tryApply(failedPreconditions: List[FailedPrecondition]): Try[FailedPreconditionsException] = if (failedPreconditions.nonEmpty) Success(new FailedPreconditionsException(failedPreconditions)) else Failure(FailedPreconditionMustBeNonEmptyList()) private def composeMessage(failedPreconditions: List[FailedPrecondition]): String = if (failedPreconditions.size > 1) s"failed preconditions [${failedPreconditions.size}] have occurred - ${failedPreconditions.map(_.optionMessage.getOrElse("")).mkString("|")}" else s"failed precondition has occurred - ${failedPreconditions.head.optionMessage.getOrElse("")}" } final class FailedPreconditionsException private[FailedPreconditionsException] ( val failedPreconditions: List[FailedPrecondition] ) extends RuntimeException(FailedPreconditionsException.composeMessage(failedPreconditions))
object FailedPreconditionsException { trait FailedPreconditionObject[F <: FailedPrecondition] { def apply: F = apply() def apply(message: String): F = apply(optionMessage = Some(message)) def apply(cause: Throwable): F = apply(optionCause = Some(cause)) def apply(message: String, cause: Throwable): F = apply(optionMessage = Some(message), optionCause = Some(cause)) def apply( optionMessage: Option[String] = None , optionCause: Option[Throwable] = None , isEnableSuppression: Boolean = false , isWritableStackTrace: Boolean = false ): F } abstract class FailedPrecondition ( val optionMessage: Option[String] , val optionCause: Option[Throwable] , val isEnableSuppression: Boolean , val isWritableStackTrace: Boolean ) extends RuntimeException( optionMessage match { case Some(string) => string case None => null }, optionCause match { case Some(throwable) => throwable case None => null }, isEnableSuppression, isWritableStackTrace ) object FailedPreconditionMustBeNonEmptyList extends FailedPreconditionObject[FailedPreconditionMustBeNonEmptyList] { def apply( optionMessage: Option[String] = None , optionCause: Option[Throwable] = None , isEnableSuppression: Boolean = false , isWritableStackTrace: Boolean = false ): FailedPreconditionMustBeNonEmptyList = new FailedPreconditionMustBeNonEmptyList( optionMessage , optionCause , isEnableSuppression , isWritableStackTrace ) } final class FailedPreconditionMustBeNonEmptyList private[FailedPreconditionMustBeNonEmptyList] ( optionMessage: Option[String] , optionCause: Option[Throwable] , isEnableSuppression: Boolean , isWritableStackTrace: Boolean ) extends FailedPrecondition( optionMessage , optionCause , isEnableSuppression , isWritableStackTrace ) def apply(failedPrecondition: FailedPrecondition): FailedPreconditionsException = FailedPreconditionsException(List(failedPrecondition)) def apply(failedPreconditions: List[FailedPrecondition]): FailedPreconditionsException = tryApply(failedPreconditions).get def tryApply(failedPrecondition: FailedPrecondition): Try[FailedPreconditionsException] = tryApply(List(failedPrecondition)) def tryApply(failedPreconditions: List[FailedPrecondition]): Try[FailedPreconditionsException] = if (failedPreconditions.nonEmpty) Success(new FailedPreconditionsException(failedPreconditions)) else Failure(FailedPreconditionMustBeNonEmptyList()) private def composeMessage(failedPreconditions: List[FailedPrecondition]): String = if (failedPreconditions.size > 1) s"failed preconditions [${failedPreconditions.size}] have occurred - ${failedPreconditions.map(_.optionMessage.getOrElse("")).mkString("|")}" else s"failed precondition has occurred - ${failedPreconditions.head.optionMessage.getOrElse("")}" } final class FailedPreconditionsException private[FailedPreconditionsException] ( val failedPreconditions: List[FailedPreconditionsException.FailedPrecondition] ) extends RuntimeException(FailedPreconditionsException.composeMessage(failedPreconditions))
object FailedPreconditionMustBeNonEmptyString extends FailedPreconditionObject[FailedPreconditionMustBeNonEmptyString] { def apply( optionMessage: Option[String] = None , optionCause: Option[Throwable] = None , isEnableSuppression: Boolean = false , isWritableStackTrace: Boolean = false ): FailedPreconditionMustBeNonEmptyString = new FailedPreconditionMustBeNonEmptyString( optionMessage , optionCause , isEnableSuppression , isWritableStackTrace ) } final class FailedPreconditionMustBeNonEmptyString private[FailedPreconditionMustBeNonEmptyString] ( optionMessage: Option[String] , optionCause: Option[Throwable] , isEnableSuppression: Boolean , isWritableStackTrace: Boolean ) extends FailedPrecondition( optionMessage , optionCause , isEnableSuppression , isWritableStackTrace )
trait MyException extends RuntimeException class MyExceptionEmpty() extends RuntimeException with MyException class MyExceptionStr(msg: String) extends RuntimeException(msg) with MyException class MyExceptionEx(t: Throwable) extends RuntimeException(t) with MyException object MyException { def apply(): MyException = new MyExceptionEmpty() def apply(msg: String): MyException = new MyExceptionStr(msg) def apply(t: Throwable): MyException = new MyExceptionEx(t) } class MyClass { try { throw MyException("oops") } catch { case e: MyException => println(e.getMessage) case _: Throwable => println("nope") } }
case class ShortException(message: String = "", cause: Option[Throwable] = None) extends Exception(message) { cause.foreach(initCause) }
throw ShortException() throw ShortException(message) throw ShortException(message, Some(cause)) throw ShortException(cause = Some(cause))
def eagerEval(x: Int) = { println("eager"); x; } def lazyEval(x: => Int) = { println("lazy"); x; }
eagerEval(answer + 2) > answer > eager lazyEval(answer + 2) > lazy > answer
scala> def myfunc(f : () => Int ) = println("Evaluated: " + f ) myfunc: (f: () => Int)Unit scala> def myfunc2(f : => Int ) = println("Evaluated: " + f ) myfunc2: (f: => Int)Unit scala> myfunc({1}) <console>:9: error: type mismatch; found : Int(1) required: () => Int myfunc({1}) ^ scala> myfunc2({1}) Evaluated: 1
case class MyCase(name: String, age: Int) data : List[MyCase] = ... data foreach { case MyCase(_, age) if age > 21 => println("old enough") case MyCase("fred", _ ) => println("Got you") case _ => ... }
scala> case class Time(hours: Int = 0, mins: Int = 0) defined class Time scala> val time1 = Time(12, 13) time1: Time = Time(12,13) scala> val time2 = Time(11, 12) time2: Time = Time(11,12) scala> time1 == time2 res6: Boolean = false scala> val time3 = Time(10, 11) time3: Time = Time(10,11) scala> time1 == time2 res7: Boolean = false
scala> import scala.reflect.runtime.{universe => u} import scala.reflect.runtime.{universe=>u} scala> val expr = u reify { 1 to 3 map (_+1) } expr: reflect.runtime.universe.Expr[scala.collection.immutable.IndexedSeq[Int]] = Expr[scala.collection.immutable.IndexedSeq[Int]](scala.this.Predef.intWrapper(1).to(3).map(((x$1) => x$1.$plus(1)))(immutable.this.IndexedSeq.canBuildFrom)) scala> u show expr.tree res57: String = scala.this.Predef.intWrapper(1).to(3).map(((x$1) => x$1.$plus(1)))(immutable.this.IndexedSeq.canBuildFrom) scala> u showRaw expr.tree res58: String = Apply(Apply(Select(Apply(Select(Apply(Select(Select(This(newTypeName("scala")), newTermName("Predef")), newTermName("intWrapper")), List(Literal(Constant(1)))), newTermName("to")), List(Literal(Constant(3)))), newTermName("map")), List(Function(List(ValDef(Modifiers(<param> <synthetic>), newTermName("x$1"), TypeTree(), EmptyTree)), Apply(Select(Ident(newTermName("x$1")), newTermName("$plus")), List(Literal(Constant(1))))))), List(Select(Select(This(newTypeName("immutable")), newTermName("IndexedSeq")), newTermName("canBuildFrom"))))
scala> import scala.tools.reflect.ToolBox import scala.tools.reflect.ToolBox scala> import scala.reflect.runtime.{currentMirror => m} import scala.reflect.runtime.{currentMirror=>m} scala> val tb = m.mkToolBox() tb: scala.tools.reflect.ToolBox[reflect.runtime.universe.type] = scala.tools.reflect.ToolBoxFactory$ToolBoxImpl@9293709 scala> val tree = tb.parse("1 to 3 map (_+1)") tree: tb.u.Tree = 1.to(3).map(((x$1) => x$1.$plus(1))) scala> val eval = tb.eval(tree) eval: Any = Vector(2, 3, 4)
object IntMacro { import language.experimental.macros import scala.reflect.makro.Context import scala.reflect.NameTransformer.encode def isEven(i: Int): Boolean = macro isEvenImpl def isEvenImpl(c: Context)(i: c.Expr[Int]): c.Expr[Boolean] = { import c.universe._ implicit val cc: c.type = c val `x = i%2` = Apply(Select(i.tree, op("%")), const(2)) val `x == 0` = Apply(Select(`x = i%2`, op("==")), const(0)) c.Expr(`x == 0`) } def op(s: String)(implicit c: Context): c.universe.TermName = c.universe.newTermName(encode(s)) def const(a: Any)(implicit c: Context): List[c.universe.Literal] = List(c.universe.Literal(c.universe.Constant(a))) } scala> import IntMacro._ import IntMacro._ scala> isEven(2) res60: Boolean = true scala> isEven(3) res61: Boolean = false
scala> import scala.tools.reflect.ToolBox import scala.tools.reflect.ToolBox scala> import scala.reflect.runtime.{currentMirror => m} import scala.reflect.runtime.{currentMirror=>m} scala> val tb = m.mkToolBox() tb: scala.tools.reflect.ToolBox[reflect.runtime.universe.type] = scala.tools.reflect.ToolBoxFactory$ToolBoxImpl@78dc5f15 scala> val tree = tb.parseExpr("1 to 3 map (_+1)") <console>:10: error: value parseExpr is not a member of scala.tools.reflect.ToolBox[reflect.runtime.universe.type] val tree = tb.parseExpr("1 to 3 map (_+1)") ^ scala> val tree = tb.parse("1 to 3 map (_+1)") tree: tb.u.Tree = 1.to(3).map(((x$1) => x$1.$plus(1))) scala> val eval = tb.eval(tree) eval: Any = Vector(2, 3, 4)
scala> Array(1, 2, 3).toSeq res0: Seq[Int] = WrappedArray(1, 2, 3) scala> Array(1, 2, 3).to[collection.immutable.Seq] res1: scala.collection.immutable.Seq[Int] = Vector(1, 2, 3)
15/09/22 18:46:24 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies) 15/09/22 18:46:24 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies) 15/09/22 18:46:27 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0 15/09/22 18:46:27 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException 15/09/22 18:46:27 WARN : Your hostname, DESKTOP-8JS2RD5 resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:103%net1, but we couldn java.lang.RuntimeException: java.lang.NullPointerException at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522) at org.apache.spark.sql.hive.client.ClientWrapper.<init> (ClientWrapper.scala:171) at org.apache.spark.sql.hive.HiveContext.executionHive$lzycompute(HiveContext.scala :163) at org.apache.spark.sql.hive.HiveContext.executionHive(HiveContext.scala:161) at org.apache.spark.sql.hive.HiveContext.<init>(HiveContext.scala:168) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) at java.lang.reflect.Constructor.newInstance(Unknown Source) at org.apache.spark.repl.SparkILoop.createSQLContext(SparkILoop.scala:1028) at $iwC$$iwC.<init>(<console>:9) at $iwC.<init>(<console>:18) at <init>(<console>:20) at .<init>(<console>:24) at .<clinit>(<console>) at .<init>(<console>:7) at .<clinit>(<console>) at $print(<console>) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065) at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340) at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840) at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871) at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819) at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857) at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902) at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814) at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:132) at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:124) at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:324) at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:124) at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:64) at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:974) at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:159) at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:64) at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.sca la:108) at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:64) at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$proc ess$1.apply$mcZ$sp(SparkILoop.scala:991) at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$proc ess$1.apply(SparkILoop.scala:945) at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$proc ess$1.apply(SparkILoop.scala:945) at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scal a:135) at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945) at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059) at org.apache.spark.repl.Main$.main(Main.scala:31) at org.apache.spark.repl.Main.main(Main.scala) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672) at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180) at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) Caused by: java.lang.NullPointerException at java.lang.ProcessBuilder.start(Unknown Source) at org.apache.hadoop.util.Shell.runCommand(Shell.java:445) at org.apache.hadoop.util.Shell.run(Shell.java:418) at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:650) at org.apache.hadoop.util.Shell.execCommand(Shell.java:739) at org.apache.hadoop.util.Shell.execCommand(Shell.java:722) at org.apache.hadoop.fs.FileUtil.execCommand(FileUtil.java:1097) at org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:559) at org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.getPermission(RawLocalFileSystem.java:534) org.apache.hadoop.hive.ql.session.SessionState.createRootHDFSDir(SessionState.java:599) at org.apache.hadoop.hive.ql.session.SessionState.createSessionDirs(SessionState.java:554)
<console>:10: error: not found: value sqlContext import sqlContext.implicits._ ^ <console>:10: error: not found: value sqlContext import sqlContext.sql ^
spark = SparkSession.builder.config("spark.sql.warehouse.dir", "C:/temp").appName("SparkSQL").getOrCreate()
C:\Windows\system32>C:\winutils\bin\winutils.exe chmod 777 C:/temp
spark-shell --driver-class-path /home/username/spark-1.6.0-libs-mysqlconnector.jar
case class Person(name: String, height: String, attributes: Map[String, String], friends: List[String]) val person = Person("Name", ....) val json = serialize(person) val sameperson = deserialize[Person](json)
libraryDependencies ++= Seq( "com.fasterxml.jackson.module" %% "jackson-module-scala" % "2.1.3", ... )
import java.lang.reflect.{Type, ParameterizedType} import com.fasterxml.jackson.databind.ObjectMapper import com.fasterxml.jackson.module.scala.DefaultScalaModule import com.fasterxml.jackson.annotation.JsonProperty; import com.fasterxml.jackson.core.`type`.TypeReference; object JacksonWrapper { val mapper = new ObjectMapper() mapper.registerModule(DefaultScalaModule) def serialize(value: Any): String = { import java.io.StringWriter val writer = new StringWriter() mapper.writeValue(writer, value) writer.toString } def deserialize[T: Manifest](value: String) : T = mapper.readValue(value, typeReference[T]) private [this] def typeReference[T: Manifest] = new TypeReference[T] { override def getType = typeFromManifest(manifest[T]) } private [this] def typeFromManifest(m: Manifest[_]): Type = { if (m.typeArguments.isEmpty) { m.erasure } else new ParameterizedType { def getRawType = m.erasure def getActualTypeArguments = m.typeArguments.map(typeFromManifest).toArray def getOwnerType = null } } }
implicit lazy val CodecCustomer: CodecJson[Customer] = casecodec6(Customer.apply, Customer.unapply)("id","name","address","city","state","user_id")
package argonaut.example import org.specs2.{ScalaCheck, Specification} import argonaut.CodecJson import argonaut.Argonaut._ case class Customer(id: Int, name: String, address: Option[String], city: Option[String], state: Option[String], user_id: Int) class CustomerExample extends Specification with ScalaCheck { import CustomerExample.CodecCustomer import CustomerExample.customers def is = "Stackoverflow question 12591457 example" ^ "round trip customers to and from json strings " ! { customers.asJson.as[List[Customer]].toOption must beSome(customers) } } object CustomerExample { implicit lazy val CodecCustomer: CodecJson[Customer] = casecodec6(Customer.apply, Customer.unapply)("id","name","address","city","state","user_id") val customers = List( Customer(1,"one",Some("one street"),Some("one city"),Some("one state"),1) , Customer(2,"two",None,Some("two city"),Some("two state"),2) , Customer(3,"three",Some("three address"),None,Some("three state"),3) , Customer(4,"four",Some("four address"),Some("four city"),None,4) ) def main(args: Array[String]): Unit = { println(s"Customers converted into json string:\n ${customers.asJson}") val jsonString = """[ | {"city":"one city","name":"one","state":"one state","user_id":1,"id":1,"address":"one street"} | ,{"city":"two city","name":"two","state":"two state","user_id":2,"id":2} | ,{"name":"three","state":"three state","user_id":3,"id":3,"address":"three address"} | ,{"city":"four city","name":"four","user_id":4,"id":4,"address":"four address"} |]""".stripMargin var parsed: Option[List[Customer]] = jsonString.decodeOption[List[Customer]] println(s"Json string turned back into customers:\n ${parsed.get}") } }
import net.liftweb.json._ import Extraction._ implicit val formats = DefaultFormats case class Person(...) val person = Person(...) val personJson = decompose(person)
> testOnly -- -z insert > testOnly *TreeSpec -- -z insert
auto var = 10; template <typename T> void my_function(T arg) { ... } my_function(1) template <typename T> void my_function(std::vector<T> arg) { ... } std::vector<int> my_vec = {1, 2, 3, 4}; my_function(my_vec)
int local = 10; auto my_closure = [&]() { return local;}; my_closure();
std::vector<int> vec = {1, 2, 3, 4}; int sum = std::accumulate(vec.begin(), vec.end(), [](int x, int y) { return x + y; });
object S { def apply(a: A):S = ... def unapply(s: S): Option[A] = ... } val s = S(a) s match { case S(a) => a }
object M { def apply(a: A*): M = ......... def unapplySeq(m: M): Option[Seq[A]] = ... } val m = M(a1, a2, a3) m match { case M(a1, a2, a3) => ... } m match { case M(a, as @ _*) => ... }
object Sorted { def unapply(xs: Seq[Int]) = if (xs == xs.sortWith(_ < _)) Some(xs) else None } object SortedSeq { def unapplySeq(xs: Seq[Int]) = if (xs == xs.sortWith(_ < _)) Some(xs) else None } scala> List(1,2,3,4) match { case Sorted(xs) => xs } res0: Seq[Int] = List(1, 2, 3, 4) scala> List(1,2,3,4) match { case SortedSeq(a, b, c, d) => List(a, b, c, d) } res1: List[Int] = List(1, 2, 3, 4) scala> List(1) match { case SortedSeq(a) => a } res2: Int = 1
scala> List(1) match { case List(x) => x } res3: Int = 1
set build.scala.versions 2.7.7 reload set build.scala.versions 2.8.0.RC2 reload
libraryDependencies ++= Seq( jdbc, "mysql" % "mysql-connector-java" % "5.1.29", "org.apache.spark" %% "spark-core" % "1.0.1", )
val classes = Seq( getClass, classOf[mysql.jdbc.Driver] ) val jars = classes.map(_.getProtectionDomain().getCodeSource().getLocation().getPath()) val conf = new SparkConf().setJars(jars)
val rdd = new org.apache.spark.rdd.JdbcRDD( sc, () => { sql.DriverManager.getConnection("jdbc:mysql: }, "SELECT * FROM BOOKS WHERE ? <= KEY AND KEY <= ?", 0, 1000, 10, row => row.getString("BOOK_TITLE") )
val df = sqlContext.load("jdbc", Map( "url" -> "jdbc:mysql: "dbtable" -> "BOOKS"))
rdd.foreachPartition { it => val conn = sql.DriverManager.getConnection("jdbc:mysql: val del = conn.prepareStatement("DELETE FROM BOOKS WHERE BOOK_TITLE = ?") for (bookTitle <- it) { del.setString(1, bookTitle) del.executeUpdate } }
Files.readAllLines(Paths.get("file_name"), StandardCharsets.UTF_8).asScala
val strs = Seq("line1", "line2", "line3") Files.write(Paths.get("output_file"), strs.mkString("\n").getBytes())
def trait2Impl(original: ClassDef, newName: String): ClassDef = { val impl = original.impl val self = impl.self val body = impl.body val parents = original :: impl.parents val newImpl = treeCopy.Template(impl, parents, self, body) val name = newTypeName(newName) val mods = (original.mods | SYNTHETIC) &~ TRAIT val tp = original.tparams val result = treeCopy.ClassDef(original, mods, name, tp, newImpl) val owner = original.symbol.owner val symbol = new TypeSymbol(owner, NoPosition, name) result.setSymbol(symbol) symbol.setFlag(SYNTHETIC) symbol.setFlag(ABSTRACT) symbol.resetFlag(INTERFACE) symbol.resetFlag(TRAIT) owner.info.decls.enter(symbol) result }
package <empty> { class Foo { def foo { "spring" } } }
package <empty> { class Foo { def foo { "spring" } } package mypackage { class MyClass extends AnyRef } }
final class &[A, B](val a: A, val b: B) implicit def productToA[A, B](ab: A & B): A = ab.a implicit def productToB[A, B](ab: A & B): B = ab.b implicit def viewsToProduct[A, V1, V2](a: A)(implicit v1: A => V1, v2: A => V2) = new &(v1(a), v2(a))
trait Foo { def foo: String } trait Bar { def bar: String } implicit def stringFoo(a: String) = new Foo { def foo = a + " sf" } implicit def stringBar(a: String) = new Bar { def bar = a + " sb" } implicit def intFoo(a: Int) = new Foo { def foo = a.toString + " if" } implicit def intBar(a: Int) = new Bar { def bar = a.toString + " ib" } val s1 = Seq[Foo & Bar]("hoho", 1) val s2 = s1 flatMap (ab => Seq(ab.foo, ab.bar))
def cata[X](some: A => X, none: => X): X = value match { case None => none case Some(a) => some(a) }
def toList[A](x: Option[A]) = x.fold(Nil)(_ :: Nil)
x.fold[List[A]](Nil)(_ :: Nil) x.fold(Nil: List[A])(_ :: Nil)
Stream.continually(is.read).takeWhile(_ != -1).map(_.toByte).toArray
Stream.continually(request.getInputStream.read()).takeWhile(_ != -1).map(_.toByte).toArray
org.apache.commons.io.IOUtils.toByteArray(request.getInputStream)
def inputStreamToByteArray(is: InputStream): Array[Byte] = Iterator continually is.read takeWhile (-1 !=) map (_.toByte) toArray
import scala.tools.nsc.io.Streamable Streamable.bytes(is)
new Streamable.Bytes { def inputStream() = is } toByteArray
def inputStreamToByteArray(is: InputStream): Array[Byte] = Resource.fromInputStream(in).byteArray
import scalaz.concurrent.Task import scalaz.stream._ import scodec.bits.ByteVector def allBytesR(is: InputStream): Process[Task, ByteVector] = io.chunkR(is).evalMap(_(4096)).reduce(_ ++ _).lastOr(ByteVector.empty)
def inputStreamToByteArray(is: InputStream): Array[Byte] = { val buf = ListBuffer[Byte]() var b = is.read() while (b != -1) { buf.append(b.byteValue) b = is.read() } buf.toArray }
implicit val system = ActorSystem() implicit val executor = system.dispatcher implicit val materializer = ActorMaterializer() val routes = (post & entity(as[String])) { e => complete { Future{ Thread.sleep(5000) e } } } ~ (get & path(Segment)) { r => complete { "get" } }
implicit val defaultDispatcher = system.dispatcher val routes: Route = post { complete { Future { Thread.sleep(5000) System.currentTimeMillis().toString } } }
my-blocking-dispatcher { type = Dispatcher executor = "thread-pool-executor" thread-pool-executor { core-pool-size-min = 16 core-pool-size-max = 16 max-pool-size-min = 16 max-pool-size-max = 16 fixed-pool-size = 16 } throughput = 100 }
implicit val blockingDispatcher = system.dispatchers.lookup("my-blocking-dispatcher") val routes: Route = post { complete { Future { Thread.sleep(5000) System.currentTimeMillis().toString } } }
implicit val dispatcher = system.dispatcher val routes: Route = post { complete { Future { blocking { Thread.sleep(5000) System.currentTimeMillis().toString } } } }
import akka.actor.ActorSystem import akka.http.scaladsl.Http import akka.http.scaladsl.server.Directives._ import akka.http.scaladsl.server.Route import akka.stream.ActorMaterializer import scala.concurrent.Future object Main { implicit val system = ActorSystem() implicit val executor = system.dispatcher implicit val materializer = ActorMaterializer() val routes: Route = (post & entity(as[String])) { e => complete { Future { Thread.sleep(5000) e } } } ~ (get & path(Segment)) { r => complete { "get" } } def main(args: Array[String]) { Http().bindAndHandle(routes, "0.0.0.0", 9000).onFailure { case e => system.shutdown() } } }
onComplete(Future{Thread.sleep(5000)}){e} onSuccess(Future{Thread.sleep(5000)}){complete(e)}
def rep[A](n: Int)(f: => A) { if (n > 0) { f; rep(n-1)(f) } }
class Rep(n: Int) { def times[A](f: => A) { loop(f, n) } private def loop[A](f: => A, n: Int) { if (n > 0) { f; loop(f, n-1) } } } implicit def int2Rep(i: Int): Rep = new Rep(i) 10.times { println("hi") }
implicit class Rep(n: Int) { def times[A](f: => A) { 1 to n foreach(_ => f) } } 10.times { println("hi") }
scala> import scalaz._; import Scalaz._; import effects._; import scalaz._ import Scalaz._ import effects._ scala> 5 times "foo" res0: java.lang.String = foofoofoofoofoo scala> 5 times List(1,2) res1: List[Int] = List(1, 2, 1, 2, 1, 2, 1, 2, 1, 2) scala> 5 times 10 res2: Int = 50 scala> 5 times ((x: Int) => x + 1).endo res3: scalaz.Endo[Int] = <function1> scala> res3(10) res4: Int = 15 scala> 5 times putStrLn("Hello, World!") res5: scalaz.effects.IO[Unit] = scalaz.effects.IO$$anon$2@36659c23 scala> res5.unsafePerformIO Hello, World! Hello, World! Hello, World! Hello, World! Hello, World!
Set(1, 2) should equal (List(1, 2)) Iterable(2, 1) should equal (Iterable(1, 2))
class Temp extends FunSuite with ShouldMatchers { test("1") { Array(1, 2).toSeq should equal (List(1, 2).toSeq) } test("2") { Array(2, 1).toSeq should not equal (List(1, 2).toSeq) } test("2b") { Array(2, 1) should not equal (List(1, 2)) } test("3") { Iterable(2, 1).toSet should equal (Iterable(1, 2).toSet) } test("4") { Iterable(2, 1) should not equal (Iterable(1, 2)) } }
test("5") { Iterable(2, 1).toSeq.sorted should equal (Iterable(1, 2).toSeq.sorted) } test("6") { Iterable(2, 1).toSeq should not equal (Iterable(1, 2).toSeq) }
def sameAs[A](c: Traversable[A], d: Traversable[A]): Boolean = if (c.isEmpty) d.isEmpty else { val (e, f) = d span (c.head !=) if (f.isEmpty) false else sameAs(c.tail, e ++ f.tail) }
test("7") { assert( sameAs(Iterable(2, 1), Iterable(1, 2) )) } test("8") { assert( sameAs(Array( test("9") { assert( sameAs("cba", Set(
def sameAs[A](c: Traversable[A], d: Traversable[A]) = { def counts(e: Traversable[A]) = e groupBy identity mapValues (_.size) counts(c) == counts(d) }
Iterable(2, 1) should contain theSameElementsAs Iterable(1, 2)
Set(1, 2).toSeq should contain theSameElementsInOrderAs List(1, 2)
try { ... do something risky ... } catch { case e: IOException => ... case e: OtherException => ... }
val mixedList = List("a", 1, 2, "b", 19, 42.0) val results = mixedList collect { case s: String => "String:" + s case i: Int => "Int:" + i.toString }
var strings = List.empty[String] var ints = List.empty[Int] mixedList collect { case s: String => strings :+= s case i: Int => ints :+= i }
val strings = mixedList collect { case s: String => s } val ints = mixedList collect { case i: Int => i }
val (strings, ints) = mixedList partition { case s: String => true; case _ => false }
val intList = List(2,7,9,1,6,5,8,2,4,6,2,9,8) val (big,small) = intList partition (_ > 5)
List("a", 1, 2, "b", 19).partition { case s:String => true case _ => false }
collect[B, That](pf: PartialFunction[A,B])( implicit bf: CanBuildFrom[Seq[A], B, That] ): That
def optionClass(a: Any) = a match { case None => 0 case Some(x) => 1 case _ => 2 } scala> List(None,3,Some(2),5,None).groupBy(optionClass) res11: scala.collection.immutable.Map[Int,List[Any]] = Map((2,List(3, 5)), (1,List(Some(2))), (0,List(None, None)))
/** * Splits the input list into a list of B */ def mapSplit[A,B,C](in: List[A])(mapper: (A) => Either[B,C]): (List[B], List[C]) = { @tailrec def mapSplit0(in: List[A], bs: List[B], cs: List[C]): (List[B], List[C]) = { in match { case a :: as => mapper(a) match { case Left(b) => mapSplit0(as, b :: bs, cs ) case Right(c) => mapSplit0(as, bs, c :: cs) } case Nil => (bs.reverse, cs.reverse) } } mapSplit0(in, Nil, Nil) } val got = mapSplit(List(1,2,3,4,5)) { case x if x % 2 == 0 => Left(x) case y => Right(y.toString * y) } assertEquals((List(2,4),List("1","333","55555")), got)
implicit class TraversableOnceHelper[A,Repr](private val repr: Repr)(implicit isTrav: Repr => TraversableOnce[A]) { def collectPartition[B,Left](pf: PartialFunction[A, B]) (implicit bfLeft: CanBuildFrom[Repr, B, Left], bfRight: CanBuildFrom[Repr, A, Repr]): (Left, Repr) = { val left = bfLeft(repr) val right = bfRight(repr) val it = repr.toIterator while (it.hasNext) { val next = it.next if (!pf.runWith(left += _)(next)) right += next } left.result -> right.result } def mapSplit[B,C,Left,Right](f: A => Either[B,C]) (implicit bfLeft: CanBuildFrom[Repr, B, Left], bfRight: CanBuildFrom[Repr, C, Right]): (Left, Right) = { val left = bfLeft(repr) val right = bfRight(repr) val it = repr.toIterator while (it.hasNext) { f(it.next) match { case Left(next) => left += next case Right(next) => right += next } } left.result -> right.result } }
val (syms, ints) = Seq(Left( val ctx = Map( val (bound, unbound) = Vector( println(bound: Vector[(Symbol, Int)], unbound: Vector[Symbol])
val (strings, ints) = List("a", 1, 2, "b", 19).partitionWith { case s: String => Left(s) case x: Int => Right(x) }
import com.holdenkarau.spark.testing.DataFrameSuiteBase import org.junit.Test import org.scalatest.FunSuite import org.apache.spark.sql.SparkSession class SessionTest extends FunSuite with DataFrameSuiteBase { implicit val sparkImpl: SparkSession = spark @Test def simpleLookupTest { val homeDir = System.getProperty("user.home") val training = spark.read.format("libsvm") .load(s"$homeDir\\Documents\\GitHub\\sample_linear_regression_data.txt") println("completed simple lookup test") } }
java.lang.NullPointerException at SessionTest.simpleLookupTest(SessionTest.scala:16) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:237) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
class MySpec extends WordSpec with Matchers with SparkContextSetup { "My analytics" should { "calculate the right thing" in withSparkContext { (sparkContext) => val data = Seq(...) val rdd = sparkContext.parallelize(data) val total = rdd.map(...).filter(...).map(...).reduce(_ + _) total shouldBe 1000 } } } trait SparkContextSetup { def withSparkContext(testMethod: (SparkContext) => Any) { val conf = new SparkConf() .setMaster("local") .setAppName("Spark test") val sparkContext = new SparkContext(conf) try { testMethod(sparkContext) } finally sparkContext.stop() } }
class MySpec extends WordSpec with Matchers with SharedSparkContext { "My analytics" should { "calculate the right thing" in { val data = Seq(...) val rdd = sc.parallelize(data) val total = rdd.map(...).filter(...).map(...).reduce(_ + _) total shouldBe 1000 } } }
val sparkContext: SparkContext = ... val data: Seq[(String, String)] = Seq(("a", "1"), ("b", "2"), ("c", "3")) val rdd: RDD[(String, String)] = sparkContext.parallelize(data) val strings: mutable.Queue[RDD[(String, String)]] = mutable.Queue.empty[RDD[(String, String)]] val streamingContext = new StreamingContext(sparkContext, Seconds(1)) val dStream: InputDStream = streamingContext.queueStream(strings) strings += rdd
class Tests extends FunSuite with BeforeAndAfterEach { var sparkSession : SparkSession = _ override def beforeEach() { sparkSession = SparkSession.builder().appName("udf testings") .master("local") .config("", "") .getOrCreate() } test("your test name here"){ assert("True".toLowerCase == "true") } override def afterEach() { sparkSession.stop() } }
class TestSharedSparkContext extends FunSuite with SharedSparkContext { val expectedResult = List(("a", 3),("b", 2),("c", 4)) test("Word counts should be equal to expected") { verifyWordCount(Seq("c a a b a c b c c")) } def verifyWordCount(seq: Seq[String]): Unit = { assertResult(expectedResult)(new WordCount().transform(sc.makeRDD(seq)).collect().toList) } }
import org.apache.spark.sql.SparkSession trait SparkSessionTestWrapper { lazy val spark: SparkSession = { SparkSession.builder().master("local").appName("spark session").getOrCreate() } }
class DatasetSpec extends FunSpec with SparkSessionTestWrapper { import spark.implicits._ describe(" it("returns a count of all the rows in a DataFrame") { val sourceDF = Seq( ("jets"), ("barcelona") ).toDF("team") assert(sourceDF.count === 2) } } }
import com.github.mrpowers.spark.fast.tests.DatasetComparer class DatasetSpec extends FunSpec with SparkSessionTestWrapper with DatasetComparer { import spark.implicits._ it("aliases a DataFrame") { val sourceDF = Seq( ("jose"), ("li"), ("luisa") ).toDF("name") val actualDF = sourceDF.select(col("name").alias("student")) val expectedDF = Seq( ("jose"), ("li"), ("luisa") ).toDF("student") assertSmallDatasetEquality(actualDF, expectedDF) } } }
class YourAppTest extends SharedSQLContext { var app: YourApp = _ protected override def beforeAll(): Unit = { super.beforeAll() app = new YourApp } protected override def afterAll(): Unit = { super.afterAll() } test("Your test") { val df = sqlContext.read.json("examples/src/main/resources/people.json") app.run(df) }
class YourAppTest extends SharedSparkSession { var app: YourApp = _ protected override def beforeAll(): Unit = { super.beforeAll() app = new YourApp } protected override def afterAll(): Unit = { super.afterAll() } test("Your test") { df = spark.read.json("examples/src/main/resources/people.json") app.run(df) }
<dependency> <groupId>org.apache.spark</groupId> <artifactId>spark-sql</artifactId> <version>SPARK_VERSION</version> <type>test-jar</type> <scope>test</scope> </dependency>
"org.apache.spark" %% "spark-sql" % SPARK_VERSION % Test classifier "tests"
class DataFrameTest extends FunSuite with DataFrameSuiteBase{ test("test dataframe"){ val sparkSession=spark import sparkSession.implicits._ var df=sparkSession.read.format("csv").load("path/to/csv") } }
import org.apache.spark.sql.SparkSession import org.junit.Assert._ import org.junit.{After, Before, _} @Test class SessionSparkTest { var spark: SparkSession = _ @Before def beforeFunction(): Unit = { spark = SparkSession.builder().appName("App Name").master("local").getOrCreate() System.out.println("Before Function") } @After def afterFunction(): Unit = { spark.stop() System.out.println("After Function") } @Test def testRddCount() = { val rdd = spark.sparkContext.parallelize(List(1, 2, 3)) val count = rdd.count() assertTrue(3 == count) } @Test def testDfNotEmpty() = { val sqlContext = spark.sqlContext import sqlContext.implicits._ val numDf = spark.sparkContext.parallelize(List(1, 2, 3)).toDF("nums") assertFalse(numDf.head(1).isEmpty) } @Test def testDfEmpty() = { val sqlContext = spark.sqlContext import sqlContext.implicits._ val emptyDf = spark.sqlContext.createDataset(spark.sparkContext.emptyRDD[Num]) assertTrue(emptyDf.head(1).isEmpty) } } case class Num(id: Int)
implicit def bool2int(b:Boolean) = if (b) 1 else 0 scala> false:Int res4: Int = 0 scala> true:Int res5: Int = 1 scala> val b=true b: Boolean = true scala> 2*b+1 res2: Int = 3
class asInt(b: Boolean) { def toInt = if(b) 1 else 0 } implicit def convertBooleanToInt(b: Boolean) = new asInt(b)
var myBool:Boolean = true myBool: Boolean = true myBool.compare(false) res3: Int = 1 myBool = false myBool: Boolean = false myBool.compare(false) res3: Int = 0
implicit class BoolToInt(val b:Boolean) extends AnyVal { def toInt = if (b) 1 else 0 def * (x:Int) = if (b) x else 0 }
Map(data -> "sumi", rel -> 2, privacy -> 0, status -> 1,name->"govind singh")
Map(rel -> 2, privacy -> 0, status -> 1,name->"govind singh")
val mx = Map("data" -> "sumi", "rel" -> 2, "privacy" -> 0) val m = mx("privacy") match { case 0 => mx - "data" case _ => mx } => m: scala.collection.immutable.Map[String,Any] = Map(rel -> 2, privacy -> 0)
val a = Map( "data" -> "sumi", "rel" -> "2", "privacy" -> "0", "status" -> "1", "name" -> "govind singh" ) val b = a.filterKeys(_ != "data")
if (m.contains("privacy") && m.getOrElse("privacy", 1) == 0) { m -= "play" }
if (m.contains("privacy") && m.getOrElse("privacy", 1) == 0) { val newM = m - "play" }
val m = Map("data" -> "sumi", "rel" -> 2, "privacy" -> 0,"status" -> 1,"name"->"govind singh") scala> if(m("privacy")==0) m.filterKeys(_ != "data") res63: Any = Map(name -> govind singh, rel -> 2, privacy -> 0, status -> 1)
class A { public static void m() { System.out.println("m from A"); } } public class B extends A { public static void m() { System.out.println("m from B"); } public static void main(String[] args) { A a = new B(); a.m(); } }
class A object A { def m() = println("m from A") } class B extends A object B { def m() = println("m from B") def main(args: Array[String]) { val a = new B A.m() } }
class foo static const int bar = 42; end class class superfoo Integer bar = ConstInteger.new(42); end class
class Planet object Earth extends Planet object Sun extends Planet
trait Monoid[T] { def zero:T def sum(t1:T, t2:T):T } def fold[T](ts:T*)(implicit m:Monoid[T]) = ts.foldLeft(m.zero)(m.sum(_,_))
implicit object StringMonoid extends Monoid[String] { def zero = "" def sum(s1:String, s2:String) = s1 + s2 }
trait Config { def databaseName:String def userName:String def password:String } object Config extends Config { def databaseName = "testDB" def userName = "scott" def password = "tiger" }
def slowCalcFuture: Future[Int] = ... def combined: Future[Int] = async { await(slowCalcFuture) + await(slowCalcFuture) } val x: Int = Await.result(combined, 10.seconds)
def combined: Future[Int] = async { val future1 = slowCalcFuture val future2 = slowCalcFuture await(future1) + await(future2) }
async { await(slowCalcFuture) + await(slowCalcFuture) }
async { await(slowCalcFuture) + await(slowCalcFuture) ^^^^^ }
async { await(slowCalcFuture) + await(slowCalcFuture) ^^^^^ }
async { val future1 = slowCalcFuture val future2 = slowCalcFuture await(future1) + await(future2) }
async { val future1 = slowCalcFuture val future2 = slowCalcFuture await(future1) + await(future2) ^^^^^ }
class Point(x: Double, y: Double){ override def toString = "x: " + x + ", y: " + y def +(sourcePoint: Point) : Point = { return new Point(x + sourcePoint.x, y + sourcePoint.y } }
class Point(_x: Double, _y: Double){ var x = _x var y = _y override def toString = "x: " + x + ", y: " + y def +(sourcePoint: Point) : Point = { return new Point(x + sourcePoint.x, y + sourcePoint.y) } }
someRow match {case Row(a:Long,b:String,c:Double) => myCaseClass(a,b,c)}
val personEncoder = Encoders.bean(Person.class) val DStoProcess = DFtoProcess.as[Person](personEncoder)
map(row => myCaseClass(row.getLong(0), row.getString(1), row.getDouble(2))
scala> import spark.implicits._ scala> val df = Seq((1, "james"), (2, "tony")).toDF("id", "name") df: org.apache.spark.sql.DataFrame = [id: int, name: string] scala> case class Student(id: Int, name: String) defined class Student scala> df.as[Student].collectAsList res6: java.util.List[Student] = [Student(1,james), Student(2,tony)]
case class MyClass(a: Long, b: String, c: Int, d: String, e: String) dataframe.map { case Row(a: java.math.BigDecimal, b: String, c: Int, _: String, _: java.sql.Date, e: java.sql.Date, _: java.sql.Timestamp, _: java.sql.Timestamp, _: java.math.BigDecimal, _: String) => MyClass(a = a.longValue(), b = b, c = c, d = d.toString, e = e.toString) }
case class MyClass(a: Long, b: String, c: Option[Int], d: String, e: String) dataframe.map(_.toSeq.toList match { case List(a: java.math.BigDecimal, b: String, c: Int, _: String, _: java.sql.Date, e: java.sql.Date, _: java.sql.Timestamp, _: java.sql.Timestamp, _: java.math.BigDecimal, _: String) => MyClass( a = a.longValue(), b = b, c = Option(c), d = d.toString, e = e.toString) }
import AssemblyKeys._ assemblySettings buildInfoSettings net.virtualvoid.sbt.graph.Plugin.graphSettings name := "scala-app-template" version := "0.1" scalaVersion := "2.9.3" val FunnyRuntime = config("funnyruntime") extend(Compile) libraryDependencies += "org.spark-project" %% "spark-core" % "0.7.3" % "provided" sourceGenerators in Compile <+= buildInfo buildInfoPackage := "com.psnively" buildInfoKeys := Seq[BuildInfoKey](name, version, scalaVersion, target) assembleArtifact in packageScala := false val root = project.in(file(".")). configs(FunnyRuntime). settings(inConfig(FunnyRuntime)(Classpaths.configSettings ++ baseAssemblySettings ++ Seq( libraryDependencies += "org.spark-project" %% "spark-core" % "0.7.3" % "funnyruntime" )): _*)
run in Compile <<= Defaults.runTask(fullClasspath in Compile, mainClass in (Compile, run), runner in (Compile, run))
runMain in Compile <<= Defaults.runMainTask(fullClasspath in Compile, runner in (Compile, run))
names foreach (n => println(n)) names mkString "," optStr getOrElse "<empty>" javaList add item
names.map (_.toUpperCase).filter (_.length > 5) names map (_.toUpperCase) filter (_.length > 5)
(fetchIt(1) |@| fetchIt(2) |@| fetchIt(3)).map(MyCaseClass)
fetchIt(1) |@| fetchIt(2) |@| fetchIf(3) map MyCaseClass
import scala.annotation.tailrec import scala.util.Random object PerformanceTest { def main(args: Array[String]): Unit = { val bigArray:Array[Int] = fillArray(new Array[Int](100000000)) println(time(lteqgt(bigArray, 25))) println(time(lteqgt2(bigArray, 25))) } def time[T](block : => T):T = { val start = System.nanoTime : Double val result = block val end = System.nanoTime : Double println("Time = " + (end - start) / 1000000.0 + " millis") result } @tailrec def fillArray(a:Array[Int], pos:Int=0):Array[Int] = { if (pos == a.length) a else { a(pos) = Random.nextInt(50) fillArray(a, pos+1) } } @tailrec def lteqgt(values: Array[Int], v:Int, lt:Int=0, eq:Int=0, gt:Int=0, pos:Int=0):(Int, Int, Int) = { if (pos == values.length) (lt, eq, gt) else lteqgt(values, v, lt + (if (values(pos) < v) 1 else 0), eq + (if (values(pos) == v) 1 else 0), gt + (if (values(pos) > v) 1 else 0), pos+1) } def lteqgt2(values:Array[Int], v:Int):(Int, Int, Int) = { var lt = 0 var eq = 0 var gt = 0 var pos = 0 val limit = values.length while (pos < limit) { if (values(pos) > v) gt += 1 else if (values(pos) < v) lt += 1 else eq += 1 pos += 1 } (lt, eq, gt) } }
Time = 245.110899 millis (50004367,2003090,47992543) Time = 465.836894 millis (50004367,2003090,47992543)
def lteqgt2(values:Array[Int], v:Int):(Int, Int, Int) = { var lt = 0 var eq = 0 var gt = 0 var pos = 0 val limit = values.length while (pos < limit) { gt += (if (values(pos) > v) 1 else 0) lt += (if (values(pos) < v) 1 else 0) eq += (if (values(pos) == v) 1 else 0) pos += 1 } (lt, eq, gt) }
class A { val a = 1 } class B extends A { override val a = 2 }
class A { final val a = 1 } class B extends A { override val a = 2 }
class Parent { val a = 1 final val b = 2 } class Subclass extends Parent { override val a = 3 override val b = 4 }
@GameRegistry.ObjectHolder(Reference.MOD_ID) object ModItems{ }
lazy val copyDependencies = TaskKey[Unit]("pack") def copyDepTask = copyDependencies <<= (update, crossTarget, scalaVersion) map { (updateReport, out, scalaVer) => updateReport.allFiles foreach { srcPath => val destPath = out / "lib" / srcPath.getName IO.copyFile(srcPath, destPath, preserveLastModified = true) } }
lazy val HubSensors = Project("HubSensors", file("HubSensors"), settings = shared ++ Seq( copyDepTask, resolvers ++= Seq(novusRels), libraryDependencies ++= Seq( jodatime ) )) dependsOn(HubCameraVision, JamServiceProxy, HubDAL)
import java.time.Duration import jata.time.temporal.ChronoUnit Duration.of(1, ChronoUnit.HOURS).getNano Duration.of(1, ChronoUnit.HOURS).toNanos
implicit def asFiniteDuration(d: java.time.Duration) = scala.concurrent.duration.Duration.fromNanos(d.toNanos)
val d: FiniteDuration = ConfigFactory.load().getDuration("application.someTimeout")
implicit def toFiniteDuration(d: java.time.Duration): FiniteDuration = Duration.fromNanos(d.toNanos)
java_release="$(cat $JAVA_HOME/release | grep JAVA_VERSION)"
cat: /usr/lib/jvm/java-8-openjdk-amd64/release: No such file or directory
$ echo $JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64`
> test [error] java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: PermGen space [error] Use > last [debug] Running task... Cancelable: false, check cycles: false [debug] [debug] Initial source changes: [debug] removed:Set() [debug] added: Set() [debug] modified: Set() [debug] Removed products: Set() [debug] Modified external sources: Set() [debug] Modified binary dependencies: Set() [debug] Initial directly invalidated sources: Set() [debug] [debug] Sources indirectly invalidated by: [debug] product: Set() [debug] binary dep: Set() [debug] external source: Set() [debug] Initially invalidated: Set() [debug] Copy resource mappings: [debug] [debug] [debug] Initial source changes: [debug] removed:Set() [debug] added: Set() [debug] modified: Set() [debug] Removed products: Set() [debug] Modified external sources: Set() [debug] Modified binary dependencies: Set() [debug] Initial directly invalidated sources: Set() [debug] [debug] Sources indirectly invalidated by: [debug] product: Set() [debug] binary dep: Set() [debug] external source: Set() [debug] Initially invalidated: Set() [debug] Copy resource mappings: [debug] [debug] Framework implementation [debug] Framework implementation [debug] Framework implementation [debug] Framework implementation [debug] Subclass fingerprints: Stream((org.specs2.specification.SpecificationStructure,false,org.specs2.runner.Fingerprints$$anon$1@34d6488c), ?) [debug] Annotation fingerprints: Stream() [debug] Running Test ExpandoObjectTest : subclass(false, org.specs2.specification.SpecificationStructure) with arguments java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: PermGen space at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252) at java.util.concurrent.FutureTask.get(FutureTask.java:111) at sbt.ConcurrentRestrictions$$anon$4.take(ConcurrentRestrictions.scala:196) at sbt.Execute.next$1(Execute.scala:85) at sbt.Execute.processAll(Execute.scala:88) at sbt.Execute.runKeep(Execute.scala:68) at sbt.EvaluateTask$.run$1(EvaluateTask.scala:162) at sbt.EvaluateTask$.runTask(EvaluateTask.scala:177) at sbt.Aggregation$$anonfun$4.apply(Aggregation.scala:46) at sbt.Aggregation$$anonfun$4.apply(Aggregation.scala:44) at sbt.EvaluateTask$.withStreams(EvaluateTask.scala:137) at sbt.Aggregation$.runTasksWithResult(Aggregation.scala:44) at sbt.Aggregation$.runTasks(Aggregation.scala:59) at sbt.Aggregation$$anonfun$applyTasks$1.apply(Aggregation.scala:31) at sbt.Aggregation$$anonfun$applyTasks$1.apply(Aggregation.scala:30) at sbt.Command$$anonfun$applyEffect$2$$anonfun$apply$3.apply(Command.scala:62) at sbt.Command$$anonfun$applyEffect$2$$anonfun$apply$3.apply(Command.scala:62) at sbt.Command$.process(Command.scala:90) at sbt.MainLoop$$anonfun$next$1$$anonfun$apply$1.apply(MainLoop.scala:71) at sbt.MainLoop$$anonfun$next$1$$anonfun$apply$1.apply(MainLoop.scala:71) at sbt.State$$anon$2.process(State.scala:170) at sbt.MainLoop$$anonfun$next$1.apply(MainLoop.scala:71) at sbt.MainLoop$$anonfun$next$1.apply(MainLoop.scala:71) at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:18) at sbt.MainLoop$.next(MainLoop.scala:71) at sbt.MainLoop$.run(MainLoop.scala:64) at sbt.MainLoop$$anonfun$runWithNewLog$1.apply(MainLoop.scala:53) at sbt.MainLoop$$anonfun$runWithNewLog$1.apply(MainLoop.scala:50) at sbt.Using.apply(Using.scala:25) at sbt.MainLoop$.runWithNewLog(MainLoop.scala:50) at sbt.MainLoop$.runAndClearLast(MainLoop.scala:33) at sbt.MainLoop$.runLoggedLoop(MainLoop.scala:17) at sbt.MainLoop$.runLogged(MainLoop.scala:13) at sbt.xMain.run(Main.scala:26) at xsbt.boot.Launch$.run(Launch.scala:55) at xsbt.boot.Launch$$anonfun$explicit$1.apply(Launch.scala:45) at xsbt.boot.Launch$.launch(Launch.scala:69) at xsbt.boot.Launch$.apply(Launch.scala:16) at xsbt.boot.Boot$.runImpl(Boot.scala:31) at xsbt.boot.Boot$.main(Boot.scala:20) at xsbt.boot.Boot.main(Boot.scala) Caused by: java.lang.OutOfMemoryError: PermGen space at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:791) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at java.net.URLClassLoader.access$100(URLClassLoader.java:71) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:423) at java.lang.ClassLoader.loadClass(ClassLoader.java:356) at sbt.Project$$anon$5.apply(Project.scala:130) at sbt.Project$$anon$5.apply(Project.scala:128) at sbt.LogManager$.commandBase$1(LogManager.scala:59) at sbt.LogManager$.command$1(LogManager.scala:60) at sbt.LogManager$$anonfun$suppressedMessage$1.apply(LogManager.scala:61) at sbt.LogManager$$anonfun$suppressedMessage$1.apply(LogManager.scala:61) at sbt.ConsoleLogger.trace(ConsoleLogger.scala:163) at sbt.AbstractLogger.log(Logger.scala:32) at sbt.MultiLogger$$anonfun$dispatch$1.apply(MultiLogger.scala:40) at sbt.MultiLogger$$anonfun$dispatch$1.apply(MultiLogger.scala:38) at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:59) at scala.collection.immutable.List.foreach(List.scala:76) at sbt.MultiLogger.dispatch(MultiLogger.scala:38) at sbt.MultiLogger.trace(MultiLogger.scala:30) at sbt.TestLogger$$anon$2.trace(TestReportListener.scala:71) at sbt.TestLogger.endGroup(TestReportListener.scala:88) at sbt.TestRunner$$anonfun$run$5.apply(TestFramework.scala:87) at sbt.TestRunner$$anonfun$run$5.apply(TestFramework.scala:87) at sbt.TestFramework$$anonfun$safeForeach$1.apply(TestFramework.scala:112) at sbt.TestFramework$$anonfun$safeForeach$1.apply(TestFramework.scala:112) at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:59) [error] java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: PermGen space [error] Use
sbt appears to be exiting abnormally. The log file for this session is at /var/folders/vf/3khb58091wd0_1rz1yh6knb00000gp/T/sbt3242766352271599341.log java.lang.OutOfMemoryError: PermGen space Error during sbt execution: java.lang.OutOfMemoryError: PermGen space
val format = new java.text.SimpleDateFormat("yyyy-MM-dd") format.parse("2013-07-06")
libraryDependencies += "com.github.nscala-time" %% "nscala-time" % "1.8.0"
import com.github.nscala_time.time.Imports._ DateTime.parse("2014-07-06")
import java.time._ import java.time.format.DateTimeFormatter val datetime_format = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss.SSS") val date_int_format = DateTimeFormatter.ofPattern("yyyyMMdd") val last_extract_value="2018-05-09 10:04:25.375" last_extract_value: String = 2018-05-09 10:04:25.375 val string_to_date = datetime_format.parse(last_extract_value) java.time.temporal.TemporalAccessor = {},ISO resolved to 2018-05-08T21:01:15.402 date_int_format.format(string_to_date) res18: String = 20180508
<dependency> <groupId>org.apache.hbase</groupId> <artifactId>hbase</artifactId> <version>0.90.4</version> <type>test-jar</type> <scope>test</scope> </dependency>
def save(srcPath: String, destPath: String) { if (!destPath.endsWith( destPath += }
void printPlusOne(int i) { i++; System.out.println("i is: " + i); System.out.println("and now it }
def save(srcPath: String, destPath: String) { val normalizedDestPath = if (destPath.endsWith( else destPath + }
def save(srcPath: String, destPath: String): String = { val newPath = (if (!destPath.endsWith("/")) destPath+ newPath }
case class Mut[A](var value: A) {} def save(srcPath: String, destPath: Mut[String]) { if (!destPath.value.endsWith("/")) destPath.value += }
val destWithSlash = destPath + (if (!destPath.endsWith("/")) "/" else "")
class SlashString(s: String) { override val toString = if (s endsWith "/") s else s + "/" } implicit def toSlashString(s: String) = new SlashString(s)
def save(srcPath: String, destPath: SlashString) { printf("saving from %s to %s", srcPath, destPath) } val src: String = "abc" val dst: String = "xyz" scala> save(src, dst) saving from abc to xyz/
def save(srcPath: String, destPath: StringBuilder) { if (!destPath.toString().endsWith("/")) destPath.append("/") // }
def save(srcPath: String, destPath: String) { var destP = destPath if (!destP.endsWith("/")) destP += "/" // }
def save(srcPath: String, destPath: String) { var dp = destPath if (!dp.endsWith( dp+= }
def savedPath(path: String) = if(path.endsWith("/")) path else path + "/" val myDestPath = ... val srcPath = ... save(srcPath, savedPath(myDestPath))
def save(srcPath: String, destPath: String) { ((destPath: String) => { })(if (!destPath.endsWith( }
implicit def iterExt[A](iter: Iterable[A]) = new { def top[B](n: Int, f: A => B)(implicit ord: Ordering[B]): List[A] = { def updateSofar (sofar: List [A], el: A): List [A] = { if (ord.compare(f(el), f(sofar.head)) > 0) (el :: sofar.tail).sortBy (f) else sofar } val (sofar, rest) = iter.splitAt(n) (sofar.toList.sortBy (f) /: rest) (updateSofar (_, _)).reverse } } case class A(s: String, i: Int) val li = List (4, 3, 6, 7, 1, 2, 9, 5).map(i => A(i.toString(), i)) println(li.top(3, _.i))
def top (n: Int, li: List [Int]) : List[Int] = { def updateSofar (sofar: List [Int], el: Int) : List [Int] = { if (el < sofar.head) (el :: sofar.tail).sortWith (_ > _) else sofar } /* better readable: val sofar = li.take (n).sortWith (_ > _) val rest = li.drop (n) (sofar /: rest) (updateSofar (_, _)) */ (li.take (n). sortWith (_ > _) /: li.drop (n)) (updateSofar (_, _)) }
def extremeN [T](n: Int, li: List [T]) (comp1: ((T, T) => Boolean), comp2: ((T, T) => Boolean)): List[T] = { def updateSofar (sofar: List [T], el: T) : List [T] = if (comp1 (el, sofar.head)) (el :: sofar.tail).sortWith (comp2 (_, _)) else sofar (li.take (n) .sortWith (comp2 (_, _)) /: li.drop (n)) (updateSofar (_, _)) } /* still bound to Int: def top (n: Int, li: List [Int]) : List[Int] = { extremeN (n, li) ((_ < _), (_ > _)) } def bottom (n: Int, li: List [Int]) : List[Int] = { extremeN (n, li) ((_ > _), (_ < _)) } */ def top [T] (n: Int, li: List [T]) (implicit ord: Ordering[T]): Iterable[T] = { extremeN (n, li) (ord.lt (_, _), ord.gt (_, _)) } def bottom [T] (n: Int, li: List [T]) (implicit ord: Ordering[T]): Iterable[T] = { extremeN (n, li) (ord.gt (_, _), ord.lt (_, _)) } top (3, li) bottom (3, li) val sl = List ("Haus", "Garten", "Boot", "Sumpf", "X", "y", "xkcd", "x11") bottom (2, sl)
def extremeN [T](n: Int, li: List [T]) (comp1: ((T, T) => Boolean), comp2: ((T, T) => Boolean)): List[T] = { def sortedIns (el: T, list: List[T]): List[T] = if (list.isEmpty) List (el) else if (comp2 (el, list.head)) el :: list else list.head :: sortedIns (el, list.tail) def updateSofar (sofar: List [T], el: T) : List [T] = if (comp1 (el, sofar.head)) sortedIns (el, sofar.tail) else sofar (li.take (n) .sortWith (comp2 (_, _)) /: li.drop (n)) (updateSofar (_, _)) }
val big = (1 to 100000) def maxes[A](n:Int)(l:Traversable[A])(implicit o:Ordering[A]) = l.foldLeft(collection.immutable.SortedSet.empty[A]) { (xs,y) => if (xs.size < n) xs + y else { import o._ val first = xs.firstKey if (first < y) xs - first + y else xs } } println(maxes(4)(big)) println(maxes(2)(List("a","ab","c","z")))
def maxes2[A](n:Int)(l:Traversable[A])(implicit o:Ordering[A]) = l.foldLeft(List.empty[A]) { (xs,y) => import o._ if (xs.size < n) (y::xs).sort(lt _) else { val first = xs.head if (first < y) (y::(xs - first)).sort(lt _) else xs } }
def pickTopN[T](k: Int, iterable: Iterable[T])(implicit ord: Ordering[T]): Seq[T] { val q = collection.mutable.PriorityQueue[T](iterable.toSeq:_*) val end = Math.min(k, q.size) (1 to end).map(_ => q.dequeue()) }
def pickTopN[A, B](n: Int, iterable: Iterable[A], f: A => B)(implicit ord: Ordering[B]): Seq[A] = { val seq = iterable.toSeq val q = collection.mutable.PriorityQueue[A](seq.take(n):_*)(ord.on(f).reverse) seq.drop(n).foreach(v => { q += v q.dequeue() }) q.dequeueAll.reverse }
class Pimp[A, Repr <% TraversableLike[A, Repr]](self : Repr) { def nth(n : Int)(implicit ord : Ordering[A]) : A = { val trav : TraversableLike[A, Repr] = self var ltp : List[A] = Nil var etp : List[A] = Nil var mtp : List[A] = Nil trav.headOption match { case None => error("Cannot get " + n + " element of empty collection") case Some(piv) => trav.foreach { a => val cf = ord.compare(piv, a) if (cf == 0) etp ::= a else if (cf > 0) ltp ::= a else mtp ::= a } if (n < ltp.length) new Pimp[A, List[A]](ltp.reverse).nth(n)(ord) else if (n < (ltp.length + etp.length)) piv else new Pimp[A, List[A]](mtp.reverse).nth(n - ltp.length - etp.length)(ord) } } }
def topN(n : Int)(implicit ord : Ordering[A], bf : CanBuildFrom[Repr, A, Repr]) ={ val b = bf() val elem = new Pimp[A, Repr](self).nth(n)(ord) import util.control.Breaks._ breakable { var soFar = 0 self.foreach { tt => if (ord.compare(tt, elem) < 0) { b += tt soFar += 1 } } assert (soFar <= n) if (soFar < n) { self.foreach { tt => if (ord.compare(tt, elem) == 0) { b += tt soFar += 1 } if (soFar == n) break } } } b.result() }
implicit def t2n[A, Repr <% TraversableLike[A, Repr]](t : Repr) : Pimp[A, Repr] = new Pimp[A, Repr](t)
scala> List(4, 3, 6, 7, 1, 2, 8, 5).topN(4) <console>:9: error: could not find implicit value for evidence parameter of type (List[Int]) => scala.collection.TraversableLike[A,List[Int]] List(4, 3, 6, 7, 1, 2, 8, 5).topN(4) ^
scala> new Pimp(List(4, 3, 6, 7, 1, 2, 8, 5)).topN(4) res3: List[Int] = List(3, 1, 2, 4)
scala> new Pimp("ioanusdhpisjdmpsdsvfgewqw").topN(6) res2: java.lang.String = adddfe
List(1,6,3,7,3,2).foldLeft(List[Int]()){(l, n) => (n :: l).sorted.take(2)}
def top[T](data: List[T], n: Int)(implicit ord: Ordering[T]): List[T] = { require( n < data.size) def partition_inner(shuffledData: List[T], pivot: T): List[T] = shuffledData.partition( e => ord.compare(e, pivot) > 0 ) match { case (left, right) if left.size == n => left case (left, x :: rest) if left.size < n => partition_inner(util.Random.shuffle(data), x) case (left @ y :: rest, right) if left.size > n => partition_inner(util.Random.shuffle(data), y) } val shuffled = util.Random.shuffle(data) partition_inner(shuffled, shuffled.head) } scala> top(List.range(1,10000000), 5)
def top[T](data: List[T], n: Int)(implicit ord: Ordering[T]): List[T] = { require( n < data.size) @tailrec def partition_inner(shuffledData: List[T], pivot: T): List[T] = shuffledData.par.partition( e => ord.compare(e, pivot) > 0 ) match { case (left, right) if left.size == n => left.toList case (left, right) if left.size < n => partition_inner(util.Random.shuffle(data), right.head) case (left, right) if left.size > n => partition_inner(util.Random.shuffle(data), left.head) } val shuffled = util.Random.shuffle(data) partition_inner(shuffled, shuffled.head) }
def top[T](n:Int, iter:Iterable[T])(implicit ord: Ordering[T]): Iterable[T] = { def partitionMax(acc: Iterable[T], it: Iterable[T]): Iterable[T] = { val max = it.max(ord) val (nextElems, rest) = it.partition(ord.gteq(_, max)) val maxElems = acc ++ nextElems if (maxElems.size >= n || rest.isEmpty) maxElems.take(n) else partitionMax(maxElems, rest) } if (iter.isEmpty) iter.take(0) else partitionMax(iter.take(0), iter) }
scala> top(5, List.range(1,1000000)) res13: Iterable[Int] = List(999999, 999998, 999997, 999996, 999995) scala> top(5, List.range(1,1000000))(Ordering[Int].on(- _)) res14: Iterable[Int] = List(1, 2, 3, 4, 5)
import scala.language.implicitConversions import scala.language.reflectiveCalls import collection.mutable.PriorityQueue implicit def iterExt[A](iter: Iterable[A]) = new { def top[B](n: Int, f: A => B)(implicit ord: Ordering[B]) : List[A] = { def updateSofar (sofar: PriorityQueue[A], el: A): PriorityQueue[A] = { if (ord.compare(f(el), f(sofar.head)) < 0){ sofar.dequeue sofar.enqueue(el) } sofar } val (sofar, rest) = iter.splitAt(n) (PriorityQueue(sofar.toSeq:_*)( Ordering.by( (x :A) => f(x) ) ) /: rest) (updateSofar (_, _)).dequeueAll.toList.reverse } } case class A(s: String, i: Int) val li = List (4, 3, 6, 7, 1, 2, 9, 5).map(i => A(i.toString(), i)) println(li.top(3, -_.i))
import io.github.netvl.picopickle.backends.jawn.JsonPickler._ case class A(x: Int, y: String) writeString(A(10, "hi")) shouldEqual """{"x":10,"y":"hi"}""" readString[A]("""{"x":10,"y":"hi"}""") shouldEqual A(10, "hi")
lazy val sub = project.in(file(".")).aggregates(subSub) lazy val subSub = project
val repl = new ILoop repl.settings = new Settings repl.in = SimpleReader() repl.createInterpreter() repl.intp.bind("i", "Int", i) repl.intp.bind("e", "Exception", e) repl.loop() repl.closeInterpreter()
val list = Seq(("one", "i"), ("two", "2"), ("two", "ii"), ("one", "1"), ("four", "iv"))
Seq(("one" -> Seq("i","1")), ("two" -> Seq("2", "ii")), ("four" -> Seq("iv"))
def aggregate [B] (z: B)(seqop: (B, A) ⇒ B, combop: (B, B) ⇒ B): B
z A z A z A z A \ / \ /seqop\ / \ / B B B B \ / combop \ / B _ _ B \ combop / B
import scala.collection.GenSeq val seq = GenSeq("This", "is", "an", "example") val chars = seq.par.aggregate(0)(_ + _.length, _ + _)
0 + "This".length 0 + "is".length 0 + "an".length 0 + "example".length
(((0 + "This".length) + "is".length) + "an".length) + "example".length
def aggregate [B] (z: B)(seqop: (B, A) ⇒ B, combop: (B, B) ⇒ B): B
def aggregate[B](z: B)(seqop: (B, A) => B, combop: (B, B) => B): B = foldLeft(z)(seqop)
val seqOp = (map:Map[String,Set[String]],tuple: (String,String)) => map + ( tuple._1 -> ( map.getOrElse( tuple._1, Set[String]() ) + tuple._2 ) ) list.foldLeft( Map[String,Set[String]]() )( seqOp )
val combOp = (map1: Map[String,Set[String]], map2: Map[String,Set[String]]) => (map1.keySet ++ map2.keySet).foldLeft( Map[String,Set[String]]() ) { (result,k) => result + ( k -> ( map1.getOrElse(k,Set[String]() ) ++ map2.getOrElse(k,Set[String]() ) ) ) }
list.par.aggregate( Map[String,Set[String]]() )( seqOp, combOp )
def aggregate[S](z: S)(seqop: (S, T) => S, combop: (S, S) => S): S = { executeAndWaitResult(new Aggregate(z, seqop, combop, splitter)) }
protected[this] class Aggregate[S](z: S, seqop: (S, T) => S, combop: (S, S) => S, protected[this] val pit: IterableSplitter[T]) extends Accessor[S, Aggregate[S]] { @volatile var result: S = null.asInstanceOf[S] def leaf(prevr: Option[S]) = result = pit.foldLeft(z)(seqop) protected[this] def newSubtask(p: IterableSplitter[T]) = new Aggregate(z, seqop, combop, p) override def merge(that: Aggregate[S]) = result = combop(result, that.result) }
def aggregate[B](z: B)(seqop: (B, A) => B, combop: (B, B) => B): B = foldLeft(z)(seqop)
Seq(1,2,3,4).aggragate(0)( addToPrev = (prev,curr) => prev + curr, combineSums = (sumA,sumB) => sumA + sumB)
Seq(1,2,3,4) .grouped(2) .map(prevAndCurrList => prevAndCurrList(0) + prevAndCurrList(1)) .foldLeft(0)(sumA,sumB => sumA + sumB)
implicit def any2ArrowAssoc[A](x: A): ArrowAssoc[A] = new ArrowAssoc(x)
class ArrowAssoc[A](x: A) { def -> [B](y: B): Tuple2[A, B] = Tuple2(x, y) }
package scala object Predef { class ArrowAssoc[A](x: A) { def -> [B](y: B): Tuple2[A, B] = Tuple2(x, y) } implicit def any2ArrowAssoc[A](x: A): ArrowAssoc[A] = new ArrowAssoc(x) ... }
scala> List(1,2,3).toSet[Int].subsets.map(_.toList).toList res9: List[List[Int]] = List(List(), List(1), List(2), List(3), List(1, 2), List(1, 3), List(2, 3), List(1, 2, 3))
def combine(in: List[Char]): Seq[String] = for { len <- 1 to in.length combinations <- in combinations len } yield combinations.mkString
val xs = List( (1 to xs.length flatMap (x => xs.combinations(x))) map ( x => x.mkString(""))
def powerset[A](s: Set[A]) = s.foldLeft(Set(Set.empty[A])) { case (ss, el) => ss ++ ss.map(_ + el) }
root |-- user_id: long (nullable = false) |-- event_id: long (nullable = false) |-- invited: integer (nullable = false) |-- day_diff: long (nullable = true) |-- interested: integer (nullable = false) |-- event_owner: long (nullable = false) |-- friend_id: long (nullable = false)
+----------+----------+-------+--------+----------+-----------+---------+ | user_id| event_id|invited|day_diff|interested|event_owner|friend_id| +----------+----------+-------+--------+----------+-----------+---------+ | 4236494| 110357109| 0| -1| 0| 937597069| null| | 78065188| 498404626| 0| 0| 0| 2904922087| null| | 282487230|2520855981| 0| 28| 0| 3749735525| null| | 335269852|1641491432| 0| 2| 0| 1490350911| null| | 437050836|1238456614| 0| 2| 0| 991277599| null| | 447244169|2095085551| 0| -1| 0| 1579858878| null| | 516353916|1076364848| 0| 3| 1| 3597645735| null| | 528218683|1151525474| 0| 1| 0| 3433080956| null| | 531967718|3632072502| 0| 1| 0| 3863085861| null| | 627948360|2823119321| 0| 0| 0| 4092665803| null| | 811791433|3513954032| 0| 2| 0| 415464198| null| | 830686203| 99027353| 0| 0| 0| 3549822604| null| |1008893291|1115453150| 0| 2| 0| 2245155244| null| |1239364869|2824096896| 0| 2| 1| 2579294650| null| |1287950172|1076364848| 0| 0| 0| 3597645735| null| |1345896548|2658555390| 0| 1| 0| 2025118823| null| |1354205322|2564682277| 0| 3| 0| 2563033185| null| |1408344828|1255629030| 0| -1| 1| 804901063| null| |1452633375|1334001859| 0| 4| 0| 1488588320| null| |1625052108|3297535757| 0| 3| 0| 1972598895| null| +----------+----------+-------+--------+----------+-----------+---------+
scala> val aaa = test.filter("friend_id is null") scala> aaa.count
val aaa = train_friend_join.select($"user_id", $"event_id", $"invited", $"day_diff", $"interested", $"event_owner", ($"friend_id" != null)?1:0)
case class Company(cName: String, cId: String, details: String) case class Employee(name: String, id: String, email: String, company: Company) val e1 = Employee("n1", null, "n1@c1.com", Company("c1", "1", "d1")) val e2 = Employee("n2", "2", "n2@c1.com", Company("c1", "1", "d1")) val e3 = Employee("n3", "3", "n3@c1.com", Company("c1", "1", "d1")) val e4 = Employee("n4", "4", "n4@c2.com", Company("c2", "2", "d2")) val e5 = Employee("n5", null, "n5@c2.com", Company("c2", "2", "d2")) val e6 = Employee("n6", "6", "n6@c2.com", Company("c2", "2", "d2")) val e7 = Employee("n7", "7", "n7@c3.com", Company("c3", "3", "d3")) val e8 = Employee("n8", "8", "n8@c3.com", Company("c3", "3", "d3")) val employees = Seq(e1, e2, e3, e4, e5, e6, e7, e8) val df = sc.parallelize(employees).toDF
+----+----+---------+---------+ |name| id| email| company| +----+----+---------+---------+ | n1|null|n1@c1.com|[c1,1,d1]| | n2| 2|n2@c1.com|[c1,1,d1]| | n3| 3|n3@c1.com|[c1,1,d1]| | n4| 4|n4@c2.com|[c2,2,d2]| | n5|null|n5@c2.com|[c2,2,d2]| | n6| 6|n6@c2.com|[c2,2,d2]| | n7| 7|n7@c3.com|[c3,3,d3]| | n8| 8|n8@c3.com|[c3,3,d3]| +----+----+---------+---------+
+----+----+---------+---------+ |name| id| email| company| +----+----+---------+---------+ | n1|null|n1@c1.com|[c1,1,d1]| | n5|null|n5@c2.com|[c2,2,d2]| +----+----+---------+---------+
df.withColumn("id", when($"id".isNull, 0).otherwise(1)).show
+----+---+---------+---------+ |name| id| email| company| +----+---+---------+---------+ | n1| 0|n1@c1.com|[c1,1,d1]| | n2| 1|n2@c1.com|[c1,1,d1]| | n3| 1|n3@c1.com|[c1,1,d1]| | n4| 1|n4@c2.com|[c2,2,d2]| | n5| 0|n5@c2.com|[c2,2,d2]| | n6| 1|n6@c2.com|[c2,2,d2]| | n7| 1|n7@c3.com|[c3,3,d3]| | n8| 1|n8@c3.com|[c3,3,d3]| +----+---+---------+---------+
val df = spark.createDataFrame(Seq( (0, "a1", "b1", "c1", "d1"), (1, "a2", "b2", "c2", "d2"), (2, "a3", "b3", null, "d3"), (3, "a4", null, "c4", "d4"), (4, null, "b5", "c5", "d5") )).toDF("id", "col1", "col2", "col3", "col4") +---+----+----+----+----+ | id|col1|col2|col3|col4| +---+----+----+----+----+ | 0| a1| b1| c1| d1| | 1| a2| b2| c2| d2| | 2| a3| b3|null| d3| | 3| a4|null| c4| d4| | 4|null| b5| c5| d5| +---+----+----+----+----+
df.filter(col("col1").isNotNull && col("col2").isNotNull).show
df.where("col1 is not null and col2 is not null").show
+---+----+----+----+----+ | id|col1|col2|col3|col4| +---+----+----+----+----+ | 0| a1| b1| c1| d1| | 1| a2| b2| c2| d2| | 2| a3| b3|null| d3| +---+----+----+----+----+
val filterCond = df.columns.map(x=>col(x).isNotNull).reduce(_ && _)
filterCond: org.apache.spark.sql.Column = (((((id IS NOT NULL) AND (col1 IS NOT NULL)) AND (col2 IS NOT NULL)) AND (col3 IS NOT NULL)) AND (col4 IS NOT NULL))
+---+----+----+----+----+ | id|col1|col2|col3|col4| +---+----+----+----+----+ | 0| a1| b1| c1| d1| | 1| a2| b2| c2| d2| +---+----+----+----+----+
Dataset<Row> containingNulls = data.where(data.col("COLUMN_NAME").isNull())
Dataset<Row> withoutNulls = data.where(data.col("COLUMN_NAME").isNotNull())
Dataset<Row> withoutNullsAndEmpty = data.where(data.col("COLUMN_NAME").isNotNull().and(data.col("COLUMN_NAME").notEqual("")))
def filter_null(field : Any) : Int = field match { case null => 0 case _ => 1 } val test = train_event_join.join( user_friends_pair, train_event_join("user_id") === user_friends_pair("user_id") && train_event_join("event_owner") === user_friends_pair("friend_id"), "left" ).select( train_event_join("user_id"), train_event_join("event_id"), train_event_join("invited"), train_event_join("day_diff"), train_event_join("interested"), train_event_join("event_owner"), user_friends_pair("friend_id") ).rdd.map{ line => ( line(0).toString.toLong, line(1).toString.toLong, line(2).toString.toLong, line(3).toString.toLong, line(4).toString.toLong, line(5).toString.toLong, filter_null(line(6)) ) }.toDF("user_id", "event_id", "invited", "day_diff", "interested", "event_owner", "creator_is_friend")
val options = Map("path" -> "...\\ex.csv", "header" -> "true") val dfNull = spark.sqlContext.load("com.databricks.spark.csv", options) scala> dfNull.show +----------+----------+-------+--------+----------+-----------+---------+ | user_id| event_id|invited|day_diff|interested|event_owner|friend_id| +----------+----------+-------+--------+----------+-----------+---------+ | 4236494| 110357109| 0| -1| 0| 937597069| null| | 78065188| 498404626| 0| 0| 0| 2904922087| null| | 282487230|2520855981| 0| 28| 0| 3749735525| null| | 335269852|1641491432| 0| 2| 0| 1490350911| null| | 437050836|1238456614| 0| 2| 0| 991277599| null| | 447244169|2095085551| 0| -1| 0| 1579858878| a| | 516353916|1076364848| 0| 3| 1| 3597645735| b| | 528218683|1151525474| 0| 1| 0| 3433080956| c| | 531967718|3632072502| 0| 1| 0| 3863085861| null| | 627948360|2823119321| 0| 0| 0| 4092665803| null| | 811791433|3513954032| 0| 2| 0| 415464198| null| | 830686203| 99027353| 0| 0| 0| 3549822604| null| |1008893291|1115453150| 0| 2| 0| 2245155244| null| |1239364869|2824096896| 0| 2| 1| 2579294650| d| |1287950172|1076364848| 0| 0| 0| 3597645735| null| |1345896548|2658555390| 0| 1| 0| 2025118823| null| |1354205322|2564682277| 0| 3| 0| 2563033185| null| |1408344828|1255629030| 0| -1| 1| 804901063| null| |1452633375|1334001859| 0| 4| 0| 1488588320| null| |1625052108|3297535757| 0| 3| 0| 1972598895| null| +----------+----------+-------+--------+----------+-----------+---------+ dfNull.withColumn("friend_idTmp", when($"friend_id".isNull, "1").otherwise("0")).drop($"friend_id").withColumnRenamed("friend_idTmp", "friend_id").show +----------+----------+-------+--------+----------+-----------+---------+ | user_id| event_id|invited|day_diff|interested|event_owner|friend_id| +----------+----------+-------+--------+----------+-----------+---------+ | 4236494| 110357109| 0| -1| 0| 937597069| 1| | 78065188| 498404626| 0| 0| 0| 2904922087| 1| | 282487230|2520855981| 0| 28| 0| 3749735525| 1| | 335269852|1641491432| 0| 2| 0| 1490350911| 1| | 437050836|1238456614| 0| 2| 0| 991277599| 1| | 447244169|2095085551| 0| -1| 0| 1579858878| 0| | 516353916|1076364848| 0| 3| 1| 3597645735| 0| | 528218683|1151525474| 0| 1| 0| 3433080956| 0| | 531967718|3632072502| 0| 1| 0| 3863085861| 1| | 627948360|2823119321| 0| 0| 0| 4092665803| 1| | 811791433|3513954032| 0| 2| 0| 415464198| 1| | 830686203| 99027353| 0| 0| 0| 3549822604| 1| |1008893291|1115453150| 0| 2| 0| 2245155244| 1| |1239364869|2824096896| 0| 2| 1| 2579294650| 0| |1287950172|1076364848| 0| 0| 0| 3597645735| 1| |1345896548|2658555390| 0| 1| 0| 2025118823| 1| |1354205322|2564682277| 0| 3| 0| 2563033185| 1| |1408344828|1255629030| 0| -1| 1| 804901063| 1| |1452633375|1334001859| 0| 4| 0| 1488588320| 1| |1625052108|3297535757| 0| 3| 0| 1972598895| 1| +----------+----------+-------+--------+----------+-----------+---------+
def contains(set: Set, elem: Int): Boolean = set(elem)
def singletonSet(elem: Int): Set = set => set == elem
/** * We represent a set by its characteristic function, i.e. * its `contains` predicate. */ type Set = Int => Boolean /** * Indicates whether a set contains a given element. */ def contains(set: Set, elem: Int): Boolean = set(elem) /** * Returns the set of the one given element. */ def singletonSet(elem: Int): Set = set => set == elem
val mySet: Int => Boolean = x => Array(0,1,2,3,5,8) contains x
scala> val mySet: Int => Boolean = x => Array(0,1,2,3,5,8) contains x mySet: Int => Boolean = <function1> scala> mySet(3) res0: Boolean = true scala> mySet(9) res1: Boolean = false
scala> type Set = Int => Boolean defined type alias Set
scala> val mySet: Set = x => Array(0,1,2,3,5,8) contains x mySet: Int => Boolean = <function1>
def singletonSet(elem: Int): Set = set => set == elem
def singletonSet(elem: Int): Set = { def innerFunction (givenElement: Int) = if (elem == givenElement) true else false innerFunction }
scala> case class Foo(a: Int)(b: Int) defined class Foo scala> Foo(0)(0) == Foo(0)(1) res0: Boolean = true scala> Seq(0, 1).map(Foo(0)(_).hashCode) res1: Seq[Int] = List(-1669410282, -1669410282)
scala> case class Foo(a: Int)(val b: Int) defined class Foo scala> Foo(0)(1).b res3: Int = 1
scala> :paste case class Foo private(x: Int, y: Int) { def fieldToIgnore: Int = 0 } object Foo { def apply(x: Int, y: Int, f: Int): Foo = new Foo(x, y) { override lazy val fieldToIgnore: Int = f } } defined class Foo defined module Foo scala> val f1 = Foo(2, 3, 11) f1: Foo = Foo(2,3) scala> val f2 = Foo(2, 3, 5) f2: Foo = Foo(2,3) scala> f1 == f2 res45: Boolean = true scala> f1. res46: Boolean = true
scala> :paste case class Person( val name:String, val addr:String) { override def equals( arg:Any) = arg match { case Person(s, _) => s == name case _ => false } override def hashCode() = name.hashCode } scala> Person("Andy", "") == Person("Andy", "XXX") res2: Boolean = true scala> Person("Andy", "") == Person("Bob", "XXX") res3: Boolean = false
sealed abstract class C { val x: Int override def equals(other: Any) = true } case class X(override val x: Int) extends C case class Y(override val x: Int, y: Int) extends C
scala> X(3) == X(4) res2: Boolean = true scala> X(3) == X(3) res3: Boolean = true scala> X(3) == Y(2,5) res4: Boolean = true
scala> val jmap:java.util.Map[String,String] = new java.util.HashMap[String,String] jmap: java.util.Map[String,String] = {} scala> jmap.put("Hi","there") res0: String = null scala> jmap.put("So","long") res1: String = null scala> jmap.put("Never","mind") res2: String = null scala> import scala.collection.JavaConversions._ import scala.collection.JavaConversions._ scala> jmap.foreach(kv => println(kv._1 + " -> " + kv._2)) Hi -> there Never -> mind So -> long scala> jmap.keys.map(_.toUpperCase).foreach(println) HI NEVER SO
scala> import scala.util.Try import scala.util.Try scala> def tryToInt( s: String ) = Try(s.toInt).toOption tryToInt: (s: String)Option[Int] scala> tryToInt("123") res0: Option[Int] = Some(123) scala> tryToInt("") res1: Option[Int] = None
implicit class RichOptionConvert(val s: String) extends AnyVal { def toOptInt() = Try (s.toInt) toOption }
implicit class RichOptionConvert(val s: String) extends AnyVal { def toOptInt() = try { Some(s.toInt) } catch { case e: NumberFormatException => None } }
"123".toOptInt res: Option[Int] = Some(123) Array(4,5,6).mkString.toOptInt res: Option[Int] = Some(456) "nan".toInt res: Option[Int] = None
scala> import util.control.Exception._ import util.control.Exception._ scala> allCatch.opt { "42".toInt } res0: Option[Int] = Some(42) scala> allCatch.opt { "answer".toInt } res1: Option[Int] = None scala> allCatch.either { "42".toInt } res3: scala.util.Either[Throwable,Int] = Right(42)
"5".toIntOption "abc".toIntOption "abc".toIntOption.getOrElse(-1)
scala> new java.lang.Double(1.0).hashCode res16: Int = 1072693248
scala> new java.lang.Double(1.0). res17: Int = 1 scala> 1.0. res15: Int = 1
> import java.lang._ import java.lang._ > val lng = Integer.MAX_VALUE.toLong + 1 lng: Long = 2147483648 > val dbl = Integer.MAX_VALUE.toDouble + 1 dbl: Double = 2.147483648E9 > lng == dbl res65: Boolean = true > lng. res66: Boolean = false > (lng. res67: (Int, Int) = (-2147483647,-2147483648) > (dbl. res68: (Int, Int) = (-2147483648,1105199104)
override def validateKey(key: String): Either[InvalidKeyError, Unit] = keys.contains(key) match { case true => Right() case false => Left(InvalidKeyError(context, key)) }
implicit def T2OptionT( x : T) : Option[T] = if ( x == null ) None else Some(x)
val iThinkThisIsAList = 2 for (i <- iThinkThisIsAList) yield { i + 1 }
class Optionable[T <: AnyRef](value: T) { def toOption: Option[T] = if ( value == null ) None else Some(value) } implicit def anyRefToOptionable[T <: AnyRef](value: T) = new Optionable(value)
val x: String = "foo" x.toOption val y: String = null x.toOption
def having(key:String) = having(key, None) def having(key:String, default:String) = having(key, Some(default)) def having(key: String, default: Option[String]=Option.empty) : Create = { keys += ( (key, default) ) this }
class A { def foo() = "A" } trait B extends A { override def foo() = "B" + super.foo() } trait C extends B { override def foo() = "C" + super.foo() } trait D extends A { override def foo() = "D" + super.foo() } object LinearizationPlayground { def main(args: Array[String]) { var d = new A with D with C with B; println(d.foo) } }
class X { print("X") } class A extends X { print("A") } trait H { print("H") } trait S extends H { print("S") } trait R { print("R") } trait T extends R with H { print("T") } class B extends A with T with S { print("B") } new B
l(A) = A >> l(B) >> l(c) >> l(D) l(A) = A >> B >> l(A) >> l(C) >> l(D) l(A) = A >> B >> A >> C >> l(B) >> l(D) l(A) = A >> B >> A >> C >> B >> l(A) >> l(D) l(A) = A >> B >> A >> C >> B >> A >> l(D) l(A) = A >> B >> A >> C >> B >> A >> D >> l(A) l(A) = A >> B >> A >> C >> B >> A >> D >> A
L(A) = A L(C) = C -> B -> A L(B) = B -> A L(D) = D -> A
class Combined extends A with D with C with B { final <superaccessor> <artifact> def super$foo(): String = B$class.foo(Combined.this); override def foo(): String = C$class.foo(Combined.this); final <superaccessor> <artifact> def super$foo(): String = D$class.foo(Combined.this); final <superaccessor> <artifact> def super$foo(): String = Combined.super.foo(); def <init>(): Combined = { Combined.super.<init>(); D$class. $init$(Combined.this); B$class. $init$(Combined.this); C$class. $init$(Combined.this); () } };
scala> trait A {println("A")} scala> trait B {println("B")} scala> trait C {println("C")} scala> new A with B with C A B C res0: A with B with C = $anon$1@5e025e70 scala> new A with C with B A C B res1: A with C with B = $anon$1@2ed94a8b
object Linearization3 { def main(args: Array[String]) { var x = new X println() println(x.foo) } } class A { print("A") def foo() = "A" } trait B extends A { print("B") override def foo() = super.foo() + "B" } trait C extends B { print("C") override def foo() = super.foo() + "C" } trait D extends A { print("D") override def foo() = super.foo() + "D" } class X extends A with D with C with B
object Linearization3 { def main(args: Array[String]) { var x = new X println() println(x.foo) } } class A { print("A") def foo() = "A" } trait B extends A { print("B") override def foo() = "B" + super.foo() } trait C extends B { print("C") override def foo() = "C" + super.foo() } trait D extends A { print("D") override def foo() = "D" + super.foo() } class X extends A with D with C with B
List(Future.successful(1), Future.successful(2)).sequence : Future[List[Int]] List(4.set("abc"), 5.set("def")).sequence : Writer[String, List[Int]]
def fetchPost(postId: Int): Future[String] List(1, 2).traverse[Future, String](fetchPost): Future[List[String]]
def logConversion(s: String): Writer[Vector[String], Int] = s.toInt.set(Vector(s"Converted $s")) List("4", "5").traverseU(logConversion): Writer[Vector[String], List[Int]]
def multiples(i: Int): Future[List[Int]] = Future.successful(List(i, i * 2, i * 3)) List(1, 10).map(multiples): List[Future[List[Int]]] List(1, 10).traverseM(multiples): Future[List[Int]]
scala> val l = 1.0 :: 5.5 :: Nil l: List[Double] = List(1.0, 5.5) scala> l res0: List[Double] = List(1.0, 5.5) scala> l ::: List(2.2, 3.7) res1: List[Double] = List(1.0, 5.5, 2.2, 3.7) scala> List(l) :+ 2.2 res2: List[Any] = List(List(1.0, 5.5), 2.2) scala> l res3: List[Double] = List(1.0, 5.5) scala>
val myList1 = 1.0 :: 5.5 :: Nil val myList2 = 2.2 :: 3.7 :: mylist1
var myList = 1.0 :: 5.5 :: Nil myList :::= List(2.2, 3.7)
val myList = scala.collection.mutable.MutableList(1.0, 5.5) myList.++=(List(2.2, 3.7))
import scala.collection.mutable.MutableList val x = MutableList(1, 2, 3, 4, 5) x += 6 x ++= MutableList(7, 8, 9)
scala> val l = 1.0 :: 5.5 :: Nil l: List[Double] = List(1.0, 5.5)
scala> l res0: List[Double] = List(1.0, 5.5) scala> l ::: List(2.2, 3.7) res1: List[Double] = List(1.0, 5.5, 2.2, 3.7)
scala> List(l) :+ 2.2 res2: List[Any] = List(List(1.0, 5.5), 2.2)
object Hidden { import scala.collection.immutable object immutable { def x = 7 } }
import org.eclipse.jetty.server.Server var server:Server=new Server()
> [warn] /home/xxx/xxx/xxx/src/main/scala/com/xxx/xxx/main/Server.scala:3: > imported `Server [warn] import org.eclipse.jetty.server.Server [warn] ^ [warn] one warning found
class Stack { ... methods such as push/pop } object Stack { ... factory method(s) and possibly others }
Exception in thread "main" java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.jetbrains.plugins.scala.testingSupport.specs2.JavaSpecs2Runner.runSingleTest(JavaSpecs2Runner.java:130) at org.jetbrains.plugins.scala.testingSupport.specs2.JavaSpecs2Runner.main(JavaSpecs2Runner.java:76) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120) Caused by: java.lang.RuntimeException: can not create specification: test.ApplicationSpec at scala.sys.package$.error(package.scala:27) at org.specs2.specification.SpecificationStructure$.createSpecification(BaseSpecification.scala:96) at org.specs2.runner.ClassRunner.createSpecification(ClassRunner.scala:64) at org.specs2.runner.ClassRunner.start(ClassRunner.scala:35) at org.specs2.runner.ClassRunner.main(ClassRunner.scala:28) at org.specs2.runner.NotifierRunner.main(NotifierRunner.scala:24) ... 11 more
resolvers += "Sonatype snapshots" at "http: addSbtPlugin("com.github.mpeltonen" % "sbt-idea" % "1.5.1")
scala> import collection.breakOut import collection.breakOut scala> List(1, 2, 3) res0: List[Int] = List(1, 2, 3) scala> res0.map(_.toString)(breakOut) : Vector[String] res2: Vector[String] = Vector(1, 2, 3)
scala> List(1, 2, 3).map(_.toString).to[Vector] res0: Vector[String] = Vector(1, 2, 3)
scala> res0.map(_.toString).toIndexedSeq res4: scala.collection.immutable.IndexedSeq[String] = Vector(1, 2, 3)
scala> res0.view.map(_.toString).toIndexedSeq res5: scala.collection.immutable.IndexedSeq[String] = Vector(1, 2, 3)
scala> trait Trans[F[_], G[_]] { | def f2g[A](f : F[A]) : G[A] | } defined trait Trans
scala> implicit val List2Vector = new Trans[List, collection.immutable.Vector] { | def f2g[A](l : List[A]) : Vector[A] = l.map(identity[A])(collection.breakOut) | } List2Vector: java.lang.Object with Trans[List,scala.collection.immutable.Vector] = $anon$1@56329755
scala> class Clever[M[_], A](ma : M[A]) { def to[N[_]](implicit t : Trans[M, N]) : N[A] = t.f2g(ma) } defined class Clever scala> implicit def ma2clever[M[_], A](ma : M[A]) = new Clever[M, A](ma) ma2clever: [M[_],A](ma: M[A])Clever[M,A]
scala> List(1, 2, 3).map(_.toString).to[Vector] res4: Vector[java.lang.String] = Vector(1, 2, 3)
listVar.sliding(2).toList.foldMap{ case List(prev, i) => Some(Map(i -> (1, Some(List(math.abs(i - prev)))))) case List(i) => Some(Map(i -> (1, None))) case _ => None }.map(_.mapValues{ case (count, gaps) => (count, gaps.map(_.min)) })
val schoolFuture = for { ud <- userStore.getUserDetails(user.userId) sid = ud.right.toOption.flatMap(_.schoolId) s <- schoolStore.getSchool(sid.get) if sid.isDefined } yield s
val schoolFuture: Future[Option[School]] = for { ud <- userStore.getUserDetails(user.userId) sid = ud.right.toOption.flatMap(_.schoolId) s <- sid.map(schoolStore.getSchool(_)) } yield s
[error] found : Option[scala.concurrent.Future[Option[School]]] [error] required: scala.concurrent.Future[Option[School]] [error] s <- sid.map(schoolStore.getSchool(_))
import concurrent.{Future, Promise} case class User(userId: Int) case class UserDetails(userId: Int, schoolId: Option[Int]) case class School(schoolId: Int, name: String) trait Error class UserStore { def getUserDetails(userId: Int): Future[Either[Error, UserDetails]] = Promise.successful(Right(UserDetails(1, Some(1)))).future } class SchoolStore { def getSchool(schoolId: Int): Future[Option[School]] = Promise.successful(Option(School(1, "Big School"))).future } object Demo { import concurrent.ExecutionContext.Implicits.global val userStore = new UserStore val schoolStore = new SchoolStore val user = User(1) val schoolFuture: Future[Option[School]] = for { ud <- userStore.getUserDetails(user.userId) sid = ud.right.toOption.flatMap(_.schoolId) s <- sid.map(schoolStore.getSchool(_)) } yield s }
getUserDetails: UserID => Future[Either[??, UserDetails]] getSchool: SchoolID => Future[Option[School]]
for { ud <- optionT(getUserDetails(user.userID) map (_.right.toOption)) sid <- optionT(Future.successful(ud.schoolID)) s <- optionT(getSchool(sid)) } yield s
for ( x0 <- c0; w1 = d1; x1 <- c1 if p1; ... ; xN <- cN) yield f c0.flatMap{ x0 => val w1 = d1 c1.filter(x1 => p1).flatMap{ x1 => ... cN.map(xN => f) ... } }
o.map(Future.successful).getOrElse(Future.failed(new Exception))
for { ud <- userStore.getUserDetails(user.userId) sid = ud.right.toOption.flatMap(_.schoolId) fid <- sid.map(Future.successful).getOrElse(Future.failed(new Exception)) s <- schoolStore.getSchool(fid) } yield s
implicit class OptionIsFuture[A](val option: Option[A]) extends AnyVal { def future = option.map(Future.successful).getOrElse(Future.failed(new Exception)) }
for { ud <- userStore.getUserDetails(user.userId) sid <- ud.right.toOption.flatMap(_.schoolId).future s <- schoolStore.getSchool(sid) } yield s
scala> None.get java.util.NoSuchElementException: None.get
val schoolFuture = for { ud <- userStore.getUserDetails(user.userId) sid = ud.right.toOption.flatMap(_.schoolId) s <- schoolStore.getSchool(sid.get) } yield s
object MyEnum extends Enumeration { val EnumValue = Value } val e: MyEnum.Value = MyEnum.EnumValue
object test { object a { val x = 1 } object b { val x = 1 } } test.a.x
object test { object a { val x = 1 } object b locally { val x = 1 } }
Source.fromFile(path).getLines.par foreach { line =>
error: value par is not a member of Iterator[String]
val chunkSize = 128 * 1024 val iterator = Source.fromFile(path).getLines.grouped(chunkSize) iterator.foreach { lines => lines.par.foreach { line => process(line) } }
case object LineRequest case object BeginProcessing class FileReader extends Actor { def getLine:Option[String] = ... def receive = { case LineRequest => self.sender.foreach{_ ! getLine} } } class Worker(reader: ActorRef) extends Actor { def process(line:String) ... def receive = { case BeginProcessing => reader ! LineRequest case Some(line) => { process(line) reader ! LineRequest } case None => self.stop } } val reader = actorOf[FileReader].start val workers = Vector.fill(4)(actorOf(new Worker(reader)).start) workers.foreach{_ ! BeginProcessing}
def src(source: Source) = Stream[String] = { if (source.hasNext) Stream.cons(source.takeWhile( _ != else Stream.empty }
scala> import com.timgroup.iterata.ParIterator.Implicits._ scala> val it = (1 to 100000).toIterator.par().map(n => (n + 1, Thread.currentThread.getId)) scala> it.map(_._2).toSet.size res2: Int = 8
source.getLines.toStream.par.foreach( line => println(line))
trait T(implicit impl: ClassName) { def foo = ... }
trait T { protected case class ClassNameW(implicit val wrapped: ClassName) protected val implWrap: ClassNameW import implWrap.wrapped def foo = ... }
trait Base[T] { val numT: Ordering[T] } /* Here we use a context bound, thus cannot specify the name of the implicit * and must define the field explicitly. */ class Der1[T: Ordering] extends Base[T] { val numT = implicitly[Ordering[T]] } /* Here we specify an implicit parameter, but add val, so that it automatically * implements the abstract value of the superclass. */ class Der2[T](implicit val numT: Ordering[T]) extends Base[T]
trait MyTrait { protected[this] implicit def e: ClassName }
class MyClass extends MyTrait { protected[this] val e = implicitly }
abstract class C trait A { this: C => val i: Int } implicit val n = 3 val a = new C with A { val i = implicitly[Int] }
abstract class A(id: Int) { type Self <: A def copy(newId: Int): Self } class B(id: Int, x: String) extends A(id) { type Self = B def copy(newId: Int) = new B(newId, x) } class C(id: Int, y: String, z: String) extends A(id) { type Self = C def copy(newId: Int) = new C(newId, y, z) }
class D(id: Int, w: String) extends A(id) { type Self = A def copy(newId: Int) = new D(newId, w) } class E(id: Int, v: String) extends A(id) { type Self = B def copy(newId: Int) = new B(newId, "") }
def createCopies[CA <: A](seq: Seq[CA]): Seq[CA] = seq.map(_.copy(genNewId()))
trait CanCopy[T <: CanCopy[T]] { self: T => type Self >: self.type <: T def copy(newId: Int): Self } abstract class A(id: Int) { self:CanCopy[_] => def copy(newId: Int): Self }
class B(id: Int, x: String) extends A(id) with CanCopy[B] { type Self = B def copy(newId: Int) = new B(newId, x) } class C(id: Int, y: String, z: String) extends A(id) with CanCopy[C] { type Self = C def copy(newId: Int) = new C(newId, y, z) }
class D(id: Int, w: String) extends A(id) with CanCopy[D] { type Self = A def copy(newId: Int) = new D(newId, w) } class E(id: Int, v: String) extends A(id) with CanCopy[E] { type Self = B def copy(newId: Int) = new B(newId, "") }
trait StrictSelf[T <: StrictSelf[T]] { self: T => type Self >: self.type <: T } abstract class A(id: Int) { self:StrictSelf[_] => def copy(newId:Int):Self }
abstract class A(id: Int) { type Self def copy(newId: Int): Self }
def genNewId(): Int = ??? def createCopies[A1 <: A { type Self = A1 }](seq: Seq[A1]): Seq[A1] = seq.map(_.copy(genNewId()))
class Base { type A } class Other extends Base class Sub extends Other
scala> def createCopies[CA <: A](seq: Seq[CA]): Seq[CA createCopies: [CA <: A](seq: Seq[CA])Seq[CA scala> val bs = List[B]( new B(1, "one"), new B(2, "two")) bs: List[B] = List(B@29b9ab6c, B@5ca554da) scala> val bs2: Seq[B] = createCopies(bs) bs2: Seq[B] = List(B@92334e4, B@6665696b)
package object math { case class SphereCoord(lat: Double, long: Double) { ... } def spheredist(a: SphereCoord, b: SphereCoord) = ... def rectArea(topleft: SphereCoord, botright: SphereCoord) = ... class DecimalInexactError extends Exception formatDecimalExactly(val num: Double) = ... }
protected class FooPackage { ... } package object foo extends FooPackage { }
def plus(x: Int)(y: Int) = x + y val plus10 = plus(10) _ println(plus10(2))
scala> def plus2(x: Int, y: Int) = x + y plus2: (x: Int,y: Int)Int scala> val anon = plus2(_,_) anon: (Int, Int) => Int = <function2> scala> anon(3, 4) res1: Int = 7
scala> val anon2 = plus2(20,_) <console>:5: error: missing parameter type for expanded function ((x$1) => plus2(20, x$1)) val anon2 = plus2(20,_) ^
scala> val anon2 = plus2(20,_: Int) anon2: (Int) => Int = <function1> scala> anon2(24) res2: Int = 44
scala> object Ashkan { def f(a:Int,b:Int) = a; def f(a:Int,b:String) = b; } defined object Ashkan scala> Ashkan.f(1,2) res45: Int = 1 scala> Ashkan.f(1,"Ashkan") res46: String = Ashkan scala> val x= Ashkan.f _ <console>:11: error: ambiguous reference to overloaded definition, both method f in object Ashkan of type (a: Int, b: String)String and method f in object Ashkan of type (a: Int, b: Int)Int match expected type ? val x= Ashkan.f _ ^ scala> val x= Ashkan.f(_,_) <console>:11: error: missing parameter type for expanded function ((x$1, x$2) => Ashkan.f(x$1, x$2)) val x= Ashkan.f(_,_) ^ <console>:11: error: missing parameter type for expanded function ((x$1: <error>, x$2) => Ashkan.f(x$1, x$2)) val x= Ashkan.f(_,_) ^ scala> val x= Ashkan.f(_,"Akbar") <console>:11: error: missing parameter type for expanded function ((x$1) => Ashkan.f(x$1, "Akbar")) val x= Ashkan.f(_,"Akbar") ^ scala> val x= Ashkan.f(1,_) <console>:11: error: missing parameter type for expanded function ((x$1) => Ashkan.f(1, x$1)) val x= Ashkan.f(1,_) ^ scala> val x= Ashkan.f(1,_:String) x: String => String = <function1>
val foo : Seq[Double] = ... val bar : Seq[Double] = ...
val baz : Seq[Double] = (foo.toList zip bar.toList) map ((f: Double, b : Double) => f+b)
implicit class IterableOfIterablePimps[T](collOfColls: Iterable[Iterable[T]]) { def mapZipped[V](f: Iterable[T] => V): Iterable[V] = new Iterable[V] { override def iterator: Iterator[V] = new Iterator[V] { override def next(): V = { val v = f(itemsLeft.map(_.head)) itemsLeft = itemsLeft.map(_.tail) v } override def hasNext: Boolean = itemsLeft.exists(_.nonEmpty) private var itemsLeft = collOfColls } } }
val collOfColls = List(List(1, 2, 3), List(4, 5, 6), List(7, 8, 9)) collOfColls.mapZipped { group => group }
abstract class A class B extends A class C extends A class D extends A class E extends A
val xs = List(new D, new B, new E, new E, new C, new B)
val ys = (xs collect { case b: B => None case c: C => None case notBorC => notBorC }).filter(_ != None).asInstanceOf[List[A]]
scala> val ys = xs flatMap { | case _: B | _: C => None | case other => Some(other) | } ys: List[A] = List(D@7ecdc97b, E@2ce07e6b, E@468bb9d1)
val ys = xs filterNot(List(classOf[B], classOf[C]) contains _.getClass)
def StrictOption(s: String) = s match { case s if s != null && s.trim.length() > 0 => Some(s) case _ => None }
if (s ne null && s.trim.length > 0) Some(s) else None
def ContentOption(s: String): Option[String] = { if (s ne null) { var i = s.length-1 while (i >= 0) { if (s.charAt(i) > i -= 1 } } None }
val res = for (v <- Option(s) if s.nonEmpty) yield v
Option.unless(str.isEmpty)(str) Option.when(str.nonEmpty)(str) Option.unless(str.isEmpty)(str) Option.when(str.nonEmpty)(str)
List(42, 69, 613) match { case x :: xs => x case Nil => 0 }
let rec len l = match l with | [] -> 0 | x :: xs -> 1 + len xs
val v = for ( a <- { val f0:Future[Class1] = process1 val f1:Future[Class2] = process2 val f2:Future[Class3] = process3 f0.zip(f1).zip(f2).map(x => (x._1._1,x._1._2,x._2)) } yield a
val result: Future[(Class1, Class2, Class3)] = { val f1 = process1 val f2 = process2 val f3 = process3 for { v1 <- f1; v2 <- f2; v3 <- f3 } yield (v1, v2, v3) }
trait Apply[Z[_]] { def apply[A, B](f: Z[A => B], a: Z[A]): Z[B] }
implicit val FutureApply = new Apply[Future] { def apply[A, B](f: Future[A => B], a: Future[A]): Future[B] = (f zip a) map { case (fn, a1) => fn(a1) } } }
implicit val FuturePure = new Pure[Future] { def pure[A](a: =>A): Future[A] = Future { a } } implicit val FutureBind = new Bind[Future] { def bind[A, B](a: Future[A], f: A => Future[B]): Future[B] = a flatMap f } implicit val FutureFunctor = new Functor[Future] { def map[A, B](a: Future[A], f: A => B): Future[B] = a map f }
val f:Future[(Class1,Class2,Class3)] = flow { val f0 = process1 val f1 = process2 val f2 = process3 (f0(), f1(), f2()) }
autoCompilerPlugins := true addCompilerPlugin("org.scala-lang.plugins" % "continuations" % "2.9.1")
Applicative[Future].map3(f0, f1, f2){ (f0r, f1r, f2r) => }
import java.nio.ByteBuffer ByteBuffer.wrap(Array[Byte](1, 2, 3, 4)).getInt ByteBuffer.wrap(Array[Byte](1, 2, 3, 4, 5, 6, 7, 8)).getDouble ByteBuffer.wrap(Array[Byte](1, 2, 3, 4, 5, 6, 7, 8)).getLong
import scala.math.BigInt val bytearray = BigInt(1337).toByteArray val int = BigInt(bytearray)
val bb = java.nio.ByteBuffer.allocate(4) val i = 5 bb.putInt(i) bb.flip val j = bb.getInt bb.clear
import java.lang.Double def doubleToByteArray(x: Double) = { val l = java.lang.Double.doubleToLongBits(x) val a = Array.fill(8)(0.toByte) for (i <- 0 to 7) a(i) = ((l >> ((7 - i) * 8)) & 0xff).toByte a } def byteArrayToDouble(x: Array[scala.Byte]) = { var i = 0 var res = 0.toLong for (i <- 0 to 7) { res += ((x(i) & 0xff).toLong << ((7 - i) * 8)) } java.lang.Double.longBitsToDouble(res) } scala> val x = doubleToByteArray(12.34) x: Array[Byte] = Array(64, 40, -82, 20, 122, -31, 71, -82) scala> val y = byteArrayToDouble(x) y: Double = 12.34
import java.nio.ByteBuffer def doubleToByteArray(x: Double) = { val l = java.lang.Double.doubleToLongBits(x) ByteBuffer.allocate(8).putLong(l).array() } def byteArrayToDouble(x:Array[Byte]) = ByteBuffer.wrap(x).getDouble
object OptionTest extends App { val x = scala.None val y = scala.Some("asdf") }
public static final scala.None$ x(); Signature: ()Lscala/None$; Code: 0: getstatic 3: invokevirtual 6: areturn
class X(i: Int) { def m1 = i*2 def m2(a: Int)(b: Int) = a*b def m3(a: Int)(implicit b: Int) = a*b }
val x = new X(5) x.i = 3 x.i X x = new X(5); x.i_$eq(3); x.i();
scala> import scala.reflect.NameTransformer._ import scala.reflect.NameTransformer._ scala> val ops = "~=<>! ops: String = ~=<>! scala> ops map { o => o -> encode(o.toString) } foreach println (~,$tilde) (=,$eq) (<,$less) (>,$greater) (!,$bang) ( (%,$percent) (^,$up) (&,$amp) (|,$bar) (*,$times) (/,$div) (+,$plus) (-,$minus) (:,$colon) (\,$bslash) (?,$qmark) (@,$at)
object X { val f: Int => Int = i => i*2 def g: Int => Int = i => i*2 def h: Int => Int => Int = a => b => a*b def i: Int => Int => Int = a => { def j: Int => Int = b => a*b j } }
X.f().apply(7); X.g().apply(7); X.h().apply(3).apply(5); X.i().apply(3).apply(5);
public abstract class scala.Option extends java.lang.Object implements ... { ... public static final scala.Option apply(java.lang.Object); public scala.Option(); }
public final class scala.Some extends scala.Option implements ... { ... public scala.Some(java.lang.Object); }
public final class scala.None extends java.lang.Object{ ... }
public final class scala.None$ extends scala.Option implements ... { ... public static final scala.None$ MODULE$; private scala.None$(); }
None$.apply(3) None$.MODULE$.isDefined(); new None$();
public class X extends java.lang.Object implements scala.ScalaObject{ ... public X(); Code: 0: aload_0 1: invokespecial 4: aload_0 5: getstatic 8: getstatic 11: iconst_3 12: newarray int 14: dup 15: iconst_0 16: iconst_1 17: iastore 18: dup 19: iconst_1 20: iconst_2 21: iastore 22: dup 23: iconst_2 24: iconst_3 25: iastore 26: invokevirtual 29: invokevirtual 32: putfield 35: return }
int[] arr = { 1, 2, 3 }; WrappedArray<Object> warr = Predef$.MODULE$.wrapIntArray(arr); List$.MODULE$.apply(warr); List$.MODULE$.apply(Predef$.MODULE$.wrapIntArray(new int[] { 1, 2, 3 }));
scala> :paste object OptionTest extends App { val x = scala.None val y = scala.Some("asdf") } defined module OptionTest scala> :javap -v OptionTest$ Compiled from "<console>" public final class OptionTest$ extends java.lang.Object implements scala.App,scala.ScalaObject SourceFile: "<console>" Scala: length = 0x [lots of output etc] public scala.None$ x(); Code: Stack=1, Locals=1, Args_size=1 0: aload_0 1: getfield 4: areturn
case class Data(stamm: Seq[String]) implicit val dataReads = ( (__ \ "stamm").read(Reads.list[String]) )(Data)
case class Person(name: String) val personReads: Reads[Person] = (__ \ "name").read[String].map { name => Person(name) }
val personWrites: Writes[Person] = (__ \ "name").write[String].contramap { (person: Person) => person.name }
val personFormat: Format[Person] = (__ \ "name").format[String].inmap(name => Person(name), (person: Person) => person.name)
case class Person(name: String) val personFormatter: Format[Person] = (__ \ "full_name").format[String].inmap(Person.apply, unlift(Person.unapply))
case class A(value: String) val reads = (__ \ "key").read[String].map(A.apply)
age,hours_per_week,education,sex,salaryRange 38,40,"hs-grad","male","A" 28,40,"bachelors","female","A" 52,45,"hs-grad","male","B" 31,50,"masters","female","B" 42,40,"bachelors","male","B"
val data = sqlContext.csvFile("/home/dusan/sample.csv")
val toInt = udf[Int, String]( _.toInt) val dataFixed = data.withColumn("age", toInt(data("age"))).withColumn("hours_per_week",toInt(data("hours_per_week")))
scala> dataFixed.printSchema root |-- age: integer (nullable = true) |-- hours_per_week: integer (nullable = true) |-- education: string (nullable = true) |-- sex: string (nullable = true) |-- salaryRange: string (nullable = true)
val rf = new RandomForestClassifier() val pipeline = new Pipeline().setStages(Array(rf)) val cv = new CrossValidator().setNumFolds(10).setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator)
import org.apache.spark.SparkConf import org.apache.spark.SparkContext import org.apache.spark.ml.classification.RandomForestClassifier import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator import org.apache.spark.ml.tuning.CrossValidator import org.apache.spark.ml.Pipeline import org.apache.spark.sql.DataFrame import org.apache.spark.sql.functions._ import org.apache.spark.mllib.linalg.{Vector, Vectors} object SampleClassification { def main(args: Array[String]): Unit = { val conf = new SparkConf().setAppName("Simple Application").setMaster("local"); val sc = new SparkContext(conf) val sqlContext = new org.apache.spark.sql.SQLContext(sc) import sqlContext.implicits._ import com.databricks.spark.csv._ val data = sqlContext.csvFile("/home/dusan/sample.csv") val toInt = udf[Int, String]( _.toInt) val dataFixed = data.withColumn("age", toInt(data("age"))).withColumn("hours_per_week",toInt(data("hours_per_week"))) val rf = new RandomForestClassifier() val pipeline = new Pipeline().setStages(Array(rf)) val cv = new CrossValidator().setNumFolds(10).setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator) val cmModel = cv.fit(dataFixed) } }
scala> val df2 = dataFixed.withColumnRenamed("age", "features") df2: org.apache.spark.sql.DataFrame = [features: int, hours_per_week: int, education: string, sex: string, salaryRange: string] scala> val cmModel = cv.fit(df2) java.lang.IllegalArgumentException: requirement failed: Column features must be of type org.apache.spark.mllib.linalg.VectorUDT@1eef but was actually IntegerType. at scala.Predef$.require(Predef.scala:233) at org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:37) at org.apache.spark.ml.PredictorParams$class.validateAndTransformSchema(Predictor.scala:50) at org.apache.spark.ml.Predictor.validateAndTransformSchema(Predictor.scala:71) at org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:118) at org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:164) at org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:164) at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51) at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60) at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:108) at org.apache.spark.ml.Pipeline.transformSchema(Pipeline.scala:164) at org.apache.spark.ml.tuning.CrossValidator.transformSchema(CrossValidator.scala:142) at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:59) at org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:107) at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67) at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:72) at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:74) at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:76)
val toVec4 = udf[Vector, Int, Int, String, String] { (a,b,c,d) => val e3 = c match { case "hs-grad" => 0 case "bachelors" => 1 case "masters" => 2 } val e4 = d match {case "male" => 0 case "female" => 1} Vectors.dense(a, b, e3, e4) }
val encodeLabel = udf[Double, String]( _ match { case "A" => 0.0 case "B" => 1.0} )
val df = dataFixed.withColumn( "features", toVec4( dataFixed("age"), dataFixed("hours_per_week"), dataFixed("education"), dataFixed("sex") ) ).withColumn("label", encodeLabel(dataFixed("salaryRange"))).select("features", "label")
scala> df.show() +-------------------+-----+ | features|label| +-------------------+-----+ |[38.0,40.0,0.0,0.0]| 0.0| |[28.0,40.0,1.0,1.0]| 0.0| |[52.0,45.0,0.0,0.0]| 1.0| |[31.0,50.0,2.0,1.0]| 1.0| |[42.0,40.0,1.0,0.0]| 1.0| +-------------------+-----+
val assembler = new VectorAssembler() .setInputCols(Array("col1", "col2", "col3")) .setOutputCol("features")
sortByKey([ascending], [numTasks]) When called on a dataset of (K, V) pairs where K implements Ordered, returns a dataset of (K, V) pairs sorted by keys in ascending or descending order, as specified in the boolean ascending argument.
class OrderedRDDFunctions { def sortByKey(ascending: Boolean = true, numPartitions: Int = self.partitions.size): RDD[P] = { val part = new RangePartitioner(numPartitions, self, ascending) val shuffled = new ShuffledRDD[K, V, P](self, part) shuffled.mapPartitions(iter => { val buf = iter.toArray if (ascending) { buf.sortWith((x, y) => x._1 < y._1).iterator } else { buf.sortWith((x, y) => x._1 > y._1).iterator } }, preservesPartitioning = true) }
/** * Take the first num elements of the RDD. It works by first scanning one partition, and use the * results from that partition to estimate the number of additional partitions needed to satisfy * the limit. */ def take(num: Int): Array[T] = {
sealed trait ResizedImageKey { /** * Get the dimensions to use on the resized image associated with this key */ def getDimension(originalDimension: Dimension): Dimension } case class Dimension(width: Int, height: Int) case object Large extends ResizedImageKey { def getDimension(originalDimension: Dimension) = Dimension(1000,1000) } case object Medium extends ResizedImageKey{ def getDimension(originalDimension: Dimension) = Dimension(500,500) } case object Small extends ResizedImageKey{ def getDimension(originalDimension: Dimension) = Dimension(100,100) }
import language.experimental.macros import scala.reflect.macros.Context object SealedExample { def values[A]: Set[A] = macro values_impl[A] def values_impl[A: c.WeakTypeTag](c: Context) = { import c.universe._ val symbol = weakTypeOf[A].typeSymbol if (!symbol.isClass) c.abort( c.enclosingPosition, "Can only enumerate values of a sealed trait or class." ) else if (!symbol.asClass.isSealed) c.abort( c.enclosingPosition, "Can only enumerate values of a sealed trait or class." ) else { val children = symbol.asClass.knownDirectSubclasses.toList if (!children.forall(_.isModuleClass)) c.abort( c.enclosingPosition, "All children must be objects." ) else c.Expr[Set[A]] { def sourceModuleRef(sym: Symbol) = Ident( sym.asInstanceOf[ scala.reflect.internal.Symbols ].sourceModule.asInstanceOf[Symbol] ) Apply( Select( reify(Set).tree, newTermName("apply") ), children.map(sourceModuleRef(_)) ) } } } }
scala> val keys: Set[ResizedImageKey] = SealedExample.values[ResizedImageKey] keys: Set[ResizedImageKey] = Set(Large, Medium, Small)
sealed trait ImageSize object ImageSize { case object Small extends ImageSize case object Medium extends ImageSize case object Large extends ImageSize val values = SealedTraitValues.values[ImageSize] }
import language.experimental.macros import scala.reflect.macros.Context object SealedExample { def values[A]: Set[A] = macro values_impl[A] def values_impl[A: c.WeakTypeTag](c: Context) = { import c.universe._ val symbol = weakTypeOf[A].typeSymbol if (!symbol.isClass) c.abort( c.enclosingPosition, "Can only enumerate values of a sealed trait or class." ) else if (!symbol.asClass.isSealed) c.abort( c.enclosingPosition, "Can only enumerate values of a sealed trait or class." ) else { val siblingSubclasses: List[Symbol] = scala.util.Try { val enclosingModule = c.enclosingClass.asInstanceOf[ModuleDef] enclosingModule.impl.body.filter { x => scala.util.Try(x.symbol.asModule.moduleClass.asClass.baseClasses.contains(symbol)) .getOrElse(false) }.map(_.symbol) } getOrElse { Nil } val children = symbol.asClass.knownDirectSubclasses.toList ::: siblingSubclasses if (!children.forall(x => x.isModuleClass || x.isModule)) c.abort( c.enclosingPosition, "All children must be objects." ) else c.Expr[Set[A]] { def sourceModuleRef(sym: Symbol) = Ident( if (sym.isModule) sym else sym.asInstanceOf[ scala.reflect.internal.Symbols ].sourceModule.asInstanceOf[Symbol] ) Apply( Select( reify(Set).tree, newTermName("apply") ), children.map(sourceModuleRef(_)) ) } } } }
object ResizedImageKey extends Enumeration { type ResizedImageKey = Value val Small, Medium, Large = Value def getDimension(value:ResizedImageKey):Dimension = value match{ case Small => Dimension(100, 100) case Medium => Dimension(500, 500) case Large => Dimension(1000, 1000) } println(ResizedImageKey.values.mkString(",")
object ResizedImageKey{ val values = Vector(Small, Medium, Large) } println(ResizedImageKey.values.mkString(",")
import shapeless._ trait AllSingletons[A, C <: Coproduct] { def values: List[A] } object AllSingletons { implicit def cnilSingletons[A]: AllSingletons[A, CNil] = new AllSingletons[A, CNil] { def values = Nil } implicit def coproductSingletons[A, H <: A, T <: Coproduct](implicit tsc: AllSingletons[A, T], witness: Witness.Aux[H] ): AllSingletons[A, H :+: T] = new AllSingletons[A, H :+: T] { def values: List[A] = witness.value :: tsc.values } } trait EnumerableAdt[A] { def values: Set[A] } object EnumerableAdt { implicit def fromAllSingletons[A, C <: Coproduct](implicit gen: Generic.Aux[A, C], singletons: AllSingletons[A, C] ): EnumerableAdt[A] = new EnumerableAdt[A] { def values: Set[A] = singletons.values.toSet } } def fetchAll[T](implicit ev: EnumerableAdt[T]):Set[T] = ev.values
object SharingPermission extends Enumeration { val READ = Value("READ") val WRITE = Value("WRITE") val MANAGE = Value("MANAGE") } /** * Permits to extend the enum definition and provide a mapping betweet SharingPermission and ActionType * @param permission */ class SharingPermissionExtended(permission: SharingPermission.Value) { val allowRead: Boolean = permission match { case SharingPermission.READ => true case SharingPermission.WRITE => true case SharingPermission.MANAGE => true } val allowWrite: Boolean = permission match { case SharingPermission.READ => false case SharingPermission.WRITE => true case SharingPermission.MANAGE => true } val allowManage: Boolean = permission match { case SharingPermission.READ => false case SharingPermission.WRITE => false case SharingPermission.MANAGE => true } def allowAction(actionType: ActionType.Value): Boolean = actionType match { case ActionType.READ => allowRead case ActionType.WRITE => allowWrite case ActionType.MANAGE => allowManage } } object SharingPermissionExtended { implicit def conversion(perm: SharingPermission.Value): SharingPermissionExtended = new SharingPermissionExtended(perm) }
val a = created recover { case e: database.ADBException => logger.error("Failed ...", e) throw new business.ABusinessException("Failed ...", e) }
val a = created recoverWith { case e: database.ADBException => logger.error("Failed ...", e) Future.failed(new business.ABusinessException("Failed ...", e)) }
/** Creates a new future that will handle any matching throwable that this * future might contain. If there is no match, or if this future contains * a valid result then the new future will contain the same. * * Example: * * {{{ * Future (6 / 0) recover { case e: ArithmeticException => 0 } * Future (6 / 0) recover { case e: NotFoundException => 0 } * Future (6 / 2) recover { case e: ArithmeticException => 0 } * }}} */ def recover[U >: T](pf: PartialFunction[Throwable, U])(implicit executor: ExecutionContext): Future[U] = { /** Creates a new future that will handle any matching throwable that this * future might contain by assigning it a value of another future. * * If there is no match, or if this future contains * a valid result then the new future will contain the same result. * * Example: * * {{{ * val f = Future { Int.MaxValue } * Future (6 / 0) recoverWith { case e: ArithmeticException => f } * }}} */ def recoverWith[U >: T](pf: PartialFunction[Throwable, Future[U]])(implicit executor: ExecutionContext): Future[U] = {
"the operation" should { f"return var res = "" val io = new ProcessIO( stdin => { stdin.write(in.getBytes) stdin.close() }, stdout => { res = convertStreamToString(stdout) stdout.close() }, stderr => { stderr.close() }) val proc = f"$operation $file".run(io) proc.exitValue() must be_==(0) res must be_==(out) } }
import sys.process._ def runCommand(cmd: Seq[String]): (Int, String, String) = { val stdoutStream = new ByteArrayOutputStream val stderrStream = new ByteArrayOutputStream val stdoutWriter = new PrintWriter(stdoutStream) val stderrWriter = new PrintWriter(stderrStream) val exitValue = cmd.!(ProcessLogger(stdoutWriter.println, stderrWriter.println)) stdoutWriter.close() stderrWriter.close() (exitValue, stdoutStream.toString, stderrStream.toString) }
import sys.process._ val os = new java.io.ByteArrayOutputStream val code = ("volname" os.close() val opt = if (code == 0) Some(os.toString("UTF-8")) else None
scala> val sb = new StringBuffer sb: StringBuffer = scala> ("/bin/ls /tmp" run BasicIO(false, sb, None)).exitValue res0: Int = 0 scala> sb res1: StringBuffer = ...
scala> import collection.mutable.ListBuffer import collection.mutable.ListBuffer scala> val b = ListBuffer[String]() b: scala.collection.mutable.ListBuffer[String] = ListBuffer() scala> ("/bin/ls /tmp" run ProcessLogger(b append _)).exitValue res4: Int = 0 scala> b mkString "\n" res5: String = ...
scala> val re = "Nonzero exit value: (\\d+)".r.unanchored re: scala.util.matching.UnanchoredRegex = Nonzero exit value: (\d+) scala> Try ("./bomb.sh" !!) match { | case Failure(f) => f.getMessage match { | case re(x) => println(s"Bad exit $x") | } | case Success(s) => println(s) | } warning: there were 1 feature warning(s); re-run with -feature for details Bad exit 3
def add(that: Rational): Rational = new Rational( this.numer * that.denom + that.numer * this.denom, this.denom * that.denom )
def add(that: Int): Rational = add(new Rational(that, 1))
def +(that: Rational): Rational = new Rational( this.numer * that.denom + that.numer * this.denom, this.denom * that.denom )
def +(that: Int): Rational = +(new Rational(that, 1))
(fragment of Rational.scala):19: error: value unary_+ is not a member of this.Rational +(new Rational(that, 1)) ^
def +(that: Int): Rational = this + (new Rational(that, 1))
def add(that: Int): Rational = this add (new Rational(that, 1))
def +(that: Int): Rational = this.+(new Rational(that, 1))
def unary_+: Rational = this.+(new Rational(that, 1)) val a = new Rational(3,2) val b = +a
def +(that: Int): Rational = +(new Rational(that, 1))
def +(that: Int): Rational = this +(new Rational(that, 1))
Map("foo"->3, "raise"->1, "the"->2, "bar"->4).toList sortBy {_._2}
List[(java.lang.String, Int)] = List((raise,1), (the,2), (foo,3), (bar,4))
import collection.immutable.ListMap ListMap(Map("foo"->3, "raise"->1, "the"->2, "bar"->4).toList.sortBy{_._2}:_*)
scala.collection.immutable.ListMap[java.lang.String,Int] = Map((raise,1), (the,2), (foo,3), (bar,4))
package controllers import play.api._ import play.api.mvc._ object Application extends Controller { def index = Action { Ok(views.html.index("Your new application is ready.")) } }
target/scala-2.11/src_managed/main target/scala-2.11/twirl/main
sourceDirectories in (Compile, TwirlKeys.compileTemplates) := (unmanagedSourceDirectories in Compile).value
addSbtPlugin("com.typesafe.sbteclipse" % "sbteclipse-plugin" % "5.1.0")
package scala.util.parsing package combinator package syntactical
package scala.util.parsing.combinator.syntactical import scala.util.parsing._ import scala.util.parsing.combinator._ ...
object Database is not a member of package com.me.project.controllers.com.me.project.database
import _root_.com.me.project.database.Database import com.me.project.database.Database
package com.mycompany.mydept.myproject.myfunctionality.sub1 import com.holdenkarau.spark.testing.DataFrameSuiteBase
class Post extends LongKeyedMapper[Post] with IdPK { def getSingleton = Post object title extends MappedText(this) object text extends MappedText(this) object date extends MappedDate(this) } object Post extends Post with LongKeyedMetaMapper[Post] { def getPosts(startAt: Int, count: Int) = { Post.findAll(OrderBy(Post.date, Descending), StartAt(startAt), MaxRows(count)) } def getPostsCount = Post.count }
trait Swim { def swim = println("Swimming!") } class Person val p1 = new Person val p2 = new Person with Swim
def swimThemAll(ps: Seq[Person with Swim]): Unit = { ps.foreach(_.swim) }
def swim(xs: Seq[_ >: Person with Swim]): Unit = { xs.foreach(_.swim) }
trait U { self => val name = "outer" val b = new AnyRef { val name = "inner" println(name) println(this.name) println(self.name) } }
val y = List(1) val z: java.util.List[Integer] = asList(y) map { (x: Int) => x : java.lang.Integer }
implicit def toIntegerList( lst: List[Int] ) = seqAsJavaList( lst.map( i => i:java.lang.Integer ) )
scala> def sizeOf( lst: java.util.List[java.lang.Integer] ) = lst.size scala> sizeOf( List(1,2,3) ) res5: Int = 3
import collection.JavaConversions._ class A { def l() = asList(List(1,2)).asInstanceOf[java.util.List[java.lang.Integer]] }
val javalist = collection.JavaConversions.asJavaList (y)
import scala.collection.JavaConverters._ val y = List (1) > y: List[Int] = List(1) val javalist = (y).asJava > javalist: java.util.List[Int] = [1]
import java.util.{List => JList} import scala.collection.JavaConverters._ def scalaList2JavaList[A, B](scalaList: List[A]) (implicit a2bConversion: A => B): JList[B] = (scalaList map a2bConversion).asJava
import java.util.{List => JList} import scala.collection.JavaConversions._ def javaList2ScalaList[A, B](javaList: JList[A]) (implicit a2bConversion: A => B): List[B] = javaList.toList map a2bConversion
def javaMap2ScalaMap[A, B, C, D](javaMap: util.Map[A, B])(implicit a2cConversion: A => C, b2dConversion: B => D): Map[C, D] = javaMap.toMap map { case (a, b) => (a2cConversion(a), b2dConversion(b)) }
val scalaMap = val javaMap = scalaMap.mapValues(Double.box)
[visitorId: string, trackingIds: array<string>, emailIds: array<string>]
visitorId |trackingIds|emailIds +-----------+------------+-------- |a158| [666b] | [12] |7g21| [c0b5] | [45] |7g21| [c0b4] | [87] |a158| [666b, 777c]| []
visitorId |trackingIds|emailIds +-----------+------------+-------- |a158| [666b,666b,777c]| [12, |7g21| [c0b5,c0b4] | [45, 87]
case class Record( visitorId: String, trackingIds: Array[String], emailIds: Array[String]) val df = Seq( Record("a158", Array("666b"), Array("12")), Record("7g21", Array("c0b5"), Array("45")), Record("7g21", Array("c0b4"), Array("87")), Record("a158", Array("666b", "777c"), Array.empty[String])).toDF
import org.apache.spark.sql.functions.udf val flatten = udf((xs: Seq[Seq[String]]) => xs.flatten)
import org.apache.spark.sql.functions.{array, lit, when} val dfWithPlaceholders = df.withColumn( "emailIds", when(size($"emailIds") === 0, array(lit(""))).otherwise($"emailIds"))
import org.apache.spark.sql.functions.{array, collect_list} val emailIds = flatten(collect_list($"emailIds")).alias("emailIds") val trackingIds = flatten(collect_list($"trackingIds")).alias("trackingIds") df .groupBy($"visitorId") .agg(trackingIds, emailIds)
df.as[Record] .groupByKey(_.visitorId) .mapGroups { case (key, vs) => vs.map(v => (v.trackingIds, v.emailIds)).toArray.unzip match { case (trackingIds, emailIds) => Record(key, trackingIds.flatten, emailIds.flatten) }}
import org.apache.spark.sql.Row dfWithPlaceholders.rdd .map { case Row(id: String, trcks: Seq[String @ unchecked], emails: Seq[String @ unchecked]) => (id, (trcks, emails)) } .groupByKey .map {case (key, vs) => vs.toArray.unzip match { case (trackingIds, emailIds) => Record(key, trackingIds.flatten, emailIds.flatten) }} .toDF
import org.apache.spark.sql.functions._ inventory .select($"*", explode($"trackingIds") as "tracking_id") .select($"*", explode($"emailIds") as "email_id") .groupBy("visitorId") .agg( collect_list("tracking_id") as "trackingIds", collect_list("email_id") as "emailIds")
package com.package.name import org.apache.spark.sql.Row import org.apache.spark.sql.expressions.{MutableAggregationBuffer, UserDefinedAggregateFunction} import org.apache.spark.sql.types._ import scala.collection.JavaConverters._ class CustomAggregation() extends UserDefinedAggregateFunction { def inputSchema: StructType = StructType(Array(StructField("col5", ArrayType(StringType)))) def bufferSchema = StructType(Array( StructField("col5_collapsed", ArrayType(StringType)))) def dataType: DataType = ArrayType(StringType) def deterministic = true def initialize(buffer: MutableAggregationBuffer) = { buffer(0) = Array.empty[String] } def update(buffer: MutableAggregationBuffer, input: Row) = { buffer(0) = if(!input.isNullAt(0)) buffer.getList[String](0).toArray ++ input.getList[String](0).toArray else buffer.getList[String](0).toArray } def merge(buffer1: MutableAggregationBuffer, buffer2: Row) = { buffer1(0) = buffer1.getList[String](0).toArray ++ buffer2.getList[String](0).toArray } def evaluate(buffer: Row) = { buffer.getList[String](0).asScala.toList.distinct } }
val CustomAggregation = new CustomAggregation() DataFrame .groupBy(col1,col2,col3) .agg(CustomAggregation(DataFrame(col5))).show()
val rddPart1 = ??? val rddPart2 = ??? val rddAll = rddPart1.union(rddPart2)
val rdd1 = sc.parallelize(Seq((1, "Aug", 30),(1, "Sep", 31),(2, "Aug", 15),(2, "Sep", 10))) val rdd2 = sc.parallelize(Seq((1, "Oct", 10),(1, "Nov", 12),(2, "Oct", 5),(2, "Nov", 15))) rdd1.union(rdd2).collect res0: Array[(Int, String, Int)] = Array((1,Aug,30), (1,Sep,31), (2,Aug,15), (2,Sep,10), (1,Oct,10), (1,Nov,12), (2,Oct,5), (2,Nov,15))
val rddPart1= ??? val rddPart2= ??? val rddAll = rddPart1.unionAll(rddPart2)
class Client(name : String, age : Int){ } object Client{ val clients = List(Client("Bob", 20), Client("Cindy", 30)) }
trait ConfigSource { def clients : List[Client] } object ConfigFileSource extends ConfigSource { override def clients = buildClientsFromProperties(Properties("clients.properties")) } object DatabaseSource extends ConfigSource { } object Client { @Resource("configuration_source") private var config : ConfigSource = _ val clients = config.clients }
def nthClient(n: Int): Configured[Client] = { config => config.clients(n) }
def ages: Configured[(Int, Int, Int)] = for { a0 <- nthClient(0) a1 <- nthClient(1) a2 <- nthClient(2) } yield (a0.age, a1.age, a2.age)
angular.module( config([ $routeProvider. when( when( otherwise({redirectTo: }]);
GET /partials/phone_index controllers.Application.phone_index
def phone_index = Action { Ok(views.html.partials.phone_index()) }
@(id: Long)(implicit request: RequestWithUser[AnyContent]) @import helper._ <!doctype html> <html lang="en" ng-app="phonecat"> <head> <meta charset="utf-8"> <title>Google Phone Gallery</title> <link rel="stylesheet" href="css/app.css"> <link rel="stylesheet" href="css/bootstrap.css"> <script src="lib/angular/angular.js"></script> <script src="js/app.js"></script> <script src="js/controllers.js"></script> <script src="js/filters.js"></script> <script src="js/services.js"></script> <script src="lib/angular/angular-resource.js"></script> </head> <body> <div ng-view></div> @ngTemplate("phone-list.html") { <div class="container-fluid"> <div class="row-fluid"> <div class="span12">Hello @request.user.name</div> </div> <div class="row-fluid"> <div class="span2"> <!--Sidebar content--> Search: <input ng-model="query"> Sort by: <select ng-model="orderProp"> <option value="name">Alphabetical</option> <option value="age">Newest</option> </select> </div> <div class="span10"> <!--Body content--> <ul class="phones"> <li ng-repeat="phone in phones | filter:query | orderBy:orderProp" class="thumbnail"> <a href=" <a href=" <p>{{phone.snippet}}</p> </li> </ul> </div> </div> </div> } @ngTemplate("phone-detail.html") { <img ng-src="{{mainImageUrl}}" class="phone"> <h1>{{phone.name}}</h1> <p>{{phone.description}}</p> <ul class="phone-thumbs"> <li ng-repeat="img in phone.images"> <img ng-src="{{img}}" ng-click="setImage(img)"> </li> </ul> <ul class="specs"> <li> <span>Availability and Networks</span> <dl> <dt>Availability</dt> <dd ng-repeat="availability in phone.availability">{{availability}}</dd> </dl> </li> </ul> } </body> </html>
angular.module( config([ $routeProvider. when( when( otherwise({redirectTo: }]);
@** * @ngTemplate * Generate an AngularJS inlined template. * * Note: Do not include scripts in your @template HTML. This will break the template. * * @param name * @param template *@ @(name: String)(template: Html) <script type="text/ng-template" id="@name">@template</script>
/partials/:view controllers.Application.showView(view:String)
Map("phone_index" -> views.html.partials.phone_index())
val routes = Map( "phone_index" -> { implicit r:RequestHeader => views.html.partials.phone_index()) }
def showView(view:String) = Action { implicit r => routes(view) }
/partials/specific controllers.Application.specific()
case class User (name: String, age: Int, posts: List[String]) { val numPosts: Int = posts.length ... def foo = "bar" ... }
val myUser = User("Foo", 25, List("Lorem", "Ipsum")) myUser.toMap
Map("name" -> "Foo", "age" -> 25, "posts" -> List("Lorem", "Ipsum"), "numPosts" -> 2)
abstract class Model { def toMap[T]: Map[String, Any] = macro toMap_impl[T] } class User(...) extends Model { ... }
object Macros { import scala.language.experimental.macros import scala.reflect.macros.Context def getMap_impl[T: c.WeakTypeTag](c: Context): c.Expr[Map[String, Any]] = { import c.universe._ val tpe = weakTypeOf[T] val members = tpe.members.toList.filter(m => !m.isMethod && m.toString.startsWith("value")) val tuples = for { m <- members val fieldString = Literal(Constant(m.toString.replace("value ", ""))) val field = Ident(m) } yield (fieldString, field) val mappings = tuples.toMap /* Parse the string version of the map [i.e. Map("posts" -> (posts), "age" -> (age), "name" -> (name))] to get the AST * for the map, which is generated as: * * Apply(Ident(newTermName("Map")), * List( * Apply(Select(Literal(Constant("posts")), newTermName("$minus$greater")), List(Ident(newTermName("posts")))), * Apply(Select(Literal(Constant("age")), newTermName("$minus$greater")), List(Ident(newTermName("age")))), * Apply(Select(Literal(Constant("name")), newTermName("$minus$greater")), List(Ident(newTermName("name")))) * ) * ) * * which is equivalent to Map("posts".$minus$greater(posts), "age".$minus$greater(age), "name".$minus$greater(name)) */ c.Expr[Map[String, Any]](c.parse(mappings.toString)) } }
[error] /Users/emre/workspace/DynamoReflection/core/src/main/scala/dynamo/Main.scala:9: not found: value posts [error] foo.getMap[User] [error] ^
lazy val root: Project = Project( "root", file("core"), settings = buildSettings ) aggregate(macros, core) lazy val macros: Project = Project( "macros", file("macros"), settings = buildSettings ++ Seq( libraryDependencies <+= (scalaVersion)("org.scala-lang" % "scala-reflect" % _)) ) lazy val core: Project = Project( "core", file("core"), settings = buildSettings ) dependsOn(macros)
import scala.language.experimental.macros abstract class Model { def toMap[T]: Map[String, Any] = macro Macros.toMap_impl[T] } object Macros { import scala.reflect.macros.Context def toMap_impl[T: c.WeakTypeTag](c: Context) = { import c.universe._ val mapApply = Select(reify(Map).tree, newTermName("apply")) val pairs = weakTypeOf[T].declarations.collect { case m: MethodSymbol if m.isCaseAccessor => val name = c.literal(m.name.decoded) val value = c.Expr(Select(c.resetAllAttrs(c.prefix.tree), m.name)) reify(name.splice -> value.splice).tree } c.Expr[Map[String, Any]](Apply(mapApply, pairs.toList)) } }
import scala.language.experimental.macros trait Model object Model { implicit class Mappable[M <: Model](val model: M) extends AnyVal { def asMap: Map[String, Any] = macro Macros.asMap_impl[M] } private object Macros { import scala.reflect.macros.Context def asMap_impl[T: c.WeakTypeTag](c: Context) = { import c.universe._ val mapApply = Select(reify(Map).tree, newTermName("apply")) val model = Select(c.prefix.tree, newTermName("model")) val pairs = weakTypeOf[T].declarations.collect { case m: MethodSymbol if m.isCaseAccessor => val name = c.literal(m.name.decoded) val value = c.Expr(Select(model, m.name)) reify(name.splice -> value.splice).tree } c.Expr[Map[String, Any]](Apply(mapApply, pairs.toList)) } } }
scala> println(User("a", 1, Nil).asMap) Map(name -> a, age -> 1, posts -> List())
(user.productElementNames zip user.productIterator).toMap
val classAObject = ClassA(1,2) implicit val classAWrites= Json.writes[ClassA] val jsonObject = Json.toJson(classAObject)
scala> jsonObject.as[JsObject] + ("c" -> Json.toJson(3)) res0: play.api.libs.json.JsObject = {"a":1,"b":2,"c":3}
scala> val jsonObject = classAWrites.writes(classAObject) jsonObject: play.api.libs.json.JsObject = {"a":1,"b":2} scala> jsonObject + ("c" -> Json.toJson(3)) res1: play.api.libs.json.JsObject = {"a":1,"b":2,"c":3}
val jsonObject = Json.toJson(classAObject).as[JsObject] jsonObject + ("c", JsNumber(3))
var jField : Json.JsonField = "myfield" obj1.asJson.->:(jField, obj2.asJson)
val a = List(1, 2, 3) val b = List(4, 5) println(a zip b)
assert [[1, 2, 3], [4, 5]].transpose() == [[1, 4], [2, 5]]
def fromDelimitedTextFile[A : Manifest : WireFormat] (path: String, sep: String = "\t") (extractFn: PartialFunction[List[String], A]) : DList[A] = { val lines = fromTextFile(path) lines.flatMap { line => val fields = line.split(sep).toList if (extractFn.isDefinedAt(fields)) List(extractFn(fields)) else Nil } }
def meth[A : ContextBound1 : ContextBoundN](a: A) def meth[A](a: A)(implicit evidence: ContextBound1[A], ContextBoundN[A])
def runiter(start: Int) { val iter = { def loop(v: Int): Stream[Int] = { println("I computed a value", v); v} loop(start) } println("about to loop") for (x <- iter) { if (x < 10) println("saw value", x) else return } }
scala> runiter(3) (I computed a value,3) about to loop (saw value,3) (I computed a value,4) (saw value,4) (I computed a value,5) (saw value,5) (I computed a value,6) (saw value,6) (I computed a value,7) (saw value,7) (I computed a value,8) (saw value,8) (I computed a value,9) (saw value,9) (I computed a value,10)
def runiter(start: Int) { val iter = { def loop(v: Int): Stream[Int] = { println("I computed a value", v); v} Stream[Int]() ++ loop(start) } println("about to loop") for (x <- iter) { if (x < 10) println("saw value", x) else return } }
scala> runiter(3) (I computed a value,3) about to loop (saw value,3) (I computed a value,4) (saw value,4) (I computed a value,5) (saw value,5) (I computed a value,6) (saw value,6) (I computed a value,7) (saw value,7) (I computed a value,8) (saw value,8) (I computed a value,9) (saw value,9) (I computed a value,10)
def runiter(start: Int) { val iter = { def loop(v: Int): Iterator[Int] = { println("I computed a value", v); Iterator(v)} ++ loop(v+1) Iterator[Int]() ++ loop(start) } println("about to loop") for (x <- iter) { if (x < 10) println("saw value", x) else return } }
scala> runiter(3) about to loop (I computed a value,3) (saw value,3) (I computed a value,4) (saw value,4) (I computed a value,5) (saw value,5) (I computed a value,6) (saw value,6) (I computed a value,7) (saw value,7) (I computed a value,8) (saw value,8) (I computed a value,9) (saw value,9) (I computed a value,10)
def f() = { val spark = SparkSession().... import spark.implicits._ }
class SomeSpec extends FlatSpec with BeforeAndAfter { var spark:SparkSession = _ import spark.implicits._ before { spark = SparkSession().... import spark.implicits._ } "a test" should "run" in { import spark.implicits._ val spark = this.spark import spark.implicits._ } }
class SomeSpec extends FlatSpec with BeforeAndAfter { self => var spark: SparkSession = _ private object testImplicits extends SQLImplicits { protected override def _sqlContext: SQLContext = self.spark.sqlContext } import testImplicits._ before { spark = SparkSession.builder().master("local").getOrCreate() } "a test" should "run" in { val df = spark.sparkContext.parallelize(List(1,2,3)).toDF() } }
class SomeSpec extends FlatSpec with SharedSQLContext { import testImplicits._ }
/** * :: Experimental :: * (Scala-specific) Implicit methods available in Scala for converting * common Scala objects into [[DataFrame]]s. * * {{{ * val sparkSession = SparkSession.builder.getOrCreate() * import sparkSession.implicits._ * }}} * * @since 2.0.0 */ @Experimental object implicits extends SQLImplicits with Serializable { protected override def _sqlContext: SQLContext = SparkSession.this.sqlContext }
@transient lazy val spark = SparkSession .builder() .master("spark: .getOrCreate() import spark.implicits._
peopleDf.filter($"age" > 15) peopleDf.where($"age" > 15) peopleDf($"age" > 15)
table1_df .filter($"Col_1_name" === "buddy") .filter($"Col_2_name" === "A") .filter(not($"Col_2_name".contains(" .sql"))) .filter("Col_2_name is not null") .take(5).foreach(println)
import sqlContext.implicits._ df.filter($"state" === "TX")
import sqlContext.implicits._ df.filter($"state" === var)
val myjson = "[{\"name\":\"Alabama\",\"abbreviation\":\"AL\"},{\"name\":\"Alaska\",\"abbreviation\":\"AK\"},{\"name\":\"American Samoa\",\"abbreviation\":\"AS\"},{\"name\":\"Arizona\",\"abbreviation\":\"AZ\"},{\"name\":\"Arkansas\",\"abbreviation\":\"AR\"},{\"name\":\"California\",\"abbreviation\":\"CA\"},{\"name\":\"Colorado\",\"abbreviation\":\"CO\"},{\"name\":\"Connecticut\",\"abbreviation\":\"CT\"},{\"name\":\"Delaware\",\"abbreviation\":\"DE\"},{\"name\":\"District Of Columbia\",\"abbreviation\":\"DC\"},{\"name\":\"Federated States Of Micronesia\",\"abbreviation\":\"FM\"},{\"name\":\"Florida\",\"abbreviation\":\"FL\"},{\"name\":\"Georgia\",\"abbreviation\":\"GA\"},{\"name\":\"Guam\",\"abbreviation\":\"GU\"},{\"name\":\"Hawaii\",\"abbreviation\":\"HI\"},{\"name\":\"Idaho\",\"abbreviation\":\"ID\"},{\"name\":\"Illinois\",\"abbreviation\":\"IL\"},{\"name\":\"Indiana\",\"abbreviation\":\"IN\"},{\"name\":\"Iowa\",\"abbreviation\":\"IA\"},{\"name\":\"Kansas\",\"abbreviation\":\"KS\"},{\"name\":\"Kentucky\",\"abbreviation\":\"KY\"},{\"name\":\"Louisiana\",\"abbreviation\":\"LA\"},{\"name\":\"Maine\",\"abbreviation\":\"ME\"},{\"name\":\"Marshall Islands\",\"abbreviation\":\"MH\"},{\"name\":\"Maryland\",\"abbreviation\":\"MD\"},{\"name\":\"Massachusetts\",\"abbreviation\":\"MA\"},{\"name\":\"Michigan\",\"abbreviation\":\"MI\"},{\"name\":\"Minnesota\",\"abbreviation\":\"MN\"},{\"name\":\"Mississippi\",\"abbreviation\":\"MS\"},{\"name\":\"Missouri\",\"abbreviation\":\"MO\"},{\"name\":\"Montana\",\"abbreviation\":\"MT\"},{\"name\":\"Nebraska\",\"abbreviation\":\"NE\"},{\"name\":\"Nevada\",\"abbreviation\":\"NV\"},{\"name\":\"New Hampshire\",\"abbreviation\":\"NH\"},{\"name\":\"New Jersey\",\"abbreviation\":\"NJ\"},{\"name\":\"New Mexico\",\"abbreviation\":\"NM\"},{\"name\":\"New York\",\"abbreviation\":\"NY\"},{\"name\":\"North Carolina\",\"abbreviation\":\"NC\"},{\"name\":\"North Dakota\",\"abbreviation\":\"ND\"},{\"name\":\"Northern Mariana Islands\",\"abbreviation\":\"MP\"},{\"name\":\"Ohio\",\"abbreviation\":\"OH\"},{\"name\":\"Oklahoma\",\"abbreviation\":\"OK\"},{\"name\":\"Oregon\",\"abbreviation\":\"OR\"},{\"name\":\"Palau\",\"abbreviation\":\"PW\"},{\"name\":\"Pennsylvania\",\"abbreviation\":\"PA\"},{\"name\":\"Puerto Rico\",\"abbreviation\":\"PR\"},{\"name\":\"Rhode Island\",\"abbreviation\":\"RI\"},{\"name\":\"South Carolina\",\"abbreviation\":\"SC\"},{\"name\":\"South Dakota\",\"abbreviation\":\"SD\"},{\"name\":\"Tennessee\",\"abbreviation\":\"TN\"},{\"name\":\"Texas\",\"abbreviation\":\"TX\"},{\"name\":\"Utah\",\"abbreviation\":\"UT\"},{\"name\":\"Vermont\",\"abbreviation\":\"VT\"},{\"name\":\"Virgin Islands\",\"abbreviation\":\"VI\"},{\"name\":\"Virginia\",\"abbreviation\":\"VA\"},{\"name\":\"Washington\",\"abbreviation\":\"WA\"},{\"name\":\"West Virginia\",\"abbreviation\":\"WV\"},{\"name\":\"Wisconsin\",\"abbreviation\":\"WI\"},{\"name\":\"Wyoming\",\"abbreviation\":\"WY\"}]" import spark.implicits._ val df = spark.read.json(Seq(myjson).toDS) df.show import spark.implicits._ val df = spark.read.json(Seq(myjson).toDS) df.show scala> df.show +------------+--------------------+ |abbreviation| name| +------------+--------------------+ | AL| Alabama| | AK| Alaska| | AS| American Samoa| | AZ| Arizona| | AR| Arkansas| | CA| California| | CO| Colorado| | CT| Connecticut| | DE| Delaware| | DC|District Of Columbia| | FM|Federated States ...| | FL| Florida| | GA| Georgia| | GU| Guam| | HI| Hawaii| | ID| Idaho| | IL| Illinois| | IN| Indiana| | IA| Iowa| | KS| Kansas| +------------+--------------------+ scala> df.filter(df("abbreviation") === "TX").show +------------+-----+ |abbreviation| name| +------------+-----+ | TX|Texas| +------------+-----+ scala> df.filter(df("abbreviation") === lit("TX")).show +------------+-----+ |abbreviation| name| +------------+-----+ | TX|Texas| +------------+-----+ scala> df.filter(not(df("abbreviation") === "TX")).show +------------+--------------------+ |abbreviation| name| +------------+--------------------+ | AL| Alabama| | AK| Alaska| | AS| American Samoa| | AZ| Arizona| | AR| Arkansas| | CA| California| | CO| Colorado| | CT| Connecticut| | DE| Delaware| | DC|District Of Columbia| | FM|Federated States ...| | FL| Florida| | GA| Georgia| | GU| Guam| | HI| Hawaii| | ID| Idaho| | IL| Illinois| | IN| Indiana| | IA| Iowa| | KS| Kansas| +------------+--------------------+ only showing top 20 rows
val json = WS.url("http: val geocoder = json.getAsString
private String getNullAsEmptyString(JsonElement jsonElement) { return jsonElement.isJsonNull() ? "" : jsonElement.getAsString(); }
scala> case class A(key: Int, x: Int) defined class A scala> val l = List(A(1, 2), A(1, 3), A(2, 1)) l: List[A] = List(A(1,2), A(1,3), A(2,1)) scala> val m: Map[Int, A] = (l, l).zipped.map(_.key -> _)(collection.breakOut) m: Map[Int,A] = Map((1,A(1,3)), (2,A(2,1)))
scala> l.groupBy(_.key) res1: scala.collection.Map[Int,List[A]] = Map((1,List(A(1,2), A(1,3))), (2,List(A(2,1))))
case class MyData(key: String, value: String) val myDataSeq = Seq(MyData("key1", "value1"), MyData("key2", "value2"), MyData("key3", "value3")) val myDataSeqAsTuple = myDataSeq.map(myData => (myData.key, myData.value)) val myDataFromTupleToMap = myDataSeqAsTuple.toMap
val map = Map[String, Option[Int]]("one" -> Some(1), "two" -> Some(2), "three" -> None)
scala> map.filter(_._2.isDefined) res4: scala.collection.immutable.Map[String,Option[Int]] = Map(one -> Some(1), two -> Some(2))
scala> map.collect { case (key, Some(value)) => (key, value) } res0: scala.collection.immutable.Map[String,Int] = Map(one -> 1, two -> 2)
val b = a map (entry => entry match { case ((x,y), u) => ((y,x), u) } )
val b = List(1, 2) b map({case 1 => "one" case 2 => "two"})
val b = a collect { case ((x, y), u) => ((y, x), u) }
val b = a map { p => val ((x,y), u) = p; ((y, x), u) }
val a: List[((Int, Int), Int)] = val b = a map { case ((x, y), u) => ((y, x), u) }
val b = (a: List[((Int, Int), Int)]) map { case ((x, y), u) => ((y, x), u) }
val xs = List((1,2)->3,(4,5)->6,(7,8)->9) xs map { case (a,b) => (a.swap, b) }
object Ambig extends App { def f( x:Int ) { println("Int" ) } def f( x:String ) { println("String") } f( null.asInstanceOf[Int ] ) f( null.asInstanceOf[String] ) f(null) }
scala> "foo".asInstanceOf[Int] java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer at scala.runtime.BoxesRunTime.unboxToInt(Unknown Source) ...
object Test extends App { println(null.asInstanceOf[Int]) def printit(x: Int) = println(x) printit(null.asInstanceOf[Int]) def nullint[T] = null.asInstanceOf[T] println(nullint[Int]) def nullspecint[@specialized(Int) T] = null.asInstanceOf[T] println(nullspecint[Int]) }
def belowThreshold(power: Int): Boolean = { return power < -40 } sqlContext.udf.register("belowThreshold", belowThreshold _)
val aggDF = sqlContext.sql("""SELECT span, belowThreshold(opticalReceivePower), timestamp FROM ifDF WHERE opticalReceivePower IS NOT null GROUP BY span, timestamp ORDER BY span""")
import org.apache.spark.sql.expressions.Aggregator import org.apache.spark.sql.{Encoder, Encoders} class BelowThreshold[I](f: I => Boolean) extends Aggregator[I, Boolean, Boolean] with Serializable { def zero = false def reduce(acc: Boolean, x: I) = acc | f(x) def merge(acc1: Boolean, acc2: Boolean) = acc1 | acc2 def finish(acc: Boolean) = acc def bufferEncoder: Encoder[Boolean] = Encoders.scalaBoolean def outputEncoder: Encoder[Boolean] = Encoders.scalaBoolean } val belowThreshold = new BelowThreshold[(String, Int)](_._2 < - 40).toColumn df.as[(String, Int)].groupByKey(_._1).agg(belowThreshold)
import org.apache.spark.sql.expressions._ import org.apache.spark.sql.types._ import org.apache.spark.sql.Row object belowThreshold extends UserDefinedAggregateFunction { def inputSchema = new StructType().add("power", IntegerType) def bufferSchema = new StructType().add("ind", BooleanType) def dataType = BooleanType def deterministic = true def initialize(buffer: MutableAggregationBuffer) = buffer.update(0, false) def update(buffer: MutableAggregationBuffer, input: Row) = { if (!input.isNullAt(0)) buffer.update(0, buffer.getBoolean(0) | input.getInt(0) < -40) } def merge(buffer1: MutableAggregationBuffer, buffer2: Row) = { buffer1.update(0, buffer1.getBoolean(0) | buffer2.getBoolean(0)) } def evaluate(buffer: Row) = buffer.getBoolean(0) }
df .groupBy($"group") .agg(belowThreshold($"power").alias("belowThreshold")) .show
val df = sc.parallelize(Seq( ("a", 0), ("a", 1), ("b", 30), ("b", -50))).toDF("group", "power") df .withColumn("belowThreshold", ($"power".lt(-40)).cast(IntegerType)) .groupBy($"group") .agg(sum($"belowThreshold").notEqual(0).alias("belowThreshold")) .show
import org.apache.spark.sql.catalyst.expressions.aggregate.DeclarativeAggregate import org.apache.spark.sql.catalyst.expressions._ import org.apache.spark.sql.types._ case class BelowThreshold(child: Expression, threshold: Expression) extends DeclarativeAggregate { override def children: Seq[Expression] = Seq(child, threshold) override def nullable: Boolean = false override def dataType: DataType = BooleanType private lazy val belowThreshold = AttributeReference( "belowThreshold", BooleanType, nullable = false )() override lazy val aggBufferAttributes = belowThreshold :: Nil override lazy val initialValues = Seq( Literal(false) ) override lazy val updateExpressions = Seq(Or( belowThreshold, If(IsNull(child), Literal(false), LessThan(child, threshold)) )) override lazy val mergeExpressions = Seq( Or(belowThreshold.left, belowThreshold.right) ) override lazy val evaluateExpression = belowThreshold override def defaultResult: Option[Literal] = Option(Literal(false)) }
scala> List(1,2,3) res0: List[Int] = List(1, 2, 3) scala> List(4,5,6) res1: List[Int] = List(4, 5, 6) scala> List(res0,res1) res2: List[List[Int]] = List(List(1, 2, 3), List(4, 5, 6)) scala> res2.flatten res3: List[Int] = List(1, 2, 3, 4, 5, 6)
val l = List(List(1, 2), List(3, 4)) println(l.flatMap(identity))
def flatten[A](list: List[List[A]]):List[A] = if (list.length==0) List[A]() else list.head ++ flatten(list.tail)
scala> flatten(List(List(1,2), List(3,4))) res0: List[Int] = List(1, 2, 3, 4)
def f[U](l: List[U]): List[U] = l match { case Nil => Nil case (x: List[U]) :: tail => f(x) ::: f(tail) case x :: tail => x :: f(tail) }
